{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0f25dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/tunadorable/local-repos/next-concept-predictor/venv/lib/python3.11/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a829654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db342b0",
   "metadata": {},
   "source": [
    "# regular GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b5bd74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=2\n",
    "n=5\n",
    "d=3\n",
    "v=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d35e3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S:  torch.Size([2, 5]) tensor([[0, 3, 6, 2, 6],\n",
      "        [6, 7, 1, 9, 1]])\n",
      "E:  torch.Size([10, 3]) tensor([[ 1.4142, -0.7139, -0.7003],\n",
      "        [-1.3562,  0.3310,  1.0252],\n",
      "        [-0.8545, -0.5486,  1.4031],\n",
      "        [-0.8196, -0.5883,  1.4079],\n",
      "        [-0.1093, -1.1664,  1.2757],\n",
      "        [-1.0950,  1.3226, -0.2276],\n",
      "        [ 0.9015,  0.4929, -1.3944],\n",
      "        [-1.3350,  1.0717,  0.2633],\n",
      "        [ 1.3191, -1.1010, -0.2181],\n",
      "        [-1.3979,  0.5137,  0.8842]], grad_fn=<NativeLayerNormBackward0>)\n",
      "X:  torch.Size([2, 5, 3]) tensor([[[ 1.4142, -0.7139, -0.7003],\n",
      "         [-0.8196, -0.5883,  1.4079],\n",
      "         [ 0.9015,  0.4929, -1.3944],\n",
      "         [-0.8545, -0.5486,  1.4031],\n",
      "         [ 0.9015,  0.4929, -1.3944]],\n",
      "\n",
      "        [[ 0.9015,  0.4929, -1.3944],\n",
      "         [-1.3350,  1.0717,  0.2633],\n",
      "         [-1.3562,  0.3310,  1.0252],\n",
      "         [-1.3979,  0.5137,  0.8842],\n",
      "         [-1.3562,  0.3310,  1.0252]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# create sequence & embedding matrix\n",
    "S = torch.randint(low=0, high=v, size=(b, n))\n",
    "E = torch.randn(v,d)\n",
    "\n",
    "# Create a LayerNorm instance\n",
    "layer_norm = nn.LayerNorm(d)\n",
    "\n",
    "# Apply LayerNorm to E\n",
    "E = layer_norm(E)\n",
    "\n",
    "# Look up the embeddings\n",
    "X = F.embedding(S, E)\n",
    "\n",
    "print(\"S: \", S.shape, S)\n",
    "print(\"E: \", E.shape, E)\n",
    "print(\"X: \", X.shape, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33f54e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xf:  torch.Size([2, 5, 3]) tensor([[[ 1.4142, -0.7139, -0.7003],\n",
      "         [-0.8196, -0.5883,  1.4079],\n",
      "         [ 0.9015,  0.4929, -1.3944],\n",
      "         [-0.8545, -0.5486,  1.4031],\n",
      "         [ 0.9015,  0.4929, -1.3944]],\n",
      "\n",
      "        [[ 0.9015,  0.4929, -1.3944],\n",
      "         [-1.3350,  1.0717,  0.2633],\n",
      "         [-1.3562,  0.3310,  1.0252],\n",
      "         [-1.3979,  0.5137,  0.8842],\n",
      "         [-1.3562,  0.3310,  1.0252]]], grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Apply layer normalization to X before each residual add\n",
    "Xf = layer_norm(X)\n",
    "\n",
    "print(\"Xf: \", Xf.shape, Xf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20b4cb4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z:  torch.Size([2, 5, 10]) tensor([[[ 3.0000, -2.8721, -1.7994, -1.7250, -0.2152, -2.3333,  1.8994,\n",
      "          -2.8374,  2.8043, -2.9628],\n",
      "         [-1.7250,  2.3602,  2.9986,  2.9999,  2.5718, -0.2010, -2.9920,\n",
      "           0.8344, -0.7406,  2.0884],\n",
      "         [ 1.8994, -2.4889, -2.9973, -2.9920, -2.4524, -0.0178,  3.0000,\n",
      "          -1.0423,  0.9506, -2.2398],\n",
      "         [-1.7994,  2.4158,  3.0000,  2.9985,  2.5233, -0.1092, -2.9973,\n",
      "           0.9223, -0.8293,  2.1534],\n",
      "         [ 1.8994, -2.4889, -2.9973, -2.9920, -2.4524, -0.0178,  3.0000,\n",
      "          -1.0423,  0.9506, -2.2398]],\n",
      "\n",
      "        [[ 1.8994, -2.4889, -2.9973, -2.9920, -2.4524, -0.0178,  3.0000,\n",
      "          -1.0423,  0.9506, -2.2398],\n",
      "         [-2.8374,  2.4351,  0.9223,  0.8344, -0.7682,  2.8192, -1.0423,\n",
      "           3.0000, -2.9984,  2.6495],\n",
      "         [-2.8722,  2.9999,  2.4159,  2.3602,  1.0700,  1.6895, -2.4890,\n",
      "           2.4352, -2.3771,  2.9724],\n",
      "         [-2.9629,  2.9724,  2.1534,  2.0884,  0.6816,  2.0089, -2.2399,\n",
      "           2.6496, -2.6026,  2.9999],\n",
      "         [-2.8722,  2.9999,  2.4159,  2.3602,  1.0700,  1.6895, -2.4890,\n",
      "           2.4352, -2.3771,  2.9724]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "Z = torch.matmul(Xf,E.T)\n",
    "\n",
    "print(\"Z: \", Z.shape, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "353add01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zn:  torch.Size([2, 10]) tensor([[ 1.8994, -2.4889, -2.9973, -2.9920, -2.4524, -0.0178,  3.0000, -1.0423,\n",
      "          0.9506, -2.2398],\n",
      "        [-2.8722,  2.9999,  2.4159,  2.3602,  1.0700,  1.6895, -2.4890,  2.4352,\n",
      "         -2.3771,  2.9724]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "Zn = Z[:,-1]\n",
    "print(\"Zn: \", Zn.shape, Zn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ecab99",
   "metadata": {},
   "source": [
    "### only used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92e4ecde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:  torch.Size([2, 10]) tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Generate random indices for one-hot positions\n",
    "# Each index is between 0 and v-1\n",
    "ideal_indices = torch.randint(low=0, high=v, size=(b,))\n",
    "\n",
    "# Create the one-hot matrix\n",
    "Q = torch.nn.functional.one_hot(ideal_indices, num_classes=v).float()\n",
    "\n",
    "print(\"Q: \", Q.shape, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dffd8a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.8813, grad_fn=<DivBackward1>) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# cross-entropy loss function includes within it the softmax function\n",
    "loss = torch.nn.functional.cross_entropy(Zn,Q)\n",
    "print(loss, loss.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc669d9",
   "metadata": {},
   "source": [
    "### only used for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37631b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:  torch.Size([2, 10]) tensor([[0.2151, 0.0027, 0.0016, 0.0016, 0.0028, 0.0316, 0.6465, 0.0114, 0.0833,\n",
      "         0.0034],\n",
      "        [0.0007, 0.2467, 0.1376, 0.1301, 0.0358, 0.0665, 0.0010, 0.1403, 0.0011,\n",
      "         0.2400]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor(-8.3805, grad_fn=<SumBackward1>) tensor(1.0000, grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Apply softmax along the last dimension (v)\n",
    "P = F.softmax(Zn, dim=-1)\n",
    "print(\"P: \", P.shape, P)\n",
    "print(torch.sum(Zn[0], dim=-1), torch.sum(P[0], dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9562812d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_probs:  torch.Size([2]) tensor([0.6465, 0.2467], grad_fn=<MaxBackward0>)\n",
      "indices:  torch.Size([2]) tensor([6, 1])\n"
     ]
    }
   ],
   "source": [
    "# finding tokens using greedy decoding\n",
    "max_probs, indices = torch.max(P, dim=1)\n",
    "print(\"max_probs: \", max_probs.shape, max_probs)\n",
    "print(\"indices: \", indices.shape, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f193a50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_nplus1:  torch.Size([2, 6]) tensor([[0, 3, 6, 2, 6, 6],\n",
      "        [6, 7, 1, 9, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "# appending tokens to s\n",
    "# Reshape new tokens to shape (b, 1)\n",
    "indices = indices.unsqueeze(1)  # Adds a new dimension\n",
    "\n",
    "# Concatenate the tensors\n",
    "S_nplus1 = torch.cat((S, indices), dim=1)  # Concatenate along the sequence length dimension\n",
    "print(\"S: \", S.shape, S)\n",
    "print(\"S_nplus1: \", S_nplus1.shape, S_nplus1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca48fab",
   "metadata": {},
   "source": [
    "# stage 1: implementing cosine norm, sin, & cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d383d909",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=2\n",
    "n=5\n",
    "d=3\n",
    "v=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e22eaade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S:  torch.Size([2, 5]) tensor([[9, 6, 3, 8, 9],\n",
      "        [3, 5, 1, 5, 9]])\n",
      "E:  torch.Size([10, 3]) tensor([[ 0.3874,  0.8193, -0.4228],\n",
      "        [ 0.3184,  0.3787, -0.8690],\n",
      "        [ 0.2020, -0.0501, -0.9781],\n",
      "        [-0.0085, -0.9285, -0.3712],\n",
      "        [-0.4964,  0.7818,  0.3773],\n",
      "        [-0.3545, -0.6024,  0.7152],\n",
      "        [ 0.4122, -0.5786,  0.7038],\n",
      "        [-0.3221,  0.6586,  0.6800],\n",
      "        [-0.6398, -0.7466, -0.1821],\n",
      "        [ 0.6131, -0.3634, -0.7015]])\n",
      "X:  torch.Size([2, 5, 3]) tensor([[[ 0.6131, -0.3634, -0.7015],\n",
      "         [ 0.4122, -0.5786,  0.7038],\n",
      "         [-0.0085, -0.9285, -0.3712],\n",
      "         [-0.6398, -0.7466, -0.1821],\n",
      "         [ 0.6131, -0.3634, -0.7015]],\n",
      "\n",
      "        [[-0.0085, -0.9285, -0.3712],\n",
      "         [-0.3545, -0.6024,  0.7152],\n",
      "         [ 0.3184,  0.3787, -0.8690],\n",
      "         [-0.3545, -0.6024,  0.7152],\n",
      "         [ 0.6131, -0.3634, -0.7015]]])\n"
     ]
    }
   ],
   "source": [
    "# create sequence & embedding matrix\n",
    "S = torch.randint(low=0, high=v, size=(b, n))\n",
    "E = torch.randn(v,d)\n",
    "\n",
    "# cosine norm for E\n",
    "E = E / torch.norm(E, p=2, dim=1, keepdim=True) \n",
    "\n",
    "# Look up the embeddings\n",
    "X = F.embedding(S, E)\n",
    "\n",
    "print(\"S: \", S.shape, S)\n",
    "print(\"E: \", E.shape, E)\n",
    "print(\"X: \", X.shape, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89c2e342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xi:  torch.Size([2, 5, 3]) tensor([[[ 0.9375, -0.9093, -0.8063],\n",
      "         [ 0.9622, -0.9697,  0.8020],\n",
      "         [-0.0267, -0.2227, -0.9192],\n",
      "         [-0.9051, -0.7145, -0.5415],\n",
      "         [ 0.9375, -0.9093, -0.8063]],\n",
      "\n",
      "        [[-0.0267, -0.2227, -0.9192],\n",
      "         [-0.8974, -0.9487,  0.7801],\n",
      "         [ 0.8415,  0.9283, -0.3999],\n",
      "         [-0.8974, -0.9487,  0.7801],\n",
      "         [ 0.9375, -0.9093, -0.8063]]])\n"
     ]
    }
   ],
   "source": [
    "Xi=torch.sin(torch.pi*X)\n",
    "print(\"Xi: \", Xi.shape, Xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7f3c82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norms:  torch.Size([2, 5, 1]) tensor([[[1.5349],\n",
      "         [1.5841],\n",
      "         [0.9462],\n",
      "         [1.2739],\n",
      "         [1.5349]],\n",
      "\n",
      "        [[0.9462],\n",
      "         [1.5212],\n",
      "         [1.3152],\n",
      "         [1.5212],\n",
      "         [1.5349]]])\n",
      "Xf:  torch.Size([2, 5, 3]) tensor([[[ 0.6108, -0.5924, -0.5253],\n",
      "         [ 0.6074, -0.6121,  0.5063],\n",
      "         [-0.0282, -0.2353, -0.9715],\n",
      "         [-0.7105, -0.5609, -0.4250],\n",
      "         [ 0.6108, -0.5924, -0.5253]],\n",
      "\n",
      "        [[-0.0282, -0.2353, -0.9715],\n",
      "         [-0.5899, -0.6237,  0.5128],\n",
      "         [ 0.6399,  0.7058, -0.3041],\n",
      "         [-0.5899, -0.6237,  0.5128],\n",
      "         [ 0.6108, -0.5924, -0.5253]]])\n"
     ]
    }
   ],
   "source": [
    "# Normalize each vector to have a unit length\n",
    "norms = torch.norm(Xi, p=2, dim=2, keepdim=True)\n",
    "Xf = Xi / norms\n",
    "print(\"norms: \", norms.shape, norms)\n",
    "print(\"Xf: \", Xf.shape, Xf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0707e316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each row is normalized: True\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# let's check that it worked just making sure\n",
    "\n",
    "# Calculate the L2 norm for each row in X_normalized\n",
    "norms_after_normalization = torch.norm(Xf, p=2, dim=2)\n",
    "\n",
    "# Check if each norm is approximately equal to 1\n",
    "# We use a small threshold to account for numerical precision issues\n",
    "is_normalized = torch.isclose(norms_after_normalization, torch.ones_like(norms_after_normalization), atol=1e-6)\n",
    "\n",
    "# Print the result\n",
    "print(\"Each row is normalized:\", is_normalized.all().item())\n",
    "print(norms_after_normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf144673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:  torch.Size([2, 2, 3]) tensor([[[-2.2603e-01, -8.0982e-04,  2.1220e-01],\n",
      "         [-9.4865e-01,  1.6137e+00,  2.4947e+00]],\n",
      "\n",
      "        [[-4.0640e-01,  3.2881e-01,  6.7619e-01],\n",
      "         [-1.3375e+00,  3.1127e-01,  1.9917e+00]]])\n"
     ]
    }
   ],
   "source": [
    "W = torch.randn(b,n)\n",
    "C = torch.matmul(W,Xf)\n",
    "print(\"C: \", C.shape, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f293a45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_select:  torch.Size([2, 3]) tensor([[-0.4064,  0.3288,  0.6762],\n",
      "        [-1.3375,  0.3113,  1.9917]])\n",
      "C_norms:  torch.Size([2, 1]) tensor([[0.8547],\n",
      "        [2.4192]])\n",
      "C_prime:  torch.Size([2, 3]) tensor([[-0.4755,  0.3847,  0.7911],\n",
      "        [-0.5529,  0.1287,  0.8233]])\n"
     ]
    }
   ],
   "source": [
    "# Normalize each vector to have a unit length & select only final row\n",
    "C_select = C[-1]\n",
    "print(\"C_select: \", C_select.shape, C_select)\n",
    "\n",
    "C_norms = torch.norm(C_select, p=2, dim=1, keepdim=True)\n",
    "print(\"C_norms: \", C_norms.shape, C_norms)\n",
    "\n",
    "C_prime = C_select / C_norms\n",
    "print(\"C_prime: \", C_prime.shape, C_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ca90781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E.T:  torch.Size([3, 10]) tensor([[ 0.3874,  0.3184,  0.2020, -0.0085, -0.4964, -0.3545,  0.4122, -0.3221,\n",
      "         -0.6398,  0.6131],\n",
      "        [ 0.8193,  0.3787, -0.0501, -0.9285,  0.7818, -0.6024, -0.5786,  0.6586,\n",
      "         -0.7466, -0.3634],\n",
      "        [-0.4228, -0.8690, -0.9781, -0.3712,  0.3773,  0.7152,  0.7038,  0.6800,\n",
      "         -0.1821, -0.7015]])\n",
      "Y:  torch.Size([2, 10]) tensor([[-0.2035, -0.6932, -0.8891, -0.6468,  0.8353,  0.5026,  0.1382,  0.9446,\n",
      "         -0.1271, -0.9863],\n",
      "        [-0.4568, -0.8428, -0.9234, -0.4204,  0.6857,  0.7073,  0.2771,  0.8227,\n",
      "          0.1077, -0.9632]])\n",
      "Y Max: tensor([0.9446, 0.8227])\n",
      "Y Min: tensor([-0.9863, -0.9632])\n",
      "Y Mean: tensor([-0.1125, -0.1006])\n"
     ]
    }
   ],
   "source": [
    "# Perform cosine similarity, which simplifies down to dot product\n",
    "# We transpose E to get shape (d, v) and then use torch.matmul for batched matrix multiplication\n",
    "Y = torch.matmul(C_prime, E.T)\n",
    "print(\"E.T: \", E.T.shape, E.T)\n",
    "print(\"Y: \", Y.shape, Y)\n",
    "\n",
    "# let's make sure Y looks good\n",
    "# Calculating statistics\n",
    "max_values = torch.max(Y, dim=1).values\n",
    "min_values = torch.min(Y, dim=1).values\n",
    "mean_values = torch.mean(Y, dim=1)\n",
    "median_values = torch.median(Y, dim=1).values\n",
    "\n",
    "print(\"Y Max:\", max_values)\n",
    "print(\"Y Min:\", min_values)\n",
    "print(\"Y Mean:\", mean_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e668d114",
   "metadata": {},
   "source": [
    "### only used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c7301d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:  torch.Size([2, 10]) tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Generate random indices for one-hot positions\n",
    "# Each index is between 0 and v-1\n",
    "ideal_indices = torch.randint(low=0, high=v, size=(b,))\n",
    "\n",
    "# Create the one-hot matrix\n",
    "Q = torch.nn.functional.one_hot(ideal_indices, num_classes=v).float()\n",
    "\n",
    "print(\"Q: \", Q.shape, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dbb0877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_prime_ideal:  torch.Size([2, 3]) tensor([[ 0.3874,  0.8193, -0.4228],\n",
      "        [-0.3221,  0.6586,  0.6800]])\n"
     ]
    }
   ],
   "source": [
    "C_prime_ideal = torch.matmul(Q,E)\n",
    "print(\"C_prime_ideal: \", C_prime_ideal.shape, C_prime_ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1d0ebf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ytrain:  torch.Size([2, 10]) tensor([[ 1.0000,  0.8010,  0.4508, -0.6071,  0.2887, -0.9332, -0.6119,  0.1273,\n",
      "         -0.7826,  0.2363],\n",
      "        [ 0.1273, -0.4441, -0.7632, -0.8612,  0.9314,  0.2038, -0.0353,  1.0000,\n",
      "         -0.4095, -0.9139]])\n"
     ]
    }
   ],
   "source": [
    "Ytrain = torch.matmul(C_prime_ideal,E.T)\n",
    "print(\"Ytrain: \", Ytrain.shape, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f48ec4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.8061) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# cross-entropy loss function includes within it the softmax function\n",
    "loss = torch.nn.functional.cross_entropy(Y,Ytrain)\n",
    "print(loss, loss.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90c9032",
   "metadata": {},
   "source": [
    "### only used for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03258830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:  torch.Size([2, 10]) tensor([[0.0730, 0.0447, 0.0368, 0.0468, 0.2062, 0.1478, 0.1027, 0.2300, 0.0788,\n",
      "         0.0334],\n",
      "        [0.0564, 0.0384, 0.0354, 0.0585, 0.1769, 0.1807, 0.1176, 0.2029, 0.0992,\n",
      "         0.0340]])\n",
      "tensor(-1.1254) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Apply softmax along the last dimension (v)\n",
    "P = F.softmax(Y, dim=-1)\n",
    "print(\"P: \", P.shape, P)\n",
    "print(torch.sum(Y[0], dim=-1), torch.sum(P[0], dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06b61dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max probs:  torch.Size([2]) tensor([0.2300, 0.2029])\n",
      "indices:  torch.Size([2]) tensor([7, 7])\n"
     ]
    }
   ],
   "source": [
    "# finding tokens using greedy decoding\n",
    "max_probs, indices = torch.max(P, dim=1)\n",
    "print(\"max probs: \", max_probs.shape, max_probs)\n",
    "print(\"indices: \", indices.shape, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdc14eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S:  torch.Size([2, 5]) tensor([[9, 6, 3, 8, 9],\n",
      "        [3, 5, 1, 5, 9]])\n",
      "S_nplus1:  torch.Size([2, 6]) tensor([[9, 6, 3, 8, 9, 7],\n",
      "        [3, 5, 1, 5, 9, 7]])\n"
     ]
    }
   ],
   "source": [
    "# appending tokens to s\n",
    "# Reshape new tokens to shape (b, 1)\n",
    "indices = indices.unsqueeze(1)  # Adds a new dimension\n",
    "\n",
    "# Concatenate the tensors\n",
    "S_nplus1 = torch.cat((S, indices), dim=1)  # Concatenate along the sequence length dimension\n",
    "print(\"S: \", S.shape, S)\n",
    "print(\"S_nplus1: \", S_nplus1.shape, S_nplus1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b3883a",
   "metadata": {},
   "source": [
    "# stage 2: implementing gamma-neighborhood selection and in-sequence concept embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a096bc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=2\n",
    "n=5\n",
    "d=3\n",
    "v=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dcb8994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S:  torch.Size([2, 5]) tensor([[0, 5, 3, 2, 3],\n",
      "        [8, 6, 6, 6, 5]])\n",
      "E:  torch.Size([10, 3]) tensor([[ 0.1426,  0.6498, -0.7466],\n",
      "        [ 0.1734, -0.0236,  0.9846],\n",
      "        [ 0.1370,  0.5486, -0.8248],\n",
      "        [-0.9660,  0.1084, -0.2348],\n",
      "        [-0.8671,  0.4975, -0.0267],\n",
      "        [-0.8485,  0.5243,  0.0723],\n",
      "        [-0.8571, -0.3588, -0.3697],\n",
      "        [ 0.4360,  0.4518,  0.7783],\n",
      "        [ 0.7900, -0.5789, -0.2020],\n",
      "        [-0.9899, -0.0675,  0.1247]])\n",
      "X:  torch.Size([2, 5, 3]) tensor([[[ 0.1426,  0.6498, -0.7466],\n",
      "         [-0.8485,  0.5243,  0.0723],\n",
      "         [-0.9660,  0.1084, -0.2348],\n",
      "         [ 0.1370,  0.5486, -0.8248],\n",
      "         [-0.9660,  0.1084, -0.2348]],\n",
      "\n",
      "        [[ 0.7900, -0.5789, -0.2020],\n",
      "         [-0.8571, -0.3588, -0.3697],\n",
      "         [-0.8571, -0.3588, -0.3697],\n",
      "         [-0.8571, -0.3588, -0.3697],\n",
      "         [-0.8485,  0.5243,  0.0723]]])\n"
     ]
    }
   ],
   "source": [
    "# create sequence & embedding matrix\n",
    "S = torch.randint(low=0, high=v, size=(b, n))\n",
    "E = torch.randn(v,d)\n",
    "\n",
    "# cosine norm for E\n",
    "E = E / torch.norm(E, p=2, dim=1, keepdim=True) \n",
    "\n",
    "# Look up the embeddings\n",
    "X = F.embedding(S, E)\n",
    "\n",
    "print(\"S: \", S.shape, S)\n",
    "print(\"E: \", E.shape, E)\n",
    "print(\"X: \", X.shape, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d67bdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xi:  torch.Size([2, 5, 3]) tensor([[[ 0.4332,  0.8913, -0.7146],\n",
      "         [-0.4582,  0.9971,  0.2252],\n",
      "         [-0.1066,  0.3340, -0.6725],\n",
      "         [ 0.4172,  0.9884, -0.5230],\n",
      "         [-0.1066,  0.3340, -0.6725]],\n",
      "\n",
      "        [[ 0.6130, -0.9694, -0.5929],\n",
      "         [-0.4340, -0.9032, -0.9173],\n",
      "         [-0.4340, -0.9032, -0.9173],\n",
      "         [-0.4340, -0.9032, -0.9173],\n",
      "         [-0.4582,  0.9971,  0.2252]]])\n"
     ]
    }
   ],
   "source": [
    "Xi=torch.sin(torch.pi*X)\n",
    "print(\"Xi: \", Xi.shape, Xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b53a71b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norms:  torch.Size([2, 5, 1]) tensor([[[1.2218],\n",
      "         [1.1202],\n",
      "         [0.7584],\n",
      "         [1.1935],\n",
      "         [0.7584]],\n",
      "\n",
      "        [[1.2911],\n",
      "         [1.3585],\n",
      "         [1.3585],\n",
      "         [1.3585],\n",
      "         [1.1202]]])\n",
      "Xf:  torch.Size([2, 5, 3]) tensor([[[ 0.3546,  0.7295, -0.5849],\n",
      "         [-0.4091,  0.8901,  0.2010],\n",
      "         [-0.1406,  0.4405, -0.8867],\n",
      "         [ 0.3495,  0.8281, -0.4382],\n",
      "         [-0.1406,  0.4405, -0.8867]],\n",
      "\n",
      "        [[ 0.4748, -0.7508, -0.4592],\n",
      "         [-0.3194, -0.6648, -0.6752],\n",
      "         [-0.3194, -0.6648, -0.6752],\n",
      "         [-0.3194, -0.6648, -0.6752],\n",
      "         [-0.4091,  0.8901,  0.2010]]])\n"
     ]
    }
   ],
   "source": [
    "# Normalize each vector to have a unit length\n",
    "norms = torch.norm(Xi, p=2, dim=2, keepdim=True)\n",
    "Xf = Xi / norms\n",
    "print(\"norms: \", norms.shape, norms)\n",
    "print(\"Xf: \", Xf.shape, Xf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fdda332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:  torch.Size([2, 2, 3]) tensor([[[ 1.6358,  1.5518, -1.9061],\n",
      "         [ 0.5572,  0.5265,  0.0051]],\n",
      "\n",
      "        [[-0.3182, -0.1825, -0.5950],\n",
      "         [ 1.0588, -0.5280, -0.0264]]])\n"
     ]
    }
   ],
   "source": [
    "W = torch.randn(b,n)\n",
    "C = torch.matmul(W,Xf)\n",
    "print(\"C: \", C.shape, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d119d9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_last: torch.Size([2, 3]) tensor([[-0.3182, -0.1825, -0.5950],\n",
      "        [ 1.0588, -0.5280, -0.0264]])\n",
      "C_last_norms: torch.Size([2, 1]) tensor([[0.6990],\n",
      "        [1.1835]])\n",
      "C_prime torch.Size([2, 3]) tensor([[-0.4552, -0.2610, -0.8513],\n",
      "        [ 0.8947, -0.4462, -0.0223]])\n"
     ]
    }
   ],
   "source": [
    "# Normalize each vector to have a unit length & select only final row\n",
    "C_last = C[-1]\n",
    "C_last_norms = torch.norm(C_last, p=2, dim=1, keepdim=True)\n",
    "C_prime = C_last / C_last_norms\n",
    "\n",
    "print(\"C_last:\", C_last.shape, C_last)\n",
    "print(\"C_last_norms:\", C_last_norms.shape, C_last_norms)\n",
    "print(\"C_prime\", C_prime.shape, C_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c45d20bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E.T:  torch.Size([3, 10]) tensor([[ 0.1426,  0.1734,  0.1370, -0.9660, -0.8671, -0.8485, -0.8571,  0.4360,\n",
      "          0.7900, -0.9899],\n",
      "        [ 0.6498, -0.0236,  0.5486,  0.1084,  0.4975,  0.5243, -0.3588,  0.4518,\n",
      "         -0.5789, -0.0675],\n",
      "        [-0.7466,  0.9846, -0.8248, -0.2348, -0.0267,  0.0723, -0.3697,  0.7783,\n",
      "         -0.2020,  0.1247]])\n",
      "Y:  torch.Size([2, 10]) tensor([[ 0.4010, -0.9109,  0.4966,  0.6113,  0.2876,  0.1878,  0.7985, -0.9790,\n",
      "         -0.0365,  0.3621],\n",
      "        [-0.1457,  0.1437, -0.1038, -0.9074, -0.9971, -0.9946, -0.5985,  0.1712,\n",
      "          0.9695, -0.8583]])\n",
      "Y Max: tensor([0.7985, 0.9695])\n",
      "Y Min: tensor([-0.9790, -0.9971])\n",
      "Y Mean: tensor([ 0.1218, -0.3321])\n"
     ]
    }
   ],
   "source": [
    "# Perform cosine similarity, which simplifies down to dot product\n",
    "# We transpose E to get shape (d, v) and then use torch.matmul for batched matrix multiplication\n",
    "Y = torch.matmul(C_prime, E.T)\n",
    "print(\"E.T: \", E.T.shape, E.T)\n",
    "print(\"Y: \", Y.shape, Y)\n",
    "\n",
    "# let's make sure Y looks good\n",
    "# Calculating statistics\n",
    "max_values = torch.max(Y, dim=1).values\n",
    "min_values = torch.min(Y, dim=1).values\n",
    "mean_values = torch.mean(Y, dim=1)\n",
    "median_values = torch.median(Y, dim=1).values\n",
    "\n",
    "# Printing the results\n",
    "print(\"Y Max:\", max_values)\n",
    "print(\"Y Min:\", min_values)\n",
    "print(\"Y Mean:\", mean_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25587e20",
   "metadata": {},
   "source": [
    "### the conditional parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc47a685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:  torch.Size([2]) tensor([0.7985, 0.9695])\n",
      "H:  torch.Size([2]) tensor([6, 8])\n"
     ]
    }
   ],
   "source": [
    "# finding closest tokens to the raw output & their similarity scores\n",
    "G, H = torch.max(Y, dim=1)\n",
    "print(\"G: \", G.shape, G)\n",
    "print(\"H: \", H.shape, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36978b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.91 # $-1\\leq \\gamma < 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8d6500a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:  torch.float32 torch.Size([2]) tensor([0., 1.])\n"
     ]
    }
   ],
   "source": [
    "A = (G > gamma).float()\n",
    "print(\"A: \", A.dtype, A.shape, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d902aa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_unsqueeze:  torch.Size([2, 1]) tensor([[0.],\n",
      "        [1.]])\n",
      "A_expanded:  torch.Size([2, 10]) tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "A_unsqueeze = A.unsqueeze(1)\n",
    "print(\"A_unsqueeze: \", A_unsqueeze.shape, A_unsqueeze)\n",
    "A_expand = A_unsqueeze.expand(-1, v)\n",
    "print(\"A_expanded: \", A_expand.shape, A_expand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e1186c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I:  torch.float32 torch.Size([2, 10]) tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "A_prime_expand:  torch.float32 torch.Size([2, 10]) tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "I = torch.ones(b,v).float()\n",
    "print(\"I: \", I.dtype, I.shape, I)\n",
    "A_prime_expand = I-A_expand\n",
    "print(\"A_prime_expand: \", A_prime_expand.dtype, A_prime_expand.shape, A_prime_expand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a07b9a5",
   "metadata": {},
   "source": [
    "### only used for trainnig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ebb58dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ideal_indices:  torch.Size([2]) tensor([9, 9])\n",
      "Q:  torch.float32 torch.Size([2, 10]) tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Generate random indices for one-hot positions\n",
    "# Each index is between 0 and v-1\n",
    "ideal_indices = torch.randint(low=0, high=v, size=(b,))\n",
    "print(\"ideal_indices: \", ideal_indices.shape, ideal_indices)\n",
    "\n",
    "# Create the one-hot matrix\n",
    "Q = torch.nn.functional.one_hot(ideal_indices, num_classes=v).float()\n",
    "\n",
    "print(\"Q: \", Q.dtype, Q.shape, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32c24ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_prime_ideal:  torch.Size([2, 3]) tensor([[-0.9899, -0.0675,  0.1247],\n",
      "        [-0.9899, -0.0675,  0.1247]])\n"
     ]
    }
   ],
   "source": [
    "# the ideal C_ to receive according to Q\n",
    "C_prime_ideal = torch.matmul(Q, E)\n",
    "print(\"C_prime_ideal: \", C_prime_ideal.shape, C_prime_ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6e457f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_ideal:  torch.Size([2, 10]) tensor([[-0.2781, -0.0473, -0.2755,  0.9196,  0.8214,  0.8135,  0.8266, -0.3651,\n",
      "         -0.7681,  1.0000],\n",
      "        [-0.2781, -0.0473, -0.2755,  0.9196,  0.8214,  0.8135,  0.8266, -0.3651,\n",
      "         -0.7681,  1.0000]])\n"
     ]
    }
   ],
   "source": [
    "# the ideal cosine similarities to receive according to Q\n",
    "Y_ideal = torch.matmul(C_prime_ideal, E.T)\n",
    "print(\"Y_ideal: \", Y_ideal.shape, Y_ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d1ac333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_prime_ideal:  torch.Size([2, 10]) tensor([[-0.0000, -0.0000, -0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000,\n",
      "         -0.0000,  0.0000],\n",
      "        [-0.2781, -0.0473, -0.2755,  0.9196,  0.8214,  0.8135,  0.8266, -0.3651,\n",
      "         -0.7681,  1.0000]])\n"
     ]
    }
   ],
   "source": [
    "Y_prime_ideal = Y_ideal*A_expand\n",
    "print(\"Y_prime_ideal: \", Y_prime_ideal.shape, Y_prime_ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd926da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_concepts:  torch.Size([2, 10]) tensor([[ 0.4010, -0.9109,  0.4966,  0.6113,  0.2876,  0.1878,  0.7985, -0.9790,\n",
      "         -0.0365,  0.3621],\n",
      "        [-0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
      "          0.0000, -0.0000]])\n"
     ]
    }
   ],
   "source": [
    "Y_concepts = Y*A_prime_expand\n",
    "print(\"Y_concepts: \", Y_concepts.shape, Y_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67d352e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train:  torch.Size([2, 10]) tensor([[ 0.4010, -0.9109,  0.4966,  0.6113,  0.2876,  0.1878,  0.7985, -0.9790,\n",
      "         -0.0365,  0.3621],\n",
      "        [-0.2781, -0.0473, -0.2755,  0.9196,  0.8214,  0.8135,  0.8266, -0.3651,\n",
      "         -0.7681,  1.0000]])\n"
     ]
    }
   ],
   "source": [
    "Y_train = Y_concepts + Y_prime_ideal\n",
    "print(\"Y_train: \", Y_train.shape, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a19be14",
   "metadata": {},
   "source": [
    "### only used for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab7225f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:  torch.Size([2, 10]) tensor([[0.1156, 0.0311, 0.1272, 0.1426, 0.1032, 0.0934, 0.1720, 0.0291, 0.0746,\n",
      "         0.1112],\n",
      "        [0.0976, 0.1303, 0.1017, 0.0456, 0.0416, 0.0417, 0.0620, 0.1339, 0.2976,\n",
      "         0.0478]])\n",
      "tensor(1.2185) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Apply softmax along the last dimension (v)\n",
    "P = F.softmax(Y, dim=-1)\n",
    "print(\"P: \", P.shape, P)\n",
    "print(torch.sum(Y[0], dim=-1), torch.sum(P[0], dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "379a5cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_inf:  torch.Size([2, 10]) tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0976, 0.1303, 0.1017, 0.0456, 0.0416, 0.0417, 0.0620, 0.1339, 0.2976,\n",
      "         0.0478]])\n"
     ]
    }
   ],
   "source": [
    "P_inf = P*A_expand\n",
    "print(\"P_inf: \", P_inf.shape, P_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5211ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_nplus1_vals:  torch.Size([2]) tensor([0.0000, 0.2976])\n",
      "S_nplus1_ind:  torch.Size([2]) tensor([0, 8])\n"
     ]
    }
   ],
   "source": [
    "S_nplus1_vals, S_nplus1_ind = torch.max(P_inf, dim=1)\n",
    "print(\"S_nplus1_vals: \", S_nplus1_vals.shape, S_nplus1_vals)\n",
    "print(\"S_nplus1_ind: \", S_nplus1_ind.shape, S_nplus1_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7972e3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_nplus1:  torch.Size([2]) tensor([-1,  8])\n"
     ]
    }
   ],
   "source": [
    "# Create a mask where tensor1 is not zero\n",
    "mask = S_nplus1_vals != 0\n",
    "\n",
    "# Initialize result tensor with a placeholder value\n",
    "S_nplus1 = torch.full(S_nplus1_ind.shape, fill_value=-1, dtype=S_nplus1_ind.dtype)\n",
    "\n",
    "# Assign values from tensor2 to result where mask is True\n",
    "S_nplus1[mask] = S_nplus1_ind[mask]\n",
    "\n",
    "print(\"S_nplus1: \", S_nplus1.shape, S_nplus1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b33aa0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon:  torch.Size([1, 3]) tensor([[0., 0., 0.]])\n",
      "E_prime:  torch.Size([11, 3]) tensor([[ 0.1426,  0.6498, -0.7466],\n",
      "        [ 0.1734, -0.0236,  0.9846],\n",
      "        [ 0.1370,  0.5486, -0.8248],\n",
      "        [-0.9660,  0.1084, -0.2348],\n",
      "        [-0.8671,  0.4975, -0.0267],\n",
      "        [-0.8485,  0.5243,  0.0723],\n",
      "        [-0.8571, -0.3588, -0.3697],\n",
      "        [ 0.4360,  0.4518,  0.7783],\n",
      "        [ 0.7900, -0.5789, -0.2020],\n",
      "        [-0.9899, -0.0675,  0.1247],\n",
      "        [ 0.0000,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "epsilon = torch.zeros(1,d)\n",
    "print(\"epsilon: \", epsilon.shape, epsilon)\n",
    "E_prime = torch.cat((E,epsilon), dim=0)\n",
    "print(\"E_prime: \", E_prime.shape, E_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9bd4897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z:  torch.Size([2, 3]) tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.7900, -0.5789, -0.2020]])\n"
     ]
    }
   ],
   "source": [
    "Z = E_prime[S_nplus1]\n",
    "print(\"Z: \", Z.shape, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "037abc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_prime_concept:  torch.Size([2, 3]) tensor([[-0.4552, -0.2610, -0.8513],\n",
      "        [ 0.0000, -0.0000, -0.0000]])\n"
     ]
    }
   ],
   "source": [
    "C_prime_concept = C_prime*A_prime_expand[:,0:d]\n",
    "print(\"C_prime_concept: \", C_prime_concept.shape, C_prime_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c082c554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z_prime:  torch.Size([2, 3]) tensor([[-0.4552, -0.2610, -0.8513],\n",
      "        [ 0.7900, -0.5789, -0.2020]])\n"
     ]
    }
   ],
   "source": [
    "Z_prime = Z + C_prime_concept\n",
    "print(\"Z_prime: \", Z_prime.shape, Z_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6594e940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  torch.Size([2, 5, 3]) tensor([[[ 0.1426,  0.6498, -0.7466],\n",
      "         [-0.8485,  0.5243,  0.0723],\n",
      "         [-0.9660,  0.1084, -0.2348],\n",
      "         [ 0.1370,  0.5486, -0.8248],\n",
      "         [-0.9660,  0.1084, -0.2348]],\n",
      "\n",
      "        [[ 0.7900, -0.5789, -0.2020],\n",
      "         [-0.8571, -0.3588, -0.3697],\n",
      "         [-0.8571, -0.3588, -0.3697],\n",
      "         [-0.8571, -0.3588, -0.3697],\n",
      "         [-0.8485,  0.5243,  0.0723]]])\n",
      "X_new:  torch.Size([2, 6, 3]) tensor([[[ 0.1426,  0.6498, -0.7466],\n",
      "         [-0.8485,  0.5243,  0.0723],\n",
      "         [-0.9660,  0.1084, -0.2348],\n",
      "         [ 0.1370,  0.5486, -0.8248],\n",
      "         [-0.9660,  0.1084, -0.2348],\n",
      "         [-0.4552, -0.2610, -0.8513]],\n",
      "\n",
      "        [[ 0.7900, -0.5789, -0.2020],\n",
      "         [-0.8571, -0.3588, -0.3697],\n",
      "         [-0.8571, -0.3588, -0.3697],\n",
      "         [-0.8571, -0.3588, -0.3697],\n",
      "         [-0.8485,  0.5243,  0.0723],\n",
      "         [ 0.7900, -0.5789, -0.2020]]])\n"
     ]
    }
   ],
   "source": [
    "print(\"X: \", X.shape, X)\n",
    "X_new = torch.cat((X,Z_prime.unsqueeze(1)), dim=1)\n",
    "print(\"X_new: \", X_new.shape, X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3b8a89",
   "metadata": {},
   "source": [
    "## change in gamma over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "855a8337",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_00 = -1\n",
    "gamma_f0 = -1\n",
    "gamma_0f = 0.8\n",
    "gamma_ff = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "799def73",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6 # sequence length\n",
    "m = 9 # num of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3db4e937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n"
     ]
    }
   ],
   "source": [
    "delta_gamma_m = (gamma_0f - gamma_00)/m\n",
    "print(delta_gamma_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4eaf9778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This epoch, to become a token a concept needs cos similarity at least gamma_0,0 = -1.00\n",
      "\tAt the 1'th token in this sequence, gamma_0,0 = -1.00\n",
      "\tAt the 2'th token in this sequence, gamma_1,0 = -1.00\n",
      "\tAt the 3'th token in this sequence, gamma_2,0 = -1.00\n",
      "\tAt the 4'th token in this sequence, gamma_3,0 = -1.00\n",
      "\tAt the 5'th token in this sequence, gamma_4,0 = -1.00\n",
      "\tAt the 6'th token in this sequence, gamma_5,0 = -1.00\n",
      "\tAt the 7'th token in this sequence, gamma_6,0 = -1.00\n",
      "\tAt the 8'th token in this sequence, gamma_7,0 = -1.00\n",
      "\tAt the 9'th token in this sequence, gamma_8,0 = -1.00\n",
      "\tAt the 10'th token in this sequence, gamma_9,0 = -1.00\n",
      "\tAt the 11'th token in this sequence, gamma_10,0 = -1.00\n",
      "\tAt the 12'th token in this sequence, gamma_11,0 = -1.00\n",
      "This epoch, to become a token a concept needs cos similarity at least gamma_0,1 = -0.80\n",
      "\tAt the 1'th token in this sequence, gamma_0,1 = -0.80\n",
      "\tAt the 2'th token in this sequence, gamma_1,1 = -0.83\n",
      "\tAt the 3'th token in this sequence, gamma_2,1 = -0.87\n",
      "\tAt the 4'th token in this sequence, gamma_3,1 = -0.90\n",
      "\tAt the 5'th token in this sequence, gamma_4,1 = -0.93\n",
      "\tAt the 6'th token in this sequence, gamma_5,1 = -0.97\n",
      "\tAt the 7'th token in this sequence, gamma_6,1 = -1.00\n",
      "\tAt the 8'th token in this sequence, gamma_7,1 = -1.00\n",
      "\tAt the 9'th token in this sequence, gamma_8,1 = -1.00\n",
      "\tAt the 10'th token in this sequence, gamma_9,1 = -1.00\n",
      "\tAt the 11'th token in this sequence, gamma_10,1 = -1.00\n",
      "\tAt the 12'th token in this sequence, gamma_11,1 = -1.00\n",
      "This epoch, to become a token a concept needs cos similarity at least gamma_0,2 = -0.60\n",
      "\tAt the 1'th token in this sequence, gamma_0,2 = -0.60\n",
      "\tAt the 2'th token in this sequence, gamma_1,2 = -0.67\n",
      "\tAt the 3'th token in this sequence, gamma_2,2 = -0.73\n",
      "\tAt the 4'th token in this sequence, gamma_3,2 = -0.80\n",
      "\tAt the 5'th token in this sequence, gamma_4,2 = -0.87\n",
      "\tAt the 6'th token in this sequence, gamma_5,2 = -0.93\n",
      "\tAt the 7'th token in this sequence, gamma_6,2 = -1.00\n",
      "\tAt the 8'th token in this sequence, gamma_7,2 = -1.00\n",
      "\tAt the 9'th token in this sequence, gamma_8,2 = -1.00\n",
      "\tAt the 10'th token in this sequence, gamma_9,2 = -1.00\n",
      "\tAt the 11'th token in this sequence, gamma_10,2 = -1.00\n",
      "\tAt the 12'th token in this sequence, gamma_11,2 = -1.00\n",
      "This epoch, to become a token a concept needs cos similarity at least gamma_0,3 = -0.40\n",
      "\tAt the 1'th token in this sequence, gamma_0,3 = -0.40\n",
      "\tAt the 2'th token in this sequence, gamma_1,3 = -0.50\n",
      "\tAt the 3'th token in this sequence, gamma_2,3 = -0.60\n",
      "\tAt the 4'th token in this sequence, gamma_3,3 = -0.70\n",
      "\tAt the 5'th token in this sequence, gamma_4,3 = -0.80\n",
      "\tAt the 6'th token in this sequence, gamma_5,3 = -0.90\n",
      "\tAt the 7'th token in this sequence, gamma_6,3 = -1.00\n",
      "\tAt the 8'th token in this sequence, gamma_7,3 = -1.00\n",
      "\tAt the 9'th token in this sequence, gamma_8,3 = -1.00\n",
      "\tAt the 10'th token in this sequence, gamma_9,3 = -1.00\n",
      "\tAt the 11'th token in this sequence, gamma_10,3 = -1.00\n",
      "\tAt the 12'th token in this sequence, gamma_11,3 = -1.00\n",
      "This epoch, to become a token a concept needs cos similarity at least gamma_0,4 = -0.20\n",
      "\tAt the 1'th token in this sequence, gamma_0,4 = -0.20\n",
      "\tAt the 2'th token in this sequence, gamma_1,4 = -0.33\n",
      "\tAt the 3'th token in this sequence, gamma_2,4 = -0.47\n",
      "\tAt the 4'th token in this sequence, gamma_3,4 = -0.60\n",
      "\tAt the 5'th token in this sequence, gamma_4,4 = -0.73\n",
      "\tAt the 6'th token in this sequence, gamma_5,4 = -0.87\n",
      "\tAt the 7'th token in this sequence, gamma_6,4 = -1.00\n",
      "\tAt the 8'th token in this sequence, gamma_7,4 = -1.00\n",
      "\tAt the 9'th token in this sequence, gamma_8,4 = -1.00\n",
      "\tAt the 10'th token in this sequence, gamma_9,4 = -1.00\n",
      "\tAt the 11'th token in this sequence, gamma_10,4 = -1.00\n",
      "\tAt the 12'th token in this sequence, gamma_11,4 = -1.00\n",
      "This epoch, to become a token a concept needs cos similarity at least gamma_0,5 = 0.00\n",
      "\tAt the 1'th token in this sequence, gamma_0,5 = 0.00\n",
      "\tAt the 2'th token in this sequence, gamma_1,5 = -0.17\n",
      "\tAt the 3'th token in this sequence, gamma_2,5 = -0.33\n",
      "\tAt the 4'th token in this sequence, gamma_3,5 = -0.50\n",
      "\tAt the 5'th token in this sequence, gamma_4,5 = -0.67\n",
      "\tAt the 6'th token in this sequence, gamma_5,5 = -0.83\n",
      "\tAt the 7'th token in this sequence, gamma_6,5 = -1.00\n",
      "\tAt the 8'th token in this sequence, gamma_7,5 = -1.00\n",
      "\tAt the 9'th token in this sequence, gamma_8,5 = -1.00\n",
      "\tAt the 10'th token in this sequence, gamma_9,5 = -1.00\n",
      "\tAt the 11'th token in this sequence, gamma_10,5 = -1.00\n",
      "\tAt the 12'th token in this sequence, gamma_11,5 = -1.00\n",
      "This epoch, to become a token a concept needs cos similarity at least gamma_0,6 = 0.20\n",
      "\tAt the 1'th token in this sequence, gamma_0,6 = 0.20\n",
      "\tAt the 2'th token in this sequence, gamma_1,6 = 0.00\n",
      "\tAt the 3'th token in this sequence, gamma_2,6 = -0.20\n",
      "\tAt the 4'th token in this sequence, gamma_3,6 = -0.40\n",
      "\tAt the 5'th token in this sequence, gamma_4,6 = -0.60\n",
      "\tAt the 6'th token in this sequence, gamma_5,6 = -0.80\n",
      "\tAt the 7'th token in this sequence, gamma_6,6 = -1.00\n",
      "\tAt the 8'th token in this sequence, gamma_7,6 = -1.00\n",
      "\tAt the 9'th token in this sequence, gamma_8,6 = -1.00\n",
      "\tAt the 10'th token in this sequence, gamma_9,6 = -1.00\n",
      "\tAt the 11'th token in this sequence, gamma_10,6 = -1.00\n",
      "\tAt the 12'th token in this sequence, gamma_11,6 = -1.00\n",
      "This epoch, to become a token a concept needs cos similarity at least gamma_0,7 = 0.40\n",
      "\tAt the 1'th token in this sequence, gamma_0,7 = 0.40\n",
      "\tAt the 2'th token in this sequence, gamma_1,7 = 0.17\n",
      "\tAt the 3'th token in this sequence, gamma_2,7 = -0.07\n",
      "\tAt the 4'th token in this sequence, gamma_3,7 = -0.30\n",
      "\tAt the 5'th token in this sequence, gamma_4,7 = -0.53\n",
      "\tAt the 6'th token in this sequence, gamma_5,7 = -0.77\n",
      "\tAt the 7'th token in this sequence, gamma_6,7 = -1.00\n",
      "\tAt the 8'th token in this sequence, gamma_7,7 = -1.00\n",
      "\tAt the 9'th token in this sequence, gamma_8,7 = -1.00\n",
      "\tAt the 10'th token in this sequence, gamma_9,7 = -1.00\n",
      "\tAt the 11'th token in this sequence, gamma_10,7 = -1.00\n",
      "\tAt the 12'th token in this sequence, gamma_11,7 = -1.00\n",
      "This epoch, to become a token a concept needs cos similarity at least gamma_0,8 = 0.60\n",
      "\tAt the 1'th token in this sequence, gamma_0,8 = 0.60\n",
      "\tAt the 2'th token in this sequence, gamma_1,8 = 0.33\n",
      "\tAt the 3'th token in this sequence, gamma_2,8 = 0.07\n",
      "\tAt the 4'th token in this sequence, gamma_3,8 = -0.20\n",
      "\tAt the 5'th token in this sequence, gamma_4,8 = -0.47\n",
      "\tAt the 6'th token in this sequence, gamma_5,8 = -0.73\n",
      "\tAt the 7'th token in this sequence, gamma_6,8 = -1.00\n",
      "\tAt the 8'th token in this sequence, gamma_7,8 = -1.00\n",
      "\tAt the 9'th token in this sequence, gamma_8,8 = -1.00\n",
      "\tAt the 10'th token in this sequence, gamma_9,8 = -1.00\n",
      "\tAt the 11'th token in this sequence, gamma_10,8 = -1.00\n",
      "\tAt the 12'th token in this sequence, gamma_11,8 = -1.00\n"
     ]
    }
   ],
   "source": [
    "for i in range(m):\n",
    "    gamma_i = gamma_00 + i*delta_gamma_m\n",
    "    print(f\"This epoch, to become a token a concept needs cos similarity at least gamma_0,{i} = {gamma_i:.2f}\")\n",
    "    \n",
    "    delta_gamma_n = (gamma_i - gamma_ff)/n\n",
    "    for j in range(2*n):\n",
    "        \n",
    "        print(f\"\\tAt the {j+1}'th token in this sequence, gamma_{j},{i} = {max(-1, gamma_i - j*delta_gamma_n):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdb4772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
