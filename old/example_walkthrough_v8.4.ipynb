{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0f25dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/tunadorable/local-repos/next-concept-predictor/venv/lib/python3.11/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a829654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b3883a",
   "metadata": {},
   "source": [
    "# example walkthrough (full model)\n",
    "here i'll start with the first token of these two sequences and we'll walk through the calculations\n",
    "\n",
    "string1: \" I think therefore I am\\<endoftext>\"\n",
    "\n",
    "string2: \"Every cloud has a silver lining\\<endoftext>\"\n",
    "\n",
    "later we'll turn it into visual training and inference loops so that you can see how the ordering plays out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a096bc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting hyperparameters\n",
    "b=2\n",
    "n=7\n",
    "d=3\n",
    "v=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc7be22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' I': 0,\n",
       " ' think': 1,\n",
       " ' there': 2,\n",
       " 'fore': 3,\n",
       " ' am': 4,\n",
       " 'Every': 5,\n",
       " ' cloud': 6,\n",
       " ' has': 7,\n",
       " ' a': 8,\n",
       " ' silver': 9,\n",
       " ' lining': 10,\n",
       " '<endoftext>': 11}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_dict = {\" I\":0,\n",
    "          \" think\":1,\n",
    "         \" there\":2,\n",
    "         \"fore\":3,\n",
    "         \" am\":4,\n",
    "         \"Every\":5,\n",
    "         \" cloud\":6,\n",
    "         \" has\":7,\n",
    "         \" a\":8,\n",
    "         \" silver\":9,\n",
    "         \" lining\":10,\n",
    "         \"<endoftext>\":11}\n",
    "E_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14b5a23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_full:  torch.int64 torch.Size([2, 7]) tensor([[ 0,  1,  2,  3,  0,  4, 11],\n",
      "        [ 5,  6,  7,  8,  9, 10, 11]])\n",
      "S_i:  torch.int64 torch.Size([2, 1]) tensor([[0],\n",
      "        [5]])\n"
     ]
    }
   ],
   "source": [
    "# create sequence of tokens\n",
    "S_full_text = [[' I', ' think', ' there', 'fore', ' I', ' am', '<endoftext>'],\n",
    "               ['Every', ' cloud', ' has', ' a', ' silver', ' lining', '<endoftext>']]\n",
    "# turn into indices\n",
    "S_full_indices = [[E_dict[word] for word in sentence] for sentence in S_full_text]\n",
    "# turn into a tensor\n",
    "S_full = torch.tensor(S_full_indices)\n",
    "print(\"S_full: \", S_full.dtype, S_full.shape, S_full)\n",
    "\n",
    "# starting off with the first token for each sequence\n",
    "i=0\n",
    "if i==0: \n",
    "    S_i = S_full[:,i].unsqueeze(dim=1) \n",
    "else: \n",
    "    S_i = S_full[:,i]\n",
    "print(\"S_i: \", S_i.dtype, S_i.shape, S_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dcb8994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:  torch.Size([12, 3]) tensor([[-0.0084,  0.6013,  0.7990],\n",
      "        [-0.7062,  0.0558,  0.7058],\n",
      "        [-0.2553,  0.3534,  0.9000],\n",
      "        [ 0.1616,  0.9819,  0.0985],\n",
      "        [ 0.4082, -0.1934,  0.8921],\n",
      "        [ 0.9826, -0.1837, -0.0258],\n",
      "        [-0.0743, -0.6807, -0.7288],\n",
      "        [ 0.7308,  0.3404,  0.5917],\n",
      "        [-0.1637,  0.9282,  0.3341],\n",
      "        [ 0.5391, -0.4316, -0.7232],\n",
      "        [-0.0080,  0.9751, -0.2215],\n",
      "        [-0.3469, -0.9187,  0.1890]])\n",
      "X:  torch.Size([2, 1, 3]) tensor([[[-0.0084,  0.6013,  0.7990]],\n",
      "\n",
      "        [[ 0.9826, -0.1837, -0.0258]]])\n"
     ]
    }
   ],
   "source": [
    "# embedding matrix\n",
    "torch.manual_seed(420)\n",
    "E = torch.randn(v,d)\n",
    "# cosine norm for E\n",
    "E = E / torch.norm(E, p=2, dim=1, keepdim=True) \n",
    "print(\"E: \", E.shape, E)\n",
    "\n",
    "# Look up the embeddings\n",
    "X = F.embedding(S_i, E)\n",
    "print(\"X: \", X.shape, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4124b09",
   "metadata": {},
   "source": [
    "pretend the activation function and cosine normalization are being used inside transformer layers\n",
    "\n",
    "we don't mess with the actual transformer layers here other than these two pieces so no need to code them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d67bdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xi:  torch.Size([2, 1, 3]) tensor([[[-0.0264,  0.9498,  0.5903]],\n",
      "\n",
      "        [[ 0.0545, -0.5455, -0.0811]]])\n"
     ]
    }
   ],
   "source": [
    "# activation function\n",
    "Xi=torch.sin(torch.pi*X)\n",
    "print(\"Xi: \", Xi.shape, Xi)\n",
    "\n",
    "# i know sin is a weird choice but ask me about how terrible the traditional options are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b53a71b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norms:  torch.Size([2, 1, 1]) tensor([[[1.1186]],\n",
      "\n",
      "        [[0.5542]]])\n",
      "Xf:  torch.Size([2, 1, 3]) tensor([[[-0.0236,  0.8491,  0.5277]],\n",
      "\n",
      "        [[ 0.0983, -0.9843, -0.1463]]])\n"
     ]
    }
   ],
   "source": [
    "# Normalize each vector to have a unit length\n",
    "norms = torch.norm(Xi, p=2, dim=2, keepdim=True)\n",
    "Xf = Xi / norms\n",
    "print(\"norms: \", norms.shape, norms)\n",
    "print(\"Xf: \", Xf.shape, Xf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d119d9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y:  torch.Size([2, 3]) tensor([[-0.0236,  0.8491,  0.5277],\n",
      "        [ 0.0983, -0.9843, -0.1463]])\n"
     ]
    }
   ],
   "source": [
    "# select final row\n",
    "Y = Xf[:,-1:].squeeze(dim=1)\n",
    "print(\"Y: \", Y.shape, Y)\n",
    "# in a noormal GPT we'd first multiply by E.T and then select the row, because normal gpt's want\n",
    "# to immediately select from a b,v tensor whereas we need a b,d tensor to give us concept vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c45d20bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E.T:  torch.Size([3, 12]) tensor([[-0.0084, -0.7062, -0.2553,  0.1616,  0.4082,  0.9826, -0.0743,  0.7308,\n",
      "         -0.1637,  0.5391, -0.0080, -0.3469],\n",
      "        [ 0.6013,  0.0558,  0.3534,  0.9819, -0.1934, -0.1837, -0.6807,  0.3404,\n",
      "          0.9282, -0.4316,  0.9751, -0.9187],\n",
      "        [ 0.7990,  0.7058,  0.9000,  0.0985,  0.8921, -0.0258, -0.7288,  0.5917,\n",
      "          0.3341, -0.7232, -0.2215,  0.1890]])\n",
      "Z:  torch.Size([2, 12]) tensor([[ 0.9324,  0.4364,  0.7810,  0.8819,  0.2969, -0.1928, -0.9608,  0.5840,\n",
      "          0.9683, -0.7608,  0.7113, -0.6721],\n",
      "        [-0.7096, -0.2276, -0.5047, -0.9651,  0.1000,  0.2812,  0.7694, -0.3498,\n",
      "         -0.9787,  0.5837, -0.9282,  0.8425]])\n",
      "Z Max: tensor([0.9683, 0.8425])\n",
      "Z Min: tensor([-0.9608, -0.9787])\n"
     ]
    }
   ],
   "source": [
    "# Perform cosine similarity, which simplifies down to dot product\n",
    "# We transpose E to get shape (d, v) and then use matmul for cosine similarity\n",
    "Z = torch.matmul(Y, E.T)\n",
    "print(\"E.T: \", E.T.shape, E.T)\n",
    "print(\"Z: \", Z.shape, Z)\n",
    "\n",
    "# let's make sure Z looks good\n",
    "print(\"Z Max:\", torch.max(Z, dim=1).values)\n",
    "print(\"Z Min:\", torch.min(Z, dim=1).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25587e20",
   "metadata": {},
   "source": [
    "### the conditional parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc47a685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:  torch.Size([2]) tensor([0.9683, 0.8425])\n",
      "H:  torch.Size([2]) tensor([ 8, 11])\n"
     ]
    }
   ],
   "source": [
    "# finding closest tokens to the raw output & their similarity scores\n",
    "G, H = torch.max(Z, dim=1)\n",
    "print(\"G: \", G.shape, G)\n",
    "print(\"H: \", H.shape, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36978b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.9 # $-1\\leq \\gamma < 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8d6500a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:  torch.float32 torch.Size([2]) tensor([1., 0.])\n"
     ]
    }
   ],
   "source": [
    "A = (G > gamma).float()\n",
    "print(\"A: \", A.dtype, A.shape, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d902aa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_unsqueeze:  torch.Size([2, 1]) tensor([[1.],\n",
      "        [0.]])\n",
      "A_expand:  torch.Size([2, 12]) tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "A_unsqueeze = A.unsqueeze(1)\n",
    "print(\"A_unsqueeze: \", A_unsqueeze.shape, A_unsqueeze)\n",
    "A_expand = A_unsqueeze.expand(-1, v)\n",
    "print(\"A_expand: \", A_expand.shape, A_expand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e1186c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I:  torch.float32 torch.Size([2, 12]) tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "A_prime_expand:  torch.float32 torch.Size([2, 12]) tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "I = torch.ones(b,v).float()\n",
    "print(\"I: \", I.dtype, I.shape, I)\n",
    "A_prime_expand = I-A_expand\n",
    "print(\"A_prime_expand: \", A_prime_expand.dtype, A_prime_expand.shape, A_prime_expand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a07b9a5",
   "metadata": {},
   "source": [
    "### only used for trainnig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ebb58dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_full:  torch.Size([2, 7]) tensor([[ 0,  1,  2,  3,  0,  4, 11],\n",
      "        [ 5,  6,  7,  8,  9, 10, 11]])\n",
      "S_next_ideal:  torch.Size([2]) tensor([1, 6])\n",
      "Q:  torch.float32 torch.Size([2, 12]) tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Generate indices for one-hot positions from S\n",
    "#ideal_indices = torch.randint(low=0, high=v, size=(b,))\n",
    "print(\"S_full: \", S_full.shape, S_full)\n",
    "S_next_ideal = S_full[:,i+1]\n",
    "print(\"S_next_ideal: \", S_next_ideal.shape, S_next_ideal)\n",
    "\n",
    "# Create the one-hot matrix\n",
    "Q = torch.nn.functional.one_hot(S_next_ideal, num_classes=v).float()\n",
    "print(\"Q: \", Q.dtype, Q.shape, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32c24ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_prime:  torch.Size([2, 12]) tensor([[-1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "        [-1., -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.]])\n"
     ]
    }
   ],
   "source": [
    "# Create a mask where zeros are marked\n",
    "zero_mask_Q = Q == 0\n",
    "\n",
    "# Replace zeros with -1\n",
    "Q[zero_mask_Q] = -1\n",
    "print(\"Q_prime: \", Q.shape, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6e457f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_expand:  torch.Size([2, 12]) tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "Z_ideal:  torch.Size([2, 12]) tensor([[-1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "        [-0., -0., -0., -0., -0., -0.,  0., -0., -0., -0., -0., -0.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"A_expand: \", A_expand.shape, A_expand)\n",
    "Z_ideal = Q*A_expand\n",
    "print(\"Z_ideal: \", Z_ideal.shape, Z_ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd926da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z_concepts:  torch.Size([2, 12]) tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000,  0.0000,\n",
      "          0.0000, -0.0000,  0.0000, -0.0000],\n",
      "        [-0.7096, -0.2276, -0.5047, -0.9651,  0.1000,  0.2812,  0.7694, -0.3498,\n",
      "         -0.9787,  0.5837, -0.9282,  0.8425]])\n"
     ]
    }
   ],
   "source": [
    "Z_concepts = Z*A_prime_expand\n",
    "print(\"Z_concepts: \", Z_concepts.shape, Z_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67d352e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z_train:  torch.Size([2, 12]) tensor([[-1.0000,  1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-0.7096, -0.2276, -0.5047, -0.9651,  0.1000,  0.2812,  0.7694, -0.3498,\n",
      "         -0.9787,  0.5837, -0.9282,  0.8425]])\n"
     ]
    }
   ],
   "source": [
    "Z_train = Z_concepts + Z_ideal\n",
    "print(\"Z_train: \", Z_train.shape, Z_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a19be14",
   "metadata": {},
   "source": [
    "### only used for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab7225f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:  torch.Size([2, 12]) tensor([[0.1360, 0.0828, 0.1169, 0.1293, 0.0720, 0.0441, 0.0205, 0.0960, 0.1410,\n",
      "         0.0250, 0.1090, 0.0273],\n",
      "        [0.0395, 0.0640, 0.0485, 0.0306, 0.0888, 0.1064, 0.1733, 0.0566, 0.0302,\n",
      "         0.1440, 0.0317, 0.1865]])\n",
      "tensor(3.0058) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Apply softmax along the last dimension (v)\n",
    "P = F.softmax(Z, dim=-1)\n",
    "print(\"P: \", P.shape, P)\n",
    "print(torch.sum(Z[0], dim=-1), torch.sum(P[0], dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "379a5cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_iplus1:  torch.Size([2]) tensor([ 8, 11])\n"
     ]
    }
   ],
   "source": [
    "S_iplus1 = torch.max(P, dim=1).indices\n",
    "print(\"S_iplus1: \", S_iplus1.shape, S_iplus1)\n",
    "# if you were only going to do greedy decoding you could skip making P and just create S_nplus1 from Z\n",
    "# however, you need to make P if you want to do probabilistic decoding so we're doing it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5211ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_iplus1_prime:  torch.Size([2]) tensor([ 8, 12])\n"
     ]
    }
   ],
   "source": [
    "# Create a mask where zeros are marked\n",
    "zero_mask_A = A == 0\n",
    "\n",
    "# Replace zeros with -1\n",
    "S_iplus1_prime = S_iplus1\n",
    "S_iplus1_prime[zero_mask_A] = v\n",
    "\n",
    "print(\"S_iplus1_prime: \", S_iplus1_prime.shape, S_iplus1_prime)\n",
    "# so at the v value we're essentially going to be ignoring that prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3d21538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old i:  0\n",
      "new i:  1\n"
     ]
    }
   ],
   "source": [
    "#i=0\n",
    "print(\"old i: \", i)\n",
    "i+=1\n",
    "print(\"new i: \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b33aa0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon:  torch.Size([1, 3]) tensor([[0., 0., 0.]])\n",
      "E_prime:  torch.Size([13, 3]) tensor([[-0.0084,  0.6013,  0.7990],\n",
      "        [-0.7062,  0.0558,  0.7058],\n",
      "        [-0.2553,  0.3534,  0.9000],\n",
      "        [ 0.1616,  0.9819,  0.0985],\n",
      "        [ 0.4082, -0.1934,  0.8921],\n",
      "        [ 0.9826, -0.1837, -0.0258],\n",
      "        [-0.0743, -0.6807, -0.7288],\n",
      "        [ 0.7308,  0.3404,  0.5917],\n",
      "        [-0.1637,  0.9282,  0.3341],\n",
      "        [ 0.5391, -0.4316, -0.7232],\n",
      "        [-0.0080,  0.9751, -0.2215],\n",
      "        [-0.3469, -0.9187,  0.1890],\n",
      "        [ 0.0000,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "epsilon = torch.zeros(1,d)\n",
    "print(\"epsilon: \", epsilon.shape, epsilon)\n",
    "E_prime = torch.cat((E,epsilon), dim=0)\n",
    "print(\"E_prime: \", E_prime.shape, E_prime)\n",
    "# notice this new empty embedding vector at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9bd4897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_token:  torch.Size([2, 3]) tensor([[-0.1637,  0.9282,  0.3341],\n",
      "        [ 0.0000,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print\n",
    "Y_token = F.embedding(S_iplus1_prime,E_prime)\n",
    "print(\"Y_token: \", Y_token.shape, Y_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "037abc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_concept:  torch.Size([2, 3]) tensor([[-0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0983, -0.9843, -0.1463]])\n"
     ]
    }
   ],
   "source": [
    "Y_concept = Y*A_prime_expand[:,0:d]\n",
    "print(\"Y_concept: \", Y_concept.shape, Y_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c082c554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_inference:  torch.Size([2, 3]) tensor([[-0.1637,  0.9282,  0.3341],\n",
      "        [ 0.0983, -0.9843, -0.1463]])\n"
     ]
    }
   ],
   "source": [
    "Y_inference = Y_token + Y_concept\n",
    "print(\"Y_inference: \", Y_inference.shape, Y_inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6594e940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old X0:  torch.Size([2, 1, 3]) tensor([[[-0.0084,  0.6013,  0.7990]],\n",
      "\n",
      "        [[ 0.9826, -0.1837, -0.0258]]])\n",
      "new X0:  torch.Size([2, 2, 3]) tensor([[[-0.0084,  0.6013,  0.7990],\n",
      "         [-0.1637,  0.9282,  0.3341]],\n",
      "\n",
      "        [[ 0.9826, -0.1837, -0.0258],\n",
      "         [ 0.0983, -0.9843, -0.1463]]])\n"
     ]
    }
   ],
   "source": [
    "print(\"old X0: \", X.shape, X)\n",
    "X = torch.cat((X,Y_inference.unsqueeze(1)), dim=1)\n",
    "print(\"new X0: \", X.shape, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e358b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the old S_i:  torch.Size([2, 2]) tensor([[ 0,  8],\n",
      "        [ 5, 12]])\n",
      "the new S_i:  torch.Size([2, 3]) tensor([[ 0,  8,  8],\n",
      "        [ 5, 12, 12]])\n"
     ]
    }
   ],
   "source": [
    "#print(\"the old S_i: \", S_i.shape, S_i)\n",
    "#S_iplus1_unsqueeze = S_iplus1.unsqueeze(dim=1)\n",
    "#S_i = torch.concat((S_i,S_iplus1_unsqueeze), dim=1)\n",
    "#print(\"the new S_i: \", S_i.shape, S_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3b8a89",
   "metadata": {},
   "source": [
    "## change in gamma over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48bc7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "855a8337",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_00 = -1\n",
    "gamma_f0 = -1\n",
    "gamma_0f = 0.8\n",
    "gamma_ff = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "799def73",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6 # sequence length\n",
    "m = 9 # num of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3db4e937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n"
     ]
    }
   ],
   "source": [
    "delta_gamma_m = (gamma_0f - gamma_00)/m\n",
    "print(delta_gamma_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4eaf9778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This epoch, to become a token a concept needs cos similarity at least gamma_0,0 = -1.00\n",
      "\tAt the 1'th token in this sequence, gamma_0,0 = -1.00\n",
      "\tAt the 2'th token in this sequence, gamma_1,0 = -1.00\n",
      "\tAt the 3'th token in this sequence, gamma_2,0 = -1.00\n",
      "\tAt the 4'th token in this sequence, gamma_3,0 = -1.00\n",
      "\tAt the 5'th token in this sequence, gamma_4,0 = -1.00\n",
      "\tAt the 6'th token in this sequence, gamma_5,0 = -1.00\n",
      "\tAt the 7'th token in this sequence, gamma_6,0 = -1.00\n",
      "\tAt the 8'th token in this sequence, gamma_7,0 = -1.00\n",
      "\tAt the 9'th token in this sequence, gamma_8,0 = -1.00\n",
      "\tAt the 10'th token in this sequence, gamma_9,0 = -1.00\n",
      "\tAt the 11'th token in this sequence, gamma_10,0 = -1.00\n",
      "\tAt the 12'th token in this sequence, gamma_11,0 = -1.00\n",
      "This epoch, to become a token a concept needs cos similarity at least gamma_0,1 = -0.80\n",
      "\tAt the 1'th token in this sequence, gamma_0,1 = -0.80\n",
      "\tAt the 2'th token in this sequence, gamma_1,1 = -0.83\n",
      "\tAt the 3'th token in this sequence, gamma_2,1 = -0.87\n",
      "\tAt the 4'th token in this sequence, gamma_3,1 = -0.90\n",
      "\tAt the 5'th token in this sequence, gamma_4,1 = -0.93\n",
      "\tAt the 6'th token in this sequence, gamma_5,1 = -0.97\n",
      "\tAt the 7'th token in this sequence, gamma_6,1 = -1.00\n",
      "\tAt the 8'th token in this sequence, gamma_7,1 = -1.00\n",
      "\tAt the 9'th token in this sequence, gamma_8,1 = -1.00\n",
      "\tAt the 10'th token in this sequence, gamma_9,1 = -1.00\n",
      "\tAt the 11'th token in this sequence, gamma_10,1 = -1.00\n",
      "\tAt the 12'th token in this sequence, gamma_11,1 = -1.00\n",
      "This epoch, to become a token a concept needs cos similarity at least gamma_0,2 = -0.60\n",
      "\tAt the 1'th token in this sequence, gamma_0,2 = -0.60\n",
      "\tAt the 2'th token in this sequence, gamma_1,2 = -0.67\n",
      "\tAt the 3'th token in this sequence, gamma_2,2 = -0.73\n",
      "\tAt the 4'th token in this sequence, gamma_3,2 = -0.80\n",
      "\tAt the 5'th token in this sequence, gamma_4,2 = -0.87\n",
      "\tAt the 6'th token in this sequence, gamma_5,2 = -0.93\n",
      "\tAt the 7'th token in this sequence, gamma_6,2 = -1.00\n",
      "\tAt the 8'th token in this sequence, gamma_7,2 = -1.00\n",
      "\tAt the 9'th token in this sequence, gamma_8,2 = -1.00\n",
      "\tAt the 10'th token in this sequence, gamma_9,2 = -1.00\n",
      "\tAt the 11'th token in this sequence, gamma_10,2 = -1.00\n",
      "\tAt the 12'th token in this sequence, gamma_11,2 = -1.00\n",
      "This epoch, to become a token a concept needs cos similarity at least gamma_0,3 = -0.40\n",
      "\tAt the 1'th token in this sequence, gamma_0,3 = -0.40\n",
      "\tAt the 2'th token in this sequence, gamma_1,3 = -0.50\n",
      "\tAt the 3'th token in this sequence, gamma_2,3 = -0.60\n",
      "\tAt the 4'th token in this sequence, gamma_3,3 = -0.70\n",
      "\tAt the 5'th token in this sequence, gamma_4,3 = -0.80\n",
      "\tAt the 6'th token in this sequence, gamma_5,3 = -0.90\n",
      "\tAt the 7'th token in this sequence, gamma_6,3 = -1.00\n",
      "\tAt the 8'th token in this sequence, gamma_7,3 = -1.00\n",
      "\tAt the 9'th token in this sequence, gamma_8,3 = -1.00\n",
      "\tAt the 10'th token in this sequence, gamma_9,3 = -1.00\n",
      "\tAt the 11'th token in this sequence, gamma_10,3 = -1.00\n",
      "\tAt the 12'th token in this sequence, gamma_11,3 = -1.00\n",
      "This epoch, to become a token a concept needs cos similarity at least gamma_0,4 = -0.20\n",
      "\tAt the 1'th token in this sequence, gamma_0,4 = -0.20\n",
      "\tAt the 2'th token in this sequence, gamma_1,4 = -0.33\n",
      "\tAt the 3'th token in this sequence, gamma_2,4 = -0.47\n",
      "\tAt the 4'th token in this sequence, gamma_3,4 = -0.60\n",
      "\tAt the 5'th token in this sequence, gamma_4,4 = -0.73\n",
      "\tAt the 6'th token in this sequence, gamma_5,4 = -0.87\n",
      "\tAt the 7'th token in this sequence, gamma_6,4 = -1.00\n",
      "\tAt the 8'th token in this sequence, gamma_7,4 = -1.00\n",
      "\tAt the 9'th token in this sequence, gamma_8,4 = -1.00\n",
      "\tAt the 10'th token in this sequence, gamma_9,4 = -1.00\n",
      "\tAt the 11'th token in this sequence, gamma_10,4 = -1.00\n",
      "\tAt the 12'th token in this sequence, gamma_11,4 = -1.00\n",
      "This epoch, to become a token a concept needs cos similarity at least gamma_0,5 = 0.00\n",
      "\tAt the 1'th token in this sequence, gamma_0,5 = 0.00\n",
      "\tAt the 2'th token in this sequence, gamma_1,5 = -0.17\n",
      "\tAt the 3'th token in this sequence, gamma_2,5 = -0.33\n",
      "\tAt the 4'th token in this sequence, gamma_3,5 = -0.50\n",
      "\tAt the 5'th token in this sequence, gamma_4,5 = -0.67\n",
      "\tAt the 6'th token in this sequence, gamma_5,5 = -0.83\n",
      "\tAt the 7'th token in this sequence, gamma_6,5 = -1.00\n",
      "\tAt the 8'th token in this sequence, gamma_7,5 = -1.00\n",
      "\tAt the 9'th token in this sequence, gamma_8,5 = -1.00\n",
      "\tAt the 10'th token in this sequence, gamma_9,5 = -1.00\n",
      "\tAt the 11'th token in this sequence, gamma_10,5 = -1.00\n",
      "\tAt the 12'th token in this sequence, gamma_11,5 = -1.00\n",
      "This epoch, to become a token a concept needs cos similarity at least gamma_0,6 = 0.20\n",
      "\tAt the 1'th token in this sequence, gamma_0,6 = 0.20\n",
      "\tAt the 2'th token in this sequence, gamma_1,6 = 0.00\n",
      "\tAt the 3'th token in this sequence, gamma_2,6 = -0.20\n",
      "\tAt the 4'th token in this sequence, gamma_3,6 = -0.40\n",
      "\tAt the 5'th token in this sequence, gamma_4,6 = -0.60\n",
      "\tAt the 6'th token in this sequence, gamma_5,6 = -0.80\n",
      "\tAt the 7'th token in this sequence, gamma_6,6 = -1.00\n",
      "\tAt the 8'th token in this sequence, gamma_7,6 = -1.00\n",
      "\tAt the 9'th token in this sequence, gamma_8,6 = -1.00\n",
      "\tAt the 10'th token in this sequence, gamma_9,6 = -1.00\n",
      "\tAt the 11'th token in this sequence, gamma_10,6 = -1.00\n",
      "\tAt the 12'th token in this sequence, gamma_11,6 = -1.00\n",
      "This epoch, to become a token a concept needs cos similarity at least gamma_0,7 = 0.40\n",
      "\tAt the 1'th token in this sequence, gamma_0,7 = 0.40\n",
      "\tAt the 2'th token in this sequence, gamma_1,7 = 0.17\n",
      "\tAt the 3'th token in this sequence, gamma_2,7 = -0.07\n",
      "\tAt the 4'th token in this sequence, gamma_3,7 = -0.30\n",
      "\tAt the 5'th token in this sequence, gamma_4,7 = -0.53\n",
      "\tAt the 6'th token in this sequence, gamma_5,7 = -0.77\n",
      "\tAt the 7'th token in this sequence, gamma_6,7 = -1.00\n",
      "\tAt the 8'th token in this sequence, gamma_7,7 = -1.00\n",
      "\tAt the 9'th token in this sequence, gamma_8,7 = -1.00\n",
      "\tAt the 10'th token in this sequence, gamma_9,7 = -1.00\n",
      "\tAt the 11'th token in this sequence, gamma_10,7 = -1.00\n",
      "\tAt the 12'th token in this sequence, gamma_11,7 = -1.00\n",
      "This epoch, to become a token a concept needs cos similarity at least gamma_0,8 = 0.60\n",
      "\tAt the 1'th token in this sequence, gamma_0,8 = 0.60\n",
      "\tAt the 2'th token in this sequence, gamma_1,8 = 0.33\n",
      "\tAt the 3'th token in this sequence, gamma_2,8 = 0.07\n",
      "\tAt the 4'th token in this sequence, gamma_3,8 = -0.20\n",
      "\tAt the 5'th token in this sequence, gamma_4,8 = -0.47\n",
      "\tAt the 6'th token in this sequence, gamma_5,8 = -0.73\n",
      "\tAt the 7'th token in this sequence, gamma_6,8 = -1.00\n",
      "\tAt the 8'th token in this sequence, gamma_7,8 = -1.00\n",
      "\tAt the 9'th token in this sequence, gamma_8,8 = -1.00\n",
      "\tAt the 10'th token in this sequence, gamma_9,8 = -1.00\n",
      "\tAt the 11'th token in this sequence, gamma_10,8 = -1.00\n",
      "\tAt the 12'th token in this sequence, gamma_11,8 = -1.00\n"
     ]
    }
   ],
   "source": [
    "for i in range(m):\n",
    "    gamma_i = gamma_00 + i*delta_gamma_m\n",
    "    print(f\"This epoch, to become a token a concept needs cos similarity at least gamma_0,{i} = {gamma_i:.2f}\")\n",
    "    \n",
    "    delta_gamma_n = (gamma_i - gamma_ff)/n\n",
    "    for j in range(2*n):\n",
    "        \n",
    "        print(f\"\\tAt the {j+1}'th token in this sequence, gamma_{j},{i} = {max(-1, gamma_i - j*delta_gamma_n):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ce66b6",
   "metadata": {},
   "source": [
    "# now making everything into loops\n",
    "\n",
    "first we'll define a bunch of functions\n",
    "\n",
    "then we'll put those functions into training & inference loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d97b0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting hyperparameters\n",
    "b=2\n",
    "n=7\n",
    "d=3\n",
    "v=12\n",
    "\n",
    "# defining the vocabulary\n",
    "E_dict = {\" I\":0,\n",
    "          \" think\":1,\n",
    "         \" there\":2,\n",
    "         \"fore\":3,\n",
    "         \" am\":4,\n",
    "         \"Every\":5,\n",
    "         \" cloud\":6,\n",
    "         \" has\":7,\n",
    "         \" a\":8,\n",
    "         \" silver\":9,\n",
    "         \" lining\":10,\n",
    "         \"<endoftext>\":11}\n",
    "\n",
    "# and our sequence of tokens\n",
    "S_full_text = [[' I', ' think', ' there', 'fore', ' I', ' am', '<endoftext>'],\n",
    "               ['Every', ' cloud', ' has', ' a', ' silver', ' lining', '<endoftext>']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216ecd8a",
   "metadata": {},
   "source": [
    "i think for now imma stick to writing a walkthrough in the overleaf pdf and revisit a code version later if you don't think the walkthrough is clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f80dafe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.,  1., -1., -1.],\n",
       "        [ 1., -1., -1., -1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [[-1,1,-1,-1],[1,-1,-1,-1]]\n",
    "tt = torch.tensor(t).float()\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c20c48af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0963, 0.7112, 0.0963, 0.0963],\n",
       "        [0.7112, 0.0963, 0.0963, 0.0963]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tts = torch.softmax(tt, dim=1)\n",
    "tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b190dfc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1749, 0.4754, 0.1749, 0.1749],\n",
       "        [0.4754, 0.1749, 0.1749, 0.1749]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = [[0,1,0,0],[1,0,0,0]]\n",
    "zt = torch.tensor(z).float()\n",
    "zts = torch.softmax(zt, dim=1)\n",
    "zts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eda53959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogSoftmax Output: tensor([[-0.6138, -1.3338, -1.6338],\n",
      "        [-1.6388, -1.0588, -0.7788]])\n",
      "NLLLoss Output: tensor(0.6963)\n",
      "CrossEntropy Loss: tensor(0.6963)\n"
     ]
    }
   ],
   "source": [
    "# Example logits and target\n",
    "logits = torch.tensor([[0.92, 0.2, -0.1], [-0.56, 0.02, 0.3]])\n",
    "target = torch.tensor([0, 2])\n",
    "\n",
    "# Apply LogSoftmax\n",
    "log_softmax_output = F.log_softmax(logits, dim=1)\n",
    "\n",
    "# Compute NLLLoss\n",
    "nll_loss_output = F.nll_loss(log_softmax_output, target)\n",
    "\n",
    "# The combined cross-entropy loss\n",
    "cross_entropy_loss = F.cross_entropy(logits, target)\n",
    "\n",
    "print(\"LogSoftmax Output:\", log_softmax_output)\n",
    "print(\"NLLLoss Output:\", nll_loss_output)\n",
    "print(\"CrossEntropy Loss:\", cross_entropy_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f35344e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Loss: tensor(0.6138)\n"
     ]
    }
   ],
   "source": [
    "def custom_loss(Z, S, A):\n",
    "    # Apply LogSoftmax\n",
    "    log_probs = F.log_softmax(Z, dim=1)\n",
    "\n",
    "    # Gather the log probabilities corresponding to the true classes\n",
    "    gathered_probs = log_probs.gather(1, S.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "    # Apply the mask\n",
    "    masked_probs = gathered_probs * A\n",
    "\n",
    "    # Compute the average loss over unmasked entries\n",
    "    # Use A.sum() to count the number of unmasked entries\n",
    "    loss = -torch.sum(masked_probs) / torch.clamp(A.sum(), min=1)\n",
    "    return loss\n",
    "\n",
    "# Example usage\n",
    "A = torch.tensor([1, 0], dtype=torch.int32) # Second entry is ignored\n",
    "\n",
    "loss = custom_loss(logits, target, A)\n",
    "print(\"Custom Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3924240c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [0]], dtype=torch.int32) tensor([[ 0.9200,  0.2000, -0.1000],\n",
      "        [-0.0000,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Reshape A to (b, 1) so it can be broadcasted\n",
    "A_prime = A.view(-1, 1)\n",
    "\n",
    "# Apply the mask\n",
    "masked_logits = logits * A_prime\n",
    "\n",
    "print(A_prime, masked_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23540c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
