{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e31e531-c8f4-4641-8a87-90d7c1dd933a",
   "metadata": {},
   "source": [
    "# v11.3\n",
    "\n",
    "whereas the last version used matryoshka models, i think it makes more sense to go all-in on the self-similarity thing and simplify the whole process by using the same decoder for all levels\n",
    "\n",
    "todo's:\n",
    "- [x] copy & paste stuff that doesn't need to be changed\n",
    "- [x] copy, paste, & remove references to matryoshka embeddings for modules w/ em\n",
    "- [x] bring over todo items that haven't been completed from v11.2 and from notes app\n",
    "- [ ] setup single attention mechanism module for both self & cross? i feel like separate is prolly still easier. and this is kinda just unnecessary extra work\n",
    "- [x] setup single decoder layer body\n",
    "- [x] setup concept loss to use MSE and COS simultaneously\n",
    "- [ ] get predictive attention mask working in crossMQA\n",
    "- [x] add different types of pooling options to embedding combiner\n",
    "- [ ] pull concept loss out of model and into training loop so that i can progressively introduce the concept embedding prediction problem rather than deal with moving goalposts from the get-go\n",
    "- [x] make option for linear layer vs MLP in output from final concept residual states to actual concepts\n",
    "- [ ] write an inference algorithm that sacrifices quality for efficiency & see how well it works\n",
    "- [ ] add multiple <|bos|> tokens to put at the beginning of each sequence, one for each level. So that way the model can know what level it's working with and have somewhere to sink attention.\n",
    "- [ ] make get_batch output values that'd result in actually using the padding token so that it gets trained\n",
    "- [ ] switch to GaLore optimizer to save ram\n",
    "- [ ] implement basic stuff i'm missing like cosine learning rate scheduling (gradient clipping?)\n",
    "- [ ] move everything into .py files without the LoggingModule parent\n",
    "- [ ] create big hyperparameter testing script to send to ben\n",
    "- [ ] would it make sense to have the RoPE theta adjust for the different sequence levels? like divide it by config.combine_factor? i really need to learn more about how RoPE works at an intuitive level rather than just \"uuuuuh trig rotations\"\n",
    "- [ ] add learned positional encodings to pooling?\n",
    "\n",
    "further ideas likely for v11.4:\n",
    "- [ ] setup effective_seq_len_mult and seq_len_list and a bunch of downstream stuff like weird batching at lower sub-levels to allow for hella long effective context lengths\n",
    "- [ ] figure out a way to make config.combine_factor dynamic instead of predetermined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a84226-3000-41f2-b05c-cdbc41396595",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16628521-543c-4de8-a5aa-d830e7215bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my virtual environments are rarely properly connected to jupyter so this fixes that\n",
    "import sys\n",
    "import os\n",
    "current_dir = os.getcwd()  # Get the current working directory\n",
    "venv_dir = os.path.join(current_dir, 'venv') \n",
    "python_version = str(sys.version_info.major) + '.' + str(sys.version_info.minor)\n",
    "site_packages_path = os.path.join(venv_dir, 'lib', 'python' + python_version, 'site-packages')\n",
    "sys.path.append(site_packages_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8381842d-1256-4d00-a8a1-dd6e4fdc6192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# imports for the debugging/demonstration setup\n",
    "import functools\n",
    "import inspect\n",
    "\n",
    "# imports for the tokenizer\n",
    "from tokenizer import SimpleTokenizer, loaded_stoi, loaded_merges\n",
    "\n",
    "# Imports used for the config\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "# Imports used for the model\n",
    "import re\n",
    "from typing import Any, List, Sequence, Tuple, Union\n",
    "\n",
    "# used for training\n",
    "import random\n",
    "import time\n",
    "\n",
    "# used to save & load models\n",
    "import json\n",
    "from dataclasses import asdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeda5ff-46cc-49f5-b496-6d316bda3835",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Demonstration/Debugging wrapper & Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02b4aea8-31e9-4fa9-8b62-187a042b33d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will be used throughout for debugging/demonstration purposes\n",
    "# using this is way cleaner than cluttering up our code with print statements\n",
    "def log_io(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(self, *args, **kwargs):\n",
    "        # Check if logging is enabled globally and for the specific function\n",
    "        if not self.logging_enabled or func.__name__ in self.disabled_logging_functions:\n",
    "            return func(self, *args, **kwargs)\n",
    "        #if not self.logging_enabled:\n",
    "            #return func(self, *args, **kwargs)\n",
    "\n",
    "        def log_item(item, name, level=0, is_root=False):\n",
    "            indent = \"    \" * level\n",
    "            if isinstance(item, torch.Tensor):\n",
    "                print(f\"{indent}Tensor '{name}' shape: {item.shape}\")\n",
    "            elif isinstance(item, tuple):\n",
    "                if is_root and level == 0:\n",
    "                    # Root level tuple, don't print it as a tuple unless it's a \"true\" tuple\n",
    "                    for idx, sub_item in enumerate(item):\n",
    "                        log_item(sub_item, f\"{name}[{idx}]\", level)\n",
    "                else:\n",
    "                    print(f\"{indent}Tuple '{name}':\")\n",
    "                    for idx, sub_item in enumerate(item):\n",
    "                        log_item(sub_item, f\"{name}[{idx}]\", level + 1)\n",
    "            elif isinstance(item, int):\n",
    "                print(f\"{indent}Integer '{name}': Value={item}\")\n",
    "            elif isinstance(item, float):\n",
    "                print(f\"{indent}Float '{name}': Value={item}\")\n",
    "            else:\n",
    "                print(f\"{indent}Other-type '{name}': Type={type(item).__name__}, Value={item}\")\n",
    "\n",
    "        print(f\"\\n{'='*10}Entering {self.__class__.__name__}.{func.__name__}{'='*10}\")\n",
    "        print(\"Inputs:\")\n",
    "        arg_names = inspect.getfullargspec(func).args[1:]  # Excluding 'self'\n",
    "        arg_values = args + tuple(kwargs.values())\n",
    "        for name, value in zip(arg_names, arg_values):\n",
    "            log_item(value, name)\n",
    "\n",
    "        result = func(self, *args, **kwargs)\n",
    "        print(\"\\nOutputs:\")\n",
    "        if isinstance(result, tuple):\n",
    "            log_item(result, \"output\", is_root=True)\n",
    "        else:\n",
    "            log_item(result, \"output\")\n",
    "\n",
    "        print(f\"{'='*10}Exiting {self.__class__.__name__}.{func.__name__}{'='*10}\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "class LoggingModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.logging_enabled = False\n",
    "        self.disabled_logging_functions = set()\n",
    "\n",
    "    def enable_logging(self):\n",
    "        self.logging_enabled = True\n",
    "\n",
    "    def disable_logging(self):\n",
    "        self.logging_enabled = False\n",
    "\n",
    "    def disable_function_logging(self, func_name):\n",
    "        self.disabled_logging_functions.add(func_name)\n",
    "\n",
    "    def enable_function_logging(self, func_name):\n",
    "        self.disabled_logging_functions.discard(func_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3214e4-7a9b-4e82-a5d3-3fea93f378e2",
   "metadata": {},
   "source": [
    "# Config & tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cff0f146-fcdc-4ef6-bc0b-c79e0c7c98c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# and the tokenizer\n",
    "tokenizer = SimpleTokenizer(loaded_stoi, loaded_merges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b307756e-23ca-4869-adc5-224128aede9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config(vocab_size=128, max_seq_len=256, embed_dim=128, num_layers=8, sa_q_heads=4, sa_kv_heads=1, sa_head_dim=32, mlp_multiplier=4, theta=100.0, dropout_rate=0.05, norm_affine=False, levels=2, combine_factor=4, combine_type='reshape->linear_post_reshape', ca_q_heads=4, ca_kv_heads=1, ca_head_dim=32, ca_use_RoPE=False, predictive_mask=False, predictive_mask_noise=None, level_loss_weight=1.0, cos_loss=True, mse_loss=True, mae_loss=True)\n",
      "sequence length of each model: [256, 64]\n",
      "loss discounts starting from lowest level: [1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "@dataclass # a class meant specifically to just hold data\n",
    "class Config:\n",
    "    \"\"\" \n",
    "    The default configuration & hyperparameters for my next-concept predictor\n",
    "    \"\"\"\n",
    "    ### boring hyperparameters\n",
    "    vocab_size: int = tokenizer.vocab_len\n",
    "    max_seq_len: int = 256\n",
    "    embed_dim: int = 128\n",
    "    num_layers: int = 8\n",
    "    sa_q_heads: int = 4\n",
    "    sa_kv_heads: int = 1\n",
    "    #attn_bias: bool = False\n",
    "    sa_head_dim: int = 32\n",
    "    mlp_multiplier: int = 4\n",
    "    theta: float = 100.0\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    dropout_rate: float = 0.05\n",
    "    eps = 1e-6\n",
    "    norm_affine: bool = False # whether norms should have a linear & bias after them. likely less necessary if you're using RMSNorm\n",
    "    norm_type = \"RMSNorm\"  # Options are RMSNorm, CosineNorm and LayerNorm. defaults to RMSNorm\n",
    "\n",
    "    ### Concept embedding vectors\n",
    "    levels: int = 2\n",
    "    combine_factor: int = 4 # how many lower-level tokens/concepts to combine into the next level's concept\n",
    "    combine_type: str = 'reshape->linear_post_reshape' # options to combine are 'sum', 'mean', 'max', 'linear', 'mlp', 'reshape', \n",
    "                                                        # 'linear_post_reshape', and 'mlp_post_reshape'\n",
    "    @property\n",
    "    def seq_len_list(self):\n",
    "        return [(self.max_seq_len // (self.combine_factor ** (i-1))) for i in range(1, self.levels + 1)]\n",
    "\n",
    "    ### Dualcoder cross-attention\n",
    "    ca_q_heads: int = sa_q_heads\n",
    "    ca_kv_heads: int = sa_kv_heads\n",
    "    ca_head_dim: int = sa_head_dim\n",
    "    ca_use_RoPE: bool = False # True: expands out k & v tensors to be usable with rope. False: leaves k & v same size but no positional encodings\n",
    "    predictive_mask: bool = False # True: upper-triangular predictive mask to focus model's attention (not currently working). False: no mask like a regular encoder\n",
    "    predictive_mask_noise: float = None # float: sd of noise to add to predictively masked concept vecs. None: don't implement noise\n",
    "\n",
    "    ### concept output\n",
    "    output_layer = 'linear' # options are 'linear' and 'mlp' which uses the default mlp_multiplier\n",
    "    # how much to discount each higher level in the loss function compared to the last\n",
    "    level_loss_weight: float = 1.0 \n",
    "    # multiple losses can act on the concept vectors at once\n",
    "    cos_loss: bool = True\n",
    "    mse_loss: bool = True\n",
    "    mae_loss: bool = True\n",
    "    \n",
    "    ### assertions\n",
    "    assert sa_q_heads % sa_kv_heads == 0, 'the number of query heads must be divisible by the number of key-value heads in self-attention'\n",
    "    assert ca_q_heads % ca_kv_heads == 0, 'the number of query heads must be divisible by the number of key-value heads in cross-attention'     \n",
    "        \n",
    "config = Config()\n",
    "print(config)\n",
    "print(f\"sequence length of each model: {config.seq_len_list}\")\n",
    "print(f\"loss discounts starting from lowest level: {[config.level_loss_weight**i for i in range(config.levels)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3f0865-495e-4c43-bff3-e87756818725",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# RoPE\n",
    "\n",
    "i like the idea of pre-computing RoPE embeddings but at this point i don't think it's worth the effort bc i'd have to not only use this code but also pipe the two instantiations of this class through from `Body` all the way to `selfMQA` and `crossMQA` and I'm not even sure if it matters. I really should learn more about RoPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14adecb-9c7c-464e-8b40-d3d22ff93cc0",
   "metadata": {},
   "source": [
    "```Python\n",
    "# this class has not been implemented nor even tested. on my todo list\n",
    "class RoPE(nn.Module):\n",
    "    def __init__(self, \n",
    "                 dim: int, \n",
    "                 max_seq_len:int = config.max_seq_len, \n",
    "                 device: str = config.device):\n",
    "        super().__init__()\n",
    "        # Validate that dim is even since we split it by 2 for real and imaginary parts\n",
    "        if dim % 2 != 0: raise ValueError(\"Dimension 'dim' must be an even number.\")\n",
    "            \n",
    "        # Precompute frequencies based on configuration\n",
    "        theta = config.theta if hasattr(config, 'theta') else 10000.0\n",
    "        \n",
    "        freqs = 1.0 / (theta ** (torch.arange(0, config.dim, 2, device=config.device).float() / config.dim))\n",
    "        t = torch.arange(config.max_seq_len, device=config.device)\n",
    "        freqs = torch.outer(t, freqs).to(config.device).float()\n",
    "        \n",
    "        # Register as buffer to prevent gradient tracking\n",
    "        self.register_buffer('freqs_cis', torch.polar(torch.ones_like(freqs), freqs)) # complex64\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply rotary embeddings to the input tensor\n",
    "        x_ = torch.view_as_complex(torch.stack(torch.chunk(x.transpose(1, 2).float(), 2, dim=-1), dim=-1))\n",
    "        x_out = torch.view_as_real(x_ * self.freqs_cis.unsqueeze(0)).type_as(x)\n",
    "        x_out = torch.cat(torch.chunk(x_out, 2, dim=-1), dim=-2)\n",
    "        x_out = x_out.reshape(x_out.shape[0], x_out.shape[1], x_out.shape[2], -1).transpose(1, 2)\n",
    "        return x_out\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "374a3ab5-9cba-4dd3-b5e9-5d0e4d419952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RoPE(x: torch.Tensor, dim: int, theta: float = 10000.0) -> torch.Tensor:\n",
    "    \"\"\"Applies the rotary embedding to the inputted query or key tensor\"\"\"\n",
    "    # Validate that dim is even since we split it by 2 for real and imaginary parts\n",
    "    if dim % 2 != 0: raise ValueError(\"Dimension 'dim' must be an even number.\")\n",
    "            \n",
    "    # Get sequence length\n",
    "    seq_len = x.size(1)\n",
    "    device = x.device\n",
    "\n",
    "    # Dynamically compute frequency cis based on the input sequence length\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2, device=device).float() / dim))\n",
    "    t = torch.arange(seq_len, device=device)\n",
    "    freqs = torch.outer(t, freqs).float()\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    # it's important to train on a wide variety of sequence lengths within your context length so that the model learns to generalize\n",
    "\n",
    "    # Apply rotary embeddings to the input tensor\n",
    "    x_ = torch.view_as_complex(torch.stack(torch.chunk(x.transpose(1, 2).float(), 2, dim=-1), dim=-1))\n",
    "    x_out = torch.view_as_real(x_ * freqs_cis.unsqueeze(0)).type_as(x)  # Ensure batch dimension is handled\n",
    "    x_out = torch.cat(torch.chunk(x_out, 2, dim=-1), dim=-2)\n",
    "    x_out = x_out.reshape(x_out.shape[0], x_out.shape[1], x_out.shape[2], -1).transpose(1, 2)\n",
    "\n",
    "    return x_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851a4b6f-2dc7-4c59-b71f-0e6740101acb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# selfMQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e735756c-9806-4000-84fd-7008bfa0d251",
   "metadata": {},
   "outputs": [],
   "source": [
    "class selfMQA(LoggingModule): # notice thoughout we'll be inheriting from LoggingModule instead of nn.Module\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.sa_q_heads = config.sa_q_heads\n",
    "        self.sa_kv_heads = config.sa_kv_heads\n",
    "        assert self.sa_q_heads % self.sa_kv_heads == 0\n",
    "        self.num_queries_per_kv = self.sa_q_heads // self.sa_kv_heads\n",
    "\n",
    "        self.embed_dim = config.embed_dim\n",
    "        self.sa_head_dim = config.sa_head_dim\n",
    "        self.theta = config.theta\n",
    "        self.dropout_rate = config.dropout_rate\n",
    "\n",
    "        #self.Wqkv = nn.Linear(self.embed_dim, \n",
    "        #                      (self.sa_q_heads + 2 * self.sq_kv_heads) * self.sa_head_dim, \n",
    "        #                      bias = config.attn_bias)\n",
    "        #self.Wo = nn.Linear(self.sa_q_heads * self.sa_head_dim,\n",
    "        #                    self.embed_dim,\n",
    "        #                    bias = config.attn_bias)\n",
    "        \n",
    "        self.Wqkv = nn.Parameter(torch.Tensor(self.embed_dim, (self.sa_q_heads + 2 * self.sa_kv_heads) * self.sa_head_dim))\n",
    "        nn.init.uniform_(self.Wqkv, -((1 / self.embed_dim) ** 0.5), (1 / self.embed_dim) ** 0.5)\n",
    "\n",
    "        self.Wo = nn.Parameter(torch.Tensor(self.sa_q_heads * self.sa_head_dim, self.embed_dim))\n",
    "        nn.init.uniform_(self.Wo, -((1 / (self.sa_q_heads * self.sa_head_dim)) ** 0.5), (1 / (self.sa_q_heads * self.sa_head_dim)) ** 0.5)\n",
    "\n",
    "        # for our attention mask we'll create a boolean mask that'll later be turned into large negative values\n",
    "        self.mask = torch.tril(torch.ones((config.max_seq_len, config.max_seq_len), dtype=torch.uint8)\n",
    "                              ).view(1, 1, config.max_seq_len, config.max_seq_len).to(dtype=torch.bool)\n",
    "\n",
    "    @log_io\n",
    "    def forward(self, x: torch.Tensor, training: bool = False) -> torch.Tensor:\n",
    "        # Extracts batch size and input sequence length from the hidden states tensor.\n",
    "        batch_size, input_len, _ = x.shape\n",
    "\n",
    "        # splicing our primary projection to get the correct sub-matrices\n",
    "        Wq, Wk, Wv = self.weight_splicing(self.Wqkv)\n",
    "        # technically self.weight_splicing has access to self.Wqkv & Wo but this way our debugger can see them\n",
    "\n",
    "        # Applies the linear projection to the hidden state to retrieve our q, k & v projections\n",
    "        xq = F.dropout(x @ Wq, p=self.dropout_rate, training=training) # also dropout if we're training\n",
    "        xk = F.dropout(x @ Wk, p=self.dropout_rate, training=training)\n",
    "        xv = F.dropout(x @ Wv, p=self.dropout_rate, training=training)\n",
    "\n",
    "        # Reshapes each of the Q, K, and V tensors to separate the heads and align the dimensions for attention operations.\n",
    "        xq = xq.view(batch_size, -1, self.sa_q_heads, self.sa_head_dim)\n",
    "        xk = xk.view(batch_size, -1, self.sa_kv_heads, self.sa_head_dim)\n",
    "        xv = xv.view(batch_size, -1, self.sa_kv_heads, self.sa_head_dim)\n",
    "\n",
    "        # Applies rotary positional embeddings to queries and keys to incorporate positional information.\n",
    "        xq, xk = self.RoPE(xq, xk)\n",
    "\n",
    "        # If the number of KV heads is different from the number of query heads, adjusts keys and values to match the query heads count.\n",
    "        if self.sa_kv_heads != self.sa_q_heads:\n",
    "            xk, xv = self.match_headcount(xk, xv) # [batch_size, input_len, n_local_heads, sa_head_dim]\n",
    "\n",
    "        # Transposes Q, K, and V tensors to align them for the batch matrix multiplication in attention calculation.\n",
    "        xq = xq.transpose(1, 2) # [batch_size, n_local_heads, input_len, sa_head_dim]\n",
    "        xk = xk.transpose(1, 2)\n",
    "        xv = xv.transpose(1, 2)\n",
    "\n",
    "        # Calculates attention scores by performing a batch matrix multiplication between queries and keys, followed by scaling.\n",
    "        logits = self.attend(xq, xk) # [batch_size, n_local_heads, input_len, input_len]\n",
    "        \n",
    "        # Applies the lower-triangular mask to the attention logits\n",
    "        logits = self.apply_mask(logits, input_len)\n",
    "\n",
    "        # applies values to get final output\n",
    "        output = self.calc_output(logits, xv, batch_size, input_len, training) \n",
    "\n",
    "        # Applies the final linear projection to the attention output, mapping it back to self.embed_dim\n",
    "        return F.dropout(output @ self.Wo, p=self.dropout_rate, training=training) # also dropout if we're training\n",
    "\n",
    "    @log_io\n",
    "    def weight_splicing(self, Wqkv):\n",
    "        Wq, Wk, Wv = Wqkv.split([self.sa_q_heads * self.sa_head_dim,\n",
    "                                 self.sa_kv_heads * self.sa_head_dim,\n",
    "                                 self.sa_kv_heads * self.sa_head_dim],dim = -1)\n",
    "        return Wq, Wk, Wv\n",
    "\n",
    "    @log_io\n",
    "    def RoPE(self, xq, xk):\n",
    "        xq = RoPE(xq, self.sa_head_dim, self.theta)\n",
    "        xk = RoPE(xk, self.sa_head_dim, self.theta)\n",
    "        return xq, xk\n",
    "\n",
    "    @log_io\n",
    "    def match_headcount(self, xk, xv):\n",
    "        xk = torch.repeat_interleave(xk, self.num_queries_per_kv, dim=2)\n",
    "        xv = torch.repeat_interleave(xv, self.num_queries_per_kv, dim=2)\n",
    "        return xk, xv\n",
    "\n",
    "    @log_io\n",
    "    def attend(self, xq, xk):\n",
    "        return torch.matmul(xq, xk.transpose(2, 3)) * (self.sa_head_dim ** -0.5)\n",
    "        \n",
    "    @log_io\n",
    "    def apply_mask(self, logits, input_len):\n",
    "        return torch.where(self.mask[..., :input_len, :input_len].expand_as(logits),\n",
    "                           logits,\n",
    "                           torch.tensor(-1e30, device=logits.device, dtype=logits.dtype))\n",
    "    \n",
    "    @log_io\n",
    "    def calc_output(self, logits, xv, batch_size, input_len, training):\n",
    "        # Applies softmax to the logits to obtain attention probabilities\n",
    "        scores = F.softmax(logits, dim=-1)\n",
    "\n",
    "        # also applies dropout if we're training\n",
    "        scores = F.dropout(scores, p=self.dropout_rate, training=training)\n",
    "        \n",
    "        # Computes the weighted sum of values based on the attention scores to obtain the output of the attention mechanism.\n",
    "        output = scores @ xv # [batch_size, n_local_heads, input_len, sa_head_dim]\n",
    "\n",
    "        # Reshapes the attention output to match the expected output dimensions, combining the heads back into the hidden dimension.\n",
    "        return output.transpose(1, 2).contiguous().view(batch_size, input_len, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5e3b57-78fc-4243-81c4-4cbb898f9e27",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## demonstration/debugging\n",
    "I've setup these little snippets after each nn.Module to help you see what's happening and for my own debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf8af24f-0fab-4457-8aca-26f1ecc479b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Entering selfMQA.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 256, 256])\n",
      "\n",
      "==========Entering selfMQA.weight_splicing==========\n",
      "Inputs:\n",
      "Tensor 'Wqkv' shape: torch.Size([256, 256])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([256, 128])\n",
      "Tensor 'output[1]' shape: torch.Size([256, 64])\n",
      "Tensor 'output[2]' shape: torch.Size([256, 64])\n",
      "==========Exiting selfMQA.weight_splicing==========\n",
      "\n",
      "==========Entering selfMQA.RoPE==========\n",
      "Inputs:\n",
      "Tensor 'xq' shape: torch.Size([32, 256, 2, 64])\n",
      "Tensor 'xk' shape: torch.Size([32, 256, 1, 64])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([32, 256, 2, 64])\n",
      "Tensor 'output[1]' shape: torch.Size([32, 256, 1, 64])\n",
      "==========Exiting selfMQA.RoPE==========\n",
      "\n",
      "==========Entering selfMQA.match_headcount==========\n",
      "Inputs:\n",
      "Tensor 'xk' shape: torch.Size([32, 256, 1, 64])\n",
      "Tensor 'xv' shape: torch.Size([32, 256, 1, 64])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([32, 256, 2, 64])\n",
      "Tensor 'output[1]' shape: torch.Size([32, 256, 2, 64])\n",
      "==========Exiting selfMQA.match_headcount==========\n",
      "\n",
      "==========Entering selfMQA.attend==========\n",
      "Inputs:\n",
      "Tensor 'xq' shape: torch.Size([32, 2, 256, 64])\n",
      "Tensor 'xk' shape: torch.Size([32, 2, 256, 64])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 2, 256, 256])\n",
      "==========Exiting selfMQA.attend==========\n",
      "\n",
      "==========Entering selfMQA.apply_mask==========\n",
      "Inputs:\n",
      "Tensor 'logits' shape: torch.Size([32, 2, 256, 256])\n",
      "Integer 'input_len': Value=256\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 2, 256, 256])\n",
      "==========Exiting selfMQA.apply_mask==========\n",
      "\n",
      "==========Entering selfMQA.calc_output==========\n",
      "Inputs:\n",
      "Tensor 'logits' shape: torch.Size([32, 2, 256, 256])\n",
      "Tensor 'xv' shape: torch.Size([32, 2, 256, 64])\n",
      "Integer 'batch_size': Value=32\n",
      "Integer 'input_len': Value=256\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 256, 128])\n",
      "==========Exiting selfMQA.calc_output==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 256, 256])\n",
      "==========Exiting selfMQA.forward==========\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of selfMQA\n",
    "module = selfMQA(config)\n",
    "\n",
    "# Initially, logging is disabled\n",
    "# Enable logging\n",
    "module.enable_logging()\n",
    "\n",
    "### Optionally disabling printing for sub-functions\n",
    "#module.disable_function_logging('weight_splicing')\n",
    "#module.disable_function_logging('RoPE')\n",
    "#module.disable_function_logging('match_headcount')\n",
    "#module.disable_function_logging('attend')\n",
    "#module.disable_function_logging('apply_mask')\n",
    "#module.disable_function_logging('calc_output')\n",
    "\n",
    "# Call the forward method - logging will occur\n",
    "output = module(torch.randn(32,config.max_seq_len,config.embed_dim))#, training=True)\n",
    "\n",
    "# Disable logging. \n",
    "# This isn't actually necessary since we won't be using this object again but that's how you'd do it\n",
    "module.disable_logging()\n",
    "\n",
    "# clearing up ram jic we're training later\n",
    "del module, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8dc236-465c-40a4-9430-5bcbe10789da",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6fc6e8d9-3d0a-44d7-9389-b64414d086eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(LoggingModule):\n",
    "    def __init__(self,\n",
    "                 embed_dim: int,\n",
    "                 mlp_multiplier: int,\n",
    "                 output_dim: int,\n",
    "                 dropout_rate: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.mlp_multiplier = mlp_multiplier\n",
    "        self.hidden_size = embed_dim * mlp_multiplier\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        # the gate, up and down projections\n",
    "        self.gate_proj = nn.Linear(embed_dim, self.hidden_size)\n",
    "        self.up_proj = nn.Linear(embed_dim, self.hidden_size)\n",
    "        self.down_proj = nn.Linear(self.hidden_size, output_dim)\n",
    "        \n",
    "    @log_io\n",
    "    def forward(self, x: torch.Tensor, training: bool = False ) -> torch.Tensor:\n",
    "        output = self.down_proj(F.gelu(self.gate_proj(x)) * self.up_proj(x))\n",
    "        return F.dropout(output, p=self.dropout_rate, training=training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c357e34-cf79-4363-a97f-d96b8a56e837",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## demonstration/debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "410acc17-013b-4a26-bc59-f5780cef9073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Entering MLP.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 256, 256])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 256, 256])\n",
      "==========Exiting MLP.forward==========\n"
     ]
    }
   ],
   "source": [
    "module = MLP(config.embed_dim, config.mlp_multiplier, config.embed_dim, config.dropout_rate)\n",
    "module.enable_logging()\n",
    "output = module(torch.randn(32,config.max_seq_len,config.embed_dim))\n",
    "del module, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9be355-a811-41de-a761-822cd1cf5ad8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "548c6663-41ce-4715-b138-30fe7dfebd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Norm(LoggingModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.eps = config.eps\n",
    "        self.affine = config.norm_affine\n",
    "        self.dropout_rate = config.dropout_rate\n",
    "        self.type = config.norm_type\n",
    "\n",
    "        # Initialize weight and bias parameters for affine transformation\n",
    "        # We start with ones for weight to keep the original scale initially, and zeros for bias.\n",
    "        self.w = nn.Parameter(torch.ones(config.embed_dim))\n",
    "        self.b = nn.Parameter(torch.zeros(config.embed_dim))\n",
    "\n",
    "    @log_io\n",
    "    def forward(self, x: torch.Tensor, training: bool = False) -> torch.Tensor:\n",
    "        # Normalize the input tensor\n",
    "        if self.type == \"CosineNorm\":\n",
    "            x = self.CosineNorm(x)\n",
    "        elif self.type == \"LayerNorm\":\n",
    "            x = self.LayerNorm(x)\n",
    "        else: # defaults to RMSNorm bc that's the most commonly used nowadays\n",
    "            x = self.RMSNorm(x)\n",
    "\n",
    "        if self.affine: # Optionally apply the affine transformation and dropout if we're training\n",
    "            x = F.dropout(x * self.w + self.b, p=self.dropout_rate, training=training)\n",
    "            \n",
    "        return x\n",
    "\n",
    "    @log_io\n",
    "    def CosineNorm(self, x):\n",
    "        # normalize x by dividing by its L2 norm along the last dimension.\n",
    "        # this places x on the unit hypersphere centered at the origin\n",
    "        # Add a small constant to the denominator to avoid division by zero.\n",
    "        return x / torch.norm(x, p=2, dim=-1, keepdim=True).clamp(min=self.eps)\n",
    "\n",
    "    @log_io\n",
    "    def LayerNorm(self, x): # nn.LayerNorm() exists but might as well make it from scratch if we have to do the other two\n",
    "        # normalize x by subtracting by its mean then dividing by its variance\n",
    "        # this places x on a hypersphere of radius sqrt(dimension) centered at the origin\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        return (x - mean) / torch.sqrt(var + self.eps)\n",
    "\n",
    "    @log_io\n",
    "    def RMSNorm(self, x):\n",
    "        # normalize x by dividing by its root-mean-square along the last dimension\n",
    "        # this places x on a hypersphere of radius sqrt(dimension) with no certain center\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5e1ddc-f4a0-42ea-b2a0-629e0115848f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## demonstration/debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ca306ab-41fb-497c-b1a1-4154c141aa22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Entering Norm.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 256, 256])\n",
      "\n",
      "==========Entering Norm.RMSNorm==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 256, 256])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 256, 256])\n",
      "==========Exiting Norm.RMSNorm==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 256, 256])\n",
      "==========Exiting Norm.forward==========\n"
     ]
    }
   ],
   "source": [
    "module = Norm(config)\n",
    "module.enable_logging()\n",
    "\n",
    "### disabling printing for sub-functions\n",
    "#module.disable_function_logging('RMSNorm')\n",
    "#module.disable_function_logging('LayerNorm')\n",
    "#module.disable_function_logging('CosineNorm')\n",
    "\n",
    "output = module(torch.randn(32, config.max_seq_len, config.embed_dim))\n",
    "del module, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f333b374-d14d-4d5f-8913-c36c47a87df7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# crossMQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3606776-86d8-4c94-8573-59babb19de59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class crossMQA(LoggingModule):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.ca_q_heads = config.ca_q_heads\n",
    "        self.ca_kv_heads = config.ca_kv_heads\n",
    "        assert self.ca_q_heads % self.ca_kv_heads == 0\n",
    "        self.num_queries_per_kv = self.ca_q_heads // self.ca_kv_heads\n",
    "        self.embed_dim = config.embed_dim\n",
    "        self.ca_head_dim = config.ca_head_dim\n",
    "        self.sa_head_dim = config.sa_head_dim # used only for an assertion to make sure sizes will fit\n",
    "        self.combine_factor = config.combine_factor # used only for an assertion to make sure sizes will fit\n",
    "        self.theta = config.theta\n",
    "        self.use_RoPE = config.ca_use_RoPE\n",
    "        self.dropout_rate = config.dropout_rate\n",
    "        self.predictive_mask = config.predictive_mask\n",
    "\n",
    "        self.Wqkv = nn.Parameter(torch.Tensor(self.embed_dim, (self.ca_q_heads + 2 * self.ca_kv_heads) * self.ca_head_dim))\n",
    "        nn.init.uniform_(self.Wqkv, -((1 / self.embed_dim) ** 0.5), (1 / self.embed_dim) ** 0.5)\n",
    "        \n",
    "        self.Wo = nn.Parameter(torch.Tensor(self.ca_q_heads * self.ca_head_dim, self.embed_dim))\n",
    "        nn.init.uniform_(self.Wo, -((1 / (self.ca_q_heads * self.ca_head_dim)) ** 0.5), (1 / (self.ca_q_heads * self.ca_head_dim)) ** 0.5)\n",
    "\n",
    "    @log_io\n",
    "    def forward(self, \n",
    "                x: torch.Tensor, # the current level tensor, sometimes a resid state full of tokens & sometimes concepts\n",
    "                c: torch.Tensor, # the upper level tensor, always a resid state full of concept vecs\n",
    "                training: bool = False\n",
    "               ) -> torch.Tensor:\n",
    "        \n",
    "        # Extracts batch size and input sequence length from the hidden states tensor.\n",
    "        batch_size, input_len_x, _ = x.shape\n",
    "        batch_size_c, input_len_c, _ = c.shape\n",
    "        assert batch_size == batch_size_c\n",
    "\n",
    "        # splicing our projection to get the correct sub-matrices\n",
    "        Wq, Wk, Wv = self.weight_splicing(self.Wqkv)\n",
    "\n",
    "        # Applies the linear projection to the hidden state to retrieve our q, k & v projections\n",
    "        xq = F.dropout(x @ Wq, p=self.dropout_rate, training=training) # also applies dropout if we're training\n",
    "        ck = F.dropout(c @ Wk, p=self.dropout_rate, training=training)\n",
    "        cv = F.dropout(c @ Wv, p=self.dropout_rate, training=training)\n",
    "\n",
    "        # Reshapes each of the Q, K, and V tensors to separate the heads and align the dimensions for attention operations.\n",
    "        xq = xq.view(batch_size, -1, self.ca_q_heads, self.ca_head_dim)\n",
    "        ck = ck.view(batch_size, -1, self.ca_kv_heads, self.ca_head_dim)\n",
    "        cv = cv.view(batch_size, -1, self.ca_kv_heads, self.ca_head_dim)\n",
    "\n",
    "        # IF we want to use RoPE (doesn't fully make sense to)\n",
    "        if self.use_RoPE:\n",
    "            expand = input_len_x // input_len_c\n",
    "            ck = ck.repeat_interleave(expand, dim=1) \n",
    "            cv = cv.repeat_interleave(expand, dim=1) # values need to be expanded for their use later on if we do this\n",
    "\n",
    "            # Applies rotary positional embeddings to queries and keys to incorporate positional information.\n",
    "            xq, ck = self.RoPE(xq, ck)\n",
    "\n",
    "        # If the number of KV heads is different from the number of query heads, adjusts keys and values to match the query heads count.\n",
    "        if self.ca_kv_heads != self.ca_q_heads:\n",
    "            ck, cv = self.match_headcount(ck, cv) # [batch_size, input_len, n_local_heads, sa_head_dim]\n",
    "\n",
    "        # Transposes Q, K, and V tensors to align them for the batch matrix multiplication in attention calculation.\n",
    "        xq = xq.transpose(1, 2) # [batch_size, n_local_heads, input_len, ca_head_dim]\n",
    "        ck = ck.transpose(1, 2)\n",
    "        cv = cv.transpose(1, 2)\n",
    "\n",
    "        # Calculates attention scores by performing a batch matrix multiplication between queries and keys, followed by scaling.\n",
    "        logits = self.attend(xq, ck) # [batch_size, n_local_heads, input_len, input_len]\n",
    "        \n",
    "        # Optionally applies the upper-triangular mask to the attention logits\n",
    "        if self.predictive_mask:\n",
    "            logits = self.apply_mask(logits, input_len_x, input_len_c)\n",
    "\n",
    "        # applies values to get final output\n",
    "        output = self.calc_output(logits, cv, batch_size, input_len_x, training)\n",
    "\n",
    "        # Applies the final linear projection to the attention output, mapping it back to d_i. \n",
    "        return F.dropout(output @ self.Wo, p=self.dropout_rate, training=training) # and dropout if we're training\n",
    "\n",
    "    @log_io\n",
    "    def weight_splicing(self, Wqkv):\n",
    "        Wq, Wk, Wv = Wqkv.split([self.ca_q_heads * self.ca_head_dim,\n",
    "                                 self.ca_kv_heads * self.ca_head_dim,\n",
    "                                 self.ca_kv_heads * self.ca_head_dim],dim = -1)\n",
    "        return Wq, Wk, Wv\n",
    "        \n",
    "    @log_io\n",
    "    def RoPE(self, xq, xk):\n",
    "        xq = RoPE(xq, self.ca_head_dim, self.theta)\n",
    "        xk = RoPE(xk, self.ca_head_dim, self.theta)\n",
    "        return xq, xk\n",
    "\n",
    "    @log_io\n",
    "    def match_headcount(self, xk, xv):\n",
    "        xk = torch.repeat_interleave(xk, self.num_queries_per_kv, dim=2)\n",
    "        xv = torch.repeat_interleave(xv, self.num_queries_per_kv, dim=2)\n",
    "        return xk, xv\n",
    "\n",
    "    @log_io\n",
    "    def attend(self, xq, ck):\n",
    "        return torch.matmul(xq, ck.transpose(2, 3)) * (self.ca_head_dim ** -0.5)\n",
    "        \n",
    "    @log_io\n",
    "    def apply_mask(self, logits, input_len_x, input_len_c):\n",
    "        self.mask = torch.triu(torch.ones((config.max_seq_len, input_len_c), dtype=torch.uint8)\n",
    "                                  ).view(1, 1, config.max_seq_len, input_len_c).to(dtype=torch.bool)\n",
    "        \n",
    "        return torch.where(self.mask[..., :input_len_x, :input_len_c].expand_as(logits),\n",
    "                           logits,\n",
    "                           torch.tensor(-1e30, device=logits.device, dtype=logits.dtype))\n",
    "    \n",
    "    @log_io\n",
    "    def calc_output(self, logits, cv, batch_size, input_len_x, training):\n",
    "        # Applies softmax to the logits to obtain attention probabilities\n",
    "        scores = F.softmax(logits, dim=-1)\n",
    "\n",
    "        # also applies dropout if we're training\n",
    "        scores = F.dropout(scores, p=self.dropout_rate, training=training)\n",
    "        \n",
    "        # Computes the weighted sum of values based on the attention scores to obtain the output of the attention mechanism.\n",
    "        output = scores @ cv # [batch_size, n_local_heads, input_len, sa_head_dim]\n",
    "\n",
    "        # Reshapes the attention output to match the expected output dimensions, combining the heads back into the hidden dimension.\n",
    "        return output.transpose(1, 2).contiguous().view(batch_size, input_len_x, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2731e8f-023c-49de-8de8-d2b42d2833c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## demonstration/debugging\n",
    "\n",
    "at one point this one had been giving me trouble so here's multiple different config.levels setups for ya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c5f9bf9-d02c-4d46-9070-217a4bbdb1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Entering crossMQA.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 256, 256])\n",
      "Tensor 'c' shape: torch.Size([32, 64, 256])\n",
      "\n",
      "==========Entering crossMQA.weight_splicing==========\n",
      "Inputs:\n",
      "Tensor 'Wqkv' shape: torch.Size([256, 256])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([256, 128])\n",
      "Tensor 'output[1]' shape: torch.Size([256, 64])\n",
      "Tensor 'output[2]' shape: torch.Size([256, 64])\n",
      "==========Exiting crossMQA.weight_splicing==========\n",
      "\n",
      "==========Entering crossMQA.match_headcount==========\n",
      "Inputs:\n",
      "Tensor 'xk' shape: torch.Size([32, 64, 1, 64])\n",
      "Tensor 'xv' shape: torch.Size([32, 64, 1, 64])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([32, 64, 2, 64])\n",
      "Tensor 'output[1]' shape: torch.Size([32, 64, 2, 64])\n",
      "==========Exiting crossMQA.match_headcount==========\n",
      "\n",
      "==========Entering crossMQA.attend==========\n",
      "Inputs:\n",
      "Tensor 'xq' shape: torch.Size([32, 2, 256, 64])\n",
      "Tensor 'ck' shape: torch.Size([32, 2, 64, 64])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 2, 256, 64])\n",
      "==========Exiting crossMQA.attend==========\n",
      "\n",
      "==========Entering crossMQA.calc_output==========\n",
      "Inputs:\n",
      "Tensor 'logits' shape: torch.Size([32, 2, 256, 64])\n",
      "Tensor 'cv' shape: torch.Size([32, 2, 64, 64])\n",
      "Integer 'batch_size': Value=32\n",
      "Integer 'input_len_x': Value=256\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 256, 128])\n",
      "==========Exiting crossMQA.calc_output==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 256, 256])\n",
      "==========Exiting crossMQA.forward==========\n"
     ]
    }
   ],
   "source": [
    "hold1 = config.levels\n",
    "config.levels = 2\n",
    "hold2 = config.predictive_mask\n",
    "config.predictive_mask = False\n",
    "module = crossMQA(config)\n",
    "module.enable_logging()\n",
    "\n",
    "### Optionally disabling printing for sub-functions\n",
    "#module.disable_function_logging('weight_splicing')\n",
    "#module.disable_function_logging('RoPE')\n",
    "#module.disable_function_logging('match_headcount')\n",
    "#module.disable_function_logging('attend')\n",
    "#module.disable_function_logging('apply_mask')\n",
    "#module.disable_function_logging('calc_output')\n",
    "\n",
    "x0 = torch.randn(32, config.max_seq_len, config.embed_dim)\n",
    "c1 = torch.randn(32, config.max_seq_len // config.combine_factor, config.embed_dim)\n",
    "output = module(x0, c1)\n",
    "config.levels = hold1\n",
    "config.predictive_mask = hold2\n",
    "del hold1, hold2, module, x0, c1, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "129b2d43-eaf2-4c87-a186-61199e76d9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Entering crossMQA.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 64, 256])\n",
      "Tensor 'c' shape: torch.Size([32, 16, 256])\n",
      "\n",
      "==========Entering crossMQA.weight_splicing==========\n",
      "Inputs:\n",
      "Tensor 'Wqkv' shape: torch.Size([256, 256])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([256, 128])\n",
      "Tensor 'output[1]' shape: torch.Size([256, 64])\n",
      "Tensor 'output[2]' shape: torch.Size([256, 64])\n",
      "==========Exiting crossMQA.weight_splicing==========\n",
      "\n",
      "==========Entering crossMQA.match_headcount==========\n",
      "Inputs:\n",
      "Tensor 'xk' shape: torch.Size([32, 16, 1, 64])\n",
      "Tensor 'xv' shape: torch.Size([32, 16, 1, 64])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([32, 16, 2, 64])\n",
      "Tensor 'output[1]' shape: torch.Size([32, 16, 2, 64])\n",
      "==========Exiting crossMQA.match_headcount==========\n",
      "\n",
      "==========Entering crossMQA.attend==========\n",
      "Inputs:\n",
      "Tensor 'xq' shape: torch.Size([32, 2, 64, 64])\n",
      "Tensor 'ck' shape: torch.Size([32, 2, 16, 64])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 2, 64, 16])\n",
      "==========Exiting crossMQA.attend==========\n",
      "\n",
      "==========Entering crossMQA.calc_output==========\n",
      "Inputs:\n",
      "Tensor 'logits' shape: torch.Size([32, 2, 64, 16])\n",
      "Tensor 'cv' shape: torch.Size([32, 2, 16, 64])\n",
      "Integer 'batch_size': Value=32\n",
      "Integer 'input_len_x': Value=64\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 64, 128])\n",
      "==========Exiting crossMQA.calc_output==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 64, 256])\n",
      "==========Exiting crossMQA.forward==========\n"
     ]
    }
   ],
   "source": [
    "hold1 = config.levels\n",
    "config.levels = 3\n",
    "hold2 = config.predictive_mask\n",
    "config.predictive_mask = False\n",
    "module = crossMQA(config)\n",
    "module.enable_logging()\n",
    "\n",
    "### Optionally disabling printing for sub-functions\n",
    "#module.disable_function_logging('weight_splicing')\n",
    "#module.disable_function_logging('RoPE')\n",
    "#module.disable_function_logging('match_headcount')\n",
    "#module.disable_function_logging('attend')\n",
    "#module.disable_function_logging('apply_mask')\n",
    "#module.disable_function_logging('calc_output')\n",
    "\n",
    "c1 = torch.randn(32, config.max_seq_len // (config.combine_factor**1), config.embed_dim)\n",
    "c2 = torch.randn(32, config.max_seq_len // (config.combine_factor**2), config.embed_dim)\n",
    "output = module(c1, c2)\n",
    "config.levels = hold1\n",
    "config.predictive_mask = hold2\n",
    "del hold1, hold2, module, c1, c2, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5af750-9441-43c2-af37-728c7323ad34",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## working on crossMQA predictive mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bf42671a-87a7-4c0d-97b8-de0e2744fe98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [0., 1., 1.],\n",
       "        [0., 1., 1.],\n",
       "        [0., 1., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original tensor using torch.triu on a 3x3 tensor of ones\n",
    "original_tensor = torch.triu(torch.ones(3, 3))\n",
    "\n",
    "input_len = 8\n",
    "# Expand the tensor by duplicating each row twice more\n",
    "expanded_tensor = original_tensor.repeat_interleave(3, dim=0)\n",
    "\n",
    "out = expanded_tensor[:input_len,:]\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0a693737-aa3b-4bd1-aee1-0c115eff9092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Entering crossMQA.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 256, 256])\n",
      "Tensor 'c' shape: torch.Size([32, 64, 256])\n",
      "\n",
      "==========Entering crossMQA.weight_splicing==========\n",
      "Inputs:\n",
      "Tensor 'Wqkv' shape: torch.Size([256, 256])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([256, 128])\n",
      "Tensor 'output[1]' shape: torch.Size([256, 64])\n",
      "Tensor 'output[2]' shape: torch.Size([256, 64])\n",
      "==========Exiting crossMQA.weight_splicing==========\n",
      "\n",
      "==========Entering crossMQA.match_headcount==========\n",
      "Inputs:\n",
      "Tensor 'xn' shape: torch.Size([32, 64, 1, 64])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 64, 2, 64])\n",
      "==========Exiting crossMQA.match_headcount==========\n",
      "\n",
      "==========Entering crossMQA.match_headcount==========\n",
      "Inputs:\n",
      "Tensor 'xn' shape: torch.Size([32, 64, 1, 64])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 64, 2, 64])\n",
      "==========Exiting crossMQA.match_headcount==========\n",
      "\n",
      "==========Entering crossMQA.attend==========\n",
      "Inputs:\n",
      "Tensor 'xq' shape: torch.Size([32, 2, 256, 64])\n",
      "Tensor 'ck' shape: torch.Size([32, 2, 64, 64])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 2, 256, 64])\n",
      "==========Exiting crossMQA.attend==========\n",
      "\n",
      "==========Entering crossMQA.apply_mask==========\n",
      "Inputs:\n",
      "Tensor 'logits' shape: torch.Size([32, 2, 256, 64])\n",
      "Integer 'input_len': Value=256\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (64) must match the existing size (256) at non-singleton dimension 3.  Target sizes: [32, 2, 256, 64].  Tensor sizes: [1, 1, 256, 256]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m x0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m32\u001b[39m, config\u001b[38;5;241m.\u001b[39mmax_seq_len, config\u001b[38;5;241m.\u001b[39membed_dim)\n\u001b[1;32m     17\u001b[0m c1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m32\u001b[39m, config\u001b[38;5;241m.\u001b[39mmax_seq_len \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m config\u001b[38;5;241m.\u001b[39mcombo, config\u001b[38;5;241m.\u001b[39membed_dim)\n\u001b[0;32m---> 18\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m config\u001b[38;5;241m.\u001b[39mlevels \u001b[38;5;241m=\u001b[39m hold1\n\u001b[1;32m     20\u001b[0m config\u001b[38;5;241m.\u001b[39mpredictive_mask \u001b[38;5;241m=\u001b[39m hold2\n",
      "File \u001b[0;32m~/Documents/next-concept-predictor/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/next-concept-predictor/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 39\u001b[0m, in \u001b[0;36mlog_io.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(arg_names, arg_values):\n\u001b[1;32m     37\u001b[0m     log_item(value, name)\n\u001b[0;32m---> 39\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOutputs:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtuple\u001b[39m):\n",
      "Cell \u001b[0;32mIn[54], line 90\u001b[0m, in \u001b[0;36mcrossMQA.forward\u001b[0;34m(self, x, c, training)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Optionally applies the upper-triangular mask to the attention logits\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 90\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_len_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# applies values to get final output\u001b[39;00m\n\u001b[1;32m     93\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalc_output(logits, cv, batch_size, input_len_x, training)\n",
      "Cell \u001b[0;32mIn[3], line 39\u001b[0m, in \u001b[0;36mlog_io.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(arg_names, arg_values):\n\u001b[1;32m     37\u001b[0m     log_item(value, name)\n\u001b[0;32m---> 39\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOutputs:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtuple\u001b[39m):\n",
      "Cell \u001b[0;32mIn[54], line 121\u001b[0m, in \u001b[0;36mcrossMQA.apply_mask\u001b[0;34m(self, logits, input_len)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;129m@log_io\u001b[39m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_mask\u001b[39m(\u001b[38;5;28mself\u001b[39m, logits, input_len):\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mwhere(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43minput_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43minput_len\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    122\u001b[0m                        logits,\n\u001b[1;32m    123\u001b[0m                        torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1e30\u001b[39m, device\u001b[38;5;241m=\u001b[39mlogits\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mlogits\u001b[38;5;241m.\u001b[39mdtype))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (64) must match the existing size (256) at non-singleton dimension 3.  Target sizes: [32, 2, 256, 64].  Tensor sizes: [1, 1, 256, 256]"
     ]
    }
   ],
   "source": [
    "hold1 = config.levels\n",
    "config.levels = 2\n",
    "hold2 = config.predictive_mask\n",
    "config.predictive_mask = True\n",
    "module = crossMQA(config)\n",
    "module.enable_logging()\n",
    "\n",
    "### Optionally disabling printing for sub-functions\n",
    "#module.disable_function_logging('weight_splicing')\n",
    "#module.disable_function_logging('RoPE')\n",
    "#module.disable_function_logging('match_headcount')\n",
    "#module.disable_function_logging('attend')\n",
    "#module.disable_function_logging('apply_mask')\n",
    "#module.disable_function_logging('calc_output')\n",
    "\n",
    "x0 = torch.randn(32, config.max_seq_len, config.embed_dim)\n",
    "c1 = torch.randn(32, config.max_seq_len // config.combine_factor, config.embed_dim)\n",
    "output = module(x0, c1)\n",
    "config.levels = hold1\n",
    "config.predictive_mask = hold2\n",
    "del hold1, hold2, module, x0, c1, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5719f276-53b7-4c66-b4da-04231f8d6c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc8505c5-d859-4e48-bdd9-e88746a3f88f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Layer\n",
    "\n",
    "we implement cross-attention inbetween self-attention and MLP like is done in Attention is All You Need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ca50177-b795-4a4e-8535-c5f00e161206",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(LoggingModule):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pre_self_mqa_norm = Norm(config)\n",
    "        self.self_mqa = selfMQA(config)\n",
    "        self.post_self_mqa_norm = Norm(config)\n",
    "        \n",
    "        self.pre_cross_mqa_x_norm = Norm(config)\n",
    "        self.pre_cross_mqa_c_norm = Norm(config)\n",
    "        self.cross_mqa = crossMQA(config)\n",
    "        self.post_cross_mqa_norm = Norm(config)\n",
    "        \n",
    "        self.pre_mlp_norm = Norm(config)\n",
    "        self.mlp = MLP(config.embed_dim, config.mlp_multiplier, config.embed_dim, config.dropout_rate)\n",
    "        self.post_mlp_norm = Norm(config)\n",
    "\n",
    "    @log_io\n",
    "    def forward(self, \n",
    "                x: torch.Tensor,\n",
    "                c: torch.Tensor = None,\n",
    "                training: bool = False,\n",
    "               ) -> torch.Tensor:\n",
    "        x = x + self.self_mqa_connection(x, training)\n",
    "        if c is not None:\n",
    "            x = x + self.cross_mqa_connection(x, c, training)\n",
    "        x = x + self.mlp_connection(x, training)\n",
    "        return x\n",
    "\n",
    "    @log_io\n",
    "    def self_mqa_connection(self, x, training):\n",
    "        return self.post_self_mqa_norm(self.self_mqa(self.pre_self_mqa_norm(x, training), training), training)\n",
    "\n",
    "    @log_io\n",
    "    def cross_mqa_connection(self, x, c, training):\n",
    "        return self.post_cross_mqa_norm(self.cross_mqa(self.pre_cross_mqa_x_norm(x, training), \n",
    "                                                       self.pre_cross_mqa_c_norm(c, training), training), training)\n",
    "\n",
    "    @log_io\n",
    "    def mlp_connection(self, x, training):\n",
    "        return self.post_mlp_norm(self.mlp(self.pre_mlp_norm(x, training), training), training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711f6f6d-9997-4196-a88e-b8bf31196c85",
   "metadata": {},
   "source": [
    "## demonstration/debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6a6444-0211-4adb-9a17-7cfe21d140ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### no predictive mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2a1bcb4-8464-4452-ac40-c6eb35fbf223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Entering Layer.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 256, 256])\n",
      "\n",
      "==========Entering Layer.self_mqa_connection==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 256, 256])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 256, 256])\n",
      "==========Exiting Layer.self_mqa_connection==========\n",
      "\n",
      "==========Entering Layer.mlp_connection==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 256, 256])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 256, 256])\n",
      "==========Exiting Layer.mlp_connection==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 256, 256])\n",
      "==========Exiting Layer.forward==========\n"
     ]
    }
   ],
   "source": [
    "module = Layer(config)\n",
    "module.enable_logging()\n",
    "\n",
    "### enabling printing for sub-modules\n",
    "#module.pre_self_mqa_norm.enable_logging()\n",
    "#module.self_mqa.enable_logging()\n",
    "#module.post_self_mqa_norm.enable_logging()\n",
    "#module.pre_cross_mqa_norm.enable_logging()\n",
    "#module.cross_mqa.enable_logging()\n",
    "#module.post_cross_mqa_norm.enable_logging()\n",
    "#module.pre_mlp_norm.enable_logging()\n",
    "#module.mlp.enable_logging()\n",
    "#module.post_mlp_norm.enable_logging()\n",
    "\n",
    "### disabling printing for sub-functions\n",
    "#module.disable_function_logging('self_mqa_connection')\n",
    "#module.disable_function_logging('cross_mqa_connection')\n",
    "#module.disable_function_logging('mlp_connection')\n",
    "\n",
    "output = module(torch.randn(32,config.max_seq_len,config.embed_dim))\n",
    "del module, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7853cc93-c55e-40fd-aa38-1a2a1f1f230f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Entering Layer.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 256, 256])\n",
      "Tensor 'c' shape: torch.Size([32, 64, 256])\n",
      "\n",
      "==========Entering Layer.self_mqa_connection==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 256, 256])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 256, 256])\n",
      "==========Exiting Layer.self_mqa_connection==========\n",
      "\n",
      "==========Entering Layer.cross_mqa_connection==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 256, 256])\n",
      "Tensor 'c' shape: torch.Size([32, 64, 256])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 256, 256])\n",
      "==========Exiting Layer.cross_mqa_connection==========\n",
      "\n",
      "==========Entering Layer.mlp_connection==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 256, 256])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 256, 256])\n",
      "==========Exiting Layer.mlp_connection==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 256, 256])\n",
      "==========Exiting Layer.forward==========\n"
     ]
    }
   ],
   "source": [
    "hold = config.predictive_mask\n",
    "config.predictive_mask = False\n",
    "module = Layer(config)\n",
    "module.enable_logging()\n",
    "\n",
    "### enabling printing for sub-modules\n",
    "#module.pre_self_mqa_norm.enable_logging()\n",
    "#module.self_mqa.enable_logging()\n",
    "#module.post_self_mqa_norm.enable_logging()\n",
    "#module.pre_cross_mqa_norm.enable_logging()\n",
    "#module.cross_mqa.enable_logging()\n",
    "#module.post_cross_mqa_norm.enable_logging()\n",
    "#module.pre_mlp_norm.enable_logging()\n",
    "#module.mlp.enable_logging()\n",
    "#module.post_mlp_norm.enable_logging()\n",
    "\n",
    "### disabling printing for sub-functions\n",
    "#module.disable_function_logging('self_mqa_connection')\n",
    "#module.disable_function_logging('cross_mqa_connection')\n",
    "#module.disable_function_logging('mlp_connection')\n",
    "\n",
    "x = torch.randn(32, config.max_seq_len, config.embed_dim)\n",
    "c = torch.randn(32, config.max_seq_len // config.combine_factor, config.embed_dim)\n",
    "output = module(x, c)\n",
    "config.predictive_mask = hold\n",
    "del hold, module, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f415280-2108-4a7a-a518-a59d64e98463",
   "metadata": {},
   "source": [
    "### prolly need to do more debugging once predictive mask works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d11636-7958-4e38-91a4-00ec0d5949f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ed7034-9822-4cfa-93a6-cde136e95203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07b97877-4427-4bfb-84ad-47bd4f570d5e",
   "metadata": {},
   "source": [
    "# ------- BOOKMARK --------\n",
    "so i think in order to set up the predictive mask i need to pipe the padding token through everything instead of having it initialize inside the original module. bc it needs to go at the beginning of even the token sequence in order to keep everything lined up for attention. and bc this whole module thing needs to be used in Body during inference. or maybe i can just adjust the predictive mask to account for this? that might be easier than having to change the current code\n",
    "\n",
    "ugh so not only that but now i also just realized that my pooling was originally super simple when it was just sum but now with the MLP & linear reshape options i've gotta make it define the concepts recursively in order for the input shape of the MLP and linear to work uuuugh. Rn the concept matchup mechanism just doesn't work during inference, meaning the model has to work entirely off of raw regression output.\n",
    "\n",
    "also for inf it'd be cool if i could select not just based on cosine similarity but also/instead based on MSE or MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27dbad8-dca3-4e88-a75a-7feec206a775",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# embedding vector combination function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f090e3eb-9251-49c0-ab54-b1bcd362e69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SumModule(LoggingModule): \n",
    "    @log_io\n",
    "    def forward(self, x):\n",
    "        return x.sum(dim=2)\n",
    "class MeanModule(LoggingModule):    \n",
    "    @log_io\n",
    "    def forward(self, x):\n",
    "        return x.mean(dim=2)\n",
    "class MaxModule(LoggingModule):    \n",
    "    @log_io\n",
    "    def forward(self, x):\n",
    "        return x.max(dim=2).values\n",
    "class ReshapeModule(LoggingModule):\n",
    "    @log_io\n",
    "    def forward(self, x):\n",
    "        return x.reshape(x.shape[0], x.shape[1], -1)\n",
    "\n",
    "class CombineEmbeddings(LoggingModule):\n",
    "    def __init__(self, config: Config, padding_vector: torch.Tensor):\n",
    "        super().__init__()\n",
    "        self.embed_dim = config.embed_dim\n",
    "        self.combine_factor = config.combine_factor\n",
    "        #self.padding_vector = nn.Parameter(torch.zeros(config.embed_dim), requires_grad=True)\n",
    "        self.padding_vector = padding_vector\n",
    "\n",
    "        # Initialize operation chain\n",
    "        self.operation_chain = nn.Sequential()\n",
    "        operation_map = {\n",
    "            \"sum\": SumModule(), # cannot go before or after reshape\n",
    "            \"mean\": MeanModule(), # cannot go before or after reshape\n",
    "            \"max\": MaxModule(), # cannot go before or after reshape\n",
    "            \"norm\": Norm(config), # cannot go before or after reshape\n",
    "            \"linear_post_reshape\": nn.Linear(config.embed_dim * config.combine_factor, config.embed_dim), # must go after reshape\n",
    "            \"linear\": nn.Linear(config.embed_dim, config.embed_dim), # cannot go after reshape\n",
    "            \"mlp_post_reshape\": MLP(config.embed_dim * config.combine_factor, config.mlp_multiplier, config.embed_dim, config.dropout_rate), # must go after reshape\n",
    "            \"mlp\": MLP(config.embed_dim, config.mlp_multiplier, config.embed_dim, config.dropout_rate), # cannot go after reshape\n",
    "            \"reshape\": ReshapeModule()}\n",
    "        for op in config.combine_type.split(\"->\"):\n",
    "            if op in operation_map:\n",
    "                self.operation_chain.add_module(op, operation_map[op])\n",
    "            else:\n",
    "                raise ValueError(f\"Pooling operation {op} is not a valid operation\")\n",
    "    \n",
    "    @log_io\n",
    "    def forward(self, tensor, combine_factor):\n",
    "        b, t, d = tensor.shape\n",
    "\n",
    "        # Calculate the necessary amount of padding\n",
    "        remainder = t % combine_factor\n",
    "        padding_needed = 0 if remainder == 0 else combine_factor - remainder\n",
    "        \n",
    "        if padding_needed > 0:\n",
    "            # Replicate the padding vector the necessary number of times\n",
    "            padding = self.padding_vector.repeat(padding_needed, 1).unsqueeze(0).expand(b, -1, -1)\n",
    "            tensor = torch.cat([padding, tensor], dim=1)\n",
    "        \n",
    "        # Update t after padding\n",
    "        t_padded = t + padding_needed\n",
    "        \n",
    "        # Reshape the tensor to group 'combine_factor' entries along the t dimension\n",
    "        reshaped_tensor = tensor.view(b, t_padded // combine_factor, combine_factor, d)\n",
    "        \n",
    "        # the actual combination operation\n",
    "        combined_tensor = self.operation_chain(reshaped_tensor)\n",
    "        assert combined_tensor.shape[0] == b, f\"b={b}; pooling operation order is invalid. output shape: {combined_tensor.shape}\"\n",
    "        assert combined_tensor.shape[1] == t_padded // self.combine_factor, f\"t={t_padded // self.combine_factor}; pooling operation order is invalid. output shape: {combined_tensor.shape}\"\n",
    "        assert combined_tensor.shape[2] == self.embed_dim, f\"d={self.embed_dim}; pooling operation order is invalid. output shape: {combined_tensor.shape}\"\n",
    "        \n",
    "        return combined_tensor\n",
    "\n",
    "    @log_io\n",
    "    def create_single_concept(self, tensor): # for use in Body.concept_matchup()\n",
    "        assert tensor.shape[1] % self.combine_factor == 0, f'Body.concept_matchup.create_single_concept is attempting to build a concept with wrong size of sub-concepts {tensor.shape[1]}'\n",
    "        return self.operation_chain(tensor.unsqueeze(1))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2121c0df-211e-4e88-a590-c37a8d0c369d",
   "metadata": {},
   "source": [
    "## demonstration/debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa9bdab-75e5-41aa-8a53-1427eb9c82af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### testing different pooling types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffa025f0-b379-4e56-b7d4-d9833a354a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Entering CombineEmbeddings.forward==========\n",
      "Inputs:\n",
      "Tensor 'tensor' shape: torch.Size([32, 256, 128])\n",
      "Integer 'combine_factor': Value=4\n",
      "\n",
      "==========Entering MLP.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 64, 4, 128])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 64, 4, 128])\n",
      "==========Exiting MLP.forward==========\n",
      "\n",
      "==========Entering SumModule.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 64, 4, 128])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 64, 128])\n",
      "==========Exiting SumModule.forward==========\n",
      "\n",
      "==========Entering Norm.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 64, 128])\n",
      "\n",
      "==========Entering Norm.RMSNorm==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 64, 128])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 64, 128])\n",
      "==========Exiting Norm.RMSNorm==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 64, 128])\n",
      "==========Exiting Norm.forward==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 64, 128])\n",
      "==========Exiting CombineEmbeddings.forward==========\n"
     ]
    }
   ],
   "source": [
    "hold1 = config.combine_type\n",
    "hold2 = config.combine_factor\n",
    "config.combine_type = 'mlp->sum->mlp->norm'\n",
    "config.combine_factor = 4\n",
    "padding_vector = nn.Parameter(torch.zeros(config.embed_dim), requires_grad=True)\n",
    "module = CombineEmbeddings(config, padding_vector)\n",
    "\n",
    "module.enable_logging()\n",
    "module.operation_chain.sum.enable_logging()\n",
    "#module.operation_chain.mean.enable_logging()\n",
    "#module.operation_chain.max.enable_logging()\n",
    "module.operation_chain.norm.enable_logging()\n",
    "#module.operation_chain.reshape.enable_logging()\n",
    "module.operation_chain.mlp.enable_logging()\n",
    "#module.operation_chain.mlp_post_reshape.enable_logging()\n",
    "\n",
    "x = torch.randn(32, config.max_seq_len, config.embed_dim)\n",
    "output = module(x, config.combine_factor)\n",
    "config.combine_type = hold1\n",
    "config.combine_factor = hold2\n",
    "del padding_vector, module, hold1, hold2, x, output\n",
    "module = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8d33d20-820f-4044-a42e-636f638add1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Entering CombineEmbeddings.forward==========\n",
      "Inputs:\n",
      "Tensor 'tensor' shape: torch.Size([32, 256, 128])\n",
      "Integer 'combine_factor': Value=2\n",
      "\n",
      "==========Entering ReshapeModule.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 128, 2, 128])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 256])\n",
      "==========Exiting ReshapeModule.forward==========\n",
      "\n",
      "==========Entering MLP.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 128, 256])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 128])\n",
      "==========Exiting MLP.forward==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 128])\n",
      "==========Exiting CombineEmbeddings.forward==========\n"
     ]
    }
   ],
   "source": [
    "hold1 = config.combine_type\n",
    "hold2 = config.combine_factor\n",
    "config.combine_type = 'reshape->mlp_post_reshape'\n",
    "config.combine_factor = 2\n",
    "padding_vector = nn.Parameter(torch.zeros(config.embed_dim), requires_grad=True)\n",
    "module = CombineEmbeddings(config, padding_vector)\n",
    "\n",
    "module.enable_logging()\n",
    "#module.operation_chain.sum.enable_logging()\n",
    "#module.operation_chain.mean.enable_logging()\n",
    "#module.operation_chain.max.enable_logging()\n",
    "#module.operation_chain.norm.enable_logging()\n",
    "module.operation_chain.reshape.enable_logging()\n",
    "#module.operation_chain.mlp.enable_logging()\n",
    "module.operation_chain.mlp_post_reshape.enable_logging()\n",
    "\n",
    "x = torch.randn(32, config.max_seq_len, config.embed_dim)\n",
    "output = module(x, config.combine_factor)\n",
    "config.combine_type = hold1\n",
    "config.combine_factor = hold2\n",
    "del padding_vector, module, hold1, hold2, x, output\n",
    "module = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16e0a66-4760-4ef1-ae85-704c5a741e16",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### off-lengths that'll require padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4fea04e-c127-4285-97b2-821ea9c5d206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Entering CombineEmbeddings.forward==========\n",
      "Inputs:\n",
      "Tensor 'tensor' shape: torch.Size([32, 255, 128])\n",
      "Integer 'combine_factor': Value=2\n",
      "\n",
      "==========Entering ReshapeModule.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 128, 2, 128])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 256])\n",
      "==========Exiting ReshapeModule.forward==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 128])\n",
      "==========Exiting CombineEmbeddings.forward==========\n"
     ]
    }
   ],
   "source": [
    "hold1 = config.combine_type\n",
    "hold2 = config.combine_factor\n",
    "config.combine_type = 'reshape->linear_post_reshape'\n",
    "config.combine_factor = 2\n",
    "padding_vector = nn.Parameter(torch.zeros(config.embed_dim), requires_grad=True)\n",
    "module = CombineEmbeddings(config, padding_vector)\n",
    "\n",
    "module.enable_logging()\n",
    "#module.operation_chain.sum.enable_logging()\n",
    "#module.operation_chain.mean.enable_logging()\n",
    "#module.operation_chain.max.enable_logging()\n",
    "#module.operation_chain.norm.enable_logging()\n",
    "module.operation_chain.reshape.enable_logging()\n",
    "#module.operation_chain.mlp.enable_logging()\n",
    "#module.operation_chain.mlp_post_reshape.enable_logging()\n",
    "\n",
    "x = torch.randn(32, config.max_seq_len-1, config.embed_dim)\n",
    "output = module(x, config.combine_factor)\n",
    "config.combine_type = hold1\n",
    "config.combine_factor = hold2\n",
    "del padding_vector, module, hold1, hold2, x, output\n",
    "module = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5feb9312-5f35-4837-ba14-3c2aaee12a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.4719,  0.6294, -0.4890, -1.5304,  0.2810,  0.2024, -0.0567, -0.2281])\n",
      "\n",
      "==========Entering CombineEmbeddings.forward==========\n",
      "Inputs:\n",
      "Tensor 'tensor' shape: torch.Size([32, 253, 128])\n",
      "Integer 'combine_factor': Value=4\n",
      "\n",
      "==========Entering MaxModule.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 64, 4, 128])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 64, 128])\n",
      "==========Exiting MaxModule.forward==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 64, 128])\n",
      "==========Exiting CombineEmbeddings.forward==========\n",
      "tensor([0.4719, 0.6294, 0.0000, 0.0000, 0.2810, 0.2024, 0.0000, 0.0000],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "hold1 = config.combine_type\n",
    "hold2 = config.combine_factor\n",
    "config.combine_type = 'max'\n",
    "config.combine_factor = 4\n",
    "padding_vector = nn.Parameter(torch.zeros(config.embed_dim), requires_grad=True)\n",
    "module = CombineEmbeddings(config, padding_vector)\n",
    "\n",
    "module.enable_logging()\n",
    "#module.operation_chain.sum.enable_logging()\n",
    "#module.operation_chain.mean.enable_logging()\n",
    "module.operation_chain.max.enable_logging()\n",
    "#module.operation_chain.norm.enable_logging()\n",
    "#module.operation_chain.reshape.enable_logging()\n",
    "#module.operation_chain.mlp.enable_logging()\n",
    "#module.operation_chain.mlp_post_reshape.enable_logging()\n",
    "\n",
    "x = torch.randn(32, config.max_seq_len-3, config.embed_dim)\n",
    "print(x[0,0,:8])\n",
    "output = module(x, config.combine_factor)\n",
    "print(output[0,0,:8])\n",
    "config.combine_type = hold1\n",
    "config.combine_factor = hold2\n",
    "del padding_vector, module, hold1, hold2, x, output\n",
    "module = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aaf67558-5fa5-42a9-9642-5bb358db7c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Entering CombineEmbeddings.forward==========\n",
      "Inputs:\n",
      "Tensor 'tensor' shape: torch.Size([32, 252, 128])\n",
      "Integer 'combine_factor': Value=4\n",
      "\n",
      "==========Entering MeanModule.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 63, 4, 128])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 63, 128])\n",
      "==========Exiting MeanModule.forward==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 63, 128])\n",
      "==========Exiting CombineEmbeddings.forward==========\n"
     ]
    }
   ],
   "source": [
    "hold1 = config.combine_type\n",
    "hold2 = config.combine_factor\n",
    "config.combine_type = 'mean'\n",
    "config.combine_factor = 4\n",
    "padding_vector = nn.Parameter(torch.zeros(config.embed_dim), requires_grad=True)\n",
    "module = CombineEmbeddings(config, padding_vector)\n",
    "\n",
    "module.enable_logging()\n",
    "#module.operation_chain.sum.enable_logging()\n",
    "module.operation_chain.mean.enable_logging()\n",
    "#module.operation_chain.max.enable_logging()\n",
    "#module.operation_chain.norm.enable_logging()\n",
    "#module.operation_chain.reshape.enable_logging()\n",
    "#module.operation_chain.mlp.enable_logging()\n",
    "#module.operation_chain.mlp_post_reshape.enable_logging()\n",
    "\n",
    "x = torch.randn(32, config.max_seq_len-4, config.embed_dim)\n",
    "output = module(x, config.combine_factor)\n",
    "config.combine_type = hold1\n",
    "config.combine_factor = hold2\n",
    "del padding_vector, module, hold1, hold2, x, output\n",
    "module = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31560096-350b-4353-b18c-c16218afc305",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### This is how Body.concept_matchup() will use this class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "827f22a6-6821-41e1-bae2-588b2f031eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Entering CombineEmbeddings.create_single_concept==========\n",
      "Inputs:\n",
      "Tensor 'tensor' shape: torch.Size([32, 4, 256])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 1, 256])\n",
      "==========Exiting CombineEmbeddings.create_single_concept==========\n"
     ]
    }
   ],
   "source": [
    "hold1 = config.combine_type\n",
    "hold2 = config.combine_factor\n",
    "config.combine_type = 'mlp->sum->mlp->norm'\n",
    "config.combine_factor = 4\n",
    "padding_vector = nn.Parameter(torch.zeros(config.embed_dim), requires_grad=True)\n",
    "module = CombineEmbeddings(config, padding_vector)\n",
    "\n",
    "module.enable_logging()\n",
    "#module.operation_chain.sum.enable_logging()\n",
    "#module.operation_chain.mean.enable_logging()\n",
    "#module.operation_chain.max.enable_logging()\n",
    "#module.operation_chain.norm.enable_logging()\n",
    "#module.operation_chain.reshape.enable_logging()\n",
    "#module.operation_chain.mlp.enable_logging()\n",
    "#module.operation_chain.mlp_post_reshape.enable_logging()\n",
    "\n",
    "x = torch.randn(32, config.combine_factor, config.embed_dim)\n",
    "output = module.create_single_concept(x)\n",
    "config.combine_type = hold1\n",
    "config.combine_factor = hold2\n",
    "del padding_vector, module, hold1, hold2, x, output\n",
    "module = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6309588b-baa8-400e-9599-1cee9cbe3ef6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aca9d16d-1a18-413e-a549-7b79ddebe13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to prevent the warning statement from printing hella times\n",
    "#cvec_warning = False\n",
    "\n",
    "class Body(LoggingModule):\n",
    "    def __init__(self, config: Config, embedding: torch.Tensor, embedding_combiner: LoggingModule):\n",
    "        super().__init__()\n",
    "        self.max_seq_len = config.max_seq_len\n",
    "        self.combine_factor = config.combine_factor\n",
    "        self.levels = config.levels\n",
    "        self.embedding = embedding\n",
    "        \n",
    "        # Initialize a sequence of Layer instances as specified by the number of hidden layers in the config\n",
    "        self.layers = nn.ModuleList(Layer(config) for _ in range(config.num_layers))\n",
    "\n",
    "        # initialize the final normalizations to stabilize residual outputs before output layer\n",
    "        self.final_norms = nn.ModuleList(Norm(config) for _ in range(config.levels))\n",
    "\n",
    "        # initialize the concept output layers as either full MLPs or simple linear layers. maybe later make an option to make them shared?\n",
    "        if config.output_layer == 'mlp':\n",
    "            self.concept_output_layers = nn.ModuleList(MLP(config.embed_dim,\n",
    "                                                           config.mlp_multiplier,\n",
    "                                                           config.embed_dim,\n",
    "                                                           config.dropout_rate) for _ in range(config.levels-1))\n",
    "        else: # defaults to a linear layer\n",
    "            self.concept_output_layers = nn.ModuleList(nn.Linear(config.embed_dim, config.embed_dim) for _ in range(config.levels-1))\n",
    "\n",
    "        # gets used during inference for the matchup to concept embedding vectors\n",
    "        self.concept_creator = embedding_combiner\n",
    "        \n",
    "    @log_io\n",
    "    def forward(self,\n",
    "                x0s: Tuple[torch.Tensor], # ordered from tokens -> highest concepts\n",
    "                targets: Tuple[torch.Tensor] = None,\n",
    "                cvec_samples: int = None,\n",
    "                cvec_greedy: bool = False,\n",
    "                cvec_temp: float = 1.0,\n",
    "               ) -> Tuple[torch.Tensor]:\n",
    "        return self.forward_training(x0s, targets) if targets is not None else self.forward_inference(x0s, cvec_samples, cvec_greedy, cvec_temp)\n",
    "        \n",
    "    @log_io\n",
    "    def forward_training(self,\n",
    "                         x0s: Tuple[torch.Tensor], # ordered from tokens -> highest concepts\n",
    "                         targets: Tuple[torch.Tensor],\n",
    "                        ) -> Tuple[torch.Tensor]:\n",
    "        # initiate tuple to hold final residual states\n",
    "        xfs = ()\n",
    "        # iterate through model levels, starting from highest level concepts & ending at lowest level tokens\n",
    "        for i, x in enumerate(reversed(x0s)): # reversed() makes us start at highest level\n",
    "\n",
    "            if i == 0:\n",
    "                # if we're dealing with the highest level concepts, there's nothing to cross-attend to\n",
    "                x = self.layers_loop(x, i, c = None, training = True)\n",
    "            else:\n",
    "                # the current level x will cross-attend to the higher level c\n",
    "                x = self.layers_loop(x, i, c = targets[-i], training = True)\n",
    "                \n",
    "            # every level gets its own norm? sure why not. only does anything if config.norm_affine == True\n",
    "            x = self.final_norms[i](x, training = True)\n",
    "\n",
    "            if i == len(x0s)-1:\n",
    "                # if we're dealing with the token residual state then we use the transposed embedding matrix as our output\n",
    "                x = x @ self.embedding.t()\n",
    "            else:\n",
    "                # all the concept levels get their own output layer to help with their regression goal\n",
    "                x = self.concept_output_layers[i](x) # not setting training=True because nn.Linear doesn't know what that is\n",
    "            \n",
    "            # add the final residual state of the level to our tuple\n",
    "            xfs += (x,)\n",
    "                \n",
    "        return xfs # return all final residual states\n",
    "        \n",
    "    @log_io\n",
    "    def forward_inference(self,\n",
    "                          x0s: Tuple[torch.Tensor], # ordered from tokens -> highest concepts\n",
    "                          cvec_samples: int = None,\n",
    "                          cvec_greedy: bool = False,\n",
    "                          cvec_temp: float = 1.0,\n",
    "                         ) -> Tuple[torch.Tensor]:\n",
    "        # initiate tuple to hold final residual states\n",
    "        xfs = ()\n",
    "        # iterate through model levels, starting from highest level concepts & ending at lowest level tokens\n",
    "        for i, x in enumerate(reversed(x0s)): # reversed() makes us start at highest level\n",
    "            \n",
    "            # if we're dealing with a concept level, then we need to fill in entire concept sequences for lower level to attend to. for token level we only want one pass\n",
    "            if i != len(x0s)-1:\n",
    "\n",
    "                # figuring out how many times we need to run this concept level in order for it to be usable for cross-attention to the layer below\n",
    "                effective_max_seq_len = self.max_seq_len // (self.combine_factor ** (self.levels-1-i))\n",
    "                assert x.shape[1] <= effective_max_seq_len, f'at level {i} a too-long sequence ({x.shape[1]} vs {effective_max_seq_len}) made it to Body'\n",
    "                extra_runs = effective_max_seq_len - x.shape[1]\n",
    "\n",
    "                # if extra_runs == 0 then this will only run once\n",
    "                for k in range(extra_runs+1): \n",
    "                    \n",
    "                    # run through layers. xfs[i-1] are the higher level concepts to pay attention to\n",
    "                    x_ = self.layers_loop(x, i, training=False) if i == 0 else self.layers_loop(x, i, xfs[i-1], training=False)\n",
    "                    # splice out the final prediction\n",
    "                    x_ = x_[:,-1,:]\n",
    "                    # normalize it\n",
    "                    x_ = self.final_norms[i](x_, training=False)\n",
    "                    # our concept output layer\n",
    "                    x_ = self.concept_output_layers[i](x_)\n",
    "                    # either select most similar concept vectors to be appended to the sequence or use the raw regression output\n",
    "                    c = self.concept_matchup(x_, cvec_samples, cvec_greedy, cvec_temp) if cvec_samples is not None else x_\n",
    "                    # append to x\n",
    "                    x = torch.concat([x, c.unsqueeze(1)], dim=1)\n",
    "\n",
    "                # this should only trim off one concept vector from the beginning of the sequence at most\n",
    "                x = x[:,-effective_max_seq_len:,:]\n",
    "                \n",
    "            else: # if we're dealing with the token layer rather than a concept layer, we only want to run once\n",
    "                # run the model\n",
    "                x = self.layers_loop(x, i, xfs[i-1], training=False)\n",
    "                # normalize\n",
    "                x = self.final_norms[i](x, training=False)\n",
    "                # the output layer is the transposed embedding matrix\n",
    "                x = x @ self.embedding.t()\n",
    "            \n",
    "            # add the final residual state of the level to our tuple\n",
    "            xfs += (x,)\n",
    "            \n",
    "        return xfs # we could return just xfs[-1] since it's inference but i have a feeling i'll want to analyze the concepts later\n",
    "\n",
    "    @log_io\n",
    "    def layers_loop(self, x: torch.Tensor,\n",
    "                    i: int,\n",
    "                    c: torch.Tensor = None,\n",
    "                    training : bool = False,\n",
    "                   ) -> torch.Tensor:\n",
    "        \n",
    "        # Iteratively process the input through each Layer of the model\n",
    "        for layer in self.layers:\n",
    "\n",
    "            # run through layers. at i==0 there's no higher level to attend to\n",
    "            x = layer(x, training=training) if i == 0 else layer(x, c, training)\n",
    "                \n",
    "        return x\n",
    "\n",
    "    @log_io # NOT CURRENTLY WORKING\n",
    "    def concept_matchup(self,\n",
    "                        c: torch.Tensor,\n",
    "                        cvec_samples: int,\n",
    "                        cvec_greedy: bool,\n",
    "                        cvec_temp: float,\n",
    "                        ) -> torch.Tensor:\n",
    "        global cvec_warning\n",
    "        batch_size, d = c.size()\n",
    "        vocab_size = self.embedding.size(0)\n",
    "    \n",
    "        # Batch cosine similarity\n",
    "        # Reshape c: (batch_size x 1 x embedding_dim)\n",
    "        # Reshape embedding: (1 x vocab_size x embedding_dim)\n",
    "        # Resulting similarity: (batch_size x vocab_size)\n",
    "        token_similarities = F.cosine_similarity(c.unsqueeze(1), self.embedding.unsqueeze(0), dim=-1)\n",
    "        \n",
    "        # how many tokens will we sample to build up our chosen concept vector?\n",
    "        if cvec_samples is None:\n",
    "            cvec_samples = self.combine_factor ** (self.levels-1)\n",
    "            if (cvec_warning == False) or (cvec_warning is None):\n",
    "                print(f\"cvec_samples not defined. defaulting to highest level's minimum size: combo**(levels-1) = {cvec_samples}\")\n",
    "                cvec_warning = True\n",
    "        assert cvec_samples >= self.combine_factor ** (self.levels-1), f'cvec_samples = {cvec_samples} needs to be >= self.combine_factor ** (self.levels-1) = {self.combine_factor ** (self.levels-1)}'\n",
    "        \n",
    "        # Select top-k token embeddings for each concept vector\n",
    "        topk_token_indices = torch.topk(token_similarities, k=cvec_samples, dim=1).indices  # (batch_size x sample)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52df12b7-a2fb-419e-8ae7-4edb97c13236",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### old shitty concept matchup code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ee2876-6524-4c25-bfdd-f137d41ade6f",
   "metadata": {},
   "source": [
    "```Python\n",
    "#### OLD shit. not only is it inefficient, but also it's designed to only do sums to get concepts and not use the learnable padding vector\n",
    "    @log_io\n",
    "    def concept_matchup(self,\n",
    "                        c: torch.Tensor,\n",
    "                        cvec_samples: int,\n",
    "                        cvec_greedy: bool,\n",
    "                        cvec_temp: float,\n",
    "                        ) -> torch.Tensor:\n",
    "        global cvec_warning\n",
    "        batch_size, d = c.size()\n",
    "        vocab_size = self.embedding.size(0)\n",
    "        embedding = self.embedding\n",
    "    \n",
    "        # Batch cosine similarity\n",
    "        # Reshape c: (batch_size x 1 x embedding_dim)\n",
    "        # Reshape embedding: (1 x vocab_size x embedding_dim)\n",
    "        # Resulting similarity: (batch_size x vocab_size)\n",
    "        token_similarities = F.cosine_similarity(c.unsqueeze(1), embedding.unsqueeze(0), dim=-1)\n",
    "        \n",
    "        # how many tokens will we sample to build up our chosen concept vector?\n",
    "        if cvec_samples is None:\n",
    "            cvec_samples = self.combine_factor ** (self.levels-1)\n",
    "            if (cvec_warning == False) or (cvec_warning is None):\n",
    "                print(f\"cvec_samples not defined. defaulting to highest level's minimum size: combo**(levels-1) = {cvec_samples}\")\n",
    "                cvec_warning = True\n",
    "        assert cvec_samples >= self.combine_factor ** (self.levels-1), f'cvec_samples = {cvec_samples} needs to be >= self.combine_factor ** (self.levels-1) = {self.combine_factor ** (self.levels-1)}'\n",
    "        \n",
    "        # Select top-k token embeddings for each concept vector\n",
    "        topk_token_indices = torch.topk(token_similarities, k=cvec_samples, dim=1).indices  # (batch_size x sample)\n",
    "    \n",
    "        # Generate concept embeddings for each set of top-k token embeddings\n",
    "        concept_embeddings_batch = []\n",
    "        X_sizes_batch = []\n",
    "        for i in range(batch_size):\n",
    "            # Pass the list of indices for each concept\n",
    "            concept_embeddings, X_sizes = self.create_concept_embeddings(embedding, \n",
    "                                                                         [topk_token_indices[i].tolist()])\n",
    "            concept_embeddings_batch.append(concept_embeddings.squeeze(0))  # Remove the extra batch dimension\n",
    "            X_sizes_batch.append(X_sizes)\n",
    "    \n",
    "        # Convert list of tensors to a tensor\n",
    "        concept_embeddings_batch = torch.stack(concept_embeddings_batch)  # (batch_size x max_X_size x d)\n",
    "    \n",
    "        # Calculate concept similarities for each concept in the batch\n",
    "        concept_similarities_batch = F.cosine_similarity(c.unsqueeze(1), concept_embeddings_batch, dim=-1)\n",
    "    \n",
    "        # Select the best matching concept embedding for each concept vector in the batch\n",
    "        if cvec_greedy:\n",
    "            best_concept_indices = concept_similarities_batch.argmax(dim=1)\n",
    "            matched_concepts = concept_embeddings_batch[torch.arange(batch_size), best_concept_indices]\n",
    "        else:\n",
    "            # Apply softmax with temperature and sample\n",
    "            topk_concept_probs = F.softmax(concept_similarities_batch / cvec_temp, dim=1)\n",
    "            concept_topk_idx = torch.multinomial(topk_concept_probs, num_samples=1).squeeze(1)\n",
    "            matched_concepts = concept_embeddings_batch[torch.arange(batch_size), concept_topk_idx]\n",
    "    \n",
    "        return matched_concepts\n",
    "\n",
    "    @log_io\n",
    "    def create_concept_embeddings(self, E: torch.Tensor, indices: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Create concept embeddings for a batch of indices.\n",
    "    \n",
    "        E: Embedding matrix (vocab_size x embedding_dim)\n",
    "        indices: A list of lists of indices (batch_size x num_indices)\n",
    "        \"\"\"\n",
    "        batch_size = len(indices)\n",
    "        d = E.size(1)\n",
    "        X_sizes = [(len(ind) - 1) * len(ind) // 2 for ind in indices]\n",
    "        max_X_size = max(X_sizes)\n",
    "        X = torch.empty((batch_size, max_X_size, d), dtype=E.dtype)\n",
    "        \n",
    "        # this could prolly be done way more efficiently with tensor operations\n",
    "        for b in range(batch_size):\n",
    "            count = 0\n",
    "            for i in range(len(indices[b])):\n",
    "                for j in range(i + 1, len(indices[b])):\n",
    "                    X[b, count] = E[indices[b][i]] + E[indices[b][j]]\n",
    "                    count += 1\n",
    "            # Padding the rest if necessary\n",
    "            if count < max_X_size:\n",
    "                X[b, count:] = torch.zeros((max_X_size - count, d))\n",
    "        \n",
    "        # X_sizes is not useful rn but i think it may be later when we switch away from TinyShakespeare\n",
    "        # and over to data that actually has variable sequence lengths\n",
    "        return X, X_sizes\n",
    "### optimized version of old shit. still prolly useless\n",
    "    @log_io\n",
    "    def optimized_concept_matchup(c: torch.Tensor, embedding: torch.Tensor, cvec_samples: int, levels: int, combo: int, cvec_greedy: bool, cvec_temp: float):\n",
    "        batch_size, d = c.size()\n",
    "        vocab_size = embedding.size(0)\n",
    "        embedding = embedding\n",
    "\n",
    "        # Batch cosine similarity\n",
    "        # Reshape c: (batch_size x 1 x d)\n",
    "        # Reshape embedding: (1 x vocab_size x d)\n",
    "        # Resulting similarity: (batch_size x vocab_size)\n",
    "        token_similarities = F.cosine_similarity(c.unsqueeze(1), embedding.unsqueeze(0), dim=-1)\n",
    "    \n",
    "        # how many tokens will we sample to build up our chosen concept vector?\n",
    "        if cvec_samples is None:\n",
    "            cvec_samples = self.combine_factor ** (self.levels-1)\n",
    "            if (cvec_warning == False) or (cvec_warning is None):\n",
    "                print(f\"cvec_samples not defined. defaulting to highest level's minimum size: combo**(levels-1) = {cvec_samples}\")\n",
    "                cvec_warning = True\n",
    "        assert cvec_samples >= self.combine_factor ** (self.levels-1), f'cvec_samples = {cvec_samples} needs to be >= self.combine_factor ** (self.levels-1) = {self.combine_factor ** (self.levels-1)}'\n",
    "        \n",
    "        # Get top-k token indices and values for each concept vector\n",
    "        topk_token_indices = torch.topk(token_similarities, k=cvec_samples, dim=1).indices  # (batch_size x sample)\n",
    "    \n",
    "        # Create concept embeddings for the entire batch\n",
    "        # Repeat embedding to match the batch size and reshape for gathering\n",
    "        expanded_embeddings = embedding.repeat(batch_size, 1, 1) # batch_size x vocab_size x d)???\n",
    "        gathered_embeddings = torch.gather(expanded_embeddings, 1, topk_token_indices.unsqueeze(2).expand(-1, -1, d))\n",
    "    \n",
    "        # Compute sum of embeddings for each pair to create concept embeddings\n",
    "        # Reshape to (batch_size, cvec_samples, cvec_samples, d) for pairwise addition\n",
    "        concept_embeddings = gathered_embeddings.unsqueeze(2) + gathered_embeddings.unsqueeze(1)\n",
    "        concept_embeddings = concept_embeddings.reshape(batch_size, cvec_samples ** 2, d)\n",
    "    \n",
    "        # Calculate concept similarities\n",
    "        concept_similarities = F.cosine_similarity(c.unsqueeze(1), concept_embeddings, dim=-1)\n",
    "    \n",
    "        # Select the best matching concept embedding\n",
    "        if cvec_greedy:\n",
    "            best_concept_indices = concept_similarities.argmax(dim=1)\n",
    "            matched_concepts = concept_embeddings[torch.arange(batch_size), best_concept_indices]\n",
    "        else:\n",
    "            # Apply softmax with temperature and sample\n",
    "            topk_concept_probs = F.softmax(concept_similarities / cvec_temp, dim=1)\n",
    "            concept_topk_idx = torch.multinomial(topk_concept_probs, num_samples=1).squeeze(1)\n",
    "            matched_concepts = concept_embeddings[torch.arange(batch_size), concept_topk_idx]\n",
    "    \n",
    "        return matched_concepts\n",
    "\n",
    "    @log_io\n",
    "    def optimized_create_concept_embeddings(E: torch.Tensor, indices: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Create concept embeddings for a batch of indices in a vectorized manner.\n",
    "    \n",
    "        E: Embedding matrix (vocab_size x embedding_dim)\n",
    "        indices: A list of lists of indices (batch_size x num_indices)\n",
    "        \"\"\"\n",
    "        batch_size = len(indices)\n",
    "        max_indices = max(len(ind) for ind in indices)\n",
    "        d = E.size(1)\n",
    "    \n",
    "        # Expand E to match the batch size and max indices\n",
    "        expanded_E = E.unsqueeze(0).expand(batch_size, -1, -1)  # (batch_size, vocab_size, d)\n",
    "    \n",
    "        # Create an index tensor for gathering\n",
    "        index_tensor = torch.zeros((batch_size, max_indices), dtype=torch.long)\n",
    "        for i, ind in enumerate(indices):\n",
    "            index_tensor[i, :len(ind)] = torch.tensor(ind, dtype=torch.long)\n",
    "    \n",
    "        # Gather embeddings according to the indices\n",
    "        gathered_embeddings = torch.gather(expanded_E, 1, index_tensor.unsqueeze(2).expand(-1, -1, d))\n",
    "    \n",
    "        # Calculate pairwise sums of the embeddings\n",
    "        pairwise_sums = gathered_embeddings.unsqueeze(2) + gathered_embeddings.unsqueeze(1)\n",
    "        # Remove self-summation pairs and duplicates (upper triangular part without diagonal)\n",
    "        concept_embeddings = pairwise_sums.triu(1)\n",
    "    \n",
    "        # Reshape and remove zero rows (due to the upper triangular operation and varying lengths)\n",
    "        concept_embeddings = concept_embeddings.reshape(batch_size, max_indices * max_indices, d)\n",
    "        non_zero_rows = concept_embeddings.abs().sum(dim=2) != 0\n",
    "        concept_embeddings = torch.stack([concept_embeddings[i][non_zero_rows[i]] for i in range(batch_size)])\n",
    "    \n",
    "        return concept_embeddings\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3ec6ea-e11d-43b7-86e6-5e12844b97d6",
   "metadata": {},
   "source": [
    "## demonstrations/debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2258a4-fce2-4d5b-8467-7377c955ff2b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c69f50b2-daf8-4933-af0a-1293fa6b6438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Entering Body.forward_training==========\n",
      "Inputs:\n",
      "Tuple 'x0s':\n",
      "    Tensor 'x0s[0]' shape: torch.Size([32, 256, 128])\n",
      "    Tensor 'x0s[1]' shape: torch.Size([32, 64, 128])\n",
      "Tuple 'targets':\n",
      "    Tensor 'targets[0]' shape: torch.Size([32, 256, 128])\n",
      "    Tensor 'targets[1]' shape: torch.Size([32, 64, 128])\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 64, 128])\n",
      "Integer 'i': Value=0\n",
      "Other-type 'c': Type=NoneType, Value=None\n",
      "Integer 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 64, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 256, 128])\n",
      "Integer 'i': Value=1\n",
      "Tensor 'c' shape: torch.Size([32, 64, 128])\n",
      "Integer 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 256, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([32, 64, 128])\n",
      "Tensor 'output[1]' shape: torch.Size([32, 256, 128])\n",
      "==========Exiting Body.forward_training==========\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # first let's do 2 levels training\n",
    "    embedder = nn.Embedding(config.vocab_size, config.embed_dim)\n",
    "    padding_vector = nn.Parameter(torch.zeros(config.embed_dim), requires_grad=True)\n",
    "    embedding_combiner = CombineEmbeddings(config, padding_vector)\n",
    "    hold = config.levels\n",
    "    config.levels = 2\n",
    "    module = Body(config, embedder.weight, embedding_combiner)\n",
    "    module.enable_logging()\n",
    "    \n",
    "    ### enabling logging for sub-modules\n",
    "    #module.layers[0].enable_logging()\n",
    "    #module.final_norms[0].enable_logging()\n",
    "    \n",
    "    ### disabling logging for sub-functions\n",
    "    module.disable_function_logging('forward')\n",
    "    #module.disable_function_logging('forward_training')\n",
    "    #module.disable_function_logging('forward_inference')\n",
    "    #module.disable_function_logging('layers_loop')\n",
    "    #module.disable_function_logging('concept_matchup')\n",
    "    #module.disable_function_logging('create_concept_embeddings')\n",
    "    \n",
    "    x = torch.randn(32, config.max_seq_len, config.embed_dim)\n",
    "    c = torch.randn(32, config.max_seq_len // config.combine_factor, config.embed_dim)\n",
    "    x0s = (x,c)\n",
    "    targets = (x + torch.randn_like(x), c + torch.randn_like(c))\n",
    "    output = module(x0s, targets)\n",
    "    config.levels = hold\n",
    "del embedder, embedding_combiner, hold, module, x, c, x0s, targets, output\n",
    "embedder, embedding_combiner, module = None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed95ade0-d798-42b8-bc15-6ba416239b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Entering Body.forward_training==========\n",
      "Inputs:\n",
      "Tuple 'x0s':\n",
      "    Tensor 'x0s[0]' shape: torch.Size([32, 256, 128])\n",
      "    Tensor 'x0s[1]' shape: torch.Size([32, 64, 128])\n",
      "    Tensor 'x0s[2]' shape: torch.Size([32, 16, 128])\n",
      "Tuple 'targets':\n",
      "    Tensor 'targets[0]' shape: torch.Size([32, 256, 128])\n",
      "    Tensor 'targets[1]' shape: torch.Size([32, 64, 128])\n",
      "    Tensor 'targets[2]' shape: torch.Size([32, 16, 128])\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 16, 128])\n",
      "Integer 'i': Value=0\n",
      "Other-type 'c': Type=NoneType, Value=None\n",
      "Integer 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 16, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 64, 128])\n",
      "Integer 'i': Value=1\n",
      "Tensor 'c' shape: torch.Size([32, 16, 128])\n",
      "Integer 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 64, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 256, 128])\n",
      "Integer 'i': Value=2\n",
      "Tensor 'c' shape: torch.Size([32, 64, 128])\n",
      "Integer 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 256, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([32, 16, 128])\n",
      "Tensor 'output[1]' shape: torch.Size([32, 64, 128])\n",
      "Tensor 'output[2]' shape: torch.Size([32, 256, 128])\n",
      "==========Exiting Body.forward_training==========\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # 3 levels training\n",
    "    embedder = nn.Embedding(config.vocab_size, config.embed_dim)\n",
    "    padding_vector = nn.Parameter(torch.zeros(config.embed_dim), requires_grad=True)\n",
    "    embedding_combiner = CombineEmbeddings(config, padding_vector)\n",
    "    hold = config.levels\n",
    "    config.levels = 3\n",
    "    module = Body(config, embedder.weight, embedding_combiner)\n",
    "    module.enable_logging()\n",
    "    \n",
    "    ### enabling logging for sub-modules\n",
    "    #module.layers[0].enable_logging()\n",
    "    #module.final_norms[0].enable_logging()\n",
    "    \n",
    "    ### disabling logging for sub-functions\n",
    "    module.disable_function_logging('forward')\n",
    "    #module.disable_function_logging('forward_training')\n",
    "    #module.disable_function_logging('forward_inference')\n",
    "    #module.disable_function_logging('layers_loop')\n",
    "    #module.disable_function_logging('concept_matchup')\n",
    "    #module.disable_function_logging('create_concept_embeddings')\n",
    "    \n",
    "    x0 = torch.randn(32, config.max_seq_len // (config.combine_factor**0), config.embed_dim)\n",
    "    c1 = torch.randn(32, config.max_seq_len // (config.combine_factor**1), config.embed_dim)\n",
    "    c2 = torch.randn(32, config.max_seq_len // (config.combine_factor**2), config.embed_dim)\n",
    "    x0s = (x0, c1, c2)\n",
    "    targets = (x0 + torch.randn_like(x0), c1 + torch.randn_like(c1), c2 + torch.randn_like(c2))\n",
    "    output = module(x0s, targets)\n",
    "    config.levels = hold\n",
    "del embedder, embedding_combiner, hold, module, x0, c1, c2, x0s, targets, output\n",
    "embedder, embedding_combiner, module = None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea569681-7086-4569-a733-e37ba76422d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Entering Body.forward_training==========\n",
      "Inputs:\n",
      "Tuple 'x0s':\n",
      "    Tensor 'x0s[0]' shape: torch.Size([32, 256, 128])\n",
      "    Tensor 'x0s[1]' shape: torch.Size([32, 64, 128])\n",
      "    Tensor 'x0s[2]' shape: torch.Size([32, 16, 128])\n",
      "    Tensor 'x0s[3]' shape: torch.Size([32, 4, 128])\n",
      "Tuple 'targets':\n",
      "    Tensor 'targets[0]' shape: torch.Size([32, 256, 128])\n",
      "    Tensor 'targets[1]' shape: torch.Size([32, 64, 128])\n",
      "    Tensor 'targets[2]' shape: torch.Size([32, 16, 128])\n",
      "    Tensor 'targets[3]' shape: torch.Size([32, 4, 128])\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 4, 128])\n",
      "Integer 'i': Value=0\n",
      "Other-type 'c': Type=NoneType, Value=None\n",
      "Integer 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 4, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 16, 128])\n",
      "Integer 'i': Value=1\n",
      "Tensor 'c' shape: torch.Size([32, 4, 128])\n",
      "Integer 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 16, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 64, 128])\n",
      "Integer 'i': Value=2\n",
      "Tensor 'c' shape: torch.Size([32, 16, 128])\n",
      "Integer 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 64, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 256, 128])\n",
      "Integer 'i': Value=3\n",
      "Tensor 'c' shape: torch.Size([32, 64, 128])\n",
      "Integer 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 256, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([32, 4, 128])\n",
      "Tensor 'output[1]' shape: torch.Size([32, 16, 128])\n",
      "Tensor 'output[2]' shape: torch.Size([32, 64, 128])\n",
      "Tensor 'output[3]' shape: torch.Size([32, 256, 128])\n",
      "==========Exiting Body.forward_training==========\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # 4 levels training\n",
    "    embedder = nn.Embedding(config.vocab_size, config.embed_dim)\n",
    "    padding_vector = nn.Parameter(torch.zeros(config.embed_dim), requires_grad=True)\n",
    "    embedding_combiner = CombineEmbeddings(config, padding_vector)\n",
    "    hold = config.levels\n",
    "    config.levels = 4\n",
    "    module = Body(config, embedder.weight, embedding_combiner)\n",
    "    module.enable_logging()\n",
    "    \n",
    "    ### enabling logging for sub-modules\n",
    "    #module.layers[0].enable_logging()\n",
    "    #module.final_norms[0].enable_logging()\n",
    "    \n",
    "    ### disabling logging for sub-functions\n",
    "    module.disable_function_logging('forward')\n",
    "    #module.disable_function_logging('forward_training')\n",
    "    #module.disable_function_logging('forward_inference')\n",
    "    #module.disable_function_logging('layers_loop')\n",
    "    #module.disable_function_logging('concept_matchup')\n",
    "    #module.disable_function_logging('create_concept_embeddings')\n",
    "    \n",
    "    x0 = torch.randn(32, config.max_seq_len // (config.combine_factor**0), config.embed_dim)\n",
    "    c1 = torch.randn(32, config.max_seq_len // (config.combine_factor**1), config.embed_dim)\n",
    "    c2 = torch.randn(32, config.max_seq_len // (config.combine_factor**2), config.embed_dim)\n",
    "    c3 = torch.randn(32, config.max_seq_len // (config.combine_factor**3), config.embed_dim)\n",
    "    x0s = (x0, c1, c2, c3)\n",
    "    targets = (x0 + torch.randn_like(x0), c1 + torch.randn_like(c1), c2 + torch.randn_like(c2), c3 + torch.randn_like(c3))\n",
    "    output = module(x0s, targets)\n",
    "    config.levels = hold\n",
    "del embedder, embedding_combiner, hold, module, x0, c1, c2, c3, x0s, targets, output\n",
    "embedder, embedding_combiner, module = None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04c038c-176d-43ad-8135-9925a7eb239d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### inference w/out concept matchup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f232db0e-ab15-4477-a966-4f04ea021b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Entering Body.forward==========\n",
      "Inputs:\n",
      "Tuple 'x0s':\n",
      "    Tensor 'x0s[0]' shape: torch.Size([32, 240, 128])\n",
      "    Tensor 'x0s[1]' shape: torch.Size([32, 60, 128])\n",
      "Other-type 'targets': Type=NoneType, Value=None\n",
      "\n",
      "==========Entering Body.forward_inference==========\n",
      "Inputs:\n",
      "Tuple 'x0s':\n",
      "    Tensor 'x0s[0]' shape: torch.Size([32, 240, 128])\n",
      "    Tensor 'x0s[1]' shape: torch.Size([32, 60, 128])\n",
      "Other-type 'cvec_samples': Type=NoneType, Value=None\n",
      "Integer 'cvec_greedy': Value=False\n",
      "Float 'cvec_temp': Value=1.0\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 60, 128])\n",
      "Integer 'i': Value=0\n",
      "Integer 'c': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 60, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 61, 128])\n",
      "Integer 'i': Value=0\n",
      "Integer 'c': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 61, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 62, 128])\n",
      "Integer 'i': Value=0\n",
      "Integer 'c': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 62, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 63, 128])\n",
      "Integer 'i': Value=0\n",
      "Integer 'c': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 63, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 64, 128])\n",
      "Integer 'i': Value=0\n",
      "Integer 'c': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 64, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 240, 128])\n",
      "Integer 'i': Value=1\n",
      "Tensor 'c' shape: torch.Size([32, 64, 128])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 240, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([32, 64, 128])\n",
      "Tensor 'output[1]' shape: torch.Size([32, 240, 128])\n",
      "==========Exiting Body.forward_inference==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([32, 64, 128])\n",
      "Tensor 'output[1]' shape: torch.Size([32, 240, 128])\n",
      "==========Exiting Body.forward==========\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # now 2 levels partial sequence length, so like we're doing inference\n",
    "    # our partial sequence will always be a clean interval of config.combine_factor because Model.create_x0s() uses CombineEmbeddings() to make the intervals clean\n",
    "    embedder = nn.Embedding(config.vocab_size, config.embed_dim)\n",
    "    padding_vector = nn.Parameter(torch.zeros(config.embed_dim), requires_grad=True)\n",
    "    embedding_combiner = CombineEmbeddings(config, padding_vector)\n",
    "    hold = config.levels\n",
    "    config.levels = 2\n",
    "    module = Body(config, embedder.weight, embedding_combiner)\n",
    "    module.enable_logging()\n",
    "    \n",
    "    ### enabling logging for sub-modules\n",
    "    #module.layers[0].enable_logging()\n",
    "    #module.final_norms[0].enable_logging()\n",
    "    \n",
    "    ### disabling logging for sub-functions\n",
    "    #module.disable_function_logging('forward')\n",
    "    #module.disable_function_logging('forward_training')\n",
    "    #module.disable_function_logging('forward_inference')\n",
    "    #module.disable_function_logging('layers_loop')\n",
    "    #module.disable_function_logging('concept_matchup')\n",
    "    module.disable_function_logging('create_concept_embeddings') # rn this one is hella inefficient using a for loop over batch so not fun to print\n",
    "    \n",
    "    x = torch.randn(32, config.max_seq_len - (config.combine_factor**2), config.embed_dim)\n",
    "    c = torch.randn(32, (config.max_seq_len // config.combine_factor) - config.combine_factor, config.embed_dim)\n",
    "    x0s = (x,c)\n",
    "    output = module(x0s, cvec_samples = None)\n",
    "    config.levels = hold\n",
    "del embedder, embedding_combiner, hold, module, x, c, x0s, output\n",
    "embedder, embedding_combiner, module = None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ca300b23-878a-43af-88ab-b0080efa186e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Entering Body.forward==========\n",
      "Inputs:\n",
      "Tuple 'x0s':\n",
      "    Tensor 'x0s[0]' shape: torch.Size([32, 192, 128])\n",
      "    Tensor 'x0s[1]' shape: torch.Size([32, 48, 128])\n",
      "    Tensor 'x0s[2]' shape: torch.Size([32, 12, 128])\n",
      "Other-type 'targets': Type=NoneType, Value=None\n",
      "\n",
      "==========Entering Body.forward_inference==========\n",
      "Inputs:\n",
      "Tuple 'x0s':\n",
      "    Tensor 'x0s[0]' shape: torch.Size([32, 192, 128])\n",
      "    Tensor 'x0s[1]' shape: torch.Size([32, 48, 128])\n",
      "    Tensor 'x0s[2]' shape: torch.Size([32, 12, 128])\n",
      "Other-type 'cvec_samples': Type=NoneType, Value=None\n",
      "Integer 'cvec_greedy': Value=False\n",
      "Float 'cvec_temp': Value=1.0\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 12, 128])\n",
      "Integer 'i': Value=0\n",
      "Integer 'c': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 12, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 13, 128])\n",
      "Integer 'i': Value=0\n",
      "Integer 'c': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 13, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 14, 128])\n",
      "Integer 'i': Value=0\n",
      "Integer 'c': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 14, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 15, 128])\n",
      "Integer 'i': Value=0\n",
      "Integer 'c': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 15, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 16, 128])\n",
      "Integer 'i': Value=0\n",
      "Integer 'c': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 16, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 48, 128])\n",
      "Integer 'i': Value=1\n",
      "Tensor 'c' shape: torch.Size([32, 16, 128])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 48, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 49, 128])\n",
      "Integer 'i': Value=1\n",
      "Tensor 'c' shape: torch.Size([32, 16, 128])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 49, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 50, 128])\n",
      "Integer 'i': Value=1\n",
      "Tensor 'c' shape: torch.Size([32, 16, 128])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 50, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 51, 128])\n",
      "Integer 'i': Value=1\n",
      "Tensor 'c' shape: torch.Size([32, 16, 128])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 51, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 52, 128])\n",
      "Integer 'i': Value=1\n",
      "Tensor 'c' shape: torch.Size([32, 16, 128])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 52, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 53, 128])\n",
      "Integer 'i': Value=1\n",
      "Tensor 'c' shape: torch.Size([32, 16, 128])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 53, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 54, 128])\n",
      "Integer 'i': Value=1\n",
      "Tensor 'c' shape: torch.Size([32, 16, 128])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 54, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 55, 128])\n",
      "Integer 'i': Value=1\n",
      "Tensor 'c' shape: torch.Size([32, 16, 128])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 55, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 56, 128])\n",
      "Integer 'i': Value=1\n",
      "Tensor 'c' shape: torch.Size([32, 16, 128])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 56, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 57, 128])\n",
      "Integer 'i': Value=1\n",
      "Tensor 'c' shape: torch.Size([32, 16, 128])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 57, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 58, 128])\n",
      "Integer 'i': Value=1\n",
      "Tensor 'c' shape: torch.Size([32, 16, 128])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 58, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 59, 128])\n",
      "Integer 'i': Value=1\n",
      "Tensor 'c' shape: torch.Size([32, 16, 128])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 59, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 60, 128])\n",
      "Integer 'i': Value=1\n",
      "Tensor 'c' shape: torch.Size([32, 16, 128])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 60, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 61, 128])\n",
      "Integer 'i': Value=1\n",
      "Tensor 'c' shape: torch.Size([32, 16, 128])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 61, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 62, 128])\n",
      "Integer 'i': Value=1\n",
      "Tensor 'c' shape: torch.Size([32, 16, 128])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 62, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 63, 128])\n",
      "Integer 'i': Value=1\n",
      "Tensor 'c' shape: torch.Size([32, 16, 128])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 63, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 64, 128])\n",
      "Integer 'i': Value=1\n",
      "Tensor 'c' shape: torch.Size([32, 16, 128])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 64, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 192, 128])\n",
      "Integer 'i': Value=2\n",
      "Tensor 'c' shape: torch.Size([32, 64, 128])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 192, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([32, 16, 128])\n",
      "Tensor 'output[1]' shape: torch.Size([32, 64, 128])\n",
      "Tensor 'output[2]' shape: torch.Size([32, 192, 128])\n",
      "==========Exiting Body.forward_inference==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([32, 16, 128])\n",
      "Tensor 'output[1]' shape: torch.Size([32, 64, 128])\n",
      "Tensor 'output[2]' shape: torch.Size([32, 192, 128])\n",
      "==========Exiting Body.forward==========\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # now 3 levels partial sequence length, so like we're doing inference\n",
    "    # our partial sequence will always be a clean interval of config.combine_factor because Model.create_x0s() uses CombineEmbeddings() to make the intervals clean\n",
    "    embedder = nn.Embedding(config.vocab_size, config.embed_dim)\n",
    "    padding_vector = nn.Parameter(torch.zeros(config.embed_dim), requires_grad=True)\n",
    "    embedding_combiner = CombineEmbeddings(config, padding_vector)\n",
    "    hold = config.levels\n",
    "    config.levels = 3\n",
    "    module = Body(config, embedder.weight, embedding_combiner)\n",
    "    module.enable_logging()\n",
    "    \n",
    "    ### enabling logging for sub-modules\n",
    "    #module.layers[0].enable_logging()\n",
    "    #module.final_norms[0].enable_logging()\n",
    "    \n",
    "    ### disabling logging for sub-functions\n",
    "    #module.disable_function_logging('forward')\n",
    "    #module.disable_function_logging('forward_training')\n",
    "    #module.disable_function_logging('forward_inference')\n",
    "    #module.disable_function_logging('layers_loop')\n",
    "    module.disable_function_logging('concept_matchup') # this one is pretty boring and our prints are already long enough\n",
    "    module.disable_function_logging('create_concept_embeddings') # rn this one is hella inefficient using a for loop over batch so not fun to print\n",
    "    \n",
    "    x0 = torch.randn(32, config.max_seq_len // (config.combine_factor ** 0) - (config.combine_factor**3), config.embed_dim)\n",
    "    c1 = torch.randn(32, config.max_seq_len // (config.combine_factor ** 1) - (config.combine_factor**2), config.embed_dim)\n",
    "    c2 = torch.randn(32, config.max_seq_len // (config.combine_factor ** 2) - (config.combine_factor**1), config.embed_dim)\n",
    "    x0s = (x0, c1, c2)\n",
    "    output = module(x0s, cvec_samples = None)\n",
    "    config.levels = hold\n",
    "del embedder, embedding_combiner, hold, module, x0, c1, c2, x0s, output\n",
    "embedder, embedding_combiner, module = None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b424ce0-7662-4907-9a43-6209419bb09c",
   "metadata": {},
   "source": [
    "### infernce w/ matchup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfdc044-222c-497c-bf7e-78f0562bda72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57f3ce31-4b47-4c61-9f96-ebb901c5690a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Concept Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6d7bfbfc-5bd6-4b23-b54e-2601684fe1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConceptLoss(LoggingModule):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__()\n",
    "        self.combine_factor = config.combine_factor\n",
    "        self.levels = config.levels\n",
    "        self.level_loss_weight = config.level_loss_weight\n",
    "\n",
    "        self.MAE_loss = nn.L1Loss() if config.mae_loss else None\n",
    "        self.MSE_loss = nn.MSELoss() if config.mse_loss else None\n",
    "        self.COS_loss = nn.CosineSimilarity(dim=-1, eps=1e-6) if config.cos_loss else None\n",
    "    \n",
    "    @log_io\n",
    "    def forward(self, \n",
    "                xfs: Tuple[torch.Tensor], # xfs are ordered highest concept level -> token level\n",
    "                targets: Tuple[torch.Tensor], # targets are ordered highest concept level -> token level\n",
    "               ) -> torch.Tensor:\n",
    "        # initialize loss value\n",
    "        concept_loss = torch.tensor(0.0)\n",
    "        \n",
    "        # iterate through all concept-embedding layers and calculate loss\n",
    "        for i in range(self.levels - 1):\n",
    "            # select our relevant final residual state and target vectors\n",
    "            lvl_output = xfs[i]\n",
    "            lvl_targets = targets[i].detach().clone()\n",
    "            \n",
    "            # calculate the decay value placed on this level's total amount of loss\n",
    "            lambadada = (self.level_loss_weight ** (self.levels -1 -i))\n",
    "            \n",
    "            # setup flattening for if we're doing MAE or MSE\n",
    "            if (self.MAE_loss is not None) or (self.MSE_loss is not None):\n",
    "                # Reshape output and target_vectors to combine batch and seq_len dimensions\n",
    "                lvl_output_flat = lvl_output.view(-1, lvl_output.size(-1))\n",
    "                lvl_targets_flat = lvl_targets.view(-1, lvl_targets.size(-1))\n",
    "\n",
    "            # calculate loss values. notice multiple might occur or even none at all\n",
    "            if self.MAE_loss is not None:\n",
    "                concept_loss = concept_loss + self.MAE_loss(lvl_output_flat, lvl_targets_flat) * lambadada\n",
    "            if self.MSE_loss is not None:\n",
    "                concept_loss = concept_loss + self.MSE_loss(lvl_output_flat, lvl_targets_flat) * lambadada\n",
    "            if self.COS_loss is not None:\n",
    "                cosine_loss = (1 - self.COS_loss(lvl_output, lvl_targets)).mean()\n",
    "                concept_loss = concept_loss + cosine_loss * lambadada\n",
    "\n",
    "        return concept_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57dbe45-22a2-4bcd-b424-45dc0a8bdd57",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Demonstration/Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c2ad6f1-9ff7-4285-a63f-9e11b79ed319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Entering ConceptLoss.forward==========\n",
      "Inputs:\n",
      "Tuple 'xfs':\n",
      "    Tensor 'xfs[0]' shape: torch.Size([32, 256, 128])\n",
      "    Tensor 'xfs[1]' shape: torch.Size([32, 64, 128])\n",
      "    Tensor 'xfs[2]' shape: torch.Size([32, 16, 128])\n",
      "Tuple 'targets':\n",
      "    Tensor 'targets[0]' shape: torch.Size([32, 256, 128])\n",
      "    Tensor 'targets[1]' shape: torch.Size([32, 64, 128])\n",
      "    Tensor 'targets[2]' shape: torch.Size([32, 16, 128])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([])\n",
      "==========Exiting ConceptLoss.forward==========\n",
      "tensor(0.5887)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    hold1 = config.levels\n",
    "    hold2 = config.cos_loss\n",
    "    hold3 = config.mse_loss\n",
    "    hold4 = config.mae_loss\n",
    "    config.levels = 3\n",
    "    config.cos_loss = True\n",
    "    config.mse_loss = False\n",
    "    config.mae_loss = False\n",
    "    module = ConceptLoss(config)\n",
    "    module.enable_logging()\n",
    "    \n",
    "    x0 = torch.randn(32, config.max_seq_len // (config.combine_factor**0), config.embed_dim)\n",
    "    c1 = torch.randn(32, config.max_seq_len // (config.combine_factor**1), config.embed_dim)\n",
    "    c2 = torch.randn(32, config.max_seq_len // (config.combine_factor**2), config.embed_dim)\n",
    "    xfs = (x0, c1, c2)\n",
    "    targets = (x0 + torch.randn_like(x0), c1 + torch.randn_like(c1), c2 + torch.randn_like(c2))\n",
    "    output = module(xfs, targets)\n",
    "    print(output)\n",
    "    config.levels = hold1\n",
    "    config.cos_loss = hold2\n",
    "    config.mse_loss = hold3\n",
    "    config.mae_loss = hold4\n",
    "del hold1, hold2, hold3, hold4, module, x0, c1, c2, xfs, targets, output\n",
    "module = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b499ffb0-c43c-4995-b59c-eaf4729823a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Entering ConceptLoss.forward==========\n",
      "Inputs:\n",
      "Tuple 'xfs':\n",
      "    Tensor 'xfs[0]' shape: torch.Size([32, 256, 128])\n",
      "    Tensor 'xfs[1]' shape: torch.Size([32, 64, 128])\n",
      "    Tensor 'xfs[2]' shape: torch.Size([32, 16, 128])\n",
      "Tuple 'targets':\n",
      "    Tensor 'targets[0]' shape: torch.Size([32, 256, 128])\n",
      "    Tensor 'targets[1]' shape: torch.Size([32, 64, 128])\n",
      "    Tensor 'targets[2]' shape: torch.Size([32, 16, 128])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([])\n",
      "==========Exiting ConceptLoss.forward==========\n",
      "tensor(2.0027)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    hold1 = config.levels\n",
    "    hold2 = config.cos_loss\n",
    "    hold3 = config.mse_loss\n",
    "    hold4 = config.mae_loss\n",
    "    config.levels = 3\n",
    "    config.cos_loss = False\n",
    "    config.mse_loss = True\n",
    "    config.mae_loss = False\n",
    "    module = ConceptLoss(config)\n",
    "    module.enable_logging()\n",
    "    \n",
    "    x0 = torch.randn(32, config.max_seq_len // (config.combine_factor**0), config.embed_dim)\n",
    "    c1 = torch.randn(32, config.max_seq_len // (config.combine_factor**1), config.embed_dim)\n",
    "    c2 = torch.randn(32, config.max_seq_len // (config.combine_factor**2), config.embed_dim)\n",
    "    xfs = (x0, c1, c2)\n",
    "    targets = (x0 + torch.randn_like(x0), c1 + torch.randn_like(c1), c2 + torch.randn_like(c2))\n",
    "    output = module(xfs, targets)\n",
    "    print(output)\n",
    "    config.levels = hold1\n",
    "    config.cos_loss = hold2\n",
    "    config.mse_loss = hold3\n",
    "    config.mae_loss = hold4\n",
    "del hold1, hold2, hold3, hold4, module, x0, c1, c2, xfs, targets, output\n",
    "module = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "89170f73-4f53-4d4d-b59e-d45d83da1b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Entering ConceptLoss.forward==========\n",
      "Inputs:\n",
      "Tuple 'xfs':\n",
      "    Tensor 'xfs[0]' shape: torch.Size([32, 256, 128])\n",
      "    Tensor 'xfs[1]' shape: torch.Size([32, 64, 128])\n",
      "    Tensor 'xfs[2]' shape: torch.Size([32, 16, 128])\n",
      "Tuple 'targets':\n",
      "    Tensor 'targets[0]' shape: torch.Size([32, 256, 128])\n",
      "    Tensor 'targets[1]' shape: torch.Size([32, 64, 128])\n",
      "    Tensor 'targets[2]' shape: torch.Size([32, 16, 128])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([])\n",
      "==========Exiting ConceptLoss.forward==========\n",
      "tensor(1.5958)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    hold1 = config.levels\n",
    "    hold2 = config.cos_loss\n",
    "    hold3 = config.mse_loss\n",
    "    hold4 = config.mae_loss\n",
    "    config.levels = 3\n",
    "    config.cos_loss = False\n",
    "    config.mse_loss = False\n",
    "    config.mae_loss = True\n",
    "    module = ConceptLoss(config)\n",
    "    module.enable_logging()\n",
    "    \n",
    "    x0 = torch.randn(32, config.max_seq_len // (config.combine_factor**0), config.embed_dim)\n",
    "    c1 = torch.randn(32, config.max_seq_len // (config.combine_factor**1), config.embed_dim)\n",
    "    c2 = torch.randn(32, config.max_seq_len // (config.combine_factor**2), config.embed_dim)\n",
    "    xfs = (x0, c1, c2)\n",
    "    targets = (x0 + torch.randn_like(x0), c1 + torch.randn_like(c1), c2 + torch.randn_like(c2))\n",
    "    output = module(xfs, targets)\n",
    "    print(output)\n",
    "    config.levels = hold1\n",
    "    config.cos_loss = hold2\n",
    "    config.mse_loss = hold3\n",
    "    config.mae_loss = hold4\n",
    "del hold1, hold2, hold3, hold4, module, x0, c1, c2, xfs, targets, output\n",
    "module = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "55286553-43f4-4ac9-9926-5920d82b9078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Entering ConceptLoss.forward==========\n",
      "Inputs:\n",
      "Tuple 'xfs':\n",
      "    Tensor 'xfs[0]' shape: torch.Size([32, 256, 128])\n",
      "    Tensor 'xfs[1]' shape: torch.Size([32, 64, 128])\n",
      "    Tensor 'xfs[2]' shape: torch.Size([32, 16, 128])\n",
      "Tuple 'targets':\n",
      "    Tensor 'targets[0]' shape: torch.Size([32, 256, 128])\n",
      "    Tensor 'targets[1]' shape: torch.Size([32, 64, 128])\n",
      "    Tensor 'targets[2]' shape: torch.Size([32, 16, 128])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([])\n",
      "==========Exiting ConceptLoss.forward==========\n",
      "tensor(4.1888)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    hold1 = config.levels\n",
    "    hold2 = config.cos_loss\n",
    "    hold3 = config.mse_loss\n",
    "    hold4 = config.mae_loss\n",
    "    config.levels = 3\n",
    "    config.cos_loss = True\n",
    "    config.mse_loss = True\n",
    "    config.mae_loss = True\n",
    "    module = ConceptLoss(config)\n",
    "    module.enable_logging()\n",
    "    \n",
    "    x0 = torch.randn(32, config.max_seq_len // (config.combine_factor**0), config.embed_dim)\n",
    "    c1 = torch.randn(32, config.max_seq_len // (config.combine_factor**1), config.embed_dim)\n",
    "    c2 = torch.randn(32, config.max_seq_len // (config.combine_factor**2), config.embed_dim)\n",
    "    xfs = (x0, c1, c2)\n",
    "    targets = (x0 + torch.randn_like(x0), c1 + torch.randn_like(c1), c2 + torch.randn_like(c2))\n",
    "    output = module(xfs, targets)\n",
    "    print(output)\n",
    "    config.levels = hold1\n",
    "    config.cos_loss = hold2\n",
    "    config.mse_loss = hold3\n",
    "    config.mae_loss = hold4\n",
    "del hold1, hold2, hold3, hold4, module, x0, c1, c2, xfs, targets, output\n",
    "module = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2835a5-2186-4a0e-81a5-864cb94f1387",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d91c1b3c-19a4-4513-9460-78c244c80d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(LoggingModule):\n",
    "    def __init__(self, config: Config, tokenizer: tokenizer):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        ### hyperparameters\n",
    "        self.max_seq_len = config.max_seq_len\n",
    "        self.sa_head_dim = config.sa_head_dim\n",
    "        self.vocab_size = config.vocab_size\n",
    "        self.embed_dim = config.embed_dim\n",
    "        self.combine_factor = config.combine_factor\n",
    "        self.levels = config.levels\n",
    "        \n",
    "        ### embedding\n",
    "        # the embedding matrix. for converting tokens to the first residual state, and the last residual state to logits\n",
    "        self.embedder = nn.Embedding(config.vocab_size, config.embed_dim)\n",
    "        # the padding vector to get used when sequence length isn't perfect\n",
    "        self.padding_vector = nn.Parameter(torch.zeros(config.embed_dim), requires_grad=True)\n",
    "        # the function that combines embeddings into higher level concept residual states\n",
    "        self.embedding_combiner = CombineEmbeddings(config, self.padding_vector)\n",
    "\n",
    "        ### the actual bulk of the model\n",
    "        self.body = Body(config, self.embedder.weight, self.embedding_combiner)\n",
    "        \n",
    "        ### the loss functions\n",
    "        # lowest-level token model\n",
    "        self.ce_loss_fn = nn.CrossEntropyLoss()\n",
    "        # concept models\n",
    "        self.concept_loss_fn = ConceptLoss(config)\n",
    "        \n",
    "    @log_io\n",
    "    def forward(self,\n",
    "                input_token_ids: torch.Tensor, # a shape (batch_size, input_seq_len) list of integer token ids to run forward pass on\n",
    "                target_token_ids: torch.Tensor = None, # a shape (batch_size, input_seq_len + combo ** (levels-1)) list of token ids to train on\n",
    "                cvec_samples: int = None,\n",
    "                cvec_greedy: bool = False,\n",
    "                cvec_temp: float = 1.0,\n",
    "               ) -> torch.Tensor:\n",
    "\n",
    "        # create the tuple of initial residual states to calculate on\n",
    "        x0s = self.create_x0s(input_token_ids) # x0s are ordered token level -> highest concept level\n",
    "        \n",
    "        if target_token_ids is None: ### if we're doing inference\n",
    "            # the body of the model that iterates through the decoder & cross-attention layers\n",
    "            xfs = self.body(x0s, cvec_samples=cvec_samples, cvec_greedy=cvec_greedy, cvec_temp=cvec_temp) \n",
    "\n",
    "            # the actual token output logits we care about\n",
    "            logits = xfs[-1]\n",
    "            \n",
    "            # if we're not training, then we don't need to calculate loss\n",
    "            loss = None\n",
    "        else: ### if we're training\n",
    "            assert input_token_ids.shape[1] == target_token_ids.shape[1] - (self.combine_factor ** (self.levels - 1)), f'inputs {input_token_ids.shape[1]} and targets {target_token_ids.shape[1]} have unexpected'\n",
    "\n",
    "            # create the tuple of target embedding vectors\n",
    "            targets = self.create_targets(target_token_ids, input_token_ids.shape[1]) # targets are ordered token level -> highest concept level\n",
    "\n",
    "            # the body of the model that iterates through the decoder & cross-attention layers\n",
    "            xfs = self.body(x0s, targets) # xfs are ordered highest concept level -> token level\n",
    "\n",
    "            ### first up is regular CE token loss\n",
    "            logits = xfs[-1]\n",
    "            batch_size, input_len, vocab_size = logits.shape\n",
    "            # splice target tokens to exclude the ones that were only to be used by concept levels\n",
    "            target_token_ids_spliced = target_token_ids[:,:input_len]\n",
    "            # we reshape our logits & targets before calculating cross-entropy loss\n",
    "            ce_loss = self.ce_loss_fn(logits.view(batch_size*input_len, vocab_size),\n",
    "                                      target_token_ids_spliced.reshape(batch_size*input_len))\n",
    "\n",
    "            ### the new thing, a regression loss for all our concept-embedding layers\n",
    "            concept_loss = self.concept_loss_fn(xfs, tuple(reversed(targets)))\n",
    "            # adding it all together\n",
    "            loss = ce_loss + concept_loss\n",
    "        \n",
    "        return logits, loss\n",
    "        \n",
    "    @log_io\n",
    "    def create_x0s(self, input_token_ids: torch.Tensor) -> Tuple[torch.Tensor]:\n",
    "        # turn the input tokens into the first residual state using the embedding matrix\n",
    "        x0 = self.embedder(input_token_ids) # (batch_size, input_len, embed_dim)\n",
    "\n",
    "        # finding the number of padding vectos we have to use at the token level to ensure the cross-attention predictive mask will line up\n",
    "        remainder = x0.shape[1] % self.combine_factor\n",
    "        padding_needed = 0 if remainder == 0 else self.combine_factor - remainder\n",
    "\n",
    "        # do the actual padding for the token level\n",
    "        # once i get a more complicatead tokenizer would i replace this with a <|bos|> token? Would that token be unique to each level?\n",
    "        if padding_needed > 0:\n",
    "            # Replicate the padding vector the necessary number of times\n",
    "            padding = self.padding_vector.repeat(padding_needed, 1).unsqueeze(0).expand(x0.shape[0], -1, -1)\n",
    "            x0_padded = torch.cat([padding, x0], dim=1)\n",
    "        else:\n",
    "            # if there's no padding to be done\n",
    "            x0_padded = x0\n",
    "        \n",
    "        # instantiate the tuple that'll hold all the residual states\n",
    "        x0s = (x0_padded * (self.embed_dim ** 0.5),) \n",
    "        \n",
    "        ### iterating through levels to create each higher-level concept residual state\n",
    "        for i in range(self.levels-1):\n",
    "            # combine into smaller tensor by adding token (or lower level concept) embeddings together\n",
    "            lvl_combo = self.combine_factor ** (i+1)\n",
    "            x0c = self.embedding_combiner(x0, lvl_combo) # c stands for concept\n",
    "            \n",
    "            # finally scale & add it to the tuple of residual states\n",
    "            x0s += (x0c * (self.embed_dim ** 0.5),)\n",
    "        \n",
    "        return x0s\n",
    "\n",
    "    @log_io\n",
    "    def create_targets(self, target_token_ids: torch.Tensor, input_len: int) -> Tuple[torch.Tensor]:\n",
    "        # turn the target tokens into the first residual state using the embedding matrix\n",
    "        t0 = self.embedder(target_token_ids[:,:input_len]) # (batch_size, input_len, embed_dim)\n",
    "        \n",
    "        # instantiate the tuple that'll hold all the residual states\n",
    "        targets = (t0,) \n",
    "        \n",
    "        ### iterating through levels to create each higher-level concepts\n",
    "        for i in range(self.levels-1):\n",
    "            # calculate the correct combo factor for this level\n",
    "            lvl_combo = self.combine_factor ** (i+1)\n",
    "\n",
    "            # my subsetting here is all messy. doesn't properly take into account off-sequences & the padding token\n",
    "            # i think maybe i can fix this in the predictive mask once i make that part\n",
    "\n",
    "            # how many tokens off are we from a perfectly sized (multiple of lvl_combo) sequence, meaning how many padding vectors do we need?\n",
    "            offset = input_len % self.combine_factor # will only ever be self.combine_factor -1 at most\n",
    "\n",
    "            # adjust input_len to ceiling the size necessary for this level\n",
    "            input_len_adj = input_len + lvl_combo\n",
    "\n",
    "            # subset the currect targets to be predicted at this level\n",
    "            target_token_ids_adj = target_token_ids[:, lvl_combo - offset:lvl_combo - offset + input_len_adj]\n",
    "\n",
    "            # turn them into embeddings\n",
    "            raw_target_vectors = self.embedder(target_token_ids_adj)\n",
    "\n",
    "            # combine the token embeddings into concepts\n",
    "            c_vecs = self.embedding_combiner(raw_target_vectors, lvl_combo)\n",
    "\n",
    "            # append to tuple\n",
    "            targets += (c_vecs,)\n",
    "        \n",
    "        return targets\n",
    "        \n",
    "    @log_io\n",
    "    def generate(self,\n",
    "                 prompt: str,\n",
    "                 output_len: int = 1, # the model will output 1 token by default\n",
    "                 temperature: float = 1.0, # 1.0 would be no effect\n",
    "                 top_p: float = 1.0,\n",
    "                 top_k: int = config.vocab_size,\n",
    "                ) -> str: \n",
    "        \"\"\" Wrapper around sampler() that deals with manipulation of the sequence \"\"\"\n",
    "        # encoding the prompt into token indices\n",
    "        tokens = self.tokenizer.encode(prompt)\n",
    "\n",
    "        # turning it into the right tensor shape\n",
    "        tokens = torch.tensor(tokens, device=config.device).unsqueeze(0)\n",
    "        \n",
    "        # we wouldn't want to go past the maximum context length we trained on\n",
    "        if len(tokens) + output_len > self.config.max_seq_len:\n",
    "            output_len = self.max_seq_len - len(tokens)\n",
    "            print(\"capping output at maximum sequence length\")\n",
    "\n",
    "        for i in range(output_len):\n",
    "            # get the model's output logits and ignore the loss, which would be a NoneType object\n",
    "            logits, _ = self(tokens[:,:self.max_seq_len])\n",
    "            print(logits[:,-1,:])\n",
    "            \n",
    "            next_token = self.Sampler(logits, temperature, top_p, top_k)\n",
    "\n",
    "            # add our new token to the sequence\n",
    "            tokens = torch.cat((tokens, next_token), dim=1)\n",
    "\n",
    "        # resets this variable so that the corresponding warning in Body.concept_matchup can come up next time we perform inference\n",
    "        global cvec_warning \n",
    "        cvec_warning = False\n",
    "\n",
    "        # decode our list of tokens to an actual string\n",
    "        return self.tokenizer.decode(tokens.squeeze(0).tolist())\n",
    "\n",
    "    @torch.no_grad() # no need to keep track of gradients during inference\n",
    "    @log_io\n",
    "    def Sampler(\n",
    "        self,\n",
    "        logits: torch.Tensor, # shape (batch_size, input_len, vocab_size)\n",
    "        temperature: float, # controls how boring vs random the outputs should be\n",
    "        top_p: float, # the maximum cumulative probability of output options we're willing to consider\n",
    "        top_k: int, # the maximum number of output options we're willing to consider\n",
    "    ) -> torch.Tensor:\n",
    "        \n",
    "        # Select the last element for each sequence & apply temperature scaling\n",
    "        logits = logits[:,-1,:].div_(temperature) # -> (batch_size, vocab_size)\n",
    "        \n",
    "        # Calculate probabilities with softmax.\n",
    "        probs = torch.softmax(logits, dim=-1, dtype=torch.float) # dim=-1 is the vocab_size dimension that we calculate along\n",
    "        #print('first probs: ', probs)\n",
    "        \n",
    "        # sort the probabilities to for use in top-p & top-k. both are (batch_size, vocab_size)\n",
    "        probs_sort, probs_idx = torch.sort(probs, dim=-1, descending=True)\n",
    "\n",
    "        ### calculating top-p\n",
    "        # creates same-size tensor of cumulatve probabilities instead of indivdiual probs\n",
    "        probs_sum = torch.cumsum(probs_sort, dim=-1) \n",
    "        # mask where 0's are top-p selections & 1's are to be excluded\n",
    "        top_ps_mask = (probs_sum - probs_sort) > top_p\n",
    "        # the original probabilities with excluded tokens changed to 0.0\n",
    "        probs_sort = torch.where(top_ps_mask, 0, probs_sort) \n",
    "\n",
    "        ### calculating top_k\n",
    "        # create a shape (vocab_size) tensor that just iterates up by 1's\n",
    "        top_ks_mask = torch.arange(probs_idx.shape[-1], device=probs_idx.device) \n",
    "        # expand our mask along the batch_size dimension to become size (batch_size, vocab_size)\n",
    "        top_ks_mask = top_ks_mask.expand(probs_idx.shape[0], -1)\n",
    "        # top_ks is a list of integers. we keep whichever entries in top_ks_mask are greater than their corresponding entries in top_ks\n",
    "        top_ks_mask = top_ks_mask >= top_k\n",
    "\n",
    "        # we'll be combining top-p with top-k and using whichever gives us fewer tokens. a very conservative approach\n",
    "        # this trims probs_sort to also fit within our top_k requirement\n",
    "        probs_sort = torch.where(top_ks_mask, 0, probs_sort)\n",
    "\n",
    "        # Re-normalization so that total probabilities add up to 1\n",
    "        probs_sort.div_(probs_sort.sum(dim=-1, keepdim=True))\n",
    "        \n",
    "        # now we rearrange the modified probabilities in probs_sort back to their original order according to probs_idx\n",
    "        probs = torch.gather(probs_sort, dim=-1, index=torch.argsort(probs_idx, dim=-1))\n",
    "        #print('probs after topp & k: ', probs)\n",
    "        \n",
    "        # samples from the distribution\n",
    "        next_token_id = torch.multinomial(probs, num_samples=1)\n",
    "        \n",
    "        return next_token_id # returns the predicted token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce987b4a-ccae-4a8c-b05c-90a7db54a273",
   "metadata": {},
   "source": [
    "## demonstration/debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99219cd7-e131-4f8c-9f63-ee51b606fcbd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c8699759-c377-4f48-9e4f-b81bf0fc71a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Entering Model.forward==========\n",
      "Inputs:\n",
      "Tensor 'input_token_ids' shape: torch.Size([32, 256])\n",
      "Tensor 'target_token_ids' shape: torch.Size([32, 260])\n",
      "\n",
      "==========Entering Model.create_x0s==========\n",
      "Inputs:\n",
      "Tensor 'input_token_ids' shape: torch.Size([32, 256])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([32, 256, 128])\n",
      "Tensor 'output[1]' shape: torch.Size([32, 64, 128])\n",
      "==========Exiting Model.create_x0s==========\n",
      "\n",
      "==========Entering Model.create_targets==========\n",
      "Inputs:\n",
      "Tensor 'target_token_ids' shape: torch.Size([32, 260])\n",
      "Integer 'input_len': Value=256\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([32, 256, 128])\n",
      "Tensor 'output[1]' shape: torch.Size([32, 64, 128])\n",
      "==========Exiting Model.create_targets==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([32, 256, 128])\n",
      "Tensor 'output[1]' shape: torch.Size([])\n",
      "==========Exiting Model.forward==========\n",
      "tensor(119.6606, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "module = Model(config, tokenizer)\n",
    "module.enable_logging()\n",
    "\n",
    "### enabling logging for sub-modules\n",
    "#module.embedding_combiner.enable_logging()\n",
    "#module.body.enable_logging()\n",
    "#module.concept_loss_fn.enable_logging()\n",
    "\n",
    "### disabling logging for sub-functions\n",
    "#module.disable_function_logging('create_x0s')\n",
    "#module.disable_function_logging('create_targets')\n",
    "#module.disable_function_logging('generate')\n",
    "#module.disable_function_logging('sampler')\n",
    "\n",
    "input_token_ids = torch.randint(config.vocab_size, \n",
    "                                (32, config.max_seq_len))\n",
    "target_token_ids = torch.randint(config.vocab_size, \n",
    "                                 (32, config.max_seq_len + (config.combine_factor ** (config.levels-1))))\n",
    "output, loss = module(input_token_ids, target_token_ids)\n",
    "print(loss)\n",
    "del module, input_token_ids, target_token_ids, output, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fe8f8f-ed60-43cc-ab4e-10f5628fb582",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9bd5e51f-4768-4a29-8929-9e60988a1e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Entering Model.forward==========\n",
      "Inputs:\n",
      "Tensor 'input_token_ids' shape: torch.Size([32, 256])\n",
      "\n",
      "==========Entering Model.create_x0s==========\n",
      "Inputs:\n",
      "Tensor 'input_token_ids' shape: torch.Size([32, 256])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([32, 256, 128])\n",
      "Tensor 'output[1]' shape: torch.Size([32, 64, 128])\n",
      "==========Exiting Model.create_x0s==========\n",
      "\n",
      "==========Entering Body.forward==========\n",
      "Inputs:\n",
      "Tuple 'x0s':\n",
      "    Tensor 'x0s[0]' shape: torch.Size([32, 256, 128])\n",
      "    Tensor 'x0s[1]' shape: torch.Size([32, 64, 128])\n",
      "Other-type 'targets': Type=NoneType, Value=None\n",
      "Integer 'cvec_samples': Value=False\n",
      "Float 'cvec_greedy': Value=1.0\n",
      "\n",
      "==========Entering Body.forward_inference==========\n",
      "Inputs:\n",
      "Tuple 'x0s':\n",
      "    Tensor 'x0s[0]' shape: torch.Size([32, 256, 128])\n",
      "    Tensor 'x0s[1]' shape: torch.Size([32, 64, 128])\n",
      "Other-type 'cvec_samples': Type=NoneType, Value=None\n",
      "Integer 'cvec_greedy': Value=False\n",
      "Float 'cvec_temp': Value=1.0\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 64, 128])\n",
      "Integer 'i': Value=0\n",
      "Integer 'c': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 64, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 256, 128])\n",
      "Integer 'i': Value=1\n",
      "Tensor 'c' shape: torch.Size([32, 64, 128])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 256, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([32, 64, 128])\n",
      "Tensor 'output[1]' shape: torch.Size([32, 256, 128])\n",
      "==========Exiting Body.forward_inference==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([32, 64, 128])\n",
      "Tensor 'output[1]' shape: torch.Size([32, 256, 128])\n",
      "==========Exiting Body.forward==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([32, 256, 128])\n",
      "Other-type 'output[1]': Type=NoneType, Value=None\n",
      "==========Exiting Model.forward==========\n"
     ]
    }
   ],
   "source": [
    "module = Model(config, tokenizer)\n",
    "module.enable_logging()\n",
    "\n",
    "### enabling logging for sub-modules\n",
    "#module.embedding_combiner.enable_logging()\n",
    "module.body.enable_logging()\n",
    "#module.concept_loss_fn.enable_logging()\n",
    "\n",
    "### disabling logging for sub-functions\n",
    "#module.disable_function_logging('create_x0s')\n",
    "#module.disable_function_logging('create_targets')\n",
    "#module.disable_function_logging('generate')\n",
    "#module.disable_function_logging('sampler')\n",
    "\n",
    "input_token_ids = torch.randint(config.vocab_size, \n",
    "                                (32, config.max_seq_len))\n",
    "output, loss = module(input_token_ids)\n",
    "del module, input_token_ids, output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "284ec8d2-f655-4a80-a8c5-69bf8f466acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Entering Model.forward==========\n",
      "Inputs:\n",
      "Tensor 'input_token_ids' shape: torch.Size([32, 255])\n",
      "\n",
      "==========Entering Model.create_x0s==========\n",
      "Inputs:\n",
      "Tensor 'input_token_ids' shape: torch.Size([32, 255])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([32, 256, 128])\n",
      "Tensor 'output[1]' shape: torch.Size([32, 64, 128])\n",
      "==========Exiting Model.create_x0s==========\n",
      "\n",
      "==========Entering Body.forward==========\n",
      "Inputs:\n",
      "Tuple 'x0s':\n",
      "    Tensor 'x0s[0]' shape: torch.Size([32, 256, 128])\n",
      "    Tensor 'x0s[1]' shape: torch.Size([32, 64, 128])\n",
      "Other-type 'targets': Type=NoneType, Value=None\n",
      "Integer 'cvec_samples': Value=False\n",
      "Float 'cvec_greedy': Value=1.0\n",
      "\n",
      "==========Entering Body.forward_inference==========\n",
      "Inputs:\n",
      "Tuple 'x0s':\n",
      "    Tensor 'x0s[0]' shape: torch.Size([32, 256, 128])\n",
      "    Tensor 'x0s[1]' shape: torch.Size([32, 64, 128])\n",
      "Other-type 'cvec_samples': Type=NoneType, Value=None\n",
      "Integer 'cvec_greedy': Value=False\n",
      "Float 'cvec_temp': Value=1.0\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 64, 128])\n",
      "Integer 'i': Value=0\n",
      "Integer 'c': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 64, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 256, 128])\n",
      "Integer 'i': Value=1\n",
      "Tensor 'c' shape: torch.Size([32, 64, 128])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 256, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([32, 64, 128])\n",
      "Tensor 'output[1]' shape: torch.Size([32, 256, 128])\n",
      "==========Exiting Body.forward_inference==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([32, 64, 128])\n",
      "Tensor 'output[1]' shape: torch.Size([32, 256, 128])\n",
      "==========Exiting Body.forward==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([32, 256, 128])\n",
      "Other-type 'output[1]': Type=NoneType, Value=None\n",
      "==========Exiting Model.forward==========\n"
     ]
    }
   ],
   "source": [
    "module = Model(config, tokenizer)\n",
    "module.enable_logging()\n",
    "\n",
    "### enabling logging for sub-modules\n",
    "#module.embedding_combiner.enable_logging()\n",
    "module.body.enable_logging()\n",
    "#module.concept_loss_fn.enable_logging()\n",
    "\n",
    "### disabling logging for sub-functions\n",
    "#module.disable_function_logging('create_x0s')\n",
    "#module.disable_function_logging('create_targets')\n",
    "#module.disable_function_logging('generate')\n",
    "#module.disable_function_logging('sampler')\n",
    "\n",
    "input_token_ids = torch.randint(config.vocab_size, \n",
    "                                (32, config.max_seq_len - 1))\n",
    "output, loss = module(input_token_ids)\n",
    "del module, input_token_ids, output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "67ee8927-e95a-4c5d-b688-6214ebf89435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Entering Model.forward==========\n",
      "Inputs:\n",
      "Tensor 'input_token_ids' shape: torch.Size([32, 241])\n",
      "\n",
      "==========Entering Model.create_x0s==========\n",
      "Inputs:\n",
      "Tensor 'input_token_ids' shape: torch.Size([32, 241])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([32, 244, 128])\n",
      "Tensor 'output[1]' shape: torch.Size([32, 61, 128])\n",
      "==========Exiting Model.create_x0s==========\n",
      "\n",
      "==========Entering Body.forward==========\n",
      "Inputs:\n",
      "Tuple 'x0s':\n",
      "    Tensor 'x0s[0]' shape: torch.Size([32, 244, 128])\n",
      "    Tensor 'x0s[1]' shape: torch.Size([32, 61, 128])\n",
      "Other-type 'targets': Type=NoneType, Value=None\n",
      "Integer 'cvec_samples': Value=False\n",
      "Float 'cvec_greedy': Value=1.0\n",
      "\n",
      "==========Entering Body.forward_inference==========\n",
      "Inputs:\n",
      "Tuple 'x0s':\n",
      "    Tensor 'x0s[0]' shape: torch.Size([32, 244, 128])\n",
      "    Tensor 'x0s[1]' shape: torch.Size([32, 61, 128])\n",
      "Other-type 'cvec_samples': Type=NoneType, Value=None\n",
      "Integer 'cvec_greedy': Value=False\n",
      "Float 'cvec_temp': Value=1.0\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 61, 128])\n",
      "Integer 'i': Value=0\n",
      "Integer 'c': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 61, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 62, 128])\n",
      "Integer 'i': Value=0\n",
      "Integer 'c': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 62, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 63, 128])\n",
      "Integer 'i': Value=0\n",
      "Integer 'c': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 63, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 64, 128])\n",
      "Integer 'i': Value=0\n",
      "Integer 'c': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 64, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "==========Entering Body.layers_loop==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 244, 128])\n",
      "Integer 'i': Value=1\n",
      "Tensor 'c' shape: torch.Size([32, 64, 128])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 244, 128])\n",
      "==========Exiting Body.layers_loop==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([32, 64, 128])\n",
      "Tensor 'output[1]' shape: torch.Size([32, 244, 128])\n",
      "==========Exiting Body.forward_inference==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([32, 64, 128])\n",
      "Tensor 'output[1]' shape: torch.Size([32, 244, 128])\n",
      "==========Exiting Body.forward==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([32, 244, 128])\n",
      "Other-type 'output[1]': Type=NoneType, Value=None\n",
      "==========Exiting Model.forward==========\n"
     ]
    }
   ],
   "source": [
    "module = Model(config, tokenizer)\n",
    "module.enable_logging()\n",
    "\n",
    "### enabling logging for sub-modules\n",
    "#module.embedding_combiner.enable_logging()\n",
    "module.body.enable_logging()\n",
    "#module.concept_loss_fn.enable_logging()\n",
    "\n",
    "### disabling logging for sub-functions\n",
    "#module.disable_function_logging('create_x0s')\n",
    "#module.disable_function_logging('create_targets')\n",
    "#module.disable_function_logging('generate')\n",
    "#module.disable_function_logging('sampler')\n",
    "\n",
    "input_token_ids = torch.randint(config.vocab_size, \n",
    "                                (32, config.max_seq_len - 15))\n",
    "output, loss = module(input_token_ids)\n",
    "del module, input_token_ids, output, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c01560-0895-49e0-aa98-b30100318433",
   "metadata": {},
   "source": [
    "# Instantiate a brand new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "40e94167-e10f-45a8-9392-8d910621f2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2350.976 K parameters\n",
      "Model(\n",
      "  (embedder): Embedding(128, 128)\n",
      "  (embedding_combiner): CombineEmbeddings(\n",
      "    (operation_chain): Sequential(\n",
      "      (reshape): ReshapeModule()\n",
      "      (linear_post_reshape): Linear(in_features=512, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (body): Body(\n",
      "    (layers): ModuleList(\n",
      "      (0-7): 8 x Layer(\n",
      "        (pre_self_mqa_norm): Norm()\n",
      "        (self_mqa): selfMQA()\n",
      "        (post_self_mqa_norm): Norm()\n",
      "        (pre_cross_mqa_x_norm): Norm()\n",
      "        (pre_cross_mqa_c_norm): Norm()\n",
      "        (cross_mqa): crossMQA()\n",
      "        (post_cross_mqa_norm): Norm()\n",
      "        (pre_mlp_norm): Norm()\n",
      "        (mlp): MLP(\n",
      "          (gate_proj): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (up_proj): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (down_proj): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (post_mlp_norm): Norm()\n",
      "      )\n",
      "    )\n",
      "    (final_norms): ModuleList(\n",
      "      (0-1): 2 x Norm()\n",
      "    )\n",
      "    (concept_output_layers): ModuleList(\n",
      "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (concept_creator): CombineEmbeddings(\n",
      "      (operation_chain): Sequential(\n",
      "        (reshape): ReshapeModule()\n",
      "        (linear_post_reshape): Linear(in_features=512, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ce_loss_fn): CrossEntropyLoss()\n",
      "  (concept_loss_fn): ConceptLoss(\n",
      "    (MAE_loss): L1Loss()\n",
      "    (MSE_loss): MSELoss()\n",
      "    (COS_loss): CosineSimilarity()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Model(config, tokenizer).to(config.device)\n",
    "\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in model.parameters())/1e3, 'K parameters')\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8efd0ad-4844-49cb-8ebc-321af1f8b892",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c40b0665-c82a-4452-b87b-588bb669778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test splits\n",
    "data = torch.tensor(tokenizer.encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be our training dataset, the rest for validation\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7d5d8341-b110-42de-9a09-34e468cc427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading for training which generates a small batch of data of inputs x and targets y\n",
    "def get_batch(split, batch_size):\n",
    "    # whether we grab from our training or validation dataset\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - (config.max_seq_len + (config.combine_factor ** (config.levels-1))), (batch_size,))\n",
    "    # some training batches need to be offset so it learns how to use the padding vector\n",
    "    offset = 0#random.randint(0, config.combine_factor)\n",
    "    x = torch.stack([data[i:i+config.max_seq_len - offset] for i in ix])\n",
    "    ### i actually need the y tensor to be + (config.combine_factor ** (config.levels-1)) to fit the future concepts\n",
    "    y = torch.stack([data[i+1:i+1+(config.max_seq_len + (config.combine_factor ** (config.levels-1))) - offset] for i in ix])\n",
    "    x, y = x.to(config.device), y.to(config.device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "baccce31-9fe4-46b3-b3c9-a1bd2b8007cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(model, batch_size, eval_iters = 5): # to estimate loss during the training loop\n",
    "    out = {}\n",
    "    model.eval() # sets model to eval mode\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split, batch_size)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train() # just resets to training mode\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2e724d95-c98a-4542-9a06-86374d268a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a PyTorch optimizer\n",
    "# this is not what they used, but this learning rate & weight decay work for our tiny minGemma\n",
    "config.learning_rate = 1e-5\n",
    "config.weight_decay = 0.05\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "\n",
    "# how long we want to train for\n",
    "config.max_iters = 2\n",
    "\n",
    "# how often we want to check & see how our loss is doing\n",
    "eval_interval = 1\n",
    "\n",
    "# batch size to use\n",
    "config.batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "23ce596e-89a3-4de6-8dc5-a0650519cad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 118.0572, val loss 117.8617, time elapsed: 3.23 seconds\n",
      "step 1: train loss 118.2126, val loss 117.9036, time elapsed: 18.99 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Enable anomaly detection. uncomment these lines if you need to do extensive debugging\n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "for iter in range(config.max_iters):\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train', config.batch_size)\n",
    "    \n",
    "    # train\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == config.max_iters - 1:\n",
    "        current_time = time.time()\n",
    "        elapsed_time = current_time - start_time\n",
    "        losses = estimate_loss(model, config.batch_size)\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}, time elapsed: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# Disable anomaly detection after the training loop\n",
    "#torch.autograd.set_detect_anomaly(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c28f086-54fe-4b38-b03a-78eacb6e7454",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Saving your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "588a4ae3-aa58-41d4-ba66-4c5f333943a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f'models/{model.__class__.__name__}_{time.strftime(\"%Y-%m-%d|%H-%M-%S\")}'\n",
    "torch.save(model.state_dict(), f'{name}.pth')\n",
    "\n",
    "# Convert the dataclass object to a dictionary\n",
    "config_dict = asdict(config)\n",
    "\n",
    "# Serialize the dictionary to a JSON file\n",
    "with open(f'{name}.json', 'w') as f:\n",
    "    json.dump(config_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d406304-9dcf-4f71-b69d-e8f860d43c15",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Load a Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c948ec-0c43-4c64-9719-f6dea92cf04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '?'\n",
    "\n",
    "# Deserialize the JSON file back to a dictionary\n",
    "with open(f'models/{name}.json', 'r') as f:\n",
    "    config_dict = json.load(f)\n",
    "\n",
    "# Convert the dictionary back to a dataclass object\n",
    "config = Config(**config_dict)\n",
    "\n",
    "# Initialize a blank model\n",
    "model = Model(config, tokenizer).to(config.device)  \n",
    "\n",
    "# here's the path to a minGemma model that i've trained with roughly 1m parameters\n",
    "path = f'models/{name}.pth'\n",
    "\n",
    "# Load the saved state dictionary\n",
    "model.load_state_dict(torch.load(path)) \n",
    "# REMEMBER TO CHANGE VALUES IN CONFIG TO MATCH THE MODEL YOU'VE LOADED\n",
    "\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in model.parameters())/1e3, 'K parameters')\n",
    "\n",
    "# If you only plan to do inference, switch to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# If you plan to continue training the model, switch to training mode\n",
    "#model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b5bed2-838f-4bc3-81e2-3ee4d69d7184",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "768fb9e3-185e-4a95-8e1d-229855132410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 14.0070, 132.3857,  26.6539, -10.9482, -19.6087,   2.8802,  -6.7978,\n",
      "         -17.8984,  21.8534,  10.9096, -11.4976,   2.3779,  10.4820,  -2.4443,\n",
      "          12.4412,   9.4708, -14.0684,   1.8588,   5.6888,  23.1455,   4.2008,\n",
      "           6.6105,  -0.8596,  -0.5641,   7.9605,   0.6630,   2.6266,   0.3261,\n",
      "         -12.6212,  -5.3472,   7.4715, -25.8441,  -5.8146,  -1.9345,  -0.8079,\n",
      "          -9.8620, -10.8991,  -1.1518, -13.4775,  10.5367,  -1.0857,   5.0193,\n",
      "         -10.3168,  24.0464,  15.7569,  -5.6152,  12.9313,  -1.9927,  -9.2126,\n",
      "          11.8529,   0.1672,  -3.5229,  -4.0193, -15.4642, -18.2790, -10.6337,\n",
      "         -10.6227, -12.9554,  -3.8079,  -1.3702, -10.6787, -15.0002,  -5.0395,\n",
      "           1.6555,  -3.8974,  31.1297,  -4.9419,   2.3523, -18.7418,  10.0106,\n",
      "         -19.0951,   1.9051,  11.8622,  13.1635,   6.7612,  -8.6053,  21.6675,\n",
      "         -15.9857,  21.3484,   9.1443, -11.1098,  17.0689, -10.1813,  -6.8712,\n",
      "           6.9992,  -0.7398,  -4.1173,  -5.9017,  -5.0159, -18.9202,  -4.9399,\n",
      "          -0.8996,  12.4223, -17.3971, -12.8461,  -2.2757,  -5.8715,  23.3013,\n",
      "           0.7978,   4.0279,   7.5099,  22.8139,  13.6943,  -9.4266, -14.2390,\n",
      "          29.8874,  24.3545,   6.8006,  11.1096,   5.5996,  11.5022,  -7.4834,\n",
      "           6.0956,   7.2878, -15.9236,  16.5049,  17.4627,   7.4979,   4.1946,\n",
      "          -4.6257,  -9.9040, -26.4729,   6.7605,  -6.8791,  10.1857,  24.1603,\n",
      "           5.5493,  -0.5202]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.1930e+01,  1.3248e+02,  2.5457e+01, -1.1722e+01, -1.9908e+01,\n",
      "          1.9540e+00, -5.5508e+00, -1.4918e+01,  2.1527e+01,  5.1818e-01,\n",
      "         -1.1131e+01, -2.6747e+00,  1.2434e+01, -7.3222e+00,  1.0752e+01,\n",
      "          7.1162e+00, -6.3041e+00,  6.5424e+00,  1.1499e+01,  2.1279e+01,\n",
      "          1.1071e+01,  6.5357e+00,  1.5240e+00,  1.1885e-01,  1.1397e+01,\n",
      "          3.3137e+00,  6.3795e-01,  8.3428e-01, -1.0107e+01,  5.9066e-01,\n",
      "          1.0497e+01, -2.8281e+01, -9.5700e+00, -2.6950e+00,  2.4954e+00,\n",
      "         -1.0501e+01, -4.7009e+00,  1.1866e+00, -1.0970e+01,  1.1992e+01,\n",
      "         -4.4133e+00,  3.8988e+00, -1.2024e+01,  2.4464e+01,  1.8564e+01,\n",
      "         -7.0374e+00,  1.2639e+01, -5.5822e+00, -8.0473e+00,  1.6126e+01,\n",
      "         -4.0958e-02, -2.3091e+00, -5.4450e+00, -1.3547e+01, -1.6305e+01,\n",
      "         -1.0877e+01, -7.5958e+00, -1.0953e+01, -6.2723e+00, -3.3959e-01,\n",
      "         -1.0935e+01, -1.3484e+01, -3.0981e+00, -1.2719e+00, -5.6267e+00,\n",
      "          2.7608e+01, -1.1641e+00,  5.9730e+00, -1.7248e+01,  1.2266e+01,\n",
      "         -1.7430e+01,  3.0746e+00,  8.4509e+00,  1.8516e+01,  1.7569e+01,\n",
      "         -9.0997e+00,  1.7617e+01, -1.4036e+01,  2.0074e+01,  1.4027e+01,\n",
      "         -1.2333e+01,  2.4247e+01, -1.2446e+01, -3.9360e+00,  7.4967e+00,\n",
      "          4.9072e-01, -4.9814e+00, -4.2057e+00, -1.1892e+01, -1.5572e+01,\n",
      "         -9.4842e+00, -1.5677e+00,  8.5209e+00, -1.2695e+01, -1.0114e+01,\n",
      "         -3.8781e+00, -9.6800e+00,  1.8343e+01, -3.0563e+00, -7.9687e-01,\n",
      "          6.3997e+00,  2.7159e+01,  1.1775e+01, -9.3528e+00, -1.3669e+01,\n",
      "          3.0523e+01,  2.4021e+01,  1.0547e+01,  1.0479e+01,  8.9025e+00,\n",
      "          1.2726e+01, -1.9795e+00,  6.1127e+00,  2.4972e+00, -2.1517e+01,\n",
      "          2.0609e+01,  1.9164e+01,  9.5446e+00,  1.2261e+01, -2.5791e+00,\n",
      "         -1.3028e+01, -2.4071e+01,  5.1204e+00, -1.2206e+01,  8.1168e+00,\n",
      "          2.1469e+01,  7.3651e+00,  3.1397e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 15.9538, 131.6239,  21.2883,  -7.2168, -23.4665,   2.7591,  -7.1518,\n",
      "         -17.6313,  15.2118,  13.3391,  -9.9496,   0.9657,   9.6515,  -1.7254,\n",
      "          17.0826,   7.5929,  -7.7180,   3.9937,   2.6518,  21.9869,   8.5721,\n",
      "           2.8683,   1.8696,  -2.7901,  11.9894,   3.4775,   4.9913,   0.9428,\n",
      "         -12.1055,  -1.3789,   7.7212, -25.9740,  -3.8876,  -3.1893,  -4.2847,\n",
      "         -10.3027, -13.1443,  -2.2611, -17.4078,   9.9632,  -7.3726,   3.8461,\n",
      "         -12.9769,  25.2992,  15.3709,  -5.1121,  15.4329,  -5.3904, -11.1131,\n",
      "          11.4719,   1.0883,  -6.9720,  -5.5693, -13.0663, -18.0929, -12.7842,\n",
      "          -8.5339,  -6.4670,  -6.6991,  -4.5730, -11.0074, -18.3427,  -0.2953,\n",
      "          -0.5437,  -5.5196,  23.1737,  -2.7488,   0.3425, -17.4334,   9.5961,\n",
      "         -20.2663,   3.0647,   4.0972,  14.1209,   8.0533, -10.8598,  19.9155,\n",
      "         -16.0257,  18.6959,  11.4164,  -9.9004,  13.9694, -14.2221,  -6.0940,\n",
      "           5.4694,  -4.2792,  -5.9775,  -6.4814,  -0.4953, -15.1219,  -7.9826,\n",
      "          -5.2112,  15.6032, -15.8976, -12.0084,  -0.9524,  -2.5929,  20.4337,\n",
      "          -6.4125,   3.6254,   5.0488,  23.3920,  15.1428, -11.4717, -12.5577,\n",
      "          28.3915,  27.0203,   3.9753,  11.0239,   7.4581,  11.7603,  -2.0568,\n",
      "           1.7935,   8.3560, -17.9906,  14.8870,  12.9357,   7.2930,   4.5038,\n",
      "          -2.0066, -10.3945, -28.4372,   6.5221,  -8.4567,   5.9783,  17.7510,\n",
      "           5.1930,   6.0712]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 13.4295, 131.3409,  23.5240,  -4.5067, -21.4315,   3.0694,  -2.2254,\n",
      "         -18.7101,  13.1420,  10.1978, -12.7518,  -0.3562,   7.3960,  -0.9494,\n",
      "          14.7662,  10.0515, -10.7634,  -1.3630,  12.2481,  24.8199,   9.2459,\n",
      "           1.8049,   2.7322,  -1.9508,  10.2173,  -0.6186,   7.1078,   0.4394,\n",
      "         -10.9534,   1.2116,  13.6623, -28.0160,  -2.7577,  -4.7603,  -0.4582,\n",
      "          -9.7805, -13.4336,  -1.4478, -16.6432,  18.0029,  -4.6875,   0.8691,\n",
      "         -13.1906,  23.1678,  17.2557,  -3.4211,  14.4279,  -0.3326,  -6.9918,\n",
      "           8.7007,   5.1523,  -9.6273,  -4.8711, -14.8308, -14.7106, -12.1403,\n",
      "         -11.7645, -11.5160,  -8.5561,  -5.7996,  -9.7769, -18.3242,   1.9507,\n",
      "          -2.2994,  -3.0348,  31.1631,  -2.1139,   3.7284, -18.9785,   9.9293,\n",
      "         -18.1614,   4.1866,   6.7699,  11.1678,  11.4875,  -7.7963,  14.8413,\n",
      "         -16.8447,  23.4768,  12.7090,  -6.9353,  15.3493, -14.9515,  -1.0226,\n",
      "           6.7841,   0.4170,  -2.8868,  -1.8403,  -5.6940, -13.2097,  -9.4936,\n",
      "          -3.0842,  13.7997, -14.2839, -15.2632,   1.6493,  -4.0230,  19.4663,\n",
      "           3.2739,  -0.8086,   9.4726,  22.1806,  15.0609,  -9.0530, -12.3951,\n",
      "          30.5679,  22.3607,   7.6972,  11.3323,   9.3469,  12.8627,  -5.7411,\n",
      "           2.7374,   6.0631, -18.7734,  13.8438,  15.8699,   9.0910,   7.0219,\n",
      "          -4.6875, -13.3458, -29.8420,   6.1643,  -5.7911,   8.6635,  22.2890,\n",
      "           2.5315,   4.5405]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 15.7916, 131.1082,  24.0847, -10.0694, -19.3030,   3.0244,  -4.9646,\n",
      "         -21.3404,  20.6187,  14.9823, -16.7400,   2.2554,  10.1289,  -1.7215,\n",
      "          16.8107,   9.8979, -10.7302,   0.6901,   3.8421,  20.8832,   5.2569,\n",
      "           5.0110,  -1.9589,  -2.3360,   9.4593,   1.4699,   3.9345,   0.7347,\n",
      "         -13.0467,  -2.6263,   8.4739, -25.0484,  -3.5810,   1.0712,  -2.8591,\n",
      "          -9.8601, -11.5092,  -0.5500, -14.6098,  10.9171,  -6.4536,   4.3280,\n",
      "         -10.7668,  23.8622,  15.6849,  -3.6931,  13.5911,  -2.0141, -12.7560,\n",
      "           9.2822,   0.2277,  -4.2170,  -8.4538, -13.1525, -16.0231, -11.1029,\n",
      "          -8.5171, -10.3746,  -5.2580,  -1.6675, -10.2563, -15.1655,  -5.7292,\n",
      "          -1.9050,  -2.4604,  27.3300,  -3.7566,   3.2822, -21.2111,   8.6327,\n",
      "         -19.4114,   1.5576,   6.9260,  13.3504,   6.2409,  -9.0731,  20.3753,\n",
      "         -17.6391,  22.9975,   9.6545,  -9.5931,  15.1094,  -8.0469,  -8.1844,\n",
      "           6.7699,  -3.2103,  -6.3148,  -8.6556,  -2.5719, -17.9751,  -5.1262,\n",
      "          -2.5825,  12.7758, -15.2566, -11.9459,  -1.7649,  -3.2865,  24.3732,\n",
      "          -2.3904,   2.5655,   4.2421,  24.0817,  14.0715,  -7.7891, -11.5495,\n",
      "          30.4835,  22.6169,   1.5105,  13.2567,   7.0923,  13.7779,  -0.8536,\n",
      "           3.8586,   8.2569, -17.8474,  17.7059,  14.8847,   8.8267,   5.0987,\n",
      "          -3.8540,  -7.3691, -26.3768,   4.4189,  -6.6073,  11.2643,  20.8857,\n",
      "           2.8454,   2.3259]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.4314e+01,  1.3244e+02,  2.4655e+01, -7.5333e+00, -2.1024e+01,\n",
      "          3.9693e+00, -3.2951e+00, -1.7972e+01,  2.4571e+01,  4.6034e+00,\n",
      "         -1.5149e+01, -3.9163e+00,  8.0223e+00, -7.0137e+00,  1.0248e+01,\n",
      "          6.3336e+00, -6.3177e+00,  6.9582e+00,  5.8803e+00,  2.1217e+01,\n",
      "          1.0446e+01,  1.2010e+00,  1.4123e+00, -1.8324e+00,  1.0339e+01,\n",
      "          4.3123e+00,  1.5345e+00,  2.4989e+00, -7.0875e+00, -3.6264e-01,\n",
      "          1.2773e+01, -2.8898e+01, -4.2991e+00, -1.1887e+00,  1.9258e+00,\n",
      "         -7.9567e+00, -6.8760e+00,  3.6449e+00, -1.1029e+01,  7.5700e+00,\n",
      "         -5.0401e+00,  5.0239e+00, -1.3226e+01,  2.2210e+01,  1.5827e+01,\n",
      "         -1.9848e+00,  1.5356e+01, -3.9503e+00, -1.2228e+01,  1.0606e+01,\n",
      "          2.6227e+00, -4.3356e+00, -1.0084e+01, -1.6216e+01, -1.6287e+01,\n",
      "         -1.0172e+01, -1.1371e+01, -7.3498e+00, -3.8552e+00, -1.9536e+00,\n",
      "         -1.1012e+01, -1.3452e+01, -4.4218e+00, -4.5689e+00, -5.6049e+00,\n",
      "          2.7182e+01,  7.7152e-01,  2.2847e+00, -1.5975e+01,  8.5915e+00,\n",
      "         -1.5343e+01,  3.8244e+00,  5.9182e+00,  1.7107e+01,  1.6621e+01,\n",
      "         -7.4578e+00,  1.8215e+01, -1.4667e+01,  1.9853e+01,  1.1611e+01,\n",
      "         -1.0471e+01,  2.2490e+01, -1.2934e+01, -8.0282e+00,  1.0707e+01,\n",
      "         -1.2327e-01, -5.0280e+00, -4.5584e+00, -7.0922e+00, -1.4989e+01,\n",
      "         -8.3345e+00, -3.5669e+00,  1.2357e+01, -1.4105e+01, -1.1262e+01,\n",
      "          1.6571e+00, -9.0262e+00,  1.6227e+01, -4.8795e+00, -3.1042e-01,\n",
      "          7.4682e+00,  2.7579e+01,  1.3875e+01, -1.0998e+01, -1.2194e+01,\n",
      "          3.0664e+01,  2.4782e+01,  8.3364e+00,  1.2669e+01,  1.1672e+01,\n",
      "          1.3069e+01,  5.2675e-01,  5.8711e+00,  5.1482e+00, -1.8849e+01,\n",
      "          1.7710e+01,  1.3224e+01,  9.3514e+00,  6.2702e+00, -3.3721e+00,\n",
      "         -1.0603e+01, -2.4205e+01,  2.4786e+00, -1.2206e+01,  6.1642e+00,\n",
      "          1.4591e+01,  6.4063e+00,  3.9517e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.4791e+01,  1.3134e+02,  2.0395e+01, -7.0427e+00, -2.2993e+01,\n",
      "          4.1716e+00, -6.5451e+00, -1.8846e+01,  1.6026e+01,  1.3600e+01,\n",
      "         -1.1768e+01,  7.1969e-01,  8.0516e+00, -9.7644e-02,  1.6406e+01,\n",
      "          7.5058e+00, -6.6018e+00,  4.2485e+00,  1.2866e+00,  2.2548e+01,\n",
      "          8.4479e+00,  2.8513e+00,  2.7581e-01, -2.4678e+00,  1.1972e+01,\n",
      "          3.1526e+00,  7.7292e+00,  2.3642e+00, -1.0511e+01,  5.9310e-01,\n",
      "          7.7899e+00, -2.5070e+01, -2.1914e+00, -1.9881e+00, -4.0247e+00,\n",
      "         -9.6904e+00, -1.3448e+01, -3.0272e+00, -1.7013e+01,  1.1191e+01,\n",
      "         -7.1354e+00,  3.9163e+00, -1.4468e+01,  2.5788e+01,  1.6435e+01,\n",
      "         -4.4957e+00,  1.4586e+01, -5.2847e+00, -1.3071e+01,  9.4866e+00,\n",
      "          2.6527e+00, -6.5037e+00, -6.8209e+00, -1.3244e+01, -1.6410e+01,\n",
      "         -1.1805e+01, -9.3002e+00, -6.3502e+00, -6.1183e+00, -4.7460e+00,\n",
      "         -1.1367e+01, -1.7854e+01,  7.4680e-02, -3.3720e+00, -4.1297e+00,\n",
      "          2.4140e+01, -2.3633e+00, -3.5293e-01, -1.8604e+01,  7.4235e+00,\n",
      "         -1.9970e+01,  3.5600e+00,  3.2115e+00,  1.3073e+01,  8.8440e+00,\n",
      "         -9.6294e+00,  1.8717e+01, -1.5395e+01,  2.0250e+01,  9.7623e+00,\n",
      "         -9.5083e+00,  1.3059e+01, -1.4856e+01, -6.1852e+00,  7.2053e+00,\n",
      "         -4.1332e+00, -7.1070e+00, -4.9567e+00,  4.7389e-01, -1.4806e+01,\n",
      "         -8.7584e+00, -5.6346e+00,  1.4655e+01, -1.5744e+01, -1.3175e+01,\n",
      "          8.2326e-01, -1.8984e+00,  1.8707e+01, -6.2922e+00,  3.0023e+00,\n",
      "          4.3088e+00,  2.3302e+01,  1.5470e+01, -1.0606e+01, -1.2347e+01,\n",
      "          2.8904e+01,  2.6542e+01,  2.1962e+00,  1.1193e+01,  7.6718e+00,\n",
      "          1.1691e+01, -3.3464e-01,  1.3588e+00,  8.0245e+00, -1.8784e+01,\n",
      "          1.5820e+01,  1.1790e+01,  6.9506e+00,  4.5954e+00, -2.8841e+00,\n",
      "         -9.7401e+00, -2.7504e+01,  4.5109e+00, -8.9008e+00,  5.7657e+00,\n",
      "          1.5942e+01,  3.8727e+00,  6.7475e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 14.2563, 130.9365,  23.7127,  -4.6469, -20.9250,   2.6023,  -5.4191,\n",
      "         -20.6644,  15.1427,  13.3377, -14.0136,   3.5086,   5.9785,   3.4078,\n",
      "          15.3432,  10.7915, -10.1874,   2.4906,   9.5293,  22.4353,  10.4074,\n",
      "          -1.6213,  -0.1954,  -1.9178,   7.8540,   0.4050,   5.8679,   2.2500,\n",
      "         -10.0073,   0.3240,  11.0234, -26.0612,  -2.4451,  -2.6749,  -0.3412,\n",
      "          -8.4391, -13.6715,  -4.3505, -14.3400,  14.5108,  -7.7412,   4.3954,\n",
      "         -13.5906,  25.7846,  16.1984,  -1.1673,  12.9296,  -0.3711,  -8.5077,\n",
      "           7.8646,   7.6614,  -8.0951,  -8.0163, -14.3591, -15.5508, -11.8196,\n",
      "          -8.7254, -11.9399,  -7.9849,  -6.7995,  -9.8957, -16.0869,   0.5806,\n",
      "          -4.8093,   0.7658,  30.2997,   0.3993,   2.9728, -20.6687,   7.6286,\n",
      "         -17.2043,   5.2803,   6.5992,  10.8708,  11.1793,  -7.7750,  17.0136,\n",
      "         -16.8753,  26.4006,  10.9797,  -8.9629,  12.8261, -12.9979,  -2.1952,\n",
      "           8.6044,  -0.3937,  -2.0734,  -3.5642,  -4.1970, -16.9270,  -8.1621,\n",
      "          -4.5997,  14.6136, -14.6754, -12.7498,   4.0967,  -3.4003,  19.7200,\n",
      "           1.0410,   2.4407,   8.8171,  22.2687,  15.8514,  -5.6751, -12.0372,\n",
      "          31.7887,  23.9615,   5.3431,  13.9188,   8.8320,  13.5700,  -2.0987,\n",
      "           4.0494,   6.9030, -19.6427,  15.4260,  12.8761,   9.8681,   5.2954,\n",
      "          -4.0696, -10.4164, -30.4635,   6.8511,  -4.6610,   7.1181,  20.7035,\n",
      "           1.7895,   2.0351]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.5569e+01,  1.3065e+02,  2.6470e+01, -1.0008e+01, -1.8178e+01,\n",
      "          3.2371e+00, -5.9897e+00, -1.9956e+01,  1.9996e+01,  1.3587e+01,\n",
      "         -1.5060e+01,  1.5225e+00,  1.0312e+01, -1.3271e+00,  1.7259e+01,\n",
      "          9.4183e+00, -9.0369e+00, -1.1131e-01,  4.5455e+00,  1.7960e+01,\n",
      "          6.0929e+00,  5.0989e+00, -2.1889e+00, -2.0184e+00,  1.1236e+01,\n",
      "         -7.5875e-01,  6.5509e+00,  2.9468e+00, -1.5377e+01, -2.2835e+00,\n",
      "          8.9566e+00, -2.3999e+01, -4.3565e+00,  8.5827e-01, -2.1121e+00,\n",
      "         -9.6626e+00, -9.8923e+00, -8.0527e-01, -1.5519e+01,  1.1452e+01,\n",
      "         -5.9377e+00,  4.8387e+00, -1.2582e+01,  2.5490e+01,  1.8466e+01,\n",
      "         -5.7416e+00,  1.3066e+01, -1.9740e+00, -1.1208e+01,  1.0858e+01,\n",
      "         -2.1171e-01, -4.9507e+00, -8.9321e+00, -1.1564e+01, -1.5720e+01,\n",
      "         -1.2143e+01, -6.3642e+00, -1.0050e+01, -4.4412e+00, -2.1184e+00,\n",
      "         -8.7246e+00, -1.3592e+01, -6.1877e+00, -1.7189e+00, -2.1595e+00,\n",
      "          2.7932e+01, -3.0388e+00,  4.0333e+00, -2.1913e+01,  8.9128e+00,\n",
      "         -1.8886e+01,  1.1911e+00,  8.1058e+00,  1.3939e+01,  6.5359e+00,\n",
      "         -1.0008e+01,  2.0212e+01, -1.6247e+01,  2.4325e+01,  8.6364e+00,\n",
      "         -8.8826e+00,  1.5898e+01, -9.7460e+00, -6.6577e+00,  6.7927e+00,\n",
      "         -2.8525e+00, -5.4351e+00, -9.2919e+00, -4.1115e+00, -1.7274e+01,\n",
      "         -4.6118e+00, -2.1265e+00,  1.2114e+01, -1.5732e+01, -1.3658e+01,\n",
      "         -1.0056e+00, -1.9266e+00,  2.2954e+01, -3.1308e+00,  3.6835e+00,\n",
      "          1.8791e+00,  2.4270e+01,  1.3267e+01, -6.4781e+00, -1.3213e+01,\n",
      "          3.0172e+01,  2.2036e+01,  1.3680e+00,  1.3325e+01,  6.5738e+00,\n",
      "          1.4516e+01, -6.4303e-01,  3.0422e+00,  7.7765e+00, -1.8666e+01,\n",
      "          1.9166e+01,  1.6204e+01,  1.0710e+01,  6.9921e+00, -3.4958e+00,\n",
      "         -9.0923e+00, -2.6780e+01,  3.8781e+00, -7.2896e+00,  1.2777e+01,\n",
      "          2.2371e+01,  2.1810e+00,  3.1843e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 14.0751, 132.4427,  24.6787,  -7.6459, -19.9647,   5.0084,  -2.4617,\n",
      "         -17.8663,  26.1628,   5.5654, -15.8108,  -3.0352,   7.4442,  -6.2400,\n",
      "          11.0361,   8.1311,  -4.6119,   5.9102,   5.7285,  22.1681,  10.6906,\n",
      "           1.8549,   1.1328,  -1.6400,   9.4551,   1.6666,   3.2392,   3.0929,\n",
      "          -7.4410,  -1.1930,  11.8716, -29.7034,  -4.3063,  -1.5586,   2.4896,\n",
      "          -7.1727,  -7.6209,   4.3325, -10.3286,   7.3755,  -3.1059,   4.7206,\n",
      "         -12.5591,  23.0508,  15.7812,  -1.1383,  14.3680,  -3.8928, -12.5296,\n",
      "           8.2439,   3.6096,  -4.0087, -11.7004, -16.2561, -16.7817,  -9.4303,\n",
      "         -11.6073,  -8.1941,  -2.6903,  -0.9774, -10.5220, -13.5317,  -4.7520,\n",
      "          -4.6452,  -4.8627,  26.8188,   0.9014,   1.4562, -16.5646,   8.4310,\n",
      "         -15.3237,   3.1754,   5.6657,  16.4318,  17.4139,  -7.4989,  17.1830,\n",
      "         -15.0671,  21.1341,  10.2784, -11.0114,  21.8507, -13.7823,  -8.2999,\n",
      "          11.2847,   0.3811,  -4.6895,  -4.3310,  -5.6771, -15.4880,  -9.1469,\n",
      "          -3.3092,  12.2521, -13.6011, -11.7757,   2.0467,  -7.5089,  14.8054,\n",
      "          -4.6169,   0.7618,   6.3755,  26.3874,  14.7990, -10.1983, -12.7021,\n",
      "          30.8338,  23.6274,   6.2055,  12.8260,  12.3866,  13.1239,   0.5112,\n",
      "           5.9381,   3.8097, -18.7130,  15.7390,  12.2547,   9.0236,   5.9992,\n",
      "          -3.3931, -10.1036, -24.7275,   3.5802, -11.5593,   6.7394,  14.4039,\n",
      "           4.6942,   5.1778]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.4644e+01,  1.3146e+02,  1.9088e+01, -6.6087e+00, -2.4483e+01,\n",
      "          3.8811e+00, -7.4393e+00, -1.7780e+01,  1.6249e+01,  1.3817e+01,\n",
      "         -1.1950e+01, -3.1286e-01,  7.7359e+00, -2.3796e-02,  1.6064e+01,\n",
      "          8.4043e+00, -6.5970e+00,  5.4804e+00,  2.3162e+00,  2.2310e+01,\n",
      "          8.2514e+00,  2.0469e+00, -1.0486e-01, -1.9613e+00,  1.1280e+01,\n",
      "          3.4891e+00,  8.6208e+00,  2.6371e+00, -9.3264e+00,  9.7286e-01,\n",
      "          8.7882e+00, -2.6057e+01, -2.7931e+00, -1.9252e+00, -3.8490e+00,\n",
      "         -9.5507e+00, -1.3107e+01, -2.2366e+00, -1.7111e+01,  1.1755e+01,\n",
      "         -7.2736e+00,  3.8315e+00, -1.4208e+01,  2.5497e+01,  1.6975e+01,\n",
      "         -4.9090e+00,  1.5128e+01, -5.1414e+00, -1.3486e+01,  9.3284e+00,\n",
      "          4.3393e+00, -5.9751e+00, -7.2198e+00, -1.1924e+01, -1.5790e+01,\n",
      "         -1.1381e+01, -9.3028e+00, -6.8019e+00, -6.2752e+00, -4.7083e+00,\n",
      "         -1.0844e+01, -1.7450e+01,  5.5528e-01, -4.0420e+00, -3.6535e+00,\n",
      "          2.5400e+01, -2.2513e+00,  5.3550e-01, -1.8989e+01,  6.9324e+00,\n",
      "         -1.8564e+01,  3.9625e+00,  2.5987e+00,  1.2671e+01,  1.0115e+01,\n",
      "         -9.6846e+00,  1.8345e+01, -1.5619e+01,  2.2641e+01,  9.4617e+00,\n",
      "         -9.8235e+00,  1.3936e+01, -1.5387e+01, -5.8930e+00,  7.7115e+00,\n",
      "         -3.7353e+00, -6.5568e+00, -4.8588e+00,  2.7648e-01, -1.5914e+01,\n",
      "         -8.9946e+00, -5.4133e+00,  1.3688e+01, -1.5696e+01, -1.3158e+01,\n",
      "          1.8863e+00, -1.9005e+00,  1.7337e+01, -5.7104e+00,  2.6326e+00,\n",
      "          3.8957e+00,  2.2624e+01,  1.4723e+01, -9.9501e+00, -1.3362e+01,\n",
      "          2.8538e+01,  2.6399e+01,  3.4242e+00,  1.1605e+01,  7.2343e+00,\n",
      "          1.2254e+01,  8.7048e-02,  1.1726e+00,  8.2513e+00, -1.8419e+01,\n",
      "          1.4611e+01,  1.0666e+01,  7.2856e+00,  5.5406e+00, -2.4391e+00,\n",
      "         -9.6467e+00, -2.7682e+01,  4.9791e+00, -8.5981e+00,  5.7557e+00,\n",
      "          1.5379e+01,  3.6536e+00,  5.7256e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 14.9078, 131.6887,  21.5836,  -5.3429, -22.3502,   1.0908,  -9.8811,\n",
      "         -17.2454,  16.7102,  11.0053, -12.5939,   0.3722,   8.4886,   2.0276,\n",
      "          12.9169,   8.2768,  -7.5438,   5.9731,  10.3055,  22.3752,  11.4976,\n",
      "          -3.2088,  -1.1329,  -0.2174,   8.7288,   3.7523,   5.8478,   2.5246,\n",
      "          -9.5699,   0.1585,  10.9338, -27.9362,  -3.4218,  -3.0487,   0.3784,\n",
      "          -7.8355,  -8.0943,  -2.6931, -16.2547,  12.7360,  -7.9367,   3.8388,\n",
      "         -13.8110,  25.5881,  19.0418,  -2.2031,  13.3661,  -4.3564, -11.8660,\n",
      "           8.3042,   6.0548,  -5.7231,  -8.7949, -14.0296, -13.7022, -10.1993,\n",
      "          -8.2442,  -8.1997,  -6.2327,  -4.9624,  -8.4399, -16.2922,  -1.0548,\n",
      "          -4.6424,   0.7429,  30.0125,  -0.5075,   2.9757, -21.3264,   5.7711,\n",
      "         -16.5691,   6.9759,   4.5183,  13.4521,  13.3882,  -8.0209,  17.1686,\n",
      "         -15.2341,  28.2329,  11.0652, -11.2155,  15.5927, -13.2664,  -3.8504,\n",
      "           9.2015,  -0.2715,  -2.3255,  -2.8252,  -4.0353, -14.6470, -10.4039,\n",
      "          -4.9470,  13.7822, -12.1855, -13.0443,   4.3624,  -5.0952,  16.8633,\n",
      "          -0.7908,   1.8211,   5.1315,  23.9455,  14.4759,  -6.6562, -14.4753,\n",
      "          28.5014,  25.0623,   7.7021,  15.0775,   9.9342,  14.3765,  -0.3083,\n",
      "           4.1016,   5.8286, -20.2784,  15.5059,  12.4491,  10.2712,   7.6514,\n",
      "          -2.0316, -10.7013, -28.8605,   4.9610,  -7.3786,   7.7046,  19.3046,\n",
      "           2.1429,   0.6062]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.6758e+01,  1.3061e+02,  2.7364e+01, -8.7709e+00, -1.9922e+01,\n",
      "          3.1345e+00, -7.4595e+00, -2.2146e+01,  1.8577e+01,  1.4848e+01,\n",
      "         -1.6140e+01,  2.5140e+00,  9.3785e+00, -9.6369e-01,  1.5431e+01,\n",
      "          9.2928e+00, -9.6455e+00,  1.2728e+00,  4.6347e+00,  1.8604e+01,\n",
      "          1.0235e+01,  4.2512e+00, -8.7656e-01, -4.7010e-01,  8.5592e+00,\n",
      "          8.7666e-01,  5.3609e+00,  3.2407e+00, -1.2099e+01, -7.1420e-01,\n",
      "          8.3082e+00, -2.5117e+01, -6.0587e+00,  1.1521e-01, -3.6864e-01,\n",
      "         -7.6786e+00, -1.0103e+01, -1.9758e+00, -1.3473e+01,  1.0701e+01,\n",
      "         -4.8964e+00,  5.3080e+00, -1.5471e+01,  2.6168e+01,  1.8230e+01,\n",
      "         -4.3815e+00,  1.3930e+01, -3.1541e+00, -9.9079e+00,  1.2820e+01,\n",
      "          3.6834e+00, -6.9140e+00, -7.9314e+00, -1.1040e+01, -1.6569e+01,\n",
      "         -1.3088e+01, -7.2614e+00, -8.4239e+00, -5.0732e+00, -3.4882e+00,\n",
      "         -9.1323e+00, -1.7237e+01, -1.0390e+00, -2.5540e+00, -2.5356e+00,\n",
      "          2.7132e+01, -8.0997e-01,  2.9605e+00, -2.1420e+01,  1.2812e+01,\n",
      "         -1.8551e+01,  2.4897e+00,  7.8036e+00,  1.3338e+01,  9.9825e+00,\n",
      "         -9.4461e+00,  1.8618e+01, -1.6865e+01,  2.3969e+01,  9.7878e+00,\n",
      "         -7.8419e+00,  1.7087e+01, -1.0762e+01, -4.2873e+00,  8.9483e+00,\n",
      "         -5.0835e-01, -3.1171e+00, -7.2610e+00, -5.4207e+00, -1.7201e+01,\n",
      "         -6.5087e+00, -1.9734e+00,  1.2991e+01, -1.3063e+01, -1.1236e+01,\n",
      "          1.2225e+00, -3.3707e+00,  1.8584e+01, -4.0950e+00,  3.9187e+00,\n",
      "          3.4874e+00,  2.3345e+01,  1.3825e+01, -5.3745e+00, -1.2882e+01,\n",
      "          3.3155e+01,  2.3104e+01,  3.5208e+00,  1.2287e+01,  9.3307e+00,\n",
      "          1.7537e+01, -5.2812e-01,  3.5329e+00,  6.9468e+00, -1.6835e+01,\n",
      "          1.6895e+01,  1.2868e+01,  1.0926e+01,  9.0633e+00, -2.9892e+00,\n",
      "         -8.7512e+00, -2.8812e+01,  5.5960e+00, -7.4930e+00,  1.0562e+01,\n",
      "          2.0057e+01,  4.4603e+00,  2.0932e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 13.2041, 132.4568,  24.6166,  -7.6706, -20.0243,   5.3643,  -3.1043,\n",
      "         -16.9485,  27.0154,   5.1440, -15.2167,  -3.2114,   7.6228,  -5.7532,\n",
      "          10.7595,   8.4767,  -3.8483,   6.2262,   5.9187,  22.5299,  11.2645,\n",
      "           2.2303,   0.4751,  -1.1073,   8.9689,   0.7932,   4.5053,   3.2563,\n",
      "          -7.3383,  -1.0226,  10.0938, -29.9132,  -4.1997,  -1.7511,   2.3447,\n",
      "          -7.3638,  -7.4847,   4.2546, -10.6776,   7.9801,  -3.1564,   4.7188,\n",
      "         -12.8309,  24.0894,  16.2599,  -1.7001,  14.1009,  -4.3448, -13.1664,\n",
      "           9.0356,   3.2566,  -3.1503, -13.0173, -16.8534, -16.9616,  -9.2757,\n",
      "         -10.8009,  -8.9653,  -2.5885,   0.3197, -10.1470, -13.4236,  -3.8348,\n",
      "          -4.6499,  -5.0191,  26.5968,   0.4116,   1.4957, -17.4064,   8.0236,\n",
      "         -14.9197,   3.1599,   5.5766,  17.0014,  18.0086,  -7.8493,  16.5829,\n",
      "         -14.2831,  22.4045,   9.7225, -11.5036,  21.3646, -13.4204,  -7.8065,\n",
      "          12.8425,   0.2226,  -4.2107,  -4.5266,  -5.5339, -15.6998,  -9.8731,\n",
      "          -3.1593,  11.7969, -13.4382, -11.4389,   2.0652,  -7.2773,  14.7464,\n",
      "          -5.4168,   0.5932,   5.1499,  26.0328,  14.3291,  -9.0204, -13.4571,\n",
      "          30.2835,  23.2776,   6.1652,  13.4222,  12.1510,  13.6202,   1.0605,\n",
      "           6.0602,   3.4368, -19.8287,  15.6600,  13.1739,   8.2955,   6.5114,\n",
      "          -3.3511,  -9.9411, -24.0300,   2.7443, -11.2993,   7.1058,  14.7792,\n",
      "           4.3441,   5.5830]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 13.7536, 131.5324,  18.5424,  -6.0962, -25.2056,   2.9503,  -7.4411,\n",
      "         -16.5580,  17.1561,  12.5189, -11.5670,  -0.3213,   7.1283,   0.1957,\n",
      "          14.7680,   8.5817,  -6.3877,   6.1886,   2.4720,  22.0472,   8.7339,\n",
      "           1.1437,  -0.4303,  -1.3527,  10.8230,   3.5100,   8.9968,   2.7792,\n",
      "          -7.6829,   1.5907,   9.0103, -26.8061,  -2.9275,  -1.8174,  -3.3480,\n",
      "          -9.2111, -12.9848,  -1.9874, -16.7115,  12.4681,  -7.1352,   3.9634,\n",
      "         -14.6684,  25.2850,  17.7012,  -5.1566,  14.5627,  -5.2007, -13.1311,\n",
      "           9.9225,   5.1954,  -5.3111,  -7.8756, -11.5588, -15.5779, -11.4830,\n",
      "          -8.7830,  -7.1865,  -5.8684,  -5.2206, -10.5033, -16.9269,   0.9631,\n",
      "          -5.1701,  -4.1869,  25.9777,  -1.6675,   1.6252, -19.4461,   6.8462,\n",
      "         -17.4807,   4.2235,   2.5064,  12.8330,  11.8219,  -9.3660,  17.8102,\n",
      "         -15.1178,  24.0660,   9.0452,  -9.4682,  15.2574, -15.0673,  -5.6343,\n",
      "           8.1615,  -3.2377,  -5.9708,  -4.5377,  -0.9503, -16.5602,  -9.3807,\n",
      "          -4.9352,  12.5690, -15.3824, -12.8206,   2.7113,  -2.1578,  15.7521,\n",
      "          -5.3429,   2.1885,   3.6122,  22.8789,  14.0361,  -8.6328, -14.2355,\n",
      "          28.7345,  25.7489,   4.4526,  11.8470,   7.3100,  13.5321,   0.7322,\n",
      "           1.7909,   7.5996, -19.2766,  14.9237,  10.1538,   7.9179,   7.3980,\n",
      "          -2.3462,  -9.8063, -27.8532,   4.6890,  -8.7825,   6.0852,  14.8594,\n",
      "           3.7232,   5.1484]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 14.6780, 131.7815,  21.9938,  -6.0402, -23.0788,   1.3364, -10.2796,\n",
      "         -17.0367,  17.4431,  10.1633, -11.9101,  -0.3555,   7.9668,   1.8202,\n",
      "          12.1862,   7.8293,  -6.9025,   6.8550,   8.8629,  22.0740,  11.4540,\n",
      "          -2.5790,  -1.2100,   0.3614,   8.5732,   3.9595,   5.8099,   3.1113,\n",
      "          -8.4740,   0.2895,  10.7445, -28.0793,  -3.7345,  -2.4380,   0.2879,\n",
      "          -8.0554,  -6.8248,  -1.9666, -16.2630,  12.3966,  -7.5290,   4.0782,\n",
      "         -14.8705,  25.6129,  19.6474,  -3.2861,  13.9030,  -5.4750, -12.3157,\n",
      "           8.7202,   6.0517,  -5.0914,  -9.2853, -13.9409, -13.4486, -10.1359,\n",
      "          -7.9103,  -7.9291,  -5.9764,  -4.1650,  -8.2801, -16.6710,  -0.5182,\n",
      "          -4.5058,  -0.1709,  29.6121,  -0.1465,   2.9563, -21.3941,   5.5742,\n",
      "         -16.3262,   6.6475,   3.8800,  13.8497,  13.4736,  -8.3800,  17.2631,\n",
      "         -14.9074,  28.5952,  10.7797, -10.8742,  15.9366, -13.4474,  -4.4999,\n",
      "           8.4363,   0.1335,  -1.8307,  -2.7073,  -3.7190, -14.5638, -10.3523,\n",
      "          -5.1819,  13.1888, -11.8781, -13.6386,   4.1931,  -5.2179,  15.5984,\n",
      "          -1.4714,   1.0927,   3.9958,  24.1013,  13.3192,  -7.0443, -15.3615,\n",
      "          27.9764,  25.3896,   8.2469,  14.6536,   9.9661,  15.0628,   0.6356,\n",
      "           4.3870,   5.0253, -21.1207,  16.0850,  12.0222,  10.4664,   8.3233,\n",
      "          -1.8991, -10.0262, -28.3090,   4.6281,  -7.9706,   7.9616,  18.4406,\n",
      "           2.1841,   0.8060]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.7127e+01,  1.3125e+02,  2.4956e+01, -7.2677e+00, -2.2962e+01,\n",
      "         -4.1727e-02, -9.5034e+00, -1.9154e+01,  1.8245e+01,  1.3418e+01,\n",
      "         -1.2488e+01,  1.4191e+00,  8.2483e+00,  5.3937e-01,  1.4725e+01,\n",
      "          9.8946e+00, -8.6505e+00,  4.6380e+00,  3.0991e+00,  1.8160e+01,\n",
      "          1.0819e+01,  1.9626e+00,  3.3793e-01, -8.3158e-01,  7.3947e+00,\n",
      "          3.0364e+00,  5.3781e+00,  1.7537e+00, -1.0916e+01,  1.2043e+00,\n",
      "          8.9207e+00, -2.6080e+01, -7.3213e+00, -5.3299e-01, -2.9312e-01,\n",
      "         -8.9562e+00, -9.0199e+00, -3.8364e-01, -1.3529e+01,  9.9576e+00,\n",
      "         -5.9548e+00,  4.0998e+00, -1.4891e+01,  2.5431e+01,  1.7611e+01,\n",
      "         -5.3652e+00,  1.4026e+01, -4.3985e+00, -1.0530e+01,  1.2235e+01,\n",
      "          4.3381e+00, -6.6494e+00, -8.2582e+00, -1.0349e+01, -1.7712e+01,\n",
      "         -1.1920e+01, -6.4062e+00, -9.7885e+00, -6.4329e+00, -3.8849e+00,\n",
      "         -8.9199e+00, -1.6117e+01,  5.5867e-01, -3.6051e+00, -2.3679e+00,\n",
      "          2.7722e+01, -2.9846e-01,  3.1486e+00, -2.0634e+01,  1.2680e+01,\n",
      "         -1.8023e+01,  3.2580e+00,  7.1101e+00,  1.3518e+01,  1.1680e+01,\n",
      "         -8.2858e+00,  1.7571e+01, -1.6684e+01,  2.5393e+01,  9.7678e+00,\n",
      "         -9.0664e+00,  1.8122e+01, -1.2362e+01, -3.9873e+00,  9.6813e+00,\n",
      "         -1.4580e+00, -1.9366e+00, -7.3712e+00, -6.2088e+00, -1.7353e+01,\n",
      "         -6.9806e+00, -2.4496e+00,  1.1908e+01, -1.3505e+01, -1.3433e+01,\n",
      "          1.6201e+00, -4.6323e+00,  1.6754e+01, -4.2021e+00,  3.0855e+00,\n",
      "          3.3602e+00,  2.2154e+01,  1.2893e+01, -4.3833e+00, -1.5003e+01,\n",
      "          3.0663e+01,  2.4070e+01,  5.3641e+00,  1.2140e+01,  9.3776e+00,\n",
      "          1.7230e+01,  1.2219e+00,  4.2678e+00,  6.4065e+00, -1.7702e+01,\n",
      "          1.6749e+01,  1.1763e+01,  9.5621e+00,  9.8026e+00, -2.2536e+00,\n",
      "         -9.9967e+00, -2.9207e+01,  5.9450e+00, -8.1226e+00,  9.3048e+00,\n",
      "          1.7655e+01,  5.7010e+00,  2.8369e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 12.4712, 132.3442,  23.5514,  -7.7319, -21.4056,   5.2504,  -3.7674,\n",
      "         -16.8480,  26.9134,   5.1828, -15.2762,  -3.5952,   7.8694,  -5.6127,\n",
      "          10.6503,   8.6305,  -3.4173,   6.7551,   4.7898,  23.0147,  10.5725,\n",
      "           2.3373,   0.7515,  -0.1965,   8.1804,   0.2763,   5.8315,   3.3290,\n",
      "          -7.0415,  -0.3665,   9.9550, -30.4059,  -3.9124,  -1.9420,   2.3838,\n",
      "          -8.2217,  -7.2564,   4.2673, -11.4551,   9.6946,  -3.4469,   4.0876,\n",
      "         -12.3791,  24.7337,  16.6969,  -2.8967,  15.2489,  -4.7645, -14.1627,\n",
      "           9.2233,   3.3970,  -2.5952, -14.2523, -16.4692, -16.6281,  -8.8649,\n",
      "          -9.9200,  -9.4985,  -2.8431,   1.1349, -10.2393, -13.7281,  -2.8255,\n",
      "          -4.1439,  -5.0489,  27.4580,  -0.1489,   1.3697, -17.8601,   6.8728,\n",
      "         -14.8424,   2.7076,   4.9312,  17.3746,  17.2388,  -7.9317,  15.8576,\n",
      "         -13.8751,  23.3490,   9.2143, -11.5420,  20.9980, -13.5064,  -7.8695,\n",
      "          12.8297,   0.7890,  -3.8623,  -4.7023,  -4.9713, -15.4696,  -9.8594,\n",
      "          -3.6202,  11.2088, -13.6229, -11.7706,   1.9135,  -7.4248,  14.0927,\n",
      "          -5.8662,  -0.5059,   4.0231,  25.1857,  13.6671,  -8.5146, -13.5064,\n",
      "          29.6360,  22.6679,   6.6040,  14.0511,  11.3180,  13.7895,   1.1827,\n",
      "           5.6354,   3.8236, -20.6631,  16.5444,  13.6577,   8.0769,   5.6851,\n",
      "          -3.8474, -10.2119, -24.0995,   1.8162, -10.8280,   6.8955,  14.7664,\n",
      "           3.8107,   5.7059]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.3056e+01,  1.3152e+02,  1.8358e+01, -6.0501e+00, -2.5226e+01,\n",
      "          1.9455e+00, -7.6052e+00, -1.5371e+01,  1.7774e+01,  1.1174e+01,\n",
      "         -1.1296e+01, -6.9725e-02,  6.9058e+00,  1.1183e+00,  1.3644e+01,\n",
      "          9.0758e+00, -6.2047e+00,  6.7468e+00,  2.4855e+00,  2.2038e+01,\n",
      "          8.7332e+00,  6.9353e-01, -2.5853e-01, -1.2743e+00,  1.0040e+01,\n",
      "          3.4821e+00,  9.6229e+00,  2.3709e+00, -6.9972e+00,  2.4696e+00,\n",
      "          9.2266e+00, -2.7802e+01, -3.8768e+00, -2.5786e+00, -2.3724e+00,\n",
      "         -9.6383e+00, -1.2757e+01, -1.7543e+00, -1.6395e+01,  1.2662e+01,\n",
      "         -6.5863e+00,  4.0978e+00, -1.4420e+01,  2.5548e+01,  1.8173e+01,\n",
      "         -5.2985e+00,  1.3776e+01, -5.5189e+00, -1.2683e+01,  1.0511e+01,\n",
      "          5.7642e+00, -4.9337e+00, -7.4516e+00, -1.1556e+01, -1.5394e+01,\n",
      "         -1.1238e+01, -8.9230e+00, -7.8396e+00, -5.9178e+00, -5.0101e+00,\n",
      "         -1.0504e+01, -1.6682e+01,  9.6412e-01, -5.7349e+00, -4.1363e+00,\n",
      "          2.6663e+01, -1.4915e+00,  2.7671e+00, -1.9569e+01,  7.0335e+00,\n",
      "         -1.6685e+01,  4.6173e+00,  3.5860e+00,  1.2918e+01,  1.3225e+01,\n",
      "         -8.5262e+00,  1.7431e+01, -1.5091e+01,  2.4934e+01,  8.9255e+00,\n",
      "         -9.5749e+00,  1.6273e+01, -1.5596e+01, -5.2621e+00,  8.5700e+00,\n",
      "         -2.5926e+00, -5.1307e+00, -4.2341e+00, -2.5897e+00, -1.6968e+01,\n",
      "         -9.0518e+00, -3.8523e+00,  1.1761e+01, -1.4776e+01, -1.3314e+01,\n",
      "          3.1255e+00, -3.2212e+00,  1.5217e+01, -5.3259e+00,  2.1563e+00,\n",
      "          3.9404e+00,  2.2671e+01,  1.3447e+01, -7.7837e+00, -1.4888e+01,\n",
      "          2.8558e+01,  2.5199e+01,  5.5979e+00,  1.2030e+01,  6.8106e+00,\n",
      "          1.4118e+01,  9.1822e-01,  3.0849e+00,  6.7336e+00, -1.9599e+01,\n",
      "          1.5375e+01,  1.0001e+01,  8.2336e+00,  8.5139e+00, -2.6569e+00,\n",
      "         -1.0627e+01, -2.7666e+01,  4.6357e+00, -9.2298e+00,  5.9237e+00,\n",
      "          1.5071e+01,  3.9048e+00,  5.0814e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 14.2151, 131.8430,  22.2040,  -6.1918, -23.2730,   1.4439, -10.0207,\n",
      "         -16.9831,  17.6420,   9.9773, -11.5793,  -0.5255,   8.0324,   2.0694,\n",
      "          11.5511,   7.8386,  -6.7403,   6.7959,   7.8691,  21.9447,  11.3214,\n",
      "          -2.2228,  -1.2494,   0.1456,   8.0834,   3.5161,   6.2824,   3.0748,\n",
      "          -7.9604,   0.9762,  11.2195, -28.4914,  -4.3350,  -2.4506,   1.1118,\n",
      "          -8.7972,  -7.1417,  -1.9916, -16.1049,  12.1596,  -7.1352,   4.4030,\n",
      "         -15.1055,  26.3620,  19.8639,  -3.8250,  14.2547,  -5.4061, -12.5266,\n",
      "           9.2706,   6.3480,  -5.0489,  -9.0892, -13.7116, -13.6813, -10.0873,\n",
      "          -8.4924,  -8.2500,  -5.9831,  -3.7722,  -8.6165, -16.8393,   0.1347,\n",
      "          -4.6003,  -0.5290,  29.8386,   0.2138,   3.1825, -21.5830,   5.4048,\n",
      "         -16.1106,   6.1157,   4.4222,  13.5653,  13.4622,  -7.8606,  17.0175,\n",
      "         -15.0560,  28.4633,  10.5692, -10.4940,  15.9353, -13.8416,  -4.2692,\n",
      "           8.3639,   0.4008,  -1.6933,  -2.3470,  -3.9232, -14.7897,  -9.6914,\n",
      "          -4.9858,  12.5998, -11.9226, -14.5196,   4.1282,  -5.6208,  14.7843,\n",
      "          -1.7274,   1.1298,   3.8438,  23.9209,  12.7455,  -6.9845, -15.2525,\n",
      "          27.8133,  25.2156,   8.3613,  14.5082,   9.7275,  15.2833,   0.9807,\n",
      "           4.8102,   4.4212, -21.6367,  16.5669,  11.7251,  10.7648,   8.3920,\n",
      "          -2.5542,  -9.9285, -28.1365,   4.3924,  -8.2379,   7.8304,  18.1206,\n",
      "           2.4682,   0.9592]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.6435e+01,  1.3122e+02,  2.4248e+01, -6.9352e+00, -2.3426e+01,\n",
      "         -2.1897e-01, -9.2202e+00, -1.8488e+01,  1.8457e+01,  1.1758e+01,\n",
      "         -1.1843e+01,  2.9966e-02,  8.0621e+00,  8.2848e-01,  1.3543e+01,\n",
      "          1.0007e+01, -8.1355e+00,  5.2791e+00,  3.4432e+00,  1.8678e+01,\n",
      "          1.1029e+01,  2.2471e+00,  9.2726e-01, -1.0563e+00,  7.0644e+00,\n",
      "          3.3919e+00,  6.3250e+00,  1.9339e+00, -1.0227e+01,  2.1055e+00,\n",
      "          1.0094e+01, -2.6574e+01, -7.3948e+00, -1.3022e+00,  6.4744e-01,\n",
      "         -9.0976e+00, -8.0965e+00,  4.5834e-01, -1.3973e+01,  1.0388e+01,\n",
      "         -6.0358e+00,  3.3310e+00, -1.4872e+01,  2.5779e+01,  1.7872e+01,\n",
      "         -5.8446e+00,  1.4626e+01, -4.2267e+00, -1.1314e+01,  1.1989e+01,\n",
      "          4.9729e+00, -6.6704e+00, -8.0424e+00, -1.0313e+01, -1.7268e+01,\n",
      "         -1.1104e+01, -6.6772e+00, -9.8323e+00, -7.3115e+00, -2.9915e+00,\n",
      "         -8.8244e+00, -1.5692e+01,  1.2676e+00, -2.9615e+00, -2.8044e+00,\n",
      "          2.7751e+01,  7.4580e-02,  3.4153e+00, -2.0742e+01,  1.2104e+01,\n",
      "         -1.7311e+01,  3.5143e+00,  6.9006e+00,  1.3396e+01,  1.3031e+01,\n",
      "         -7.5018e+00,  1.6553e+01, -1.6617e+01,  2.6206e+01,  9.9510e+00,\n",
      "         -8.8744e+00,  1.8001e+01, -1.3286e+01, -3.5328e+00,  9.7103e+00,\n",
      "         -1.2065e+00, -1.4017e+00, -6.5890e+00, -6.4738e+00, -1.7004e+01,\n",
      "         -6.6471e+00, -2.0252e+00,  1.1355e+01, -1.3551e+01, -1.4920e+01,\n",
      "          2.2530e+00, -4.6257e+00,  1.6194e+01, -3.7718e+00,  2.4793e+00,\n",
      "          4.0415e+00,  2.1755e+01,  1.2393e+01, -4.4829e+00, -1.5859e+01,\n",
      "          2.9668e+01,  2.4368e+01,  5.7952e+00,  1.1903e+01,  9.4616e+00,\n",
      "          1.7448e+01,  2.0533e+00,  4.0253e+00,  5.6437e+00, -1.8487e+01,\n",
      "          1.6326e+01,  1.1952e+01,  1.0079e+01,  9.7420e+00, -2.2561e+00,\n",
      "         -1.0487e+01, -2.8436e+01,  5.6031e+00, -8.7403e+00,  9.1498e+00,\n",
      "          1.7963e+01,  5.9881e+00,  2.7745e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.1862e+01,  1.3206e+02,  2.2986e+01, -7.3030e+00, -2.2058e+01,\n",
      "          4.9978e+00, -4.4956e+00, -1.6756e+01,  2.6614e+01,  5.5744e+00,\n",
      "         -1.5155e+01, -3.6167e+00,  8.3752e+00, -5.5672e+00,  1.0431e+01,\n",
      "          8.5737e+00, -2.9245e+00,  6.2513e+00,  4.8202e+00,  2.2859e+01,\n",
      "          1.0651e+01,  2.1324e+00,  4.5712e-01, -7.1749e-01,  8.1691e+00,\n",
      "         -3.1096e-02,  6.3502e+00,  3.2019e+00, -6.6160e+00,  3.2710e-01,\n",
      "          9.9193e+00, -3.0538e+01, -3.3745e+00, -2.0194e+00,  2.8017e+00,\n",
      "         -9.0106e+00, -7.1584e+00,  3.6046e+00, -1.2009e+01,  1.0809e+01,\n",
      "         -4.1740e+00,  3.5788e+00, -1.1898e+01,  2.5067e+01,  1.7520e+01,\n",
      "         -3.2676e+00,  1.6134e+01, -4.3949e+00, -1.4832e+01,  9.9670e+00,\n",
      "          3.8461e+00, -2.4033e+00, -1.4710e+01, -1.5537e+01, -1.6533e+01,\n",
      "         -8.9884e+00, -8.6966e+00, -9.6227e+00, -2.9209e+00,  8.0296e-01,\n",
      "         -9.9309e+00, -1.3888e+01, -2.2221e+00, -4.5856e+00, -4.8649e+00,\n",
      "          2.7955e+01, -2.9248e-01,  2.0512e+00, -1.8849e+01,  6.2830e+00,\n",
      "         -1.4700e+01,  2.4645e+00,  4.7929e+00,  1.6567e+01,  1.7110e+01,\n",
      "         -7.8717e+00,  1.5732e+01, -1.3618e+01,  2.3800e+01,  9.3197e+00,\n",
      "         -1.1436e+01,  2.0092e+01, -1.3354e+01, -7.5761e+00,  1.2475e+01,\n",
      "          7.4458e-01, -4.3396e+00, -4.6338e+00, -4.9369e+00, -1.5122e+01,\n",
      "         -9.9249e+00, -3.7579e+00,  1.0473e+01, -1.3729e+01, -1.1742e+01,\n",
      "          1.7793e+00, -7.6759e+00,  1.3801e+01, -5.9470e+00, -9.4863e-01,\n",
      "          3.6154e+00,  2.4758e+01,  1.3061e+01, -7.7109e+00, -1.3602e+01,\n",
      "          2.9454e+01,  2.2432e+01,  6.5348e+00,  1.4848e+01,  1.1598e+01,\n",
      "          1.4484e+01,  1.1999e+00,  4.9624e+00,  3.9077e+00, -2.1204e+01,\n",
      "          1.7195e+01,  1.3725e+01,  8.2125e+00,  5.6241e+00, -4.1364e+00,\n",
      "         -1.0381e+01, -2.4361e+01,  1.0408e+00, -1.0814e+01,  6.9520e+00,\n",
      "          1.4937e+01,  3.7217e+00,  5.0512e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.2091e+01,  1.3154e+02,  1.8510e+01, -6.1599e+00, -2.4877e+01,\n",
      "          1.1991e+00, -7.8748e+00, -1.4351e+01,  1.8882e+01,  1.0512e+01,\n",
      "         -1.1107e+01, -1.2288e-01,  7.1723e+00,  1.5794e+00,  1.2106e+01,\n",
      "          9.2155e+00, -6.1605e+00,  7.0327e+00,  2.9042e+00,  2.1953e+01,\n",
      "          8.4448e+00,  5.2931e-01, -1.8414e-01, -1.5283e+00,  9.7087e+00,\n",
      "          3.5138e+00,  9.5459e+00,  1.8815e+00, -6.7783e+00,  2.6968e+00,\n",
      "          8.6804e+00, -2.7687e+01, -4.3934e+00, -3.0637e+00, -1.2916e+00,\n",
      "         -9.5913e+00, -1.2006e+01, -1.6800e+00, -1.6298e+01,  1.3029e+01,\n",
      "         -6.7106e+00,  4.0232e+00, -1.4074e+01,  2.5837e+01,  1.8525e+01,\n",
      "         -5.5989e+00,  1.3391e+01, -5.5034e+00, -1.2392e+01,  1.1057e+01,\n",
      "          5.9009e+00, -4.2363e+00, -7.5451e+00, -1.1381e+01, -1.5047e+01,\n",
      "         -1.0711e+01, -8.5512e+00, -8.7232e+00, -5.6582e+00, -4.9074e+00,\n",
      "         -1.0240e+01, -1.6256e+01,  3.2116e-01, -5.8024e+00, -3.6304e+00,\n",
      "          2.7371e+01, -1.2933e+00,  3.4105e+00, -2.0281e+01,  6.8953e+00,\n",
      "         -1.6353e+01,  4.8754e+00,  4.1666e+00,  1.2792e+01,  1.4447e+01,\n",
      "         -7.9719e+00,  1.7376e+01, -1.4986e+01,  2.5619e+01,  8.8798e+00,\n",
      "         -9.9386e+00,  1.6556e+01, -1.5139e+01, -5.2695e+00,  8.6553e+00,\n",
      "         -2.1743e+00, -5.4796e+00, -4.7367e+00, -3.7444e+00, -1.7076e+01,\n",
      "         -8.7400e+00, -2.7848e+00,  1.1214e+01, -1.4506e+01, -1.2933e+01,\n",
      "          3.3793e+00, -4.1410e+00,  1.5232e+01, -5.0032e+00,  2.3247e+00,\n",
      "          4.0953e+00,  2.2362e+01,  1.3047e+01, -7.1792e+00, -1.5675e+01,\n",
      "          2.8442e+01,  2.5077e+01,  6.4214e+00,  1.2281e+01,  6.9587e+00,\n",
      "          1.4833e+01,  1.3520e+00,  3.7095e+00,  6.0809e+00, -2.0195e+01,\n",
      "          1.5826e+01,  1.0352e+01,  8.4363e+00,  9.3974e+00, -3.3635e+00,\n",
      "         -1.0756e+01, -2.6985e+01,  4.4515e+00, -9.3802e+00,  6.0455e+00,\n",
      "          1.5521e+01,  4.1013e+00,  4.9835e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 13.8778, 131.8732,  22.4143,  -6.1881, -23.3713,   1.4360, -10.3088,\n",
      "         -16.7794,  18.0634,  10.0130, -11.5116,  -0.7202,   7.9117,   2.0278,\n",
      "          11.2123,   7.8619,  -6.7942,   6.4815,   7.7722,  21.8741,  11.2146,\n",
      "          -1.7963,  -1.1018,   0.1378,   7.9541,   3.4869,   6.1237,   2.9144,\n",
      "          -7.7823,   0.9891,  11.0528, -28.5397,  -4.7575,  -2.6074,   1.2921,\n",
      "          -8.9064,  -6.8499,  -1.9595, -16.0554,  12.5333,  -7.2258,   4.3925,\n",
      "         -15.1150,  26.4835,  20.0671,  -4.1739,  14.8916,  -5.3337, -12.5853,\n",
      "           9.7181,   6.4190,  -4.9545,  -9.2666, -13.5079, -13.5101,  -9.6603,\n",
      "          -8.3644,  -8.7100,  -6.1611,  -3.7650,  -8.6485, -17.0709,   0.4020,\n",
      "          -4.5869,  -0.4565,  30.1967,   0.1471,   3.2169, -21.9938,   5.3669,\n",
      "         -16.1231,   5.5284,   4.5450,  13.2616,  13.6628,  -7.5290,  16.9488,\n",
      "         -14.9080,  28.3706,  10.6739, -10.5698,  16.0802, -13.8500,  -4.3311,\n",
      "           7.9962,   0.3122,  -2.0411,  -2.2804,  -4.1007, -14.4987,  -9.4841,\n",
      "          -4.8941,  12.0847, -11.9186, -14.5309,   4.1356,  -5.9389,  14.2814,\n",
      "          -1.6083,   0.8900,   3.6536,  23.7582,  12.3345,  -7.0704, -15.2731,\n",
      "          27.4247,  25.2425,   8.1392,  14.4240,  10.1056,  15.4800,   1.0079,\n",
      "           4.8974,   4.3434, -21.9723,  16.9297,  11.7207,  10.8466,   8.8327,\n",
      "          -3.1330,  -9.9584, -28.0385,   4.1292,  -8.2765,   7.6163,  17.9471,\n",
      "           2.6391,   1.0365]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.5547e+01,  1.3118e+02,  2.3823e+01, -6.9373e+00, -2.3142e+01,\n",
      "         -2.3063e-01, -9.1673e+00, -1.7913e+01,  1.8570e+01,  1.0600e+01,\n",
      "         -1.1502e+01, -6.3656e-01,  7.6147e+00,  1.3120e+00,  1.2614e+01,\n",
      "          1.0236e+01, -7.7238e+00,  5.1132e+00,  4.0204e+00,  1.9018e+01,\n",
      "          1.1131e+01,  2.2822e+00,  1.3003e+00, -7.4379e-01,  6.6933e+00,\n",
      "          3.4228e+00,  6.6145e+00,  2.1145e+00, -9.7836e+00,  2.2556e+00,\n",
      "          1.0226e+01, -2.7043e+01, -7.8387e+00, -2.1420e+00,  1.0217e+00,\n",
      "         -8.6480e+00, -7.2779e+00,  6.4900e-01, -1.4019e+01,  1.0901e+01,\n",
      "         -6.1554e+00,  2.9816e+00, -1.4784e+01,  2.5868e+01,  1.8185e+01,\n",
      "         -5.6903e+00,  1.5141e+01, -4.1048e+00, -1.1079e+01,  1.1805e+01,\n",
      "          5.4631e+00, -6.9798e+00, -8.1643e+00, -1.0683e+01, -1.6800e+01,\n",
      "         -1.0458e+01, -6.6511e+00, -9.8922e+00, -7.6510e+00, -2.6957e+00,\n",
      "         -8.3458e+00, -1.5597e+01,  1.5141e+00, -2.6378e+00, -2.7902e+00,\n",
      "          2.8045e+01, -5.6094e-02,  3.5793e+00, -2.1005e+01,  1.1610e+01,\n",
      "         -1.6985e+01,  3.6176e+00,  7.0352e+00,  1.3347e+01,  1.4187e+01,\n",
      "         -6.8343e+00,  1.6185e+01, -1.6413e+01,  2.6489e+01,  1.0270e+01,\n",
      "         -8.8781e+00,  1.8257e+01, -1.3849e+01, -3.1888e+00,  9.5358e+00,\n",
      "         -5.7647e-01, -1.2188e+00, -5.9370e+00, -6.5611e+00, -1.6136e+01,\n",
      "         -7.1849e+00, -1.8362e+00,  1.0957e+01, -1.2910e+01, -1.5225e+01,\n",
      "          2.7342e+00, -4.7361e+00,  1.5762e+01, -3.2028e+00,  1.9028e+00,\n",
      "          4.5300e+00,  2.1780e+01,  1.2000e+01, -4.5993e+00, -1.6252e+01,\n",
      "          2.9100e+01,  2.4659e+01,  6.0222e+00,  1.1942e+01,  1.0225e+01,\n",
      "          1.7757e+01,  1.9846e+00,  4.1775e+00,  5.0617e+00, -1.9138e+01,\n",
      "          1.6130e+01,  1.1760e+01,  1.0186e+01,  1.0139e+01, -2.6916e+00,\n",
      "         -1.1087e+01, -2.8183e+01,  5.4019e+00, -8.9608e+00,  8.6544e+00,\n",
      "          1.8217e+01,  5.9825e+00,  2.8419e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.1611e+01,  1.3194e+02,  2.2497e+01, -6.8702e+00, -2.2353e+01,\n",
      "          4.2610e+00, -5.4104e+00, -1.6452e+01,  2.6332e+01,  5.6677e+00,\n",
      "         -1.4435e+01, -3.4171e+00,  8.6137e+00, -5.0283e+00,  1.0432e+01,\n",
      "          8.5769e+00, -2.6364e+00,  5.7582e+00,  5.0578e+00,  2.2748e+01,\n",
      "          1.0528e+01,  1.9041e+00,  3.3145e-01, -7.5900e-01,  8.1368e+00,\n",
      "         -1.6997e-01,  6.7859e+00,  3.1372e+00, -6.8000e+00,  7.3791e-01,\n",
      "          1.0003e+01, -3.0454e+01, -3.7824e+00, -2.5523e+00,  3.0362e+00,\n",
      "         -9.1119e+00, -7.3107e+00,  2.9446e+00, -1.2096e+01,  1.1540e+01,\n",
      "         -4.3992e+00,  3.1945e+00, -1.1490e+01,  2.5074e+01,  1.7902e+01,\n",
      "         -3.2589e+00,  1.5972e+01, -4.2363e+00, -1.4759e+01,  1.0018e+01,\n",
      "          3.9547e+00, -2.3999e+00, -1.4368e+01, -1.4919e+01, -1.6597e+01,\n",
      "         -8.7784e+00, -8.1626e+00, -9.9004e+00, -2.7685e+00,  2.9593e-03,\n",
      "         -9.5558e+00, -1.3625e+01, -2.4766e+00, -5.1706e+00, -4.6359e+00,\n",
      "          2.8255e+01, -3.4655e-01,  2.7061e+00, -1.9241e+01,  6.2263e+00,\n",
      "         -1.4604e+01,  2.4716e+00,  5.2933e+00,  1.5938e+01,  1.7353e+01,\n",
      "         -7.2692e+00,  1.5849e+01, -1.3695e+01,  2.3906e+01,  9.1291e+00,\n",
      "         -1.1766e+01,  2.0164e+01, -1.3686e+01, -7.5302e+00,  1.2220e+01,\n",
      "          4.6570e-01, -4.6329e+00, -4.3112e+00, -4.9742e+00, -1.5161e+01,\n",
      "         -9.9634e+00, -3.5378e+00,  1.0039e+01, -1.3593e+01, -1.1703e+01,\n",
      "          1.5648e+00, -7.5280e+00,  1.3764e+01, -5.4816e+00, -1.0718e+00,\n",
      "          3.3954e+00,  2.4733e+01,  1.2574e+01, -7.1372e+00, -1.3873e+01,\n",
      "          2.9093e+01,  2.2431e+01,  6.1478e+00,  1.4935e+01,  1.1494e+01,\n",
      "          1.4622e+01,  1.2317e+00,  4.4400e+00,  3.7252e+00, -2.1594e+01,\n",
      "          1.7224e+01,  1.3399e+01,  8.4553e+00,  6.2073e+00, -4.2936e+00,\n",
      "         -1.0799e+01, -2.4696e+01,  9.8645e-01, -1.0744e+01,  7.1009e+00,\n",
      "          1.5416e+01,  3.5830e+00,  4.9966e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.1716e+01,  1.3152e+02,  1.8660e+01, -6.1371e+00, -2.4756e+01,\n",
      "          8.5807e-01, -7.5720e+00, -1.4128e+01,  1.9487e+01,  9.5857e+00,\n",
      "         -1.0867e+01,  9.4343e-03,  7.4992e+00,  1.8902e+00,  1.0858e+01,\n",
      "          8.9220e+00, -6.0946e+00,  6.8691e+00,  2.6322e+00,  2.2191e+01,\n",
      "          8.5821e+00,  4.6761e-01, -1.5438e-01, -1.6243e+00,  9.4066e+00,\n",
      "          3.2147e+00,  9.3772e+00,  1.8190e+00, -6.8654e+00,  2.7347e+00,\n",
      "          8.8002e+00, -2.7424e+01, -4.4661e+00, -3.5311e+00, -1.3379e-01,\n",
      "         -9.4284e+00, -1.1684e+01, -1.7964e+00, -1.5993e+01,  1.3156e+01,\n",
      "         -6.6698e+00,  3.9092e+00, -1.3518e+01,  2.5864e+01,  1.8599e+01,\n",
      "         -5.6781e+00,  1.2740e+01, -5.5247e+00, -1.2050e+01,  1.1362e+01,\n",
      "          5.8112e+00, -4.2518e+00, -7.7215e+00, -1.1277e+01, -1.4905e+01,\n",
      "         -1.0453e+01, -8.6304e+00, -9.0501e+00, -4.9166e+00, -5.0705e+00,\n",
      "         -1.0027e+01, -1.5470e+01, -5.0168e-01, -5.9294e+00, -3.7816e+00,\n",
      "          2.7660e+01, -9.3425e-01,  4.2154e+00, -2.0436e+01,  6.6962e+00,\n",
      "         -1.6326e+01,  4.8363e+00,  4.7032e+00,  1.2591e+01,  1.5242e+01,\n",
      "         -7.2383e+00,  1.7623e+01, -1.5129e+01,  2.5877e+01,  8.5629e+00,\n",
      "         -1.0233e+01,  1.6740e+01, -1.5060e+01, -5.6891e+00,  8.8028e+00,\n",
      "         -1.7549e+00, -5.6240e+00, -4.6246e+00, -4.1197e+00, -1.7245e+01,\n",
      "         -8.5235e+00, -2.3632e+00,  1.0909e+01, -1.4379e+01, -1.2930e+01,\n",
      "          3.0403e+00, -4.6937e+00,  1.5342e+01, -4.9481e+00,  2.3679e+00,\n",
      "          4.2538e+00,  2.2861e+01,  1.2569e+01, -6.9223e+00, -1.6061e+01,\n",
      "          2.8068e+01,  2.4869e+01,  6.3501e+00,  1.2479e+01,  6.7535e+00,\n",
      "          1.4936e+01,  2.0496e+00,  3.9121e+00,  5.0859e+00, -2.1384e+01,\n",
      "          1.6216e+01,  1.0468e+01,  8.7776e+00,  9.8985e+00, -3.6630e+00,\n",
      "         -1.0968e+01, -2.6392e+01,  4.3696e+00, -9.3664e+00,  6.5214e+00,\n",
      "          1.6225e+01,  4.0108e+00,  4.7910e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 13.9189, 131.7382,  22.6326,  -6.3149, -23.3691,   1.6863,  -9.7368,\n",
      "         -17.1041,  18.2055,   9.6063, -11.5766,  -0.6932,   7.7558,   1.9997,\n",
      "          10.8238,   7.6577,  -6.4662,   5.8133,   7.3699,  22.0966,  11.5661,\n",
      "          -1.5806,  -1.2698,   0.1661,   7.9663,   3.1103,   6.3393,   3.0659,\n",
      "          -7.7501,   1.1606,  11.1635, -28.4224,  -4.8467,  -2.5000,   1.8089,\n",
      "          -9.0102,  -7.0306,  -1.9973, -15.8780,  12.4808,  -6.9616,   4.3862,\n",
      "         -15.1975,  26.5290,  20.2542,  -4.2943,  15.1704,  -5.2737, -12.6274,\n",
      "           9.8868,   6.5703,  -5.1341,  -9.4862, -13.2468, -13.0989,  -9.6631,\n",
      "          -8.4409,  -8.6207,  -5.7808,  -3.8331,  -8.6659, -17.0719,   0.5826,\n",
      "          -4.9026,  -1.1287,  30.0140,   0.4301,   3.5961, -22.0157,   5.3677,\n",
      "         -16.0698,   5.2236,   4.5565,  12.8421,  13.7747,  -7.3478,  17.0540,\n",
      "         -15.0090,  28.3732,  10.6761, -10.2252,  16.0355, -14.0200,  -4.5807,\n",
      "           7.5959,   0.4516,  -1.9772,  -1.8374,  -3.8479, -14.5281,  -9.3461,\n",
      "          -5.0284,  11.5425, -11.7173, -14.7803,   3.7051,  -5.7408,  13.9125,\n",
      "          -1.7991,   0.8265,   3.4689,  24.1965,  12.0276,  -6.9196, -15.5289,\n",
      "          27.2974,  25.0723,   7.5141,  14.3879,  10.1264,  15.6056,   1.3928,\n",
      "           4.6671,   3.6547, -22.7448,  17.1492,  11.3594,  10.9896,   9.4380,\n",
      "          -3.2382,  -9.7116, -27.9833,   4.1718,  -8.3747,   7.8773,  17.9971,\n",
      "           2.3586,   1.2566]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.5045e+01,  1.3126e+02,  2.3619e+01, -7.2896e+00, -2.2957e+01,\n",
      "          2.3601e-01, -8.5248e+00, -1.7651e+01,  1.8859e+01,  9.4219e+00,\n",
      "         -1.1687e+01, -1.0435e+00,  7.2759e+00,  1.4381e+00,  1.1471e+01,\n",
      "          1.0197e+01, -7.4874e+00,  4.9064e+00,  4.1978e+00,  1.9532e+01,\n",
      "          1.1352e+01,  2.3435e+00,  1.2583e+00, -5.0796e-01,  6.8889e+00,\n",
      "          3.1509e+00,  6.8233e+00,  2.0912e+00, -9.3823e+00,  2.1761e+00,\n",
      "          1.0441e+01, -2.7150e+01, -7.3696e+00, -2.2759e+00,  1.5074e+00,\n",
      "         -8.4799e+00, -6.8339e+00,  7.2640e-01, -1.3957e+01,  1.1203e+01,\n",
      "         -5.9319e+00,  2.9111e+00, -1.4607e+01,  2.5681e+01,  1.8640e+01,\n",
      "         -5.6158e+00,  1.5398e+01, -4.2540e+00, -1.1268e+01,  1.1989e+01,\n",
      "          5.8575e+00, -6.7112e+00, -8.3967e+00, -1.0939e+01, -1.6097e+01,\n",
      "         -1.0166e+01, -6.6367e+00, -9.8033e+00, -7.3270e+00, -3.0212e+00,\n",
      "         -8.1289e+00, -1.5694e+01,  1.3734e+00, -2.6626e+00, -3.1477e+00,\n",
      "          2.8376e+01,  1.3247e-01,  3.9469e+00, -2.1020e+01,  1.1054e+01,\n",
      "         -1.6578e+01,  3.9743e+00,  7.0380e+00,  1.3257e+01,  1.4845e+01,\n",
      "         -6.5118e+00,  1.6343e+01, -1.6382e+01,  2.6625e+01,  1.0122e+01,\n",
      "         -8.6870e+00,  1.8321e+01, -1.4169e+01, -3.4555e+00,  9.0267e+00,\n",
      "          9.5346e-02, -1.0360e+00, -5.3331e+00, -6.2151e+00, -1.5763e+01,\n",
      "         -7.4578e+00, -1.8469e+00,  1.0562e+01, -1.2347e+01, -1.5339e+01,\n",
      "          2.8532e+00, -4.7298e+00,  1.5305e+01, -3.0496e+00,  1.7842e+00,\n",
      "          4.7984e+00,  2.2270e+01,  1.1721e+01, -4.7634e+00, -1.6704e+01,\n",
      "          2.8772e+01,  2.4804e+01,  6.1020e+00,  1.1805e+01,  1.0426e+01,\n",
      "          1.8019e+01,  2.1258e+00,  4.4985e+00,  4.1422e+00, -2.0075e+01,\n",
      "          1.6273e+01,  1.1651e+01,  1.0412e+01,  1.0644e+01, -2.8774e+00,\n",
      "         -1.0993e+01, -2.7720e+01,  5.4152e+00, -8.9834e+00,  8.5726e+00,\n",
      "          1.8348e+01,  5.5977e+00,  2.6700e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.1457e+01,  1.3195e+02,  2.2087e+01, -7.1124e+00, -2.2338e+01,\n",
      "          3.8444e+00, -5.9631e+00, -1.6266e+01,  2.6116e+01,  5.3679e+00,\n",
      "         -1.4522e+01, -3.1325e+00,  8.7257e+00, -4.3371e+00,  9.4083e+00,\n",
      "          8.5184e+00, -2.7847e+00,  6.1403e+00,  4.8501e+00,  2.2959e+01,\n",
      "          1.0293e+01,  1.9087e+00,  1.0621e-02, -6.7831e-01,  8.5849e+00,\n",
      "         -2.2258e-01,  6.6501e+00,  2.7708e+00, -6.6592e+00,  9.2844e-01,\n",
      "          1.0173e+01, -3.0099e+01, -3.7468e+00, -2.7211e+00,  3.2749e+00,\n",
      "         -9.2614e+00, -7.2517e+00,  2.6574e+00, -1.2019e+01,  1.1947e+01,\n",
      "         -4.4714e+00,  3.1258e+00, -1.1160e+01,  2.5154e+01,  1.8294e+01,\n",
      "         -3.5267e+00,  1.5894e+01, -4.4385e+00, -1.4794e+01,  1.0239e+01,\n",
      "          4.2339e+00, -1.9185e+00, -1.3705e+01, -1.4728e+01, -1.6233e+01,\n",
      "         -8.5541e+00, -7.8496e+00, -1.0076e+01, -2.4373e+00, -8.9121e-01,\n",
      "         -9.3942e+00, -1.3726e+01, -2.9161e+00, -5.7652e+00, -4.3291e+00,\n",
      "          2.8406e+01, -5.3851e-02,  3.1463e+00, -1.9700e+01,  6.2494e+00,\n",
      "         -1.4746e+01,  2.9967e+00,  5.6834e+00,  1.5414e+01,  1.7204e+01,\n",
      "         -6.8663e+00,  1.5837e+01, -1.3938e+01,  2.3992e+01,  8.7915e+00,\n",
      "         -1.2060e+01,  2.0015e+01, -1.3910e+01, -7.3868e+00,  1.1779e+01,\n",
      "          4.4522e-01, -5.1619e+00, -3.8628e+00, -4.8814e+00, -1.5055e+01,\n",
      "         -9.6293e+00, -3.5559e+00,  9.5196e+00, -1.3274e+01, -1.1408e+01,\n",
      "          1.5812e+00, -7.6954e+00,  1.3614e+01, -5.1367e+00, -1.2223e+00,\n",
      "          3.5622e+00,  2.4983e+01,  1.2260e+01, -6.7853e+00, -1.4624e+01,\n",
      "          2.8879e+01,  2.2493e+01,  6.2306e+00,  1.4857e+01,  1.1227e+01,\n",
      "          1.5033e+01,  1.5840e+00,  4.3770e+00,  3.2346e+00, -2.2420e+01,\n",
      "          1.7702e+01,  1.3105e+01,  8.6063e+00,  7.3473e+00, -4.3449e+00,\n",
      "         -1.0618e+01, -2.4644e+01,  9.9392e-01, -1.0802e+01,  7.2003e+00,\n",
      "          1.5725e+01,  3.3713e+00,  4.6337e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.1337e+01,  1.3163e+02,  1.8730e+01, -6.5865e+00, -2.4650e+01,\n",
      "          5.9661e-01, -7.5501e+00, -1.3723e+01,  2.0374e+01,  8.7381e+00,\n",
      "         -1.1574e+01, -1.3082e-01,  8.0865e+00,  2.0337e+00,  9.5292e+00,\n",
      "          8.7814e+00, -6.2363e+00,  7.3223e+00,  2.2863e+00,  2.2268e+01,\n",
      "          8.4119e+00,  1.1342e+00,  1.1757e-01, -1.6087e+00,  9.5289e+00,\n",
      "          2.9012e+00,  8.8842e+00,  1.5974e+00, -6.7080e+00,  2.5270e+00,\n",
      "          9.3527e+00, -2.7318e+01, -4.0890e+00, -3.5899e+00,  4.2845e-01,\n",
      "         -9.4676e+00, -1.1079e+01, -1.3552e+00, -1.5569e+01,  1.3694e+01,\n",
      "         -6.5585e+00,  3.8756e+00, -1.2827e+01,  2.5756e+01,  1.8590e+01,\n",
      "         -5.9330e+00,  1.2624e+01, -5.6958e+00, -1.2178e+01,  1.1664e+01,\n",
      "          5.4314e+00, -3.6631e+00, -7.8716e+00, -1.1266e+01, -1.4954e+01,\n",
      "         -1.0093e+01, -8.4536e+00, -9.3676e+00, -4.3707e+00, -5.4366e+00,\n",
      "         -9.9674e+00, -1.5075e+01, -1.3918e+00, -5.4757e+00, -3.5618e+00,\n",
      "          2.8043e+01, -5.0343e-01,  4.4390e+00, -2.0549e+01,  6.5632e+00,\n",
      "         -1.6261e+01,  4.9158e+00,  5.0544e+00,  1.2880e+01,  1.5333e+01,\n",
      "         -6.4424e+00,  1.7565e+01, -1.5233e+01,  2.5670e+01,  8.1362e+00,\n",
      "         -1.0548e+01,  1.7169e+01, -1.4980e+01, -6.0576e+00,  8.5333e+00,\n",
      "         -1.4668e+00, -6.1162e+00, -4.4676e+00, -4.4896e+00, -1.7206e+01,\n",
      "         -8.0630e+00, -2.2658e+00,  1.0741e+01, -1.4457e+01, -1.2814e+01,\n",
      "          2.9682e+00, -5.1912e+00,  1.5302e+01, -4.6348e+00,  2.0724e+00,\n",
      "          4.5741e+00,  2.3044e+01,  1.2136e+01, -7.1035e+00, -1.6541e+01,\n",
      "          2.7759e+01,  2.4697e+01,  6.4981e+00,  1.2177e+01,  6.7250e+00,\n",
      "          1.5249e+01,  2.6100e+00,  4.3072e+00,  4.3486e+00, -2.2152e+01,\n",
      "          1.7030e+01,  1.0884e+01,  9.1084e+00,  9.9872e+00, -3.8595e+00,\n",
      "         -1.1136e+01, -2.5758e+01,  4.3139e+00, -9.5122e+00,  7.0000e+00,\n",
      "          1.6680e+01,  4.1008e+00,  4.1409e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.3814e+01,  1.3174e+02,  2.2729e+01, -6.7495e+00, -2.3197e+01,\n",
      "          1.7018e+00, -9.6330e+00, -1.6940e+01,  1.9024e+01,  9.2624e+00,\n",
      "         -1.1712e+01, -9.9527e-01,  7.8042e+00,  2.0051e+00,  1.0319e+01,\n",
      "          7.6160e+00, -6.2331e+00,  5.6807e+00,  6.7464e+00,  2.2154e+01,\n",
      "          1.1553e+01, -9.4344e-01, -1.2160e+00,  1.0218e-01,  8.0740e+00,\n",
      "          2.8179e+00,  6.3717e+00,  3.1525e+00, -7.5334e+00,  1.2045e+00,\n",
      "          1.1437e+01, -2.8582e+01, -5.0501e+00, -2.3118e+00,  1.9010e+00,\n",
      "         -9.1763e+00, -6.9915e+00, -1.4865e+00, -1.5409e+01,  1.2691e+01,\n",
      "         -6.6342e+00,  4.2926e+00, -1.5346e+01,  2.6703e+01,  2.0207e+01,\n",
      "         -4.4899e+00,  1.5537e+01, -5.1460e+00, -1.2614e+01,  9.7500e+00,\n",
      "          6.2088e+00, -4.8219e+00, -9.4877e+00, -1.3075e+01, -1.3387e+01,\n",
      "         -9.4651e+00, -8.3414e+00, -8.6335e+00, -5.7021e+00, -3.9051e+00,\n",
      "         -8.5274e+00, -1.7244e+01,  6.4702e-01, -4.7380e+00, -1.3977e+00,\n",
      "          3.0067e+01,  7.7915e-01,  3.5110e+00, -2.2195e+01,  5.5051e+00,\n",
      "         -1.6101e+01,  4.8989e+00,  4.8111e+00,  1.2822e+01,  1.3374e+01,\n",
      "         -6.7617e+00,  1.6710e+01, -1.5037e+01,  2.8019e+01,  1.0547e+01,\n",
      "         -9.8341e+00,  1.6388e+01, -1.4397e+01, -4.8334e+00,  7.0412e+00,\n",
      "          2.4847e-01, -2.4764e+00, -1.7568e+00, -3.9084e+00, -1.4319e+01,\n",
      "         -9.2511e+00, -5.0408e+00,  1.0918e+01, -1.1854e+01, -1.4918e+01,\n",
      "          3.4532e+00, -5.7306e+00,  1.3615e+01, -1.4601e+00,  6.8068e-01,\n",
      "          3.6347e+00,  2.4320e+01,  1.1570e+01, -7.0856e+00, -1.5933e+01,\n",
      "          2.7201e+01,  2.4888e+01,  7.1269e+00,  1.3845e+01,  1.0398e+01,\n",
      "          1.5787e+01,  1.6272e+00,  4.7590e+00,  3.3950e+00, -2.3190e+01,\n",
      "          1.7690e+01,  1.1223e+01,  1.1051e+01,  9.7266e+00, -3.4099e+00,\n",
      "         -9.7224e+00, -2.7969e+01,  4.1651e+00, -8.6388e+00,  8.1064e+00,\n",
      "          1.7912e+01,  2.4642e+00,  1.1451e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 14.7767, 131.3941,  23.4196,  -7.5887, -22.8400,   0.3967,  -8.3964,\n",
      "         -17.0125,  19.4943,   8.6990, -11.6380,  -1.5262,   7.3890,   1.5285,\n",
      "          10.6669,  10.1162,  -7.1431,   4.9831,   3.9328,  19.7128,  11.1991,\n",
      "           2.3864,   1.1326,  -0.3868,   7.1838,   3.1312,   6.7587,   2.4113,\n",
      "          -8.9285,   2.0263,  10.9558, -27.4950,  -7.1814,  -2.1162,   1.6527,\n",
      "          -8.4075,  -6.5969,   0.8637, -13.6430,  11.2199,  -5.5156,   2.8751,\n",
      "         -14.6590,  25.6101,  18.7973,  -5.5829,  15.5995,  -4.2098, -11.3959,\n",
      "          11.8030,   5.7587,  -6.3175,  -8.4699, -11.1365, -16.1910,  -9.7977,\n",
      "          -6.7133,  -9.6479,  -7.1765,  -3.3836,  -7.8467, -15.8082,   1.1480,\n",
      "          -2.7026,  -3.6486,  28.9350,   0.3722,   4.0381, -21.1071,  10.7252,\n",
      "         -16.2346,   3.8339,   7.4655,  13.5209,  14.8636,  -5.9470,  16.2145,\n",
      "         -16.3463,  26.3565,  10.1328,  -8.4685,  18.6272, -14.4173,  -3.6917,\n",
      "           8.3812,   0.2661,  -1.1144,  -5.1985,  -5.9621, -15.3804,  -7.6433,\n",
      "          -1.9619,  10.0247, -12.4594, -15.3529,   2.9207,  -4.6405,  14.9299,\n",
      "          -2.6010,   1.9291,   5.1264,  22.6876,  11.2856,  -5.1427, -16.9495,\n",
      "          28.5916,  24.9440,   6.0387,  11.2880,  10.8464,  17.9337,   2.0280,\n",
      "           4.8982,   3.8799, -20.5459,  16.7120,  11.6241,  10.6286,  10.8586,\n",
      "          -3.2429, -11.0420, -27.6479,   5.2240,  -9.1853,   8.6200,  18.3087,\n",
      "           5.6611,   2.2149]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.1443e+01,  1.3202e+02,  2.1958e+01, -7.2967e+00, -2.2422e+01,\n",
      "          3.3510e+00, -6.3954e+00, -1.5862e+01,  2.6096e+01,  5.5517e+00,\n",
      "         -1.4386e+01, -2.8243e+00,  8.7260e+00, -3.6810e+00,  8.8442e+00,\n",
      "          8.2939e+00, -2.6602e+00,  6.0020e+00,  4.5180e+00,  2.2914e+01,\n",
      "          1.0122e+01,  1.6418e+00, -4.5919e-01, -7.1139e-01,  8.9544e+00,\n",
      "         -8.5312e-02,  6.7105e+00,  2.8436e+00, -6.4418e+00,  1.0103e+00,\n",
      "          1.0397e+01, -3.0040e+01, -4.0091e+00, -2.7635e+00,  3.1888e+00,\n",
      "         -9.2947e+00, -7.2921e+00,  2.4652e+00, -1.1881e+01,  1.2095e+01,\n",
      "         -4.0868e+00,  3.1666e+00, -1.1382e+01,  2.5270e+01,  1.8402e+01,\n",
      "         -3.7206e+00,  1.6004e+01, -4.4960e+00, -1.4423e+01,  1.0205e+01,\n",
      "          4.2634e+00, -1.8314e+00, -1.3214e+01, -1.4613e+01, -1.6347e+01,\n",
      "         -8.3374e+00, -7.8206e+00, -9.8409e+00, -2.4345e+00, -1.5327e+00,\n",
      "         -9.0099e+00, -1.4109e+01, -3.0448e+00, -6.1058e+00, -4.6986e+00,\n",
      "          2.8828e+01,  1.6852e-01,  3.4287e+00, -2.0226e+01,  6.3506e+00,\n",
      "         -1.5007e+01,  2.8669e+00,  6.2040e+00,  1.5185e+01,  1.6976e+01,\n",
      "         -6.3945e+00,  1.5793e+01, -1.4006e+01,  2.3917e+01,  9.0345e+00,\n",
      "         -1.1985e+01,  1.9992e+01, -1.4365e+01, -7.2250e+00,  1.0970e+01,\n",
      "          2.0535e-01, -5.4263e+00, -3.5643e+00, -4.8862e+00, -1.4898e+01,\n",
      "         -9.4948e+00, -3.7967e+00,  9.0153e+00, -1.3346e+01, -1.1196e+01,\n",
      "          1.5081e+00, -7.6973e+00,  1.3534e+01, -4.6206e+00, -1.0218e+00,\n",
      "          3.6823e+00,  2.5074e+01,  1.1919e+01, -6.8157e+00, -1.5440e+01,\n",
      "          2.8741e+01,  2.2634e+01,  6.4055e+00,  1.4727e+01,  1.1183e+01,\n",
      "          1.5000e+01,  1.5689e+00,  4.2010e+00,  3.1756e+00, -2.2843e+01,\n",
      "          1.8092e+01,  1.2641e+01,  8.5856e+00,  8.1246e+00, -4.5589e+00,\n",
      "         -1.0772e+01, -2.5050e+01,  1.2308e+00, -1.0986e+01,  7.4570e+00,\n",
      "          1.5982e+01,  3.0688e+00,  4.4441e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0730e+01,  1.3177e+02,  1.8677e+01, -6.7464e+00, -2.4566e+01,\n",
      "          5.4609e-01, -7.2876e+00, -1.3210e+01,  2.0931e+01,  8.1855e+00,\n",
      "         -1.1854e+01, -4.2526e-01,  8.3425e+00,  2.0336e+00,  8.6081e+00,\n",
      "          8.6443e+00, -6.3027e+00,  7.3134e+00,  2.4932e+00,  2.2602e+01,\n",
      "          8.3621e+00,  1.1518e+00, -1.0613e-01, -1.6568e+00,  9.7717e+00,\n",
      "          2.5158e+00,  8.4443e+00,  1.4654e+00, -6.3135e+00,  2.0682e+00,\n",
      "          9.7034e+00, -2.7600e+01, -3.9470e+00, -3.7398e+00,  7.6779e-01,\n",
      "         -9.5179e+00, -1.0920e+01, -1.2005e+00, -1.5295e+01,  1.3919e+01,\n",
      "         -6.0756e+00,  3.7824e+00, -1.2728e+01,  2.5822e+01,  1.8597e+01,\n",
      "         -6.2606e+00,  1.2807e+01, -6.0534e+00, -1.2044e+01,  1.2023e+01,\n",
      "          5.1420e+00, -3.3678e+00, -7.9836e+00, -1.1640e+01, -1.4734e+01,\n",
      "         -9.8390e+00, -8.3798e+00, -9.7080e+00, -4.2976e+00, -5.5661e+00,\n",
      "         -9.4714e+00, -1.5112e+01, -1.6824e+00, -5.0318e+00, -4.0309e+00,\n",
      "          2.8756e+01, -4.2720e-01,  4.8509e+00, -2.0739e+01,  6.3234e+00,\n",
      "         -1.6011e+01,  4.4236e+00,  5.4458e+00,  1.3209e+01,  1.5605e+01,\n",
      "         -5.9872e+00,  1.7568e+01, -1.5342e+01,  2.5589e+01,  8.2792e+00,\n",
      "         -1.0828e+01,  1.7503e+01, -1.4884e+01, -6.2059e+00,  8.3378e+00,\n",
      "         -1.1843e+00, -6.1871e+00, -4.2210e+00, -4.5218e+00, -1.7082e+01,\n",
      "         -7.8825e+00, -2.5482e+00,  1.0684e+01, -1.4550e+01, -1.2529e+01,\n",
      "          2.8088e+00, -5.4826e+00,  1.5293e+01, -4.3616e+00,  2.0904e+00,\n",
      "          4.6098e+00,  2.3226e+01,  1.1683e+01, -7.5412e+00, -1.6775e+01,\n",
      "          2.7520e+01,  2.4585e+01,  6.7231e+00,  1.2304e+01,  6.9519e+00,\n",
      "          1.5284e+01,  2.6493e+00,  4.3641e+00,  3.7434e+00, -2.2843e+01,\n",
      "          1.7549e+01,  1.1076e+01,  9.2284e+00,  1.0257e+01, -4.0860e+00,\n",
      "         -1.1369e+01, -2.5380e+01,  4.4257e+00, -9.6841e+00,  7.3498e+00,\n",
      "          1.7188e+01,  3.9631e+00,  3.7310e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.3327e+01,  1.3181e+02,  2.2507e+01, -7.0039e+00, -2.3055e+01,\n",
      "          1.7752e+00, -9.2210e+00, -1.6495e+01,  1.9585e+01,  8.9398e+00,\n",
      "         -1.2006e+01, -1.2461e+00,  7.5589e+00,  1.9258e+00,  9.8364e+00,\n",
      "          7.7104e+00, -6.0975e+00,  5.3046e+00,  6.6687e+00,  2.2769e+01,\n",
      "          1.1286e+01, -6.5658e-01, -1.3826e+00,  3.0469e-02,  8.1637e+00,\n",
      "          2.5089e+00,  6.5441e+00,  2.9120e+00, -7.2392e+00,  9.1208e-01,\n",
      "          1.1631e+01, -2.8888e+01, -5.2248e+00, -2.4509e+00,  1.9715e+00,\n",
      "         -9.4830e+00, -7.2659e+00, -1.0126e+00, -1.5369e+01,  1.2812e+01,\n",
      "         -6.0785e+00,  4.0746e+00, -1.5321e+01,  2.6753e+01,  2.0266e+01,\n",
      "         -4.7866e+00,  1.6076e+01, -5.4140e+00, -1.2534e+01,  1.0011e+01,\n",
      "          6.1003e+00, -4.8022e+00, -9.4081e+00, -1.3351e+01, -1.3081e+01,\n",
      "         -9.1707e+00, -8.5070e+00, -8.8124e+00, -5.6233e+00, -3.8151e+00,\n",
      "         -8.2444e+00, -1.7501e+01,  7.3667e-01, -4.4460e+00, -1.8891e+00,\n",
      "          3.0441e+01,  5.9226e-01,  3.6984e+00, -2.2285e+01,  5.5095e+00,\n",
      "         -1.6184e+01,  4.5359e+00,  4.9632e+00,  1.2668e+01,  1.3421e+01,\n",
      "         -6.4155e+00,  1.6677e+01, -1.5044e+01,  2.7762e+01,  1.0732e+01,\n",
      "         -9.6786e+00,  1.6664e+01, -1.4666e+01, -5.1884e+00,  6.6861e+00,\n",
      "          4.4810e-01, -2.7506e+00, -1.3972e+00, -4.0467e+00, -1.4080e+01,\n",
      "         -9.2064e+00, -5.1732e+00,  1.0576e+01, -1.1778e+01, -1.4854e+01,\n",
      "          3.1382e+00, -5.9963e+00,  1.3408e+01, -1.2960e+00,  7.0819e-01,\n",
      "          3.4966e+00,  2.4171e+01,  1.1273e+01, -7.3251e+00, -1.6158e+01,\n",
      "          2.7035e+01,  2.4832e+01,  7.0978e+00,  1.3899e+01,  1.0488e+01,\n",
      "          1.5751e+01,  1.5276e+00,  4.6179e+00,  2.8796e+00, -2.3669e+01,\n",
      "          1.7964e+01,  1.0853e+01,  1.0742e+01,  9.9811e+00, -3.6144e+00,\n",
      "         -9.8728e+00, -2.7899e+01,  4.3594e+00, -8.9318e+00,  8.1980e+00,\n",
      "          1.8075e+01,  2.1328e+00,  1.1576e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.4152e+01,  1.3162e+02,  2.3100e+01, -7.8673e+00, -2.2826e+01,\n",
      "          4.3507e-01, -8.2494e+00, -1.6176e+01,  1.9841e+01,  7.9488e+00,\n",
      "         -1.1912e+01, -1.6601e+00,  7.4636e+00,  1.5622e+00,  9.8723e+00,\n",
      "          1.0207e+01, -7.1880e+00,  5.0324e+00,  3.9746e+00,  2.0201e+01,\n",
      "          1.0630e+01,  2.4746e+00,  9.9176e-01, -3.5801e-01,  7.2889e+00,\n",
      "          3.0056e+00,  6.7394e+00,  2.1501e+00, -8.6722e+00,  1.7151e+00,\n",
      "          1.1312e+01, -2.7641e+01, -6.8139e+00, -2.2183e+00,  1.8768e+00,\n",
      "         -8.6730e+00, -6.4435e+00,  8.4842e-01, -1.3755e+01,  1.1526e+01,\n",
      "         -5.1045e+00,  2.7250e+00, -1.4095e+01,  2.5475e+01,  1.9197e+01,\n",
      "         -5.8351e+00,  1.5685e+01, -4.4819e+00, -1.1521e+01,  1.2276e+01,\n",
      "          5.7039e+00, -6.0605e+00, -8.4676e+00, -1.1677e+01, -1.5921e+01,\n",
      "         -9.3758e+00, -6.7517e+00, -9.8719e+00, -6.7965e+00, -3.5925e+00,\n",
      "         -7.7038e+00, -1.5869e+01,  7.3271e-01, -2.5513e+00, -3.7630e+00,\n",
      "          2.9695e+01,  7.5741e-02,  4.3275e+00, -2.1053e+01,  1.0465e+01,\n",
      "         -1.6112e+01,  3.9480e+00,  7.8246e+00,  1.3778e+01,  1.5105e+01,\n",
      "         -5.5262e+00,  1.6433e+01, -1.6190e+01,  2.6186e+01,  1.0043e+01,\n",
      "         -8.6867e+00,  1.8911e+01, -1.4333e+01, -4.0520e+00,  8.2197e+00,\n",
      "          7.4018e-01, -1.3447e+00, -4.7841e+00, -6.1321e+00, -1.5066e+01,\n",
      "         -7.5140e+00, -2.0090e+00,  9.7849e+00, -1.2329e+01, -1.5175e+01,\n",
      "          2.9411e+00, -5.0643e+00,  1.4771e+01, -2.2685e+00,  2.0178e+00,\n",
      "          5.0321e+00,  2.2850e+01,  1.1120e+01, -5.4130e+00, -1.6772e+01,\n",
      "          2.8152e+01,  2.4933e+01,  6.4804e+00,  1.1356e+01,  1.0881e+01,\n",
      "          1.7736e+01,  1.7927e+00,  5.3228e+00,  3.4405e+00, -2.1090e+01,\n",
      "          1.7346e+01,  1.1800e+01,  1.0543e+01,  1.1009e+01, -3.5907e+00,\n",
      "         -1.1277e+01, -2.7341e+01,  5.0460e+00, -9.2392e+00,  8.5313e+00,\n",
      "          1.8409e+01,  5.5924e+00,  1.7924e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.1170e+01,  1.3214e+02,  2.1865e+01, -7.4947e+00, -2.2344e+01,\n",
      "          2.8721e+00, -6.7887e+00, -1.5349e+01,  2.5846e+01,  5.6204e+00,\n",
      "         -1.4436e+01, -2.3072e+00,  8.6906e+00, -2.9930e+00,  8.3513e+00,\n",
      "          8.2723e+00, -2.8677e+00,  5.9308e+00,  4.2420e+00,  2.2888e+01,\n",
      "          9.8042e+00,  1.5041e+00, -8.0347e-01, -7.2818e-01,  8.9574e+00,\n",
      "          8.4917e-02,  6.7469e+00,  2.6209e+00, -6.4831e+00,  9.2667e-01,\n",
      "          1.0556e+01, -2.9800e+01, -4.0686e+00, -2.9743e+00,  3.1692e+00,\n",
      "         -9.5327e+00, -7.2279e+00,  2.2011e+00, -1.2063e+01,  1.2334e+01,\n",
      "         -3.9983e+00,  3.1742e+00, -1.1019e+01,  2.5409e+01,  1.8674e+01,\n",
      "         -3.9253e+00,  1.5993e+01, -4.6628e+00, -1.4141e+01,  1.0647e+01,\n",
      "          4.3276e+00, -1.8432e+00, -1.2826e+01, -1.4692e+01, -1.6306e+01,\n",
      "         -8.0370e+00, -7.8125e+00, -9.8236e+00, -2.1330e+00, -1.8448e+00,\n",
      "         -8.8823e+00, -1.4285e+01, -3.0744e+00, -6.2137e+00, -4.4611e+00,\n",
      "          2.9379e+01,  6.5684e-02,  3.7072e+00, -2.0667e+01,  6.2902e+00,\n",
      "         -1.5373e+01,  3.0707e+00,  6.7140e+00,  1.4926e+01,  1.6877e+01,\n",
      "         -6.0318e+00,  1.5876e+01, -1.3877e+01,  2.4020e+01,  8.9901e+00,\n",
      "         -1.2080e+01,  2.0046e+01, -1.4417e+01, -7.0587e+00,  1.0734e+01,\n",
      "          1.6292e-01, -5.7433e+00, -3.0443e+00, -5.2877e+00, -1.4655e+01,\n",
      "         -9.2666e+00, -3.8265e+00,  8.6144e+00, -1.2987e+01, -1.1061e+01,\n",
      "          1.5416e+00, -8.0637e+00,  1.3480e+01, -4.1890e+00, -9.5640e-01,\n",
      "          3.4386e+00,  2.5010e+01,  1.1730e+01, -6.5419e+00, -1.5742e+01,\n",
      "          2.8447e+01,  2.2626e+01,  6.8019e+00,  1.4952e+01,  1.1015e+01,\n",
      "          1.5167e+01,  1.5394e+00,  4.3468e+00,  2.9642e+00, -2.3432e+01,\n",
      "          1.8623e+01,  1.2465e+01,  8.3892e+00,  8.8245e+00, -4.7112e+00,\n",
      "         -1.1036e+01, -2.5140e+01,  1.2105e+00, -1.0986e+01,  7.4847e+00,\n",
      "          1.6168e+01,  2.9001e+00,  3.9932e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 10.2440, 131.8682,  19.0033,  -6.8616, -24.2629,   0.5640,  -7.1665,\n",
      "         -12.9114,  21.1727,   7.7543, -12.1391,  -0.2721,   8.6160,   2.1602,\n",
      "           8.0311,   8.7750,  -6.3009,   7.1628,   2.3824,  22.4503,   8.0994,\n",
      "           1.4904,  -0.4189,  -1.6708,   9.6942,   2.0818,   8.1057,   1.3741,\n",
      "          -6.2170,   1.7550,   9.6657, -27.4713,  -3.8219,  -3.8323,   1.2223,\n",
      "          -9.4806, -10.6824,  -1.3062, -15.0273,  14.3048,  -5.8061,   3.6738,\n",
      "         -12.2539,  25.8685,  18.7758,  -6.3360,  12.7691,  -6.2015, -11.8808,\n",
      "          12.5689,   4.7891,  -3.0403,  -8.3624, -11.9265, -14.9319,  -9.7623,\n",
      "          -8.0245, -10.0721,  -3.9107,  -5.5810,  -9.3037, -15.0073,  -1.7214,\n",
      "          -4.6299,  -4.1465,  29.2370,  -0.3264,   5.1229, -20.9156,   6.1602,\n",
      "         -15.9244,   4.2233,   5.9143,  13.3100,  15.8941,  -5.5967,  17.5876,\n",
      "         -15.2261,  25.4646,   8.1574, -11.0795,  18.0679, -14.4977,  -6.3038,\n",
      "           8.2799,  -0.7919,  -6.2337,  -4.0137,  -5.0524, -16.9868,  -7.7727,\n",
      "          -2.4113,  10.5442, -14.2176, -12.2461,   2.7002,  -5.6996,  15.0283,\n",
      "          -4.0608,   2.1257,   4.1816,  23.3899,  11.3736,  -7.4845, -16.7706,\n",
      "          27.4340,  24.1981,   7.0442,  12.5174,   6.9923,  15.5964,   2.7551,\n",
      "           4.5138,   3.3787, -23.4897,  17.9736,  11.5283,   9.4062,  10.5042,\n",
      "          -4.2851, -11.4689, -25.2358,   4.3932,  -9.6211,   7.5334,  17.3877,\n",
      "           3.9796,   3.4066]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.2954e+01,  1.3180e+02,  2.2695e+01, -7.3055e+00, -2.2605e+01,\n",
      "          1.8227e+00, -8.8311e+00, -1.6317e+01,  2.0142e+01,  8.6226e+00,\n",
      "         -1.2131e+01, -1.0275e+00,  7.5515e+00,  2.0882e+00,  9.3903e+00,\n",
      "          7.8619e+00, -5.8634e+00,  4.8445e+00,  6.1610e+00,  2.2979e+01,\n",
      "          1.1187e+01, -2.0483e-01, -1.7482e+00, -9.8132e-03,  8.2434e+00,\n",
      "          2.1873e+00,  6.5171e+00,  2.8690e+00, -7.0448e+00,  6.3811e-01,\n",
      "          1.1573e+01, -2.8737e+01, -5.2415e+00, -2.4244e+00,  2.2086e+00,\n",
      "         -9.7573e+00, -7.3270e+00, -8.5685e-01, -1.5177e+01,  1.2971e+01,\n",
      "         -5.6915e+00,  3.9046e+00, -1.5203e+01,  2.6802e+01,  2.0515e+01,\n",
      "         -4.8948e+00,  1.6296e+01, -5.5131e+00, -1.2415e+01,  1.0312e+01,\n",
      "          6.0043e+00, -4.5592e+00, -9.5081e+00, -1.3388e+01, -1.3097e+01,\n",
      "         -9.0717e+00, -8.3345e+00, -8.9249e+00, -5.2644e+00, -3.7572e+00,\n",
      "         -8.2819e+00, -1.7495e+01,  9.4606e-01, -4.4746e+00, -2.3438e+00,\n",
      "          3.0509e+01,  4.3251e-01,  3.8547e+00, -2.2526e+01,  5.5892e+00,\n",
      "         -1.6489e+01,  4.1765e+00,  5.2722e+00,  1.2336e+01,  1.3385e+01,\n",
      "         -6.0701e+00,  1.6563e+01, -1.4800e+01,  2.7506e+01,  1.0535e+01,\n",
      "         -9.4864e+00,  1.6950e+01, -1.4720e+01, -5.5656e+00,  6.2547e+00,\n",
      "          6.1122e-01, -3.1252e+00, -9.6503e-01, -4.3934e+00, -1.3898e+01,\n",
      "         -9.2102e+00, -5.1193e+00,  1.0045e+01, -1.1566e+01, -1.4679e+01,\n",
      "          2.9030e+00, -6.2185e+00,  1.3078e+01, -1.2640e+00,  8.5924e-01,\n",
      "          3.2363e+00,  2.4085e+01,  1.0986e+01, -7.2268e+00, -1.6427e+01,\n",
      "          2.7025e+01,  2.4630e+01,  6.8563e+00,  1.3845e+01,  1.0628e+01,\n",
      "          1.5986e+01,  1.6664e+00,  4.4473e+00,  2.4492e+00, -2.4342e+01,\n",
      "          1.8280e+01,  1.0748e+01,  1.0704e+01,  1.0409e+01, -3.8165e+00,\n",
      "         -9.7460e+00, -2.8057e+01,  4.2336e+00, -9.0415e+00,  8.1865e+00,\n",
      "          1.8075e+01,  1.8279e+00,  1.2099e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.3801e+01,  1.3174e+02,  2.3236e+01, -8.0124e+00, -2.2724e+01,\n",
      "          4.4180e-01, -8.0868e+00, -1.5825e+01,  2.0043e+01,  7.3684e+00,\n",
      "         -1.2074e+01, -1.3650e+00,  7.6485e+00,  1.7397e+00,  9.1863e+00,\n",
      "          1.0180e+01, -7.0290e+00,  4.8356e+00,  3.6406e+00,  2.0208e+01,\n",
      "          1.0489e+01,  2.5048e+00,  6.6255e-01, -4.5571e-01,  7.4799e+00,\n",
      "          2.9126e+00,  6.3464e+00,  2.0334e+00, -8.3452e+00,  1.5591e+00,\n",
      "          1.1268e+01, -2.7523e+01, -6.4761e+00, -2.1083e+00,  2.2222e+00,\n",
      "         -9.0073e+00, -6.2143e+00,  5.2894e-01, -1.3631e+01,  1.1816e+01,\n",
      "         -4.9074e+00,  2.7415e+00, -1.3750e+01,  2.5443e+01,  1.9593e+01,\n",
      "         -6.0342e+00,  1.5581e+01, -4.6471e+00, -1.1606e+01,  1.2774e+01,\n",
      "          5.7310e+00, -5.6645e+00, -8.5824e+00, -1.2035e+01, -1.5858e+01,\n",
      "         -9.1981e+00, -6.4909e+00, -1.0045e+01, -6.5414e+00, -3.9281e+00,\n",
      "         -7.9466e+00, -1.5940e+01,  5.1950e-01, -2.8232e+00, -4.1415e+00,\n",
      "          2.9921e+01, -1.0411e-01,  4.5648e+00, -2.1222e+01,  1.0394e+01,\n",
      "         -1.6250e+01,  3.7373e+00,  8.1327e+00,  1.3841e+01,  1.5147e+01,\n",
      "         -5.1343e+00,  1.6508e+01, -1.5901e+01,  2.6009e+01,  9.9526e+00,\n",
      "         -8.9210e+00,  1.9064e+01, -1.4140e+01, -4.3009e+00,  7.9788e+00,\n",
      "          9.4979e-01, -1.5851e+00, -4.4326e+00, -6.2127e+00, -1.4872e+01,\n",
      "         -7.3784e+00, -2.1697e+00,  9.3226e+00, -1.2247e+01, -1.4898e+01,\n",
      "          2.9315e+00, -5.3331e+00,  1.4394e+01, -2.3063e+00,  2.1053e+00,\n",
      "          5.0425e+00,  2.3201e+01,  1.1088e+01, -5.5235e+00, -1.6685e+01,\n",
      "          2.7995e+01,  2.4779e+01,  6.4688e+00,  1.1379e+01,  1.0961e+01,\n",
      "          1.7588e+01,  1.7226e+00,  5.4552e+00,  3.2504e+00, -2.1724e+01,\n",
      "          1.7952e+01,  1.2061e+01,  1.0795e+01,  1.1486e+01, -4.0228e+00,\n",
      "         -1.1286e+01, -2.7537e+01,  4.7431e+00, -9.1877e+00,  8.1766e+00,\n",
      "          1.8446e+01,  5.4703e+00,  1.6023e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.1197e+01,  1.3225e+02,  2.1967e+01, -7.7928e+00, -2.2212e+01,\n",
      "          2.5947e+00, -6.9971e+00, -1.5251e+01,  2.5611e+01,  5.6404e+00,\n",
      "         -1.4573e+01, -1.6787e+00,  8.6347e+00, -2.4605e+00,  7.9604e+00,\n",
      "          8.2630e+00, -3.1133e+00,  5.7105e+00,  3.6835e+00,  2.2780e+01,\n",
      "          9.7664e+00,  1.2369e+00, -1.1474e+00, -8.1645e-01,  8.9738e+00,\n",
      "          2.9528e-01,  6.3711e+00,  2.3864e+00, -6.3796e+00,  7.2283e-01,\n",
      "          1.0513e+01, -2.9497e+01, -4.0548e+00, -3.0294e+00,  3.3112e+00,\n",
      "         -9.8248e+00, -7.1260e+00,  1.9015e+00, -1.2008e+01,  1.2480e+01,\n",
      "         -3.9303e+00,  3.2929e+00, -1.0787e+01,  2.5567e+01,  1.8904e+01,\n",
      "         -4.1984e+00,  1.5966e+01, -4.8605e+00, -1.4030e+01,  1.1055e+01,\n",
      "          4.6364e+00, -1.6818e+00, -1.2468e+01, -1.4728e+01, -1.6204e+01,\n",
      "         -7.7668e+00, -7.7360e+00, -9.7143e+00, -2.0919e+00, -2.1222e+00,\n",
      "         -9.1661e+00, -1.4564e+01, -3.0969e+00, -6.5643e+00, -4.5488e+00,\n",
      "          2.9636e+01, -7.8039e-02,  3.9097e+00, -2.1083e+01,  6.2102e+00,\n",
      "         -1.5769e+01,  2.9139e+00,  7.0105e+00,  1.4483e+01,  1.6590e+01,\n",
      "         -5.7210e+00,  1.5844e+01, -1.3804e+01,  2.4083e+01,  8.7817e+00,\n",
      "         -1.2174e+01,  2.0013e+01, -1.4518e+01, -7.1102e+00,  1.0186e+01,\n",
      "          1.1320e-01, -6.0167e+00, -2.5795e+00, -5.3466e+00, -1.4494e+01,\n",
      "         -9.1116e+00, -4.0324e+00,  8.1674e+00, -1.2679e+01, -1.0878e+01,\n",
      "          1.5431e+00, -8.3707e+00,  1.3189e+01, -4.1709e+00, -8.6904e-01,\n",
      "          3.4524e+00,  2.5143e+01,  1.1658e+01, -6.5296e+00, -1.5981e+01,\n",
      "          2.8312e+01,  2.2652e+01,  6.8055e+00,  1.5075e+01,  1.0887e+01,\n",
      "          1.5215e+01,  1.5498e+00,  4.3644e+00,  2.9126e+00, -2.4070e+01,\n",
      "          1.9050e+01,  1.2381e+01,  8.4584e+00,  9.5567e+00, -4.9481e+00,\n",
      "         -1.0957e+01, -2.5559e+01,  1.2321e+00, -1.0849e+01,  7.1099e+00,\n",
      "          1.6351e+01,  2.5891e+00,  3.7519e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0067e+01,  1.3202e+02,  1.9194e+01, -7.0146e+00, -2.4020e+01,\n",
      "          4.9847e-01, -7.1110e+00, -1.2861e+01,  2.1206e+01,  7.2655e+00,\n",
      "         -1.2325e+01, -5.5059e-02,  8.8344e+00,  2.2124e+00,  7.6593e+00,\n",
      "          9.0768e+00, -6.5525e+00,  6.8971e+00,  2.3282e+00,  2.2398e+01,\n",
      "          8.1046e+00,  1.4778e+00, -5.2216e-01, -1.7609e+00,  9.4949e+00,\n",
      "          1.8213e+00,  7.5625e+00,  9.8132e-01, -6.2646e+00,  1.2768e+00,\n",
      "          9.5389e+00, -2.7540e+01, -3.9014e+00, -4.0179e+00,  1.6599e+00,\n",
      "         -9.6252e+00, -1.0697e+01, -1.3324e+00, -1.4633e+01,  1.4483e+01,\n",
      "         -5.5117e+00,  3.6133e+00, -1.1670e+01,  2.5989e+01,  1.8854e+01,\n",
      "         -6.3301e+00,  1.2746e+01, -6.1543e+00, -1.1811e+01,  1.2946e+01,\n",
      "          4.7873e+00, -2.7606e+00, -8.4176e+00, -1.2245e+01, -1.4959e+01,\n",
      "         -9.5745e+00, -7.9382e+00, -1.0581e+01, -3.7676e+00, -5.7164e+00,\n",
      "         -9.3265e+00, -1.5008e+01, -1.9706e+00, -4.5591e+00, -4.2068e+00,\n",
      "          2.9697e+01, -4.7328e-01,  5.2907e+00, -2.1079e+01,  6.1591e+00,\n",
      "         -1.5820e+01,  3.7799e+00,  6.3197e+00,  1.3306e+01,  1.5956e+01,\n",
      "         -5.1913e+00,  1.7520e+01, -1.5379e+01,  2.5394e+01,  8.1065e+00,\n",
      "         -1.1394e+01,  1.8602e+01, -1.4325e+01, -6.2973e+00,  8.3106e+00,\n",
      "         -4.4924e-01, -6.2433e+00, -3.6660e+00, -5.2521e+00, -1.6932e+01,\n",
      "         -7.8049e+00, -2.4894e+00,  1.0281e+01, -1.3891e+01, -1.1983e+01,\n",
      "          2.5827e+00, -5.9383e+00,  1.4739e+01, -3.9963e+00,  2.1992e+00,\n",
      "          4.2450e+00,  2.3700e+01,  1.1307e+01, -7.4505e+00, -1.6640e+01,\n",
      "          2.7378e+01,  2.3948e+01,  6.9976e+00,  1.2687e+01,  7.1201e+00,\n",
      "          1.5749e+01,  2.7181e+00,  4.6182e+00,  3.2768e+00, -2.3930e+01,\n",
      "          1.8292e+01,  1.1892e+01,  9.8005e+00,  1.0944e+01, -4.5815e+00,\n",
      "         -1.1602e+01, -2.5446e+01,  4.5734e+00, -9.4807e+00,  7.2343e+00,\n",
      "          1.7746e+01,  3.9469e+00,  3.1045e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.2676e+01,  1.3189e+02,  2.2745e+01, -7.7864e+00, -2.2210e+01,\n",
      "          1.8750e+00, -8.4888e+00, -1.6194e+01,  2.0673e+01,  8.0809e+00,\n",
      "         -1.2350e+01, -8.6433e-01,  7.7826e+00,  2.0967e+00,  9.0586e+00,\n",
      "          8.0856e+00, -6.1724e+00,  4.3991e+00,  5.7382e+00,  2.3251e+01,\n",
      "          1.1270e+01,  1.3517e-01, -1.8656e+00, -1.1736e-01,  8.2126e+00,\n",
      "          2.0309e+00,  6.3404e+00,  2.4190e+00, -7.0062e+00,  1.1815e-01,\n",
      "          1.1420e+01, -2.8651e+01, -5.4077e+00, -2.5117e+00,  2.5638e+00,\n",
      "         -9.9537e+00, -7.6413e+00, -7.1472e-01, -1.4798e+01,  1.3031e+01,\n",
      "         -5.1617e+00,  3.8480e+00, -1.4798e+01,  2.6883e+01,  2.0596e+01,\n",
      "         -4.9401e+00,  1.6181e+01, -5.5340e+00, -1.2268e+01,  1.0728e+01,\n",
      "          6.0927e+00, -4.3601e+00, -9.2342e+00, -1.3480e+01, -1.3273e+01,\n",
      "         -8.8763e+00, -8.4749e+00, -9.1549e+00, -4.7795e+00, -3.7887e+00,\n",
      "         -8.3836e+00, -1.7432e+01,  7.6346e-01, -4.5765e+00, -2.7522e+00,\n",
      "          3.0828e+01,  2.3848e-01,  4.0464e+00, -2.2678e+01,  5.8255e+00,\n",
      "         -1.6544e+01,  3.6753e+00,  5.8213e+00,  1.2064e+01,  1.3459e+01,\n",
      "         -5.7738e+00,  1.6493e+01, -1.4882e+01,  2.7168e+01,  1.0103e+01,\n",
      "         -9.4182e+00,  1.7364e+01, -1.4734e+01, -5.8752e+00,  6.1264e+00,\n",
      "          7.4130e-01, -3.4911e+00, -4.9014e-01, -4.5559e+00, -1.3818e+01,\n",
      "         -9.3295e+00, -5.0657e+00,  9.5757e+00, -1.1289e+01, -1.4432e+01,\n",
      "          2.5358e+00, -6.4697e+00,  1.2795e+01, -1.3112e+00,  1.0295e+00,\n",
      "          3.4071e+00,  2.4316e+01,  1.0725e+01, -7.2581e+00, -1.6374e+01,\n",
      "          2.7119e+01,  2.4428e+01,  6.5782e+00,  1.3839e+01,  1.0617e+01,\n",
      "          1.6146e+01,  1.6256e+00,  4.5163e+00,  2.2077e+00, -2.4856e+01,\n",
      "          1.8518e+01,  1.0874e+01,  1.0864e+01,  1.0876e+01, -4.0072e+00,\n",
      "         -9.7782e+00, -2.8178e+01,  4.2200e+00, -8.9901e+00,  7.9700e+00,\n",
      "          1.8392e+01,  1.7108e+00,  1.2135e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.3482e+01,  1.3182e+02,  2.3393e+01, -8.2749e+00, -2.2617e+01,\n",
      "          4.4260e-01, -8.0742e+00, -1.5770e+01,  2.0210e+01,  6.9221e+00,\n",
      "         -1.1995e+01, -1.0996e+00,  7.8724e+00,  1.8489e+00,  8.6936e+00,\n",
      "          1.0091e+01, -7.2807e+00,  4.5084e+00,  3.4146e+00,  2.0027e+01,\n",
      "          1.0552e+01,  2.5691e+00,  5.2893e-01, -5.4761e-01,  7.4737e+00,\n",
      "          2.8716e+00,  6.1691e+00,  1.7724e+00, -8.1803e+00,  1.3420e+00,\n",
      "          1.1062e+01, -2.7349e+01, -6.3778e+00, -2.0902e+00,  2.6131e+00,\n",
      "         -9.1548e+00, -6.3453e+00,  2.2924e-01, -1.3458e+01,  1.2138e+01,\n",
      "         -4.5843e+00,  2.8244e+00, -1.3474e+01,  2.5547e+01,  1.9719e+01,\n",
      "         -6.1838e+00,  1.5212e+01, -4.6517e+00, -1.1635e+01,  1.3299e+01,\n",
      "          5.7724e+00, -5.3700e+00, -8.4507e+00, -1.2343e+01, -1.6130e+01,\n",
      "         -9.1370e+00, -6.5483e+00, -1.0260e+01, -6.1272e+00, -4.2784e+00,\n",
      "         -8.1575e+00, -1.5990e+01,  2.9286e-01, -2.9966e+00, -4.4212e+00,\n",
      "          3.0410e+01, -6.4538e-02,  4.8291e+00, -2.1354e+01,  1.0437e+01,\n",
      "         -1.6142e+01,  3.4201e+00,  8.5706e+00,  1.3899e+01,  1.5204e+01,\n",
      "         -4.9637e+00,  1.6556e+01, -1.5790e+01,  2.5861e+01,  9.5842e+00,\n",
      "         -9.0043e+00,  1.9190e+01, -1.3951e+01, -4.3507e+00,  8.0288e+00,\n",
      "          1.0147e+00, -1.7469e+00, -4.1757e+00, -6.1320e+00, -1.4952e+01,\n",
      "         -7.3160e+00, -2.1837e+00,  8.9720e+00, -1.2097e+01, -1.4768e+01,\n",
      "          2.7893e+00, -5.5368e+00,  1.4090e+01, -2.1472e+00,  2.0599e+00,\n",
      "          5.2803e+00,  2.3734e+01,  1.0918e+01, -5.5887e+00, -1.6461e+01,\n",
      "          2.7935e+01,  2.4593e+01,  6.4507e+00,  1.1476e+01,  1.0677e+01,\n",
      "          1.7419e+01,  1.5424e+00,  5.7320e+00,  3.1610e+00, -2.2245e+01,\n",
      "          1.8381e+01,  1.2561e+01,  1.1088e+01,  1.1857e+01, -4.3222e+00,\n",
      "         -1.1383e+01, -2.7611e+01,  4.5133e+00, -8.8873e+00,  7.9547e+00,\n",
      "          1.8747e+01,  5.5029e+00,  1.3784e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.1046e+01,  1.3221e+02,  2.2248e+01, -8.0570e+00, -2.2011e+01,\n",
      "          2.4133e+00, -7.1621e+00, -1.5507e+01,  2.5398e+01,  5.6800e+00,\n",
      "         -1.4461e+01, -1.1155e+00,  8.4507e+00, -1.8290e+00,  7.7111e+00,\n",
      "          8.0136e+00, -3.5939e+00,  5.3060e+00,  3.2312e+00,  2.2449e+01,\n",
      "          1.0080e+01,  1.2058e+00, -1.3027e+00, -8.3054e-01,  9.1212e+00,\n",
      "          6.0091e-01,  6.1836e+00,  2.3603e+00, -6.2161e+00,  5.1611e-01,\n",
      "          1.0334e+01, -2.8962e+01, -4.0636e+00, -2.9897e+00,  3.3858e+00,\n",
      "         -9.7293e+00, -7.0721e+00,  1.5858e+00, -1.2047e+01,  1.2634e+01,\n",
      "         -3.8813e+00,  3.5713e+00, -1.0930e+01,  2.5742e+01,  1.8970e+01,\n",
      "         -4.3178e+00,  1.5711e+01, -4.9890e+00, -1.3884e+01,  1.1392e+01,\n",
      "          4.9379e+00, -1.5915e+00, -1.2020e+01, -1.4708e+01, -1.6237e+01,\n",
      "         -7.6482e+00, -7.8649e+00, -9.4641e+00, -1.8071e+00, -2.5299e+00,\n",
      "         -9.2883e+00, -1.4866e+01, -3.0922e+00, -6.8222e+00, -4.6249e+00,\n",
      "          3.0103e+01,  2.4459e-01,  4.2697e+00, -2.1428e+01,  6.2733e+00,\n",
      "         -1.5902e+01,  2.7899e+00,  7.3557e+00,  1.4120e+01,  1.6444e+01,\n",
      "         -5.6516e+00,  1.5871e+01, -1.3765e+01,  2.4259e+01,  8.3130e+00,\n",
      "         -1.1967e+01,  1.9793e+01, -1.4282e+01, -6.9275e+00,  9.6933e+00,\n",
      "         -9.5322e-04, -6.1084e+00, -2.1146e+00, -5.2181e+00, -1.4624e+01,\n",
      "         -8.9459e+00, -4.0211e+00,  7.8296e+00, -1.2244e+01, -1.0763e+01,\n",
      "          1.5775e+00, -8.3004e+00,  1.3017e+01, -3.8791e+00, -8.7353e-01,\n",
      "          3.6389e+00,  2.5430e+01,  1.1406e+01, -6.4083e+00, -1.6170e+01,\n",
      "          2.8459e+01,  2.2856e+01,  6.6975e+00,  1.5030e+01,  1.0531e+01,\n",
      "          1.5376e+01,  1.5797e+00,  4.5131e+00,  2.6415e+00, -2.4591e+01,\n",
      "          1.9399e+01,  1.2422e+01,  8.6660e+00,  1.0315e+01, -5.0736e+00,\n",
      "         -1.0876e+01, -2.5689e+01,  1.2249e+00, -1.0550e+01,  7.0968e+00,\n",
      "          1.6640e+01,  2.4806e+00,  3.4742e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.7412e+00,  1.3202e+02,  1.9648e+01, -7.1672e+00, -2.3744e+01,\n",
      "          5.1991e-01, -7.0853e+00, -1.3254e+01,  2.1358e+01,  7.0794e+00,\n",
      "         -1.2333e+01,  7.0797e-03,  8.7182e+00,  2.3454e+00,  7.4067e+00,\n",
      "          9.0019e+00, -6.7931e+00,  6.4357e+00,  2.2585e+00,  2.2150e+01,\n",
      "          8.2258e+00,  1.6387e+00, -6.4697e-01, -1.6989e+00,  9.6446e+00,\n",
      "          1.7249e+00,  7.0970e+00,  8.8240e-01, -5.9531e+00,  9.7320e-01,\n",
      "          9.1010e+00, -2.7200e+01, -3.7821e+00, -3.8496e+00,  1.9887e+00,\n",
      "         -9.3840e+00, -1.0561e+01, -1.4434e+00, -1.4358e+01,  1.4690e+01,\n",
      "         -5.3192e+00,  3.6698e+00, -1.1844e+01,  2.6074e+01,  1.8860e+01,\n",
      "         -6.3176e+00,  1.2738e+01, -6.2578e+00, -1.1880e+01,  1.3288e+01,\n",
      "          4.7398e+00, -2.4128e+00, -8.6323e+00, -1.2516e+01, -1.5019e+01,\n",
      "         -9.5045e+00, -7.6899e+00, -1.0891e+01, -3.6128e+00, -5.9336e+00,\n",
      "         -9.1589e+00, -1.5292e+01, -2.0540e+00, -4.5587e+00, -4.4985e+00,\n",
      "          3.0155e+01, -5.9244e-02,  5.5759e+00, -2.1299e+01,  6.2687e+00,\n",
      "         -1.5445e+01,  3.4119e+00,  6.5783e+00,  1.3236e+01,  1.6096e+01,\n",
      "         -5.1300e+00,  1.7614e+01, -1.5446e+01,  2.5530e+01,  7.7719e+00,\n",
      "         -1.1361e+01,  1.8675e+01, -1.3710e+01, -6.3662e+00,  8.1115e+00,\n",
      "         -2.4470e-01, -6.0724e+00, -3.5725e+00, -5.1081e+00, -1.7086e+01,\n",
      "         -7.7669e+00, -2.4765e+00,  1.0121e+01, -1.3470e+01, -1.1602e+01,\n",
      "          2.4854e+00, -5.7375e+00,  1.4510e+01, -3.6371e+00,  2.0609e+00,\n",
      "          4.1702e+00,  2.3999e+01,  1.1060e+01, -7.4058e+00, -1.6611e+01,\n",
      "          2.7562e+01,  2.3909e+01,  6.9323e+00,  1.2728e+01,  7.1313e+00,\n",
      "          1.6142e+01,  2.7709e+00,  4.8195e+00,  3.0807e+00, -2.4313e+01,\n",
      "          1.8584e+01,  1.2307e+01,  1.0193e+01,  1.1460e+01, -4.7562e+00,\n",
      "         -1.1302e+01, -2.5439e+01,  4.6221e+00, -9.0960e+00,  7.3342e+00,\n",
      "          1.8052e+01,  3.9021e+00,  2.8934e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.2038e+01,  1.3187e+02,  2.2964e+01, -8.2367e+00, -2.1779e+01,\n",
      "          1.9253e+00, -8.1762e+00, -1.6317e+01,  2.1200e+01,  7.7179e+00,\n",
      "         -1.2613e+01, -6.8573e-01,  7.7514e+00,  2.3471e+00,  8.8008e+00,\n",
      "          8.1631e+00, -6.5283e+00,  3.8655e+00,  5.3314e+00,  2.3315e+01,\n",
      "          1.1304e+01,  5.8981e-01, -1.8897e+00,  1.7687e-02,  8.4604e+00,\n",
      "          1.9905e+00,  5.9821e+00,  2.1708e+00, -6.5812e+00, -3.2653e-01,\n",
      "          1.1031e+01, -2.8121e+01, -5.2490e+00, -2.3459e+00,  2.7483e+00,\n",
      "         -9.8103e+00, -7.6923e+00, -7.5505e-01, -1.4437e+01,  1.3402e+01,\n",
      "         -4.8291e+00,  3.8642e+00, -1.4794e+01,  2.6888e+01,  2.0715e+01,\n",
      "         -5.0055e+00,  1.6002e+01, -5.7886e+00, -1.2164e+01,  1.1317e+01,\n",
      "          6.1854e+00, -4.0107e+00, -9.2995e+00, -1.3696e+01, -1.3310e+01,\n",
      "         -8.6979e+00, -8.1505e+00, -9.4286e+00, -4.3438e+00, -4.0508e+00,\n",
      "         -8.3388e+00, -1.7629e+01,  5.1407e-01, -4.7183e+00, -3.2557e+00,\n",
      "          3.1191e+01,  3.6675e-01,  4.2607e+00, -2.2876e+01,  6.0367e+00,\n",
      "         -1.6446e+01,  3.2419e+00,  6.1538e+00,  1.1811e+01,  1.3638e+01,\n",
      "         -5.6359e+00,  1.6610e+01, -1.4971e+01,  2.6966e+01,  9.4395e+00,\n",
      "         -9.3845e+00,  1.7529e+01, -1.4354e+01, -6.2213e+00,  5.8077e+00,\n",
      "          8.9749e-01, -3.7884e+00, -2.0941e-01, -4.4808e+00, -1.3836e+01,\n",
      "         -9.3517e+00, -4.9714e+00,  9.3452e+00, -1.0948e+01, -1.3819e+01,\n",
      "          2.3528e+00, -6.3033e+00,  1.2566e+01, -1.0708e+00,  1.0493e+00,\n",
      "          3.5174e+00,  2.4484e+01,  1.0472e+01, -7.3658e+00, -1.6492e+01,\n",
      "          2.7367e+01,  2.4386e+01,  6.4168e+00,  1.3711e+01,  1.0587e+01,\n",
      "          1.6547e+01,  1.6056e+00,  4.6857e+00,  1.8932e+00, -2.5296e+01,\n",
      "          1.8932e+01,  1.1120e+01,  1.1127e+01,  1.1507e+01, -4.1583e+00,\n",
      "         -9.6034e+00, -2.8146e+01,  4.2345e+00, -8.6409e+00,  7.9607e+00,\n",
      "          1.8650e+01,  1.5383e+00,  1.1517e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.2961e+01,  1.3182e+02,  2.3593e+01, -8.5259e+00, -2.2380e+01,\n",
      "          4.3927e-01, -8.1195e+00, -1.5762e+01,  2.0405e+01,  6.4891e+00,\n",
      "         -1.2149e+01, -8.2368e-01,  7.8403e+00,  2.1468e+00,  8.1619e+00,\n",
      "          9.9895e+00, -7.5287e+00,  4.2630e+00,  3.0829e+00,  1.9925e+01,\n",
      "          1.0514e+01,  2.8337e+00,  5.3819e-01, -3.3018e-01,  7.6268e+00,\n",
      "          2.8205e+00,  5.7978e+00,  1.6310e+00, -7.7728e+00,  1.1327e+00,\n",
      "          1.0866e+01, -2.7083e+01, -6.2491e+00, -1.9918e+00,  2.7473e+00,\n",
      "         -9.1255e+00, -6.3413e+00,  8.3193e-03, -1.3230e+01,  1.2663e+01,\n",
      "         -4.4788e+00,  2.9511e+00, -1.3382e+01,  2.5572e+01,  1.9854e+01,\n",
      "         -6.3070e+00,  1.4941e+01, -4.9265e+00, -1.1511e+01,  1.3834e+01,\n",
      "          5.7996e+00, -5.0905e+00, -8.6168e+00, -1.2726e+01, -1.6160e+01,\n",
      "         -9.0088e+00, -6.2450e+00, -1.0551e+01, -5.8058e+00, -4.7456e+00,\n",
      "         -8.2268e+00, -1.6117e+01,  4.1295e-02, -3.1418e+00, -4.6098e+00,\n",
      "          3.0740e+01,  4.2976e-02,  4.9954e+00, -2.1402e+01,  1.0363e+01,\n",
      "         -1.6101e+01,  3.2939e+00,  8.8330e+00,  1.3917e+01,  1.5167e+01,\n",
      "         -4.6869e+00,  1.6653e+01, -1.5741e+01,  2.5693e+01,  9.0991e+00,\n",
      "         -9.1990e+00,  1.9343e+01, -1.3714e+01, -4.5806e+00,  7.9386e+00,\n",
      "          1.2606e+00, -1.9650e+00, -3.9784e+00, -5.9505e+00, -1.4813e+01,\n",
      "         -7.3074e+00, -2.2411e+00,  8.8818e+00, -1.1897e+01, -1.4426e+01,\n",
      "          2.7482e+00, -5.5717e+00,  1.3798e+01, -1.7804e+00,  1.8369e+00,\n",
      "          5.4798e+00,  2.4148e+01,  1.0703e+01, -5.8492e+00, -1.6350e+01,\n",
      "          2.7949e+01,  2.4534e+01,  6.4299e+00,  1.1464e+01,  1.0519e+01,\n",
      "          1.7485e+01,  1.3366e+00,  6.0426e+00,  3.0148e+00, -2.2785e+01,\n",
      "          1.8959e+01,  1.2886e+01,  1.1240e+01,  1.2270e+01, -4.5512e+00,\n",
      "         -1.1372e+01, -2.7607e+01,  4.3791e+00, -8.5232e+00,  7.8051e+00,\n",
      "          1.9013e+01,  5.4338e+00,  1.1104e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0990e+01,  1.3224e+02,  2.2480e+01, -8.3420e+00, -2.1782e+01,\n",
      "          2.1714e+00, -7.4391e+00, -1.5575e+01,  2.5184e+01,  5.4508e+00,\n",
      "         -1.4608e+01, -6.4942e-01,  8.2183e+00, -1.1619e+00,  7.4798e+00,\n",
      "          7.9869e+00, -3.9957e+00,  5.0595e+00,  2.6876e+00,  2.2297e+01,\n",
      "          1.0079e+01,  1.4086e+00, -1.1588e+00, -5.8518e-01,  9.0807e+00,\n",
      "          8.3503e-01,  5.9181e+00,  2.3261e+00, -6.1463e+00,  2.8352e-01,\n",
      "          1.0429e+01, -2.8699e+01, -4.1750e+00, -2.9811e+00,  3.3543e+00,\n",
      "         -9.6663e+00, -7.0777e+00,  1.3932e+00, -1.1875e+01,  1.2955e+01,\n",
      "         -3.8338e+00,  3.7555e+00, -1.0858e+01,  2.5844e+01,  1.9010e+01,\n",
      "         -4.4412e+00,  1.5390e+01, -5.2701e+00, -1.3604e+01,  1.1607e+01,\n",
      "          5.1365e+00, -1.6350e+00, -1.1759e+01, -1.4814e+01, -1.6179e+01,\n",
      "         -7.5160e+00, -7.7709e+00, -9.4395e+00, -1.7086e+00, -2.8915e+00,\n",
      "         -9.4156e+00, -1.4986e+01, -3.1212e+00, -6.9383e+00, -4.6168e+00,\n",
      "          3.0397e+01,  3.5560e-01,  4.3945e+00, -2.1490e+01,  6.2178e+00,\n",
      "         -1.6095e+01,  2.7626e+00,  7.6839e+00,  1.3845e+01,  1.6165e+01,\n",
      "         -5.2979e+00,  1.5916e+01, -1.3852e+01,  2.4266e+01,  7.8441e+00,\n",
      "         -1.2004e+01,  1.9896e+01, -1.4370e+01, -7.0058e+00,  9.2845e+00,\n",
      "          1.0373e-01, -6.1441e+00, -1.7092e+00, -5.1402e+00, -1.4513e+01,\n",
      "         -8.7957e+00, -4.0430e+00,  7.7377e+00, -1.1954e+01, -1.0808e+01,\n",
      "          1.5591e+00, -8.1938e+00,  1.2766e+01, -3.5379e+00, -9.7927e-01,\n",
      "          3.8833e+00,  2.5696e+01,  1.1224e+01, -6.5304e+00, -1.6251e+01,\n",
      "          2.8435e+01,  2.3002e+01,  6.5400e+00,  1.4867e+01,  1.0263e+01,\n",
      "          1.5460e+01,  1.4838e+00,  4.7953e+00,  2.4778e+00, -2.4965e+01,\n",
      "          1.9746e+01,  1.2313e+01,  8.7713e+00,  1.0829e+01, -5.1490e+00,\n",
      "         -1.0877e+01, -2.5903e+01,  1.3293e+00, -1.0353e+01,  6.9857e+00,\n",
      "          1.6944e+01,  2.4457e+00,  3.1982e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.8552e+00,  1.3203e+02,  2.0028e+01, -7.2206e+00, -2.3393e+01,\n",
      "          4.8090e-01, -7.1403e+00, -1.3415e+01,  2.1286e+01,  6.7264e+00,\n",
      "         -1.2353e+01,  1.9764e-01,  8.6299e+00,  2.5653e+00,  7.2983e+00,\n",
      "          9.1671e+00, -6.8316e+00,  6.0798e+00,  2.1011e+00,  2.2087e+01,\n",
      "          8.2424e+00,  1.9040e+00, -6.3180e-01, -1.4171e+00,  9.5393e+00,\n",
      "          1.5105e+00,  6.8423e+00,  9.4830e-01, -5.9382e+00,  7.3900e-01,\n",
      "          9.2902e+00, -2.7212e+01, -4.0923e+00, -3.8177e+00,  2.1787e+00,\n",
      "         -9.2803e+00, -1.0577e+01, -1.4835e+00, -1.3890e+01,  1.4865e+01,\n",
      "         -5.0183e+00,  3.6282e+00, -1.1641e+01,  2.6142e+01,  1.8845e+01,\n",
      "         -6.2167e+00,  1.2653e+01, -6.3224e+00, -1.1676e+01,  1.3343e+01,\n",
      "          4.8912e+00, -2.3631e+00, -8.7671e+00, -1.2681e+01, -1.5115e+01,\n",
      "         -9.4259e+00, -7.5782e+00, -1.1044e+01, -3.4732e+00, -6.1185e+00,\n",
      "         -9.0765e+00, -1.5265e+01, -2.0495e+00, -4.7074e+00, -4.7351e+00,\n",
      "          3.0419e+01,  3.1992e-02,  5.6992e+00, -2.1269e+01,  6.3602e+00,\n",
      "         -1.5433e+01,  3.1349e+00,  6.9984e+00,  1.3068e+01,  1.5982e+01,\n",
      "         -4.9017e+00,  1.7536e+01, -1.5592e+01,  2.5476e+01,  7.5850e+00,\n",
      "         -1.1478e+01,  1.9055e+01, -1.3858e+01, -6.3741e+00,  7.9452e+00,\n",
      "          9.2340e-02, -5.8668e+00, -3.2223e+00, -5.1648e+00, -1.7009e+01,\n",
      "         -7.7876e+00, -2.5271e+00,  9.9983e+00, -1.3245e+01, -1.1497e+01,\n",
      "          2.2962e+00, -5.5546e+00,  1.4262e+01, -3.3406e+00,  2.0265e+00,\n",
      "          4.3353e+00,  2.4295e+01,  1.0955e+01, -7.3944e+00, -1.6541e+01,\n",
      "          2.7534e+01,  2.3806e+01,  6.6845e+00,  1.2759e+01,  7.1465e+00,\n",
      "          1.6202e+01,  2.5915e+00,  4.9572e+00,  2.9665e+00, -2.4477e+01,\n",
      "          1.8716e+01,  1.2395e+01,  1.0441e+01,  1.1645e+01, -4.8082e+00,\n",
      "         -1.1347e+01, -2.5711e+01,  4.6623e+00, -8.9687e+00,  7.2899e+00,\n",
      "          1.8377e+01,  3.8284e+00,  2.6885e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 11.8430, 131.8331,  23.1647,  -8.2946, -21.3984,   1.9526,  -7.7589,\n",
      "         -16.3338,  21.3914,   7.3710, -12.7193,  -0.4801,   7.8829,   2.5636,\n",
      "           8.6834,   8.3705,  -6.6130,   3.3485,   4.9817,  23.4576,  11.3379,\n",
      "           0.9686,  -1.9123,   0.1570,   8.5925,   1.7908,   5.9393,   2.1208,\n",
      "          -6.4151,  -0.5152,  11.0787, -27.8424,  -5.3236,  -2.2026,   3.0496,\n",
      "          -9.7162,  -8.0287,  -0.9612, -14.0562,  13.5475,  -4.3728,   3.7979,\n",
      "         -14.6074,  27.0293,  20.8545,  -5.0170,  15.6846,  -5.8198, -11.9056,\n",
      "          11.6633,   6.4845,  -3.9054,  -9.1934, -13.6846, -13.4203,  -8.7592,\n",
      "          -8.0642,  -9.4370,  -4.0171,  -4.2643,  -8.3101, -17.6188,   0.3741,\n",
      "          -4.9841,  -3.8939,  31.4150,   0.3494,   4.5181, -22.8756,   6.3158,\n",
      "         -16.4389,   2.8168,   6.5480,  11.5259,  13.7443,  -5.5751,  16.6847,\n",
      "         -15.2079,  26.6826,   9.0200,  -9.4366,  17.6761, -14.3739,  -6.2912,\n",
      "           5.6956,   1.1287,  -3.8520,   0.1612,  -4.4847, -13.9238,  -9.3081,\n",
      "          -4.8121,   9.2199, -10.8799, -13.3679,   2.1669,  -5.9222,  12.3998,\n",
      "          -1.1559,   1.3766,   3.7776,  24.7036,  10.4970,  -7.3661, -16.5191,\n",
      "          27.5309,  24.2293,   6.1448,  13.6568,  10.4988,  16.6618,   1.4571,\n",
      "           4.7400,   1.6245, -25.3383,  18.9964,  11.1478,  11.4043,  11.7744,\n",
      "          -4.1745,  -9.8112, -28.2964,   4.2966,  -8.5017,   7.9328,  18.9418,\n",
      "           1.4443,   1.1802]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.2736e+01,  1.3181e+02,  2.3843e+01, -8.4841e+00, -2.2109e+01,\n",
      "          5.7470e-01, -7.7812e+00, -1.5681e+01,  2.0494e+01,  6.3144e+00,\n",
      "         -1.2215e+01, -6.0580e-01,  8.0002e+00,  2.2800e+00,  7.7528e+00,\n",
      "          9.9231e+00, -7.5071e+00,  3.8981e+00,  2.9522e+00,  2.0138e+01,\n",
      "          1.0505e+01,  2.9406e+00,  3.4691e-01, -2.8099e-01,  7.7969e+00,\n",
      "          2.4408e+00,  5.7584e+00,  1.6578e+00, -7.5000e+00,  9.7531e-01,\n",
      "          1.0961e+01, -2.7051e+01, -6.2026e+00, -1.9338e+00,  3.0870e+00,\n",
      "         -9.1915e+00, -6.5578e+00, -3.0904e-01, -1.3243e+01,  1.2852e+01,\n",
      "         -4.0832e+00,  3.0645e+00, -1.3352e+01,  2.5776e+01,  2.0103e+01,\n",
      "         -6.3880e+00,  1.4738e+01, -5.0431e+00, -1.1390e+01,  1.4155e+01,\n",
      "          5.9252e+00, -4.9156e+00, -8.5047e+00, -1.2842e+01, -1.6022e+01,\n",
      "         -9.0832e+00, -6.3470e+00, -1.0516e+01, -5.5554e+00, -4.9734e+00,\n",
      "         -8.3502e+00, -1.6237e+01, -5.4570e-02, -3.2096e+00, -5.1419e+00,\n",
      "          3.0907e+01,  8.8601e-02,  5.2462e+00, -2.1399e+01,  1.0257e+01,\n",
      "         -1.6082e+01,  3.1208e+00,  9.0073e+00,  1.3769e+01,  1.5075e+01,\n",
      "         -4.6945e+00,  1.6779e+01, -1.5694e+01,  2.5614e+01,  8.8818e+00,\n",
      "         -9.2938e+00,  1.9275e+01, -1.3775e+01, -4.6493e+00,  7.7155e+00,\n",
      "          1.5021e+00, -1.9812e+00, -3.6481e+00, -5.7969e+00, -1.4857e+01,\n",
      "         -7.2098e+00, -2.2727e+00,  8.7770e+00, -1.1977e+01, -1.4294e+01,\n",
      "          2.6365e+00, -5.4647e+00,  1.3621e+01, -1.7763e+00,  2.0006e+00,\n",
      "          5.6123e+00,  2.4478e+01,  1.0742e+01, -5.9836e+00, -1.6335e+01,\n",
      "          2.7978e+01,  2.4341e+01,  6.2720e+00,  1.1548e+01,  1.0372e+01,\n",
      "          1.7340e+01,  1.0435e+00,  6.0967e+00,  2.6963e+00, -2.2993e+01,\n",
      "          1.9129e+01,  1.2924e+01,  1.1385e+01,  1.2359e+01, -4.6230e+00,\n",
      "         -1.1464e+01, -2.7707e+01,  4.3297e+00, -8.4837e+00,  7.7770e+00,\n",
      "          1.9369e+01,  5.2181e+00,  1.0162e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0838e+01,  1.3227e+02,  2.2703e+01, -8.3729e+00, -2.1644e+01,\n",
      "          2.0877e+00, -7.3204e+00, -1.5424e+01,  2.4952e+01,  5.3913e+00,\n",
      "         -1.4764e+01, -4.1432e-01,  8.2147e+00, -8.8732e-01,  7.1002e+00,\n",
      "          7.9490e+00, -4.2481e+00,  4.8341e+00,  2.6169e+00,  2.2444e+01,\n",
      "          1.0090e+01,  1.4531e+00, -1.2167e+00, -5.8299e-01,  9.2025e+00,\n",
      "          8.5119e-01,  5.8053e+00,  2.1655e+00, -6.0904e+00,  7.6812e-02,\n",
      "          1.0546e+01, -2.8580e+01, -4.0202e+00, -2.9316e+00,  3.4686e+00,\n",
      "         -9.7953e+00, -7.1233e+00,  1.1794e+00, -1.2068e+01,  1.3123e+01,\n",
      "         -3.5515e+00,  3.8488e+00, -1.0935e+01,  2.6020e+01,  1.9263e+01,\n",
      "         -4.6559e+00,  1.5233e+01, -5.4688e+00, -1.3522e+01,  1.1978e+01,\n",
      "          5.3327e+00, -1.5311e+00, -1.1304e+01, -1.4874e+01, -1.5775e+01,\n",
      "         -7.5173e+00, -7.8241e+00, -9.3959e+00, -1.7313e+00, -3.1319e+00,\n",
      "         -9.5654e+00, -1.5219e+01, -3.0495e+00, -6.9130e+00, -4.8325e+00,\n",
      "          3.0681e+01,  4.2974e-01,  4.5893e+00, -2.1624e+01,  6.1226e+00,\n",
      "         -1.6118e+01,  2.7794e+00,  7.8068e+00,  1.3544e+01,  1.5978e+01,\n",
      "         -5.3083e+00,  1.6024e+01, -1.3825e+01,  2.4456e+01,  7.6977e+00,\n",
      "         -1.1939e+01,  1.9738e+01, -1.4237e+01, -6.9097e+00,  8.8778e+00,\n",
      "          2.5887e-01, -6.1020e+00, -1.3446e+00, -5.1040e+00, -1.4506e+01,\n",
      "         -8.5180e+00, -4.0707e+00,  7.6061e+00, -1.1877e+01, -1.0879e+01,\n",
      "          1.5764e+00, -8.1448e+00,  1.2615e+01, -3.4470e+00, -8.7237e-01,\n",
      "          3.9823e+00,  2.5851e+01,  1.1206e+01, -6.5025e+00, -1.6441e+01,\n",
      "          2.8477e+01,  2.2989e+01,  6.4979e+00,  1.4808e+01,  1.0112e+01,\n",
      "          1.5505e+01,  1.2802e+00,  4.8239e+00,  2.1215e+00, -2.5094e+01,\n",
      "          1.9889e+01,  1.2278e+01,  8.8778e+00,  1.1212e+01, -5.1668e+00,\n",
      "         -1.0897e+01, -2.5972e+01,  1.3924e+00, -1.0342e+01,  7.0298e+00,\n",
      "          1.7283e+01,  2.3977e+00,  3.0002e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.6254e+00,  1.3216e+02,  2.0302e+01, -7.3354e+00, -2.3112e+01,\n",
      "          4.5842e-01, -7.0728e+00, -1.3301e+01,  2.1548e+01,  6.7290e+00,\n",
      "         -1.2608e+01,  1.9020e-01,  8.8236e+00,  2.5504e+00,  7.1859e+00,\n",
      "          9.3008e+00, -6.9259e+00,  5.7788e+00,  2.3468e+00,  2.2324e+01,\n",
      "          8.1907e+00,  2.0619e+00, -6.8867e-01, -1.3848e+00,  9.4802e+00,\n",
      "          1.2657e+00,  6.5900e+00,  7.5356e-01, -5.9905e+00,  3.8024e-01,\n",
      "          9.3323e+00, -2.7247e+01, -4.0098e+00, -3.8445e+00,  2.3761e+00,\n",
      "         -9.3789e+00, -1.0461e+01, -1.4832e+00, -1.3895e+01,  1.4950e+01,\n",
      "         -4.7714e+00,  3.6336e+00, -1.1498e+01,  2.6197e+01,  1.9061e+01,\n",
      "         -6.1818e+00,  1.2825e+01, -6.3184e+00, -1.1692e+01,  1.3609e+01,\n",
      "          4.8226e+00, -2.2291e+00, -8.7712e+00, -1.2845e+01, -1.5045e+01,\n",
      "         -9.2903e+00, -7.5836e+00, -1.1259e+01, -3.3989e+00, -6.1056e+00,\n",
      "         -9.1014e+00, -1.5456e+01, -2.1776e+00, -4.5096e+00, -4.8163e+00,\n",
      "          3.0837e+01,  1.2936e-02,  5.7330e+00, -2.1320e+01,  6.3424e+00,\n",
      "         -1.5320e+01,  2.9330e+00,  7.2260e+00,  1.2977e+01,  1.5926e+01,\n",
      "         -4.8665e+00,  1.7624e+01, -1.5487e+01,  2.5488e+01,  7.5980e+00,\n",
      "         -1.1527e+01,  1.9199e+01, -1.3741e+01, -6.4130e+00,  7.6706e+00,\n",
      "          1.4064e-01, -5.8483e+00, -2.9942e+00, -5.3710e+00, -1.6949e+01,\n",
      "         -7.7277e+00, -2.5397e+00,  9.8453e+00, -1.3152e+01, -1.1333e+01,\n",
      "          2.2521e+00, -5.7172e+00,  1.4233e+01, -3.0934e+00,  2.0921e+00,\n",
      "          4.3778e+00,  2.4286e+01,  1.1027e+01, -7.3582e+00, -1.6518e+01,\n",
      "          2.7458e+01,  2.3563e+01,  6.6688e+00,  1.2832e+01,  7.3346e+00,\n",
      "          1.6237e+01,  2.2736e+00,  5.0049e+00,  2.7297e+00, -2.4431e+01,\n",
      "          1.8901e+01,  1.2562e+01,  1.0588e+01,  1.1665e+01, -4.9854e+00,\n",
      "         -1.1495e+01, -2.5834e+01,  4.6269e+00, -8.8830e+00,  7.1826e+00,\n",
      "          1.8585e+01,  3.7318e+00,  2.5143e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.1382e+01,  1.3196e+02,  2.3163e+01, -8.4778e+00, -2.1214e+01,\n",
      "          1.9384e+00, -7.5759e+00, -1.6056e+01,  2.1901e+01,  7.2620e+00,\n",
      "         -1.2857e+01, -4.4098e-01,  8.1745e+00,  2.4920e+00,  8.4661e+00,\n",
      "          8.5649e+00, -6.8893e+00,  3.0775e+00,  4.9201e+00,  2.3628e+01,\n",
      "          1.1206e+01,  1.2870e+00, -1.8010e+00,  1.2512e-01,  8.6096e+00,\n",
      "          1.6346e+00,  5.6985e+00,  1.6699e+00, -6.3897e+00, -8.2573e-01,\n",
      "          1.0945e+01, -2.7620e+01, -5.0979e+00, -2.2261e+00,  3.2364e+00,\n",
      "         -9.6954e+00, -8.1282e+00, -1.0244e+00, -1.3973e+01,  1.3836e+01,\n",
      "         -4.2331e+00,  3.7425e+00, -1.4311e+01,  2.6948e+01,  2.1005e+01,\n",
      "         -5.0514e+00,  1.5553e+01, -5.7444e+00, -1.1838e+01,  1.2138e+01,\n",
      "          6.4195e+00, -3.7315e+00, -9.1012e+00, -1.3772e+01, -1.3756e+01,\n",
      "         -8.6624e+00, -7.9227e+00, -9.6693e+00, -3.8288e+00, -4.4393e+00,\n",
      "         -8.3564e+00, -1.7669e+01,  2.3470e-02, -4.8549e+00, -4.0248e+00,\n",
      "          3.1841e+01,  2.8829e-01,  4.5748e+00, -2.2879e+01,  6.4587e+00,\n",
      "         -1.6354e+01,  2.5624e+00,  6.8554e+00,  1.1435e+01,  1.3837e+01,\n",
      "         -5.4048e+00,  1.6823e+01, -1.5186e+01,  2.6444e+01,  8.6728e+00,\n",
      "         -9.4911e+00,  1.7908e+01, -1.4206e+01, -6.4715e+00,  5.5971e+00,\n",
      "          1.0942e+00, -4.2717e+00,  2.3271e-01, -4.7156e+00, -1.3979e+01,\n",
      "         -9.3038e+00, -4.6344e+00,  9.1445e+00, -1.0871e+01, -1.2811e+01,\n",
      "          2.1008e+00, -6.0477e+00,  1.2459e+01, -1.0401e+00,  1.5317e+00,\n",
      "          3.9491e+00,  2.4763e+01,  1.0543e+01, -7.4152e+00, -1.6453e+01,\n",
      "          2.7482e+01,  2.3985e+01,  6.1778e+00,  1.3558e+01,  1.0544e+01,\n",
      "          1.6709e+01,  1.1891e+00,  4.8209e+00,  1.4272e+00, -2.5288e+01,\n",
      "          1.9187e+01,  1.1354e+01,  1.1570e+01,  1.1791e+01, -4.4367e+00,\n",
      "         -1.0101e+01, -2.8314e+01,  4.2151e+00, -8.2656e+00,  7.7610e+00,\n",
      "          1.9090e+01,  1.5075e+00,  1.1357e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 12.4642, 131.9163,  23.9894,  -8.6280, -21.9754,   0.5113,  -7.7161,\n",
      "         -15.4853,  20.8258,   6.2396, -12.1314,  -0.4650,   8.2572,   2.2543,\n",
      "           7.4487,   9.7459,  -7.7329,   3.6703,   2.8056,  20.1814,  10.3700,\n",
      "           2.9782,   0.3013,  -0.2015,   7.8286,   2.2336,   5.4934,   1.4660,\n",
      "          -7.3647,   0.7489,  10.8883, -27.0023,  -6.1062,  -1.9118,   3.2260,\n",
      "          -9.2128,  -6.6549,  -0.4546, -13.3240,  13.2057,  -4.0245,   3.1609,\n",
      "         -13.3129,  25.6765,  20.2686,  -6.4291,  14.6441,  -5.0148, -11.2840,\n",
      "          14.3724,   5.6720,  -4.8429,  -8.4484, -12.9540, -16.2950,  -9.0480,\n",
      "          -6.3968, -10.5733,  -5.2963,  -5.1299,  -8.4792, -16.2594,  -0.2813,\n",
      "          -3.0480,  -5.2832,  31.2112,   0.1606,   5.3067, -21.3479,  10.1248,\n",
      "         -15.9829,   2.9608,   9.1944,  13.7440,  14.8783,  -4.4545,  16.8715,\n",
      "         -15.4758,  25.5123,   8.7230,  -9.3252,  19.4627, -13.6483,  -4.8507,\n",
      "           7.4822,   1.4363,  -2.2582,  -3.5604,  -5.9420, -14.8349,  -7.2605,\n",
      "          -2.2771,   8.6510, -12.0910, -14.1666,   2.5991,  -5.7187,  13.6204,\n",
      "          -1.4377,   1.9778,   5.6992,  24.7553,  10.6448,  -6.1226, -16.1477,\n",
      "          27.8953,  24.1228,   6.2836,  11.4758,  10.3912,  17.2455,   0.6844,\n",
      "           6.1960,   2.5589, -23.1990,  19.4938,  13.0787,  11.3913,  12.3257,\n",
      "          -4.9532, -11.6174, -27.8098,   4.0815,  -8.3127,   7.6728,  19.5177,\n",
      "           5.2215,   0.9015]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0824e+01,  1.3230e+02,  2.3007e+01, -8.4384e+00, -2.1605e+01,\n",
      "          1.8967e+00, -7.2093e+00, -1.5361e+01,  2.4860e+01,  5.3520e+00,\n",
      "         -1.4541e+01, -1.6309e-01,  8.1990e+00, -6.3711e-01,  6.9147e+00,\n",
      "          7.7795e+00, -4.6167e+00,  4.4684e+00,  2.4065e+00,  2.2340e+01,\n",
      "          1.0121e+01,  1.3984e+00, -1.2267e+00, -4.8734e-01,  9.2251e+00,\n",
      "          8.8848e-01,  5.6122e+00,  2.1013e+00, -6.1104e+00, -5.3005e-02,\n",
      "          1.0466e+01, -2.8331e+01, -3.9501e+00, -2.8177e+00,  3.5437e+00,\n",
      "         -9.7914e+00, -7.2389e+00,  9.7686e-01, -1.2070e+01,  1.3454e+01,\n",
      "         -3.4958e+00,  3.8735e+00, -1.1154e+01,  2.6012e+01,  1.9374e+01,\n",
      "         -4.8169e+00,  1.5049e+01, -5.4138e+00, -1.3275e+01,  1.2176e+01,\n",
      "          5.2374e+00, -1.6605e+00, -1.1047e+01, -1.4850e+01, -1.5881e+01,\n",
      "         -7.5562e+00, -7.7423e+00, -9.2869e+00, -1.7494e+00, -3.4026e+00,\n",
      "         -9.6943e+00, -1.5292e+01, -2.8953e+00, -6.8270e+00, -5.0919e+00,\n",
      "          3.0878e+01,  5.8893e-01,  4.6139e+00, -2.1669e+01,  6.0860e+00,\n",
      "         -1.6100e+01,  2.6056e+00,  7.9462e+00,  1.3300e+01,  1.5780e+01,\n",
      "         -5.0497e+00,  1.6100e+01, -1.3664e+01,  2.4644e+01,  7.6386e+00,\n",
      "         -1.1747e+01,  1.9859e+01, -1.4139e+01, -6.9695e+00,  8.4831e+00,\n",
      "          1.6830e-01, -6.1162e+00, -1.0768e+00, -5.3156e+00, -1.4555e+01,\n",
      "         -8.4933e+00, -4.1321e+00,  7.4890e+00, -1.1895e+01, -1.0998e+01,\n",
      "          1.6218e+00, -8.1064e+00,  1.2546e+01, -3.1167e+00, -8.1348e-01,\n",
      "          4.0876e+00,  2.6059e+01,  1.1135e+01, -6.4772e+00, -1.6449e+01,\n",
      "          2.8451e+01,  2.2984e+01,  6.4064e+00,  1.4541e+01,  1.0085e+01,\n",
      "          1.5477e+01,  1.1095e+00,  4.8128e+00,  2.0157e+00, -2.5195e+01,\n",
      "          2.0170e+01,  1.2312e+01,  8.9604e+00,  1.1484e+01, -5.3626e+00,\n",
      "         -1.0989e+01, -2.6244e+01,  1.3657e+00, -1.0061e+01,  7.0462e+00,\n",
      "          1.7500e+01,  2.3469e+00,  2.8770e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[  9.7461, 132.2238,  20.6394,  -7.3220, -23.0186,   0.4810,  -6.8809,\n",
      "         -13.4874,  21.5794,   6.5840, -12.4948,   0.2752,   8.7330,   2.4729,\n",
      "           7.0958,   9.1730,  -7.0586,   5.3178,   2.2494,  22.4559,   8.3363,\n",
      "           1.9411,  -0.7940,  -1.2144,   9.5549,   1.0784,   6.2206,   0.7071,\n",
      "          -5.8969,   0.2034,   9.2905, -27.1806,  -4.0410,  -3.7185,   2.5740,\n",
      "          -9.3953, -10.5960,  -1.5519, -13.6613,  15.0997,  -4.6188,   3.5324,\n",
      "         -11.6797,  26.1499,  19.2136,  -6.2167,  12.9708,  -6.3056, -11.5912,\n",
      "          13.7277,   4.8389,  -2.3362,  -8.8142, -12.9459, -15.0924,  -9.2378,\n",
      "          -7.5152, -11.2088,  -3.3564,  -6.1894,  -9.1112, -15.5647,  -2.1052,\n",
      "          -4.6231,  -5.2414,  31.0214,   0.1740,   5.8389, -21.3282,   6.3019,\n",
      "         -15.2237,   2.5763,   7.3310,  12.6486,  15.7697,  -4.7390,  17.5462,\n",
      "         -15.4571,  25.6355,   7.6638, -11.4650,  19.2783, -13.5606,  -6.5040,\n",
      "           7.4408,   0.2082,  -5.7044,  -2.6174,  -5.4116, -16.9310,  -7.8886,\n",
      "          -2.7504,   9.6441, -13.0617, -11.2507,   2.1554,  -5.6982,  14.1458,\n",
      "          -2.8608,   2.0647,   4.3758,  24.5633,  10.9678,  -7.3109, -16.3887,\n",
      "          27.4964,  23.4238,   6.4354,  12.8718,   7.5534,  16.1942,   1.9884,\n",
      "           4.8853,   2.5369, -24.6495,  19.1862,  12.5897,  10.6111,  11.9024,\n",
      "          -5.1704, -11.4491, -26.1143,   4.4824,  -8.5733,   7.1680,  18.8331,\n",
      "           3.3968,   2.4066]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 11.1077, 132.0250,  23.2299,  -8.5643, -21.0976,   1.9588,  -7.1105,\n",
      "         -16.0821,  22.0526,   7.0540, -12.8466,  -0.1784,   8.1639,   2.4510,\n",
      "           8.4043,   8.5503,  -6.9524,   2.5605,   4.6681,  23.8866,  11.1865,\n",
      "           1.3199,  -1.8834,   0.1859,   8.7280,   1.4575,   5.4328,   1.3884,\n",
      "          -6.1878,  -0.9744,  10.7383, -27.3609,  -4.8768,  -2.1672,   3.4670,\n",
      "          -9.8473,  -8.4332,  -1.2378, -13.7214,  14.1211,  -4.0082,   3.6280,\n",
      "         -14.1342,  26.8573,  21.0929,  -5.1359,  15.4028,  -5.8899, -11.6464,\n",
      "          12.4919,   6.6084,  -3.6981,  -9.1017, -13.9161, -13.8984,  -8.6934,\n",
      "          -7.8126,  -9.7012,  -3.5935,  -4.6942,  -8.4822, -17.7242,  -0.1333,\n",
      "          -5.0885,  -4.5106,  32.0271,   0.3746,   4.7213, -22.7952,   6.4016,\n",
      "         -16.2953,   2.0929,   6.9910,  11.0776,  13.9657,  -5.3261,  16.9295,\n",
      "         -15.2887,  26.3078,   8.5449,  -9.5461,  17.9731, -14.0823,  -6.7096,\n",
      "           5.4388,   1.2007,  -4.4022,   0.6404,  -4.7186, -14.0666,  -9.4838,\n",
      "          -4.7613,   9.0058, -10.8435, -12.4313,   1.9380,  -5.9938,  12.3540,\n",
      "          -1.0554,   1.5641,   4.1874,  24.9809,  10.6341,  -7.4291, -16.2574,\n",
      "          27.5764,  23.7936,   5.9907,  13.5765,  10.5482,  16.6027,   0.9568,\n",
      "           4.6708,   1.0872, -25.5823,  19.4250,  11.3954,  11.5801,  12.0185,\n",
      "          -4.7204, -10.2610, -28.5138,   4.1791,  -7.9238,   7.5443,  19.2200,\n",
      "           1.1038,   1.2312]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.2224e+01,  1.3200e+02,  2.4089e+01, -8.7581e+00, -2.1912e+01,\n",
      "          5.6931e-01, -7.3833e+00, -1.5482e+01,  2.0880e+01,  6.0274e+00,\n",
      "         -1.2222e+01, -2.0808e-01,  8.2144e+00,  2.2220e+00,  7.2195e+00,\n",
      "          9.5441e+00, -7.8684e+00,  3.3072e+00,  2.6503e+00,  2.0505e+01,\n",
      "          1.0272e+01,  2.9261e+00,  1.2898e-01, -1.4579e-01,  7.8597e+00,\n",
      "          2.0449e+00,  5.2548e+00,  1.1763e+00, -7.1894e+00,  6.2576e-01,\n",
      "          1.0791e+01, -2.6928e+01, -5.9166e+00, -1.9122e+00,  3.4400e+00,\n",
      "         -9.5390e+00, -6.8770e+00, -6.6134e-01, -1.3230e+01,  1.3513e+01,\n",
      "         -3.8131e+00,  3.2297e+00, -1.3178e+01,  2.5615e+01,  2.0410e+01,\n",
      "         -6.5174e+00,  1.4558e+01, -5.3047e+00, -1.1194e+01,  1.4734e+01,\n",
      "          5.7710e+00, -4.7643e+00, -8.4283e+00, -1.3227e+01, -1.6180e+01,\n",
      "         -9.0451e+00, -6.4463e+00, -1.0689e+01, -4.9945e+00, -5.3724e+00,\n",
      "         -8.7356e+00, -1.6372e+01, -4.2384e-01, -3.2140e+00, -5.5974e+00,\n",
      "          3.1402e+01,  2.1340e-01,  5.4568e+00, -2.1224e+01,  9.7804e+00,\n",
      "         -1.5880e+01,  2.7557e+00,  9.2700e+00,  1.3461e+01,  1.4800e+01,\n",
      "         -4.3212e+00,  1.6937e+01, -1.5475e+01,  2.5501e+01,  8.6394e+00,\n",
      "         -9.4340e+00,  1.9529e+01, -1.3559e+01, -5.0988e+00,  7.3722e+00,\n",
      "          1.4987e+00, -2.3031e+00, -3.0374e+00, -5.8538e+00, -1.4803e+01,\n",
      "         -7.3895e+00, -2.5621e+00,  8.5381e+00, -1.2102e+01, -1.4191e+01,\n",
      "          2.4762e+00, -5.9116e+00,  1.3554e+01, -1.3345e+00,  1.8374e+00,\n",
      "          5.8979e+00,  2.5106e+01,  1.0636e+01, -6.2501e+00, -1.5928e+01,\n",
      "          2.7887e+01,  2.3951e+01,  6.2291e+00,  1.1674e+01,  1.0320e+01,\n",
      "          1.7053e+01,  3.4238e-01,  6.1414e+00,  2.2091e+00, -2.3667e+01,\n",
      "          1.9848e+01,  1.3098e+01,  1.1267e+01,  1.2443e+01, -5.1919e+00,\n",
      "         -1.1709e+01, -2.7944e+01,  3.9114e+00, -8.1038e+00,  7.4308e+00,\n",
      "          1.9691e+01,  4.7774e+00,  7.9862e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0618e+01,  1.3231e+02,  2.3228e+01, -8.5362e+00, -2.1475e+01,\n",
      "          1.8026e+00, -7.0487e+00, -1.5342e+01,  2.4693e+01,  5.1238e+00,\n",
      "         -1.4626e+01,  3.4024e-02,  8.1256e+00, -4.2609e-01,  6.6106e+00,\n",
      "          7.7946e+00, -4.9331e+00,  4.2417e+00,  2.3056e+00,  2.2465e+01,\n",
      "          9.9868e+00,  1.6209e+00, -1.2874e+00, -5.1649e-01,  9.1201e+00,\n",
      "          8.9892e-01,  5.4333e+00,  1.8104e+00, -6.0967e+00, -1.6329e-01,\n",
      "          1.0460e+01, -2.8091e+01, -3.7367e+00, -2.8229e+00,  3.7020e+00,\n",
      "         -1.0083e+01, -7.3551e+00,  8.5431e-01, -1.2026e+01,  1.3740e+01,\n",
      "         -3.3080e+00,  3.9807e+00, -1.1100e+01,  2.6103e+01,  1.9445e+01,\n",
      "         -4.9940e+00,  1.4967e+01, -5.6159e+00, -1.3160e+01,  1.2631e+01,\n",
      "          5.4187e+00, -1.6371e+00, -1.0745e+01, -1.5010e+01, -1.5666e+01,\n",
      "         -7.5057e+00, -7.6744e+00, -9.4194e+00, -1.6966e+00, -3.6692e+00,\n",
      "         -9.9006e+00, -1.5469e+01, -2.7747e+00, -6.8449e+00, -5.1954e+00,\n",
      "          3.1112e+01,  6.1121e-01,  4.7449e+00, -2.1626e+01,  5.9362e+00,\n",
      "         -1.6015e+01,  2.5000e+00,  8.2081e+00,  1.3010e+01,  1.5682e+01,\n",
      "         -4.8391e+00,  1.6163e+01, -1.3731e+01,  2.4673e+01,  7.4570e+00,\n",
      "         -1.1702e+01,  1.9981e+01, -1.4111e+01, -7.0763e+00,  8.3070e+00,\n",
      "          2.1363e-01, -6.1014e+00, -5.3864e-01, -5.2700e+00, -1.4490e+01,\n",
      "         -8.3480e+00, -4.2174e+00,  7.4114e+00, -1.1713e+01, -1.1170e+01,\n",
      "          1.6132e+00, -8.1231e+00,  1.2479e+01, -2.9704e+00, -9.3535e-01,\n",
      "          4.3589e+00,  2.6235e+01,  1.1074e+01, -6.5686e+00, -1.6358e+01,\n",
      "          2.8379e+01,  2.2969e+01,  6.3777e+00,  1.4478e+01,  9.8385e+00,\n",
      "          1.5466e+01,  9.5057e-01,  4.8234e+00,  1.6743e+00, -2.5595e+01,\n",
      "          2.0377e+01,  1.2389e+01,  9.1177e+00,  1.1727e+01, -5.4196e+00,\n",
      "         -1.1080e+01, -2.6340e+01,  1.3895e+00, -9.8054e+00,  6.8412e+00,\n",
      "          1.7744e+01,  2.1061e+00,  2.6272e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.6927e+00,  1.3228e+02,  2.0936e+01, -7.4839e+00, -2.2854e+01,\n",
      "          5.2645e-01, -6.8903e+00, -1.3593e+01,  2.1685e+01,  6.3439e+00,\n",
      "         -1.2687e+01,  4.0180e-01,  8.7197e+00,  2.3677e+00,  6.9123e+00,\n",
      "          9.2150e+00, -7.0581e+00,  5.0153e+00,  2.1859e+00,  2.2473e+01,\n",
      "          8.2673e+00,  2.2780e+00, -8.7010e-01, -1.2059e+00,  9.4090e+00,\n",
      "          9.4842e-01,  6.0910e+00,  4.7342e-01, -5.9917e+00,  1.1549e-01,\n",
      "          9.3320e+00, -2.7076e+01, -3.8935e+00, -3.6131e+00,  2.8333e+00,\n",
      "         -9.6789e+00, -1.0624e+01, -1.4907e+00, -1.3365e+01,  1.5311e+01,\n",
      "         -4.3944e+00,  3.5474e+00, -1.1485e+01,  2.6179e+01,  1.9203e+01,\n",
      "         -6.2155e+00,  1.3070e+01, -6.3500e+00, -1.1685e+01,  1.4051e+01,\n",
      "          4.8878e+00, -2.2737e+00, -8.8387e+00, -1.3117e+01, -1.5211e+01,\n",
      "         -9.1339e+00, -7.4255e+00, -1.1355e+01, -3.2707e+00, -6.2414e+00,\n",
      "         -9.2748e+00, -1.5698e+01, -2.0082e+00, -4.6824e+00, -5.3012e+00,\n",
      "          3.1269e+01,  2.2529e-01,  5.7996e+00, -2.1298e+01,  6.2137e+00,\n",
      "         -1.5113e+01,  2.3084e+00,  7.6438e+00,  1.2438e+01,  1.5650e+01,\n",
      "         -4.5275e+00,  1.7513e+01, -1.5451e+01,  2.5537e+01,  7.4921e+00,\n",
      "         -1.1378e+01,  1.9538e+01, -1.3545e+01, -6.6855e+00,  7.4546e+00,\n",
      "          2.3005e-01, -5.7566e+00, -2.1581e+00, -5.4112e+00, -1.6909e+01,\n",
      "         -7.9106e+00, -2.8761e+00,  9.4899e+00, -1.2894e+01, -1.1328e+01,\n",
      "          2.0041e+00, -5.7672e+00,  1.4010e+01, -2.6365e+00,  1.8483e+00,\n",
      "          4.5409e+00,  2.4783e+01,  1.0859e+01, -7.3426e+00, -1.6229e+01,\n",
      "          2.7415e+01,  2.3233e+01,  6.2727e+00,  1.2946e+01,  7.5014e+00,\n",
      "          1.6152e+01,  1.7224e+00,  4.8581e+00,  2.3777e+00, -2.4990e+01,\n",
      "          1.9413e+01,  1.2827e+01,  1.0754e+01,  1.1912e+01, -5.1993e+00,\n",
      "         -1.1470e+01, -2.6270e+01,  4.3157e+00, -8.3513e+00,  7.0172e+00,\n",
      "          1.9042e+01,  3.1548e+00,  2.1504e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0803e+01,  1.3209e+02,  2.3399e+01, -8.7254e+00, -2.0924e+01,\n",
      "          2.0383e+00, -6.8789e+00, -1.6064e+01,  2.2312e+01,  6.7940e+00,\n",
      "         -1.2930e+01,  8.0417e-02,  8.3126e+00,  2.3796e+00,  8.1355e+00,\n",
      "          8.5983e+00, -6.9069e+00,  2.1700e+00,  4.3959e+00,  2.3782e+01,\n",
      "          1.1155e+01,  1.6263e+00, -1.9404e+00, -6.8434e-03,  8.7818e+00,\n",
      "          1.2391e+00,  5.3447e+00,  1.0751e+00, -6.1727e+00, -1.0053e+00,\n",
      "          1.0652e+01, -2.7041e+01, -4.5841e+00, -2.0201e+00,  3.7701e+00,\n",
      "         -1.0061e+01, -8.6343e+00, -1.3177e+00, -1.3322e+01,  1.4408e+01,\n",
      "         -3.8304e+00,  3.5779e+00, -1.3884e+01,  2.6894e+01,  2.1054e+01,\n",
      "         -5.1312e+00,  1.5222e+01, -5.7818e+00, -1.1653e+01,  1.2931e+01,\n",
      "          6.6873e+00, -3.5137e+00, -9.0471e+00, -1.3993e+01, -1.4352e+01,\n",
      "         -8.6441e+00, -7.6925e+00, -9.7776e+00, -3.4308e+00, -4.8620e+00,\n",
      "         -8.7578e+00, -1.7736e+01, -1.9833e-01, -5.2694e+00, -4.6743e+00,\n",
      "          3.2232e+01,  4.1369e-01,  4.7649e+00, -2.2850e+01,  6.3710e+00,\n",
      "         -1.6270e+01,  1.7499e+00,  7.3373e+00,  1.0856e+01,  1.4087e+01,\n",
      "         -5.0752e+00,  1.6929e+01, -1.5265e+01,  2.5984e+01,  8.0998e+00,\n",
      "         -9.4997e+00,  1.8189e+01, -1.4087e+01, -6.9041e+00,  5.4601e+00,\n",
      "          1.2292e+00, -4.7678e+00,  9.8788e-01, -4.7513e+00, -1.4105e+01,\n",
      "         -9.5306e+00, -4.6935e+00,  8.8823e+00, -1.0752e+01, -1.2192e+01,\n",
      "          1.8033e+00, -5.9968e+00,  1.2235e+01, -9.6128e-01,  1.5239e+00,\n",
      "          4.4929e+00,  2.5284e+01,  1.0579e+01, -7.4935e+00, -1.6071e+01,\n",
      "          2.7669e+01,  2.3547e+01,  5.7321e+00,  1.3542e+01,  1.0491e+01,\n",
      "          1.6539e+01,  7.8790e-01,  4.6454e+00,  8.7529e-01, -2.5942e+01,\n",
      "          1.9596e+01,  1.1699e+01,  1.1770e+01,  1.2048e+01, -4.7905e+00,\n",
      "         -1.0385e+01, -2.8615e+01,  4.0430e+00, -7.6128e+00,  7.3356e+00,\n",
      "          1.9410e+01,  9.1744e-01,  1.0969e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.2046e+01,  1.3205e+02,  2.4340e+01, -8.8563e+00, -2.1777e+01,\n",
      "          6.2381e-01, -7.1931e+00, -1.5487e+01,  2.1059e+01,  5.8435e+00,\n",
      "         -1.2176e+01,  8.8134e-02,  8.2872e+00,  2.2131e+00,  6.9322e+00,\n",
      "          9.3392e+00, -7.7920e+00,  2.9591e+00,  2.3995e+00,  2.0410e+01,\n",
      "          1.0332e+01,  2.9585e+00, -4.3159e-02, -2.7414e-01,  8.0451e+00,\n",
      "          1.8756e+00,  5.1145e+00,  1.0775e+00, -7.0647e+00,  5.5204e-01,\n",
      "          1.0680e+01, -2.6688e+01, -5.7472e+00, -1.7487e+00,  3.7054e+00,\n",
      "         -9.7132e+00, -7.0479e+00, -7.8532e-01, -1.2963e+01,  1.3790e+01,\n",
      "         -3.6831e+00,  3.2561e+00, -1.3194e+01,  2.5666e+01,  2.0419e+01,\n",
      "         -6.5128e+00,  1.4428e+01, -5.1996e+00, -1.1208e+01,  1.5025e+01,\n",
      "          5.7662e+00, -4.5918e+00, -8.3862e+00, -1.3313e+01, -1.6426e+01,\n",
      "         -8.9901e+00, -6.4090e+00, -1.0707e+01, -4.8516e+00, -5.5148e+00,\n",
      "         -9.0028e+00, -1.6399e+01, -4.1399e-01, -3.4367e+00, -5.8994e+00,\n",
      "          3.1525e+01,  3.3178e-01,  5.4727e+00, -2.1304e+01,  9.5837e+00,\n",
      "         -1.5839e+01,  2.4386e+00,  9.4553e+00,  1.3204e+01,  1.4717e+01,\n",
      "         -4.0938e+00,  1.6956e+01, -1.5324e+01,  2.5377e+01,  8.3743e+00,\n",
      "         -9.4041e+00,  1.9637e+01, -1.3559e+01, -5.2437e+00,  7.2539e+00,\n",
      "          1.4332e+00, -2.5131e+00, -2.6739e+00, -5.8331e+00, -1.4820e+01,\n",
      "         -7.4289e+00, -2.6290e+00,  8.3920e+00, -1.2130e+01, -1.4172e+01,\n",
      "          2.4266e+00, -5.9609e+00,  1.3416e+01, -1.1375e+00,  1.8004e+00,\n",
      "          6.1609e+00,  2.5505e+01,  1.0510e+01, -6.3593e+00, -1.5812e+01,\n",
      "          2.8010e+01,  2.3764e+01,  5.9266e+00,  1.1692e+01,  1.0320e+01,\n",
      "          1.6945e+01,  9.9002e-02,  6.0826e+00,  2.0658e+00, -2.4043e+01,\n",
      "          2.0081e+01,  1.3321e+01,  1.1383e+01,  1.2521e+01, -5.2686e+00,\n",
      "         -1.1685e+01, -2.8145e+01,  3.6734e+00, -7.8758e+00,  7.2485e+00,\n",
      "          1.9904e+01,  4.5270e+00,  6.4972e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 10.5553, 132.3196,  23.5344,  -8.5760, -21.3067,   1.7803,  -6.8680,\n",
      "         -15.3729,  24.5386,   4.9465, -14.4767,   0.3183,   8.1111,  -0.1743,\n",
      "           6.3779,   7.7284,  -5.0926,   3.7989,   2.1928,  22.2991,  10.2033,\n",
      "           1.6184,  -1.3627,  -0.6923,   9.2809,   0.9202,   5.2563,   1.7260,\n",
      "          -6.0587,  -0.3681,  10.3046, -27.7359,  -3.5899,  -2.7038,   3.8493,\n",
      "         -10.1913,  -7.4601,   0.6818, -11.9062,  14.0103,  -3.2486,   4.0143,\n",
      "         -11.3084,  26.2211,  19.4872,  -5.1362,  14.7882,  -5.5191, -13.0681,\n",
      "          12.9970,   5.5278,  -1.6011, -10.5085, -15.0229, -15.6420,  -7.4629,\n",
      "          -7.5581,  -9.3649,  -1.8406,  -3.9372, -10.1139, -15.6253,  -2.5848,\n",
      "          -6.9597,  -5.4775,  31.2628,   0.6125,   4.8180, -21.7712,   5.8851,\n",
      "         -16.0324,   2.2064,   8.3939,  12.7342,  15.6017,  -4.7031,  16.2110,\n",
      "         -13.6694,  24.7181,   7.2901, -11.4910,  20.0346, -14.0946,  -7.0816,\n",
      "           7.9602,   0.1508,  -6.1096,  -0.2388,  -5.2815, -14.4847,  -8.2837,\n",
      "          -4.1509,   7.3845, -11.6366, -11.1949,   1.7048,  -7.9736,  12.3789,\n",
      "          -2.8134,  -0.8223,   4.7578,  26.5070,  11.0339,  -6.6589, -16.2928,\n",
      "          28.5063,  23.0086,   6.0961,  14.2899,   9.7790,  15.5003,   0.8477,\n",
      "           4.7536,   1.5382, -25.8847,  20.5626,  12.6064,   9.4010,  12.0138,\n",
      "          -5.4216, -11.0501, -26.5516,   1.4394,  -9.5150,   6.6644,  18.0699,\n",
      "           1.9712,   2.4502]], grad_fn=<SliceBackward0>)\n",
      "tensor([[  9.6949, 132.3553,  21.1703,  -7.5441, -22.6810,   0.5642,  -6.7922,\n",
      "         -13.6800,  21.7269,   6.1979, -12.6944,   0.5275,   8.6315,   2.3328,\n",
      "           6.7914,   9.1587,  -7.1331,   4.5192,   2.2953,  22.4466,   8.5791,\n",
      "           2.2953,  -0.8672,  -1.2407,   9.5151,   0.9647,   5.8489,   0.3939,\n",
      "          -5.9741,  -0.1910,   9.3064, -26.9544,  -3.8670,  -3.5199,   2.9809,\n",
      "          -9.7853, -10.6538,  -1.4471, -13.1244,  15.5262,  -4.2817,   3.4666,\n",
      "         -11.5413,  26.2631,  19.1819,  -6.2348,  13.1533,  -6.2603, -11.7699,\n",
      "          14.3029,   5.0048,  -2.2817,  -8.8218, -13.2455, -15.1558,  -8.9524,\n",
      "          -7.3982, -11.4259,  -3.4265,  -6.3244,  -9.3754, -15.8115,  -1.8887,\n",
      "          -4.9009,  -5.5373,  31.4988,   0.2023,   5.7879, -21.3341,   6.1986,\n",
      "         -15.0411,   1.9518,   7.7502,  12.1662,  15.5466,  -4.5116,  17.4893,\n",
      "         -15.4601,  25.5641,   7.4115, -11.2339,  19.6463, -13.4568,  -6.7578,\n",
      "           7.3050,   0.1711,  -5.7758,  -1.8636,  -5.3333, -16.8803,  -7.9986,\n",
      "          -2.9799,   9.4504, -12.8584, -11.2088,   1.9883,  -5.7288,  13.8558,\n",
      "          -2.4014,   1.7034,   4.8534,  25.0459,  10.7799,  -7.3805, -16.0481,\n",
      "          27.5013,  23.2341,   5.9519,  12.9198,   7.6849,  16.1624,   1.4505,\n",
      "           4.7314,   2.2984, -25.1909,  19.5857,  13.0229,  10.8579,  12.0734,\n",
      "          -5.2721, -11.4222, -26.3905,   4.1970,  -8.0623,   6.8914,  19.3566,\n",
      "           2.9297,   1.9993]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0599e+01,  1.3218e+02,  2.3360e+01, -8.8790e+00, -2.0738e+01,\n",
      "          2.0548e+00, -6.6187e+00, -1.5955e+01,  2.2432e+01,  6.6199e+00,\n",
      "         -1.2919e+01,  2.9198e-01,  8.3526e+00,  2.3163e+00,  7.9935e+00,\n",
      "          8.6545e+00, -7.0589e+00,  1.6975e+00,  4.3577e+00,  2.3826e+01,\n",
      "          1.1302e+01,  1.7893e+00, -1.8398e+00, -1.1220e-01,  8.8379e+00,\n",
      "          1.2374e+00,  5.1889e+00,  8.2299e-01, -6.1357e+00, -1.3071e+00,\n",
      "          1.0648e+01, -2.6943e+01, -4.4745e+00, -2.0461e+00,  3.9211e+00,\n",
      "         -1.0188e+01, -8.8370e+00, -1.3526e+00, -1.3088e+01,  1.4740e+01,\n",
      "         -3.7038e+00,  3.4549e+00, -1.3613e+01,  2.6924e+01,  2.0950e+01,\n",
      "         -5.1585e+00,  1.5067e+01, -5.7375e+00, -1.1650e+01,  1.3262e+01,\n",
      "          6.8303e+00, -3.4767e+00, -8.9569e+00, -1.4076e+01, -1.4469e+01,\n",
      "         -8.5053e+00, -7.7569e+00, -9.9025e+00, -3.4263e+00, -4.9863e+00,\n",
      "         -8.9221e+00, -1.7724e+01, -2.2690e-01, -5.4496e+00, -4.8491e+00,\n",
      "          3.2476e+01,  2.8395e-01,  4.8438e+00, -2.2740e+01,  6.4191e+00,\n",
      "         -1.6273e+01,  1.4359e+00,  7.4645e+00,  1.0601e+01,  1.4149e+01,\n",
      "         -4.9958e+00,  1.6942e+01, -1.5360e+01,  2.5781e+01,  7.7985e+00,\n",
      "         -9.4426e+00,  1.8363e+01, -1.4063e+01, -7.0613e+00,  5.3406e+00,\n",
      "          1.2226e+00, -5.0596e+00,  1.1900e+00, -4.7009e+00, -1.4125e+01,\n",
      "         -9.7156e+00, -4.6467e+00,  8.9382e+00, -1.0793e+01, -1.1941e+01,\n",
      "          1.7282e+00, -6.0203e+00,  1.2122e+01, -8.1298e-01,  1.4023e+00,\n",
      "          4.9049e+00,  2.5494e+01,  1.0508e+01, -7.5947e+00, -1.5754e+01,\n",
      "          2.7746e+01,  2.3564e+01,  5.5371e+00,  1.3437e+01,  1.0570e+01,\n",
      "          1.6512e+01,  5.3426e-01,  4.6224e+00,  6.9783e-01, -2.6171e+01,\n",
      "          1.9744e+01,  1.1860e+01,  1.1727e+01,  1.2114e+01, -4.9285e+00,\n",
      "         -1.0462e+01, -2.8552e+01,  4.0076e+00, -7.3802e+00,  7.1580e+00,\n",
      "          1.9662e+01,  8.4767e-01,  1.0506e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.1878e+01,  1.3213e+02,  2.4357e+01, -8.9856e+00, -2.1611e+01,\n",
      "          5.7207e-01, -6.9976e+00, -1.5413e+01,  2.1139e+01,  5.7163e+00,\n",
      "         -1.2072e+01,  3.3487e-01,  8.3023e+00,  2.2029e+00,  6.8294e+00,\n",
      "          9.2838e+00, -8.0543e+00,  2.4970e+00,  2.3737e+00,  2.0480e+01,\n",
      "          1.0405e+01,  3.0065e+00, -2.6992e-02, -3.0318e-01,  8.0329e+00,\n",
      "          1.8167e+00,  5.0643e+00,  9.0094e-01, -7.0572e+00,  2.5741e-01,\n",
      "          1.0649e+01, -2.6657e+01, -5.6917e+00, -1.8040e+00,  3.8785e+00,\n",
      "         -9.8433e+00, -7.3323e+00, -8.4809e-01, -1.2802e+01,  1.4189e+01,\n",
      "         -3.5054e+00,  3.1676e+00, -1.2946e+01,  2.5685e+01,  2.0400e+01,\n",
      "         -6.5187e+00,  1.4247e+01, -5.1198e+00, -1.1156e+01,  1.5229e+01,\n",
      "          5.7888e+00, -4.5634e+00, -8.3235e+00, -1.3440e+01, -1.6458e+01,\n",
      "         -8.9285e+00, -6.5359e+00, -1.0812e+01, -4.6511e+00, -5.5815e+00,\n",
      "         -9.1388e+00, -1.6366e+01, -4.5336e-01, -3.5966e+00, -6.0321e+00,\n",
      "          3.1767e+01,  2.5705e-01,  5.6009e+00, -2.1141e+01,  9.5757e+00,\n",
      "         -1.5772e+01,  2.2522e+00,  9.5099e+00,  1.2953e+01,  1.4624e+01,\n",
      "         -3.9911e+00,  1.7027e+01, -1.5399e+01,  2.5264e+01,  8.1568e+00,\n",
      "         -9.3857e+00,  1.9764e+01, -1.3499e+01, -5.4249e+00,  7.1388e+00,\n",
      "          1.3790e+00, -2.7820e+00, -2.4015e+00, -5.8801e+00, -1.4889e+01,\n",
      "         -7.5475e+00, -2.6049e+00,  8.4442e+00, -1.2186e+01, -1.4078e+01,\n",
      "          2.3695e+00, -6.0576e+00,  1.3406e+01, -8.1597e-01,  1.6553e+00,\n",
      "          6.4264e+00,  2.5775e+01,  1.0368e+01, -6.4448e+00, -1.5521e+01,\n",
      "          2.8021e+01,  2.3709e+01,  5.8878e+00,  1.1727e+01,  1.0329e+01,\n",
      "          1.6915e+01, -2.1209e-01,  6.1053e+00,  1.9282e+00, -2.4289e+01,\n",
      "          2.0270e+01,  1.3470e+01,  1.1289e+01,  1.2527e+01, -5.4039e+00,\n",
      "         -1.1770e+01, -2.8117e+01,  3.5784e+00, -7.6607e+00,  7.1865e+00,\n",
      "          2.0156e+01,  4.4326e+00,  5.6261e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0415e+01,  1.3234e+02,  2.3659e+01, -8.6426e+00, -2.1162e+01,\n",
      "          1.6821e+00, -6.6177e+00, -1.5328e+01,  2.4366e+01,  4.8210e+00,\n",
      "         -1.4320e+01,  6.5042e-01,  8.1010e+00, -7.1067e-03,  6.2615e+00,\n",
      "          7.7395e+00, -5.4122e+00,  3.1913e+00,  2.1928e+00,  2.2225e+01,\n",
      "          1.0377e+01,  1.7322e+00, -1.2633e+00, -7.6658e-01,  9.2154e+00,\n",
      "          8.9342e-01,  5.2637e+00,  1.5401e+00, -6.2081e+00, -6.0118e-01,\n",
      "          1.0316e+01, -2.7552e+01, -3.4698e+00, -2.7086e+00,  4.0019e+00,\n",
      "         -1.0232e+01, -7.6874e+00,  4.8930e-01, -1.1887e+01,  1.4427e+01,\n",
      "         -3.1097e+00,  3.9693e+00, -1.1224e+01,  2.6273e+01,  1.9544e+01,\n",
      "         -5.2166e+00,  1.4500e+01, -5.4538e+00, -1.2850e+01,  1.3343e+01,\n",
      "          5.5899e+00, -1.7329e+00, -1.0261e+01, -1.5015e+01, -1.5620e+01,\n",
      "         -7.5738e+00, -7.5890e+00, -9.3602e+00, -1.7459e+00, -4.1743e+00,\n",
      "         -1.0206e+01, -1.5662e+01, -2.4417e+00, -6.9682e+00, -5.5970e+00,\n",
      "          3.1496e+01,  5.3034e-01,  5.0635e+00, -2.1698e+01,  6.0134e+00,\n",
      "         -1.6041e+01,  2.0513e+00,  8.4525e+00,  1.2510e+01,  1.5575e+01,\n",
      "         -4.6043e+00,  1.6343e+01, -1.3779e+01,  2.4701e+01,  7.0704e+00,\n",
      "         -1.1259e+01,  2.0151e+01, -1.3981e+01, -7.1341e+00,  7.7461e+00,\n",
      "          1.2743e-01, -6.1702e+00,  9.7617e-02, -5.4632e+00, -1.4604e+01,\n",
      "         -8.3002e+00, -3.9835e+00,  7.4769e+00, -1.1558e+01, -1.1249e+01,\n",
      "          1.7180e+00, -7.8627e+00,  1.2430e+01, -2.5636e+00, -7.5228e-01,\n",
      "          4.9453e+00,  2.6730e+01,  1.0958e+01, -6.5987e+00, -1.6107e+01,\n",
      "          2.8526e+01,  2.2992e+01,  6.0756e+00,  1.4191e+01,  9.6780e+00,\n",
      "          1.5575e+01,  6.8722e-01,  4.8233e+00,  1.2416e+00, -2.6097e+01,\n",
      "          2.0732e+01,  1.2722e+01,  9.5567e+00,  1.2173e+01, -5.4589e+00,\n",
      "         -1.1249e+01, -2.6614e+01,  1.5645e+00, -9.2874e+00,  6.7829e+00,\n",
      "          1.8411e+01,  1.9810e+00,  2.2480e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.6534e+00,  1.3236e+02,  2.1452e+01, -7.6233e+00, -2.2536e+01,\n",
      "          6.4540e-01, -6.5680e+00, -1.3897e+01,  2.1822e+01,  6.0468e+00,\n",
      "         -1.2739e+01,  7.2495e-01,  8.5704e+00,  2.2929e+00,  6.7336e+00,\n",
      "          9.0657e+00, -7.2556e+00,  3.8357e+00,  2.2406e+00,  2.2393e+01,\n",
      "          8.8560e+00,  2.3773e+00, -9.0021e-01, -1.2547e+00,  9.5869e+00,\n",
      "          7.8519e-01,  5.7909e+00,  3.5660e-01, -5.9516e+00, -4.0146e-01,\n",
      "          9.2317e+00, -2.6775e+01, -3.6745e+00, -3.3877e+00,  3.2392e+00,\n",
      "         -9.7790e+00, -1.0755e+01, -1.4665e+00, -1.2994e+01,  1.5799e+01,\n",
      "         -4.0838e+00,  3.3777e+00, -1.1586e+01,  2.6236e+01,  1.9312e+01,\n",
      "         -6.2638e+00,  1.3125e+01, -6.1308e+00, -1.1796e+01,  1.4530e+01,\n",
      "          4.9491e+00, -2.3309e+00, -8.8603e+00, -1.3349e+01, -1.5238e+01,\n",
      "         -8.9841e+00, -7.3720e+00, -1.1304e+01, -3.3153e+00, -6.3308e+00,\n",
      "         -9.4722e+00, -1.5921e+01, -1.7864e+00, -4.9762e+00, -5.7731e+00,\n",
      "          3.1623e+01,  2.5201e-01,  5.9371e+00, -2.1268e+01,  6.3741e+00,\n",
      "         -1.4978e+01,  1.7271e+00,  7.7666e+00,  1.1972e+01,  1.5514e+01,\n",
      "         -4.4736e+00,  1.7588e+01, -1.5428e+01,  2.5511e+01,  7.2031e+00,\n",
      "         -1.1025e+01,  1.9706e+01, -1.3244e+01, -6.8968e+00,  7.1702e+00,\n",
      "          1.2419e-01, -5.8053e+00, -1.5393e+00, -5.4392e+00, -1.7000e+01,\n",
      "         -7.9915e+00, -2.8718e+00,  9.4367e+00, -1.2708e+01, -1.1132e+01,\n",
      "          1.9566e+00, -5.6527e+00,  1.3814e+01, -2.2078e+00,  1.6199e+00,\n",
      "          4.8460e+00,  2.5349e+01,  1.0743e+01, -7.3100e+00, -1.5858e+01,\n",
      "          2.7581e+01,  2.3116e+01,  5.8311e+00,  1.2909e+01,  7.7393e+00,\n",
      "          1.6210e+01,  1.2713e+00,  4.7264e+00,  2.0307e+00, -2.5396e+01,\n",
      "          1.9771e+01,  1.3167e+01,  1.0906e+01,  1.2191e+01, -5.3039e+00,\n",
      "         -1.1466e+01, -2.6453e+01,  4.1436e+00, -7.8045e+00,  7.0859e+00,\n",
      "          1.9616e+01,  2.7795e+00,  1.9006e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 10.4151, 132.1747,  23.4419,  -9.0007, -20.6379,   2.1462,  -6.2763,\n",
      "         -16.0211,  22.5081,   6.5193, -12.9356,   0.6363,   8.3592,   2.2896,\n",
      "           7.9210,   8.6633,  -7.1133,   1.1222,   4.1670,  23.7554,  11.5428,\n",
      "           1.8424,  -1.8675,  -0.2166,   8.9926,   1.0196,   5.1187,   0.7100,\n",
      "          -6.0117,  -1.4941,  10.4797, -26.6888,  -4.1429,  -1.9638,   4.1355,\n",
      "         -10.2028,  -9.0381,  -1.4557, -12.9884,  15.0442,  -3.5792,   3.3636,\n",
      "         -13.5055,  26.8563,  21.0060,  -5.2273,  14.8743,  -5.6744, -11.6996,\n",
      "          13.5565,   6.7971,  -3.4008,  -9.0180, -14.1285, -14.6220,  -8.5325,\n",
      "          -7.6956,  -9.8032,  -3.2845,  -5.0819,  -9.1726, -17.7817,  -0.2152,\n",
      "          -5.5645,  -5.0897,  32.5212,   0.2807,   4.9780, -22.6385,   6.5493,\n",
      "         -16.2827,   1.2594,   7.4566,  10.4364,  14.1985,  -5.0153,  17.0338,\n",
      "         -15.3107,  25.6559,   7.4247,  -9.2525,  18.3688, -13.8565,  -7.2128,\n",
      "           5.1345,   1.1964,  -5.2299,   1.3396,  -4.7399, -14.2767,  -9.7767,\n",
      "          -4.5093,   8.9911, -10.6961, -11.7039,   1.6863,  -5.9843,  12.0716,\n",
      "          -0.7726,   1.3396,   4.9651,  25.7108,  10.5397,  -7.5195, -15.5569,\n",
      "          27.8651,  23.4978,   5.3646,  13.3316,  10.5687,  16.5597,   0.3946,\n",
      "           4.6343,   0.3983, -26.4274,  19.8907,  11.9785,  11.6670,  12.2226,\n",
      "          -5.0153, -10.4461, -28.5273,   4.0337,  -7.0950,   7.2728,  19.8725,\n",
      "           0.6955,   1.0285]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.1683e+01,  1.3216e+02,  2.4465e+01, -9.0798e+00, -2.1480e+01,\n",
      "          6.1579e-01, -6.6682e+00, -1.5483e+01,  2.1277e+01,  5.5959e+00,\n",
      "         -1.2137e+01,  6.5855e-01,  8.2480e+00,  2.2614e+00,  6.6844e+00,\n",
      "          9.2158e+00, -8.2561e+00,  2.0716e+00,  2.2246e+00,  2.0533e+01,\n",
      "          1.0600e+01,  2.9684e+00, -1.4594e-01, -3.1617e-01,  8.2254e+00,\n",
      "          1.5881e+00,  4.8939e+00,  7.7013e-01, -6.8735e+00,  3.7641e-03,\n",
      "          1.0428e+01, -2.6450e+01, -5.3784e+00, -1.7113e+00,  4.0911e+00,\n",
      "         -9.9126e+00, -7.6341e+00, -9.3559e-01, -1.2690e+01,  1.4526e+01,\n",
      "         -3.4110e+00,  3.1545e+00, -1.2890e+01,  2.5622e+01,  2.0476e+01,\n",
      "         -6.5804e+00,  1.4061e+01, -5.0806e+00, -1.1205e+01,  1.5452e+01,\n",
      "          5.7013e+00, -4.4266e+00, -8.4073e+00, -1.3571e+01, -1.6476e+01,\n",
      "         -8.9445e+00, -6.4787e+00, -1.0858e+01, -4.4627e+00, -5.6957e+00,\n",
      "         -9.3865e+00, -1.6406e+01, -4.7211e-01, -3.7613e+00, -6.2532e+00,\n",
      "          3.1799e+01,  2.9692e-01,  5.6855e+00, -2.1015e+01,  9.5519e+00,\n",
      "         -1.5714e+01,  2.1494e+00,  9.4843e+00,  1.2739e+01,  1.4478e+01,\n",
      "         -3.9828e+00,  1.7105e+01, -1.5364e+01,  2.5234e+01,  7.8473e+00,\n",
      "         -9.2913e+00,  1.9771e+01, -1.3247e+01, -5.6226e+00,  6.9320e+00,\n",
      "          1.3035e+00, -2.9593e+00, -2.1827e+00, -5.9200e+00, -1.5013e+01,\n",
      "         -7.6069e+00, -2.6094e+00,  8.4876e+00, -1.2180e+01, -1.3854e+01,\n",
      "          2.3487e+00, -6.0839e+00,  1.3392e+01, -6.5267e-01,  1.5533e+00,\n",
      "          6.4944e+00,  2.6020e+01,  1.0347e+01, -6.4303e+00, -1.5366e+01,\n",
      "          2.8144e+01,  2.3619e+01,  5.7310e+00,  1.1685e+01,  1.0298e+01,\n",
      "          1.7000e+01, -4.3053e-01,  6.1105e+00,  1.7128e+00, -2.4641e+01,\n",
      "          2.0527e+01,  1.3581e+01,  1.1199e+01,  1.2679e+01, -5.5110e+00,\n",
      "         -1.1699e+01, -2.8144e+01,  3.5413e+00, -7.3704e+00,  7.2207e+00,\n",
      "          2.0381e+01,  4.1940e+00,  4.9637e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0327e+01,  1.3237e+02,  2.3740e+01, -8.7996e+00, -2.1020e+01,\n",
      "          1.7006e+00, -6.3678e+00, -1.5364e+01,  2.4306e+01,  4.6645e+00,\n",
      "         -1.4205e+01,  8.8179e-01,  8.0670e+00,  2.0707e-01,  6.0572e+00,\n",
      "          7.8417e+00, -5.8047e+00,  2.8662e+00,  2.0798e+00,  2.2227e+01,\n",
      "          1.0541e+01,  1.8165e+00, -1.2168e+00, -7.2391e-01,  9.1861e+00,\n",
      "          7.7183e-01,  5.0841e+00,  1.3195e+00, -6.2184e+00, -8.3333e-01,\n",
      "          1.0257e+01, -2.7344e+01, -3.2847e+00, -2.6569e+00,  4.1975e+00,\n",
      "         -1.0326e+01, -8.0245e+00,  3.8116e-01, -1.1777e+01,  1.4757e+01,\n",
      "         -3.0529e+00,  3.9413e+00, -1.1244e+01,  2.6262e+01,  1.9582e+01,\n",
      "         -5.3880e+00,  1.4239e+01, -5.4448e+00, -1.2770e+01,  1.3645e+01,\n",
      "          5.6119e+00, -1.7826e+00, -1.0127e+01, -1.5042e+01, -1.5620e+01,\n",
      "         -7.6355e+00, -7.4606e+00, -9.5430e+00, -1.7919e+00, -4.3766e+00,\n",
      "         -1.0393e+01, -1.5645e+01, -2.2906e+00, -6.9278e+00, -5.7284e+00,\n",
      "          3.1537e+01,  4.7597e-01,  5.0809e+00, -2.1560e+01,  6.0645e+00,\n",
      "         -1.6055e+01,  1.9878e+00,  8.5145e+00,  1.2330e+01,  1.5308e+01,\n",
      "         -4.4751e+00,  1.6318e+01, -1.3871e+01,  2.4722e+01,  6.8032e+00,\n",
      "         -1.0996e+01,  2.0187e+01, -1.3833e+01, -7.2052e+00,  7.5496e+00,\n",
      "          1.0339e-01, -6.1888e+00,  3.0999e-01, -5.5316e+00, -1.4664e+01,\n",
      "         -8.3342e+00, -3.9617e+00,  7.5352e+00, -1.1603e+01, -1.1317e+01,\n",
      "          1.7513e+00, -7.7639e+00,  1.2457e+01, -2.4076e+00, -6.8176e-01,\n",
      "          5.1888e+00,  2.6873e+01,  1.0924e+01, -6.5780e+00, -1.5999e+01,\n",
      "          2.8554e+01,  2.3032e+01,  5.8840e+00,  1.3941e+01,  9.5808e+00,\n",
      "          1.5658e+01,  4.4936e-01,  4.8789e+00,  1.0619e+00, -2.6367e+01,\n",
      "          2.0991e+01,  1.2799e+01,  9.6237e+00,  1.2331e+01, -5.5615e+00,\n",
      "         -1.1258e+01, -2.6742e+01,  1.6580e+00, -8.9601e+00,  6.7334e+00,\n",
      "          1.8752e+01,  1.9139e+00,  2.0049e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.7095e+00,  1.3243e+02,  2.1616e+01, -7.7909e+00, -2.2322e+01,\n",
      "          6.8779e-01, -6.4284e+00, -1.3994e+01,  2.1960e+01,  5.8468e+00,\n",
      "         -1.2804e+01,  8.4422e-01,  8.5683e+00,  2.2703e+00,  6.6294e+00,\n",
      "          9.1648e+00, -7.4101e+00,  3.5320e+00,  2.1739e+00,  2.2344e+01,\n",
      "          9.0286e+00,  2.4951e+00, -8.7015e-01, -1.1638e+00,  9.5448e+00,\n",
      "          5.6016e-01,  5.6026e+00,  2.2368e-01, -6.0113e+00, -6.3091e-01,\n",
      "          9.2580e+00, -2.6799e+01, -3.6001e+00, -3.3439e+00,  3.4053e+00,\n",
      "         -9.8931e+00, -1.1035e+01, -1.3565e+00, -1.2714e+01,  1.6010e+01,\n",
      "         -3.8378e+00,  3.3058e+00, -1.1494e+01,  2.6194e+01,  1.9246e+01,\n",
      "         -6.3248e+00,  1.3122e+01, -6.0147e+00, -1.1846e+01,  1.4625e+01,\n",
      "          4.9313e+00, -2.3097e+00, -8.8625e+00, -1.3498e+01, -1.5431e+01,\n",
      "         -8.9377e+00, -7.3532e+00, -1.1382e+01, -3.3070e+00, -6.3505e+00,\n",
      "         -9.5905e+00, -1.5883e+01, -1.7223e+00, -4.9990e+00, -5.9299e+00,\n",
      "          3.1694e+01,  1.8584e-01,  5.8571e+00, -2.1155e+01,  6.4547e+00,\n",
      "         -1.4935e+01,  1.5692e+00,  7.9768e+00,  1.1886e+01,  1.5211e+01,\n",
      "         -4.3702e+00,  1.7438e+01, -1.5479e+01,  2.5378e+01,  7.0627e+00,\n",
      "         -1.0861e+01,  1.9905e+01, -1.3263e+01, -6.9591e+00,  7.0736e+00,\n",
      "          9.6976e-02, -5.8554e+00, -1.3056e+00, -5.5504e+00, -1.7020e+01,\n",
      "         -8.0399e+00, -2.9537e+00,  9.3125e+00, -1.2732e+01, -1.1135e+01,\n",
      "          1.8834e+00, -5.6514e+00,  1.3808e+01, -2.0360e+00,  1.4664e+00,\n",
      "          5.0670e+00,  2.5524e+01,  1.0739e+01, -7.2975e+00, -1.5731e+01,\n",
      "          2.7610e+01,  2.3026e+01,  5.5822e+00,  1.2772e+01,  7.7937e+00,\n",
      "          1.6216e+01,  9.4894e-01,  4.7414e+00,  2.0086e+00, -2.5546e+01,\n",
      "          2.0018e+01,  1.3295e+01,  1.0882e+01,  1.2236e+01, -5.4110e+00,\n",
      "         -1.1577e+01, -2.6638e+01,  4.1098e+00, -7.6400e+00,  7.0034e+00,\n",
      "          1.9875e+01,  2.6843e+00,  1.7555e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0434e+01,  1.3226e+02,  2.3461e+01, -9.0990e+00, -2.0502e+01,\n",
      "          2.1635e+00, -6.0592e+00, -1.6007e+01,  2.2606e+01,  6.4291e+00,\n",
      "         -1.2954e+01,  7.3930e-01,  8.4904e+00,  2.2685e+00,  7.8351e+00,\n",
      "          8.7725e+00, -7.1461e+00,  8.7638e-01,  4.0207e+00,  2.3665e+01,\n",
      "          1.1609e+01,  1.9069e+00, -1.8691e+00, -2.5385e-01,  9.0445e+00,\n",
      "          7.9123e-01,  5.0373e+00,  5.5979e-01, -6.0130e+00, -1.5523e+00,\n",
      "          1.0491e+01, -2.6764e+01, -4.0799e+00, -1.9884e+00,  4.3075e+00,\n",
      "         -1.0332e+01, -9.4074e+00, -1.4449e+00, -1.2734e+01,  1.5199e+01,\n",
      "         -3.3227e+00,  3.2810e+00, -1.3389e+01,  2.6803e+01,  2.0859e+01,\n",
      "         -5.2852e+00,  1.4754e+01, -5.5917e+00, -1.1706e+01,  1.3686e+01,\n",
      "          6.7585e+00, -3.3501e+00, -8.9161e+00, -1.4195e+01, -1.5044e+01,\n",
      "         -8.5130e+00, -7.7369e+00, -9.8276e+00, -3.2965e+00, -5.1899e+00,\n",
      "         -9.3227e+00, -1.7732e+01, -1.6634e-01, -5.5739e+00, -5.3536e+00,\n",
      "          3.2594e+01,  2.6107e-01,  4.9787e+00, -2.2493e+01,  6.7037e+00,\n",
      "         -1.6211e+01,  1.0937e+00,  7.7570e+00,  1.0366e+01,  1.4102e+01,\n",
      "         -4.8814e+00,  1.6894e+01, -1.5376e+01,  2.5453e+01,  7.2718e+00,\n",
      "         -9.1374e+00,  1.8548e+01, -1.3911e+01, -7.2559e+00,  5.0701e+00,\n",
      "          1.1609e+00, -5.3337e+00,  1.3967e+00, -4.8415e+00, -1.4398e+01,\n",
      "         -9.8482e+00, -4.4984e+00,  8.8856e+00, -1.0821e+01, -1.1672e+01,\n",
      "          1.6036e+00, -5.9158e+00,  1.2130e+01, -6.7233e-01,  1.2877e+00,\n",
      "          5.2050e+00,  2.5835e+01,  1.0594e+01, -7.5338e+00, -1.5374e+01,\n",
      "          2.7936e+01,  2.3393e+01,  5.1304e+00,  1.3090e+01,  1.0558e+01,\n",
      "          1.6448e+01,  1.0877e-01,  4.6219e+00,  4.3300e-01, -2.6463e+01,\n",
      "          2.0048e+01,  1.2130e+01,  1.1599e+01,  1.2200e+01, -5.1497e+00,\n",
      "         -1.0653e+01, -2.8678e+01,  4.0518e+00, -6.9900e+00,  7.1484e+00,\n",
      "          2.0094e+01,  7.1506e-01,  1.0319e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.1581e+01,  1.3221e+02,  2.4543e+01, -9.0563e+00, -2.1247e+01,\n",
      "          6.5242e-01, -6.3450e+00, -1.5480e+01,  2.1438e+01,  5.5822e+00,\n",
      "         -1.2129e+01,  7.7779e-01,  8.3820e+00,  2.2753e+00,  6.6173e+00,\n",
      "          9.1557e+00, -8.2573e+00,  1.7243e+00,  2.2222e+00,  2.0629e+01,\n",
      "          1.0626e+01,  2.8667e+00, -3.9697e-01, -3.2981e-01,  8.3933e+00,\n",
      "          1.2127e+00,  4.8091e+00,  6.9804e-01, -6.7480e+00, -1.0697e-01,\n",
      "          1.0349e+01, -2.6536e+01, -5.3752e+00, -1.7741e+00,  4.3212e+00,\n",
      "         -1.0022e+01, -8.0795e+00, -1.0377e+00, -1.2506e+01,  1.4678e+01,\n",
      "         -3.0059e+00,  3.1534e+00, -1.2948e+01,  2.5657e+01,  2.0413e+01,\n",
      "         -6.5841e+00,  1.3982e+01, -4.9889e+00, -1.1140e+01,  1.5490e+01,\n",
      "          5.6608e+00, -4.2912e+00, -8.2828e+00, -1.3699e+01, -1.6785e+01,\n",
      "         -8.9474e+00, -6.6239e+00, -1.0836e+01, -4.3436e+00, -5.8017e+00,\n",
      "         -9.4711e+00, -1.6454e+01, -4.4546e-01, -3.7983e+00, -6.6692e+00,\n",
      "          3.1930e+01,  4.1247e-01,  5.7529e+00, -2.0929e+01,  9.5387e+00,\n",
      "         -1.5537e+01,  1.8871e+00,  9.7385e+00,  1.2545e+01,  1.4370e+01,\n",
      "         -3.9126e+00,  1.7041e+01, -1.5371e+01,  2.5138e+01,  7.8121e+00,\n",
      "         -9.2594e+00,  1.9866e+01, -1.3305e+01, -5.6763e+00,  6.7688e+00,\n",
      "          1.2690e+00, -3.0321e+00, -1.9209e+00, -6.0058e+00, -1.5176e+01,\n",
      "         -7.6485e+00, -2.6691e+00,  8.3538e+00, -1.2360e+01, -1.3834e+01,\n",
      "          2.2928e+00, -5.9495e+00,  1.3468e+01, -4.8425e-01,  1.5709e+00,\n",
      "          6.6700e+00,  2.6203e+01,  1.0430e+01, -6.4975e+00, -1.5250e+01,\n",
      "          2.8260e+01,  2.3405e+01,  5.5252e+00,  1.1636e+01,  1.0279e+01,\n",
      "          1.6810e+01, -7.7720e-01,  6.0046e+00,  1.6863e+00, -2.4722e+01,\n",
      "          2.0671e+01,  1.3720e+01,  1.1190e+01,  1.2653e+01, -5.6410e+00,\n",
      "         -1.1931e+01, -2.8381e+01,  3.5240e+00, -7.3314e+00,  7.1078e+00,\n",
      "          2.0647e+01,  4.0093e+00,  5.2423e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 10.1769, 132.3772,  23.8862,  -8.7300, -20.8034,   1.7831,  -6.0122,\n",
      "         -15.4033,  24.2842,   4.7051, -14.0393,   0.9413,   8.1608,   0.3494,\n",
      "           5.9628,   7.9053,  -5.9622,   2.4466,   2.2214,  22.2734,  10.5791,\n",
      "           1.8129,  -1.3678,  -0.7325,   9.3342,   0.4388,   5.0029,   1.1965,\n",
      "          -6.0661,  -0.9430,  10.1699, -27.2471,  -3.3120,  -2.6940,   4.4160,\n",
      "         -10.3853,  -8.3412,   0.2110, -11.7796,  14.9044,  -2.7406,   3.9396,\n",
      "         -11.4477,  26.3263,  19.6016,  -5.5016,  14.1113,  -5.3856, -12.5636,\n",
      "          13.8627,   5.6737,  -1.7687,  -9.8559, -15.0842, -15.7927,  -7.7163,\n",
      "          -7.5004,  -9.5675,  -1.8745,  -4.5951, -10.3397, -15.7798,  -2.1567,\n",
      "          -6.7394,  -6.0890,  31.6676,   0.6565,   5.2062, -21.5235,   6.1842,\n",
      "         -15.9118,   1.7884,   8.7056,  12.1610,  15.2649,  -4.4510,  16.3003,\n",
      "         -13.9720,  24.7912,   6.8523, -10.7726,  20.1394, -13.7689,  -7.1517,\n",
      "           7.3056,   0.2095,  -6.0710,   0.5574,  -5.6251, -14.8552,  -8.3018,\n",
      "          -3.9177,   7.5183, -11.7332, -11.4412,   1.7791,  -7.4321,  12.6160,\n",
      "          -2.2091,  -0.4329,   5.4155,  26.9470,  11.0069,  -6.6079, -15.9079,\n",
      "          28.6507,  23.0218,   5.7014,  13.7292,   9.5382,  15.5425,   0.1722,\n",
      "           4.7961,   0.8759, -26.3979,  21.0830,  12.9358,   9.7971,  12.3867,\n",
      "          -5.6851, -11.5414, -26.9567,   1.8044,  -8.7780,   6.7426,  19.1417,\n",
      "           1.7851,   1.9210]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.4894e+00,  1.3246e+02,  2.1829e+01, -7.7913e+00, -2.2042e+01,\n",
      "          8.4139e-01, -6.1166e+00, -1.4071e+01,  2.2171e+01,  5.8735e+00,\n",
      "         -1.2923e+01,  8.3477e-01,  8.6378e+00,  2.2054e+00,  6.5701e+00,\n",
      "          9.1610e+00, -7.4355e+00,  3.0580e+00,  2.4090e+00,  2.2448e+01,\n",
      "          9.1564e+00,  2.4848e+00, -1.0547e+00, -1.1750e+00,  9.7528e+00,\n",
      "          1.8521e-01,  5.4628e+00,  1.1864e-01, -5.8660e+00, -7.8954e-01,\n",
      "          9.1285e+00, -2.6781e+01, -3.5093e+00, -3.4007e+00,  3.6388e+00,\n",
      "         -9.9951e+00, -1.1197e+01, -1.3652e+00, -1.2677e+01,  1.6159e+01,\n",
      "         -3.5027e+00,  3.2891e+00, -1.1644e+01,  2.6244e+01,  1.9312e+01,\n",
      "         -6.3757e+00,  1.3226e+01, -5.9824e+00, -1.1827e+01,  1.4839e+01,\n",
      "          4.8848e+00, -2.2220e+00, -8.7832e+00, -1.3713e+01, -1.5581e+01,\n",
      "         -8.8827e+00, -7.4182e+00, -1.1387e+01, -3.3342e+00, -6.3763e+00,\n",
      "         -9.5881e+00, -1.6069e+01, -1.7069e+00, -4.8904e+00, -6.2598e+00,\n",
      "          3.1849e+01,  3.5595e-01,  5.9497e+00, -2.1168e+01,  6.4981e+00,\n",
      "         -1.4727e+01,  1.3312e+00,  8.1570e+00,  1.1724e+01,  1.5258e+01,\n",
      "         -4.4251e+00,  1.7388e+01, -1.5427e+01,  2.5388e+01,  7.1305e+00,\n",
      "         -1.0768e+01,  1.9869e+01, -1.3155e+01, -6.9422e+00,  6.9365e+00,\n",
      "          9.1872e-02, -5.8116e+00, -1.0087e+00, -5.6094e+00, -1.7100e+01,\n",
      "         -8.0140e+00, -3.0031e+00,  9.1963e+00, -1.2795e+01, -1.1175e+01,\n",
      "          1.8711e+00, -5.5654e+00,  1.3915e+01, -1.8580e+00,  1.4579e+00,\n",
      "          5.1678e+00,  2.5640e+01,  1.0840e+01, -7.3607e+00, -1.5587e+01,\n",
      "          2.7694e+01,  2.2910e+01,  5.4161e+00,  1.2758e+01,  7.9156e+00,\n",
      "          1.6074e+01,  6.2029e-01,  4.6359e+00,  1.7974e+00, -2.5598e+01,\n",
      "          2.0141e+01,  1.3521e+01,  1.0839e+01,  1.2274e+01, -5.5264e+00,\n",
      "         -1.1849e+01, -2.6739e+01,  4.0645e+00, -7.4948e+00,  7.0002e+00,\n",
      "          2.0177e+01,  2.4336e+00,  1.7520e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 10.1766, 132.3329,  23.4908,  -9.0898, -20.3460,   2.2033,  -5.8254,\n",
      "         -15.9254,  22.7209,   6.4851, -13.0317,   0.8020,   8.6157,   2.2641,\n",
      "           7.7368,   8.8698,  -7.2456,   0.5831,   4.1234,  23.6681,  11.5957,\n",
      "           1.8883,  -1.8927,  -0.2911,   9.2203,   0.5160,   4.9408,   0.3191,\n",
      "          -5.9653,  -1.6226,  10.3734, -26.7159,  -3.9601,  -2.1649,   4.4697,\n",
      "         -10.4869,  -9.6539,  -1.4609, -12.7208,  15.4025,  -3.1849,   3.1994,\n",
      "         -13.3086,  26.7477,  20.8458,  -5.3114,  14.7184,  -5.5835, -11.7102,\n",
      "          14.0137,   6.6439,  -3.2796,  -8.8414, -14.3710, -15.3125,  -8.4124,\n",
      "          -7.7757, -10.0014,  -3.3125,  -5.2925,  -9.4059, -17.7973,  -0.2455,\n",
      "          -5.4586,  -5.5121,  32.7698,   0.3173,   5.0777, -22.4546,   6.7478,\n",
      "         -16.0415,   0.9827,   7.9828,  10.2286,  14.2416,  -4.8268,  16.8261,\n",
      "         -15.3276,  25.4216,   7.2295,  -9.1603,  18.5783, -13.8002,  -7.2271,\n",
      "           5.0853,   1.1577,  -5.4249,   1.4544,  -4.9513, -14.5072,  -9.8245,\n",
      "          -4.4412,   8.8656, -10.9244, -11.6728,   1.6002,  -5.9621,  12.3041,\n",
      "          -0.4962,   1.3049,   5.3122,  25.8588,  10.6853,  -7.5691, -15.1627,\n",
      "          27.9766,  23.3367,   5.0266,  13.0135,  10.5788,  16.2972,  -0.2077,\n",
      "           4.6038,   0.3134, -26.4526,  20.1542,  12.3973,  11.4452,  12.1840,\n",
      "          -5.2996, -10.9628, -28.6761,   3.9854,  -6.7762,   7.0844,  20.3601,\n",
      "           0.6123,   1.0364]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 11.2291, 132.2732,  24.6239,  -9.0840, -20.9251,   0.6693,  -6.1329,\n",
      "         -15.3886,  21.6769,   5.5939, -12.1590,   0.9167,   8.5302,   2.3049,\n",
      "           6.5043,   9.1667,  -8.4558,   1.3938,   2.3497,  20.7341,  10.5637,\n",
      "           2.8634,  -0.5189,  -0.2672,   8.5208,   0.8942,   4.6940,   0.4776,\n",
      "          -6.7090,  -0.3114,  10.2002, -26.4401,  -5.3071,  -1.9905,   4.5037,\n",
      "         -10.1480,  -8.4316,  -1.1077, -12.4468,  15.0141,  -2.8652,   3.1466,\n",
      "         -12.8602,  25.6179,  20.4170,  -6.5452,  13.8674,  -4.9597, -11.0064,\n",
      "          15.7041,   5.5293,  -4.1711,  -8.2769, -13.9028, -16.9925,  -8.8359,\n",
      "          -6.6794, -11.0575,  -4.1461,  -5.8800,  -9.5615, -16.4441,  -0.5713,\n",
      "          -3.7519,  -6.7191,  32.1751,   0.4681,   5.8381, -20.8860,   9.4006,\n",
      "         -15.3968,   1.7606,   9.9634,  12.3456,  14.4125,  -3.7967,  16.9869,\n",
      "         -15.2827,  25.0812,   7.6698,  -9.3680,  19.9868, -13.2045,  -5.7364,\n",
      "           6.7445,   1.2027,  -3.2845,  -1.6809,  -6.1429, -15.2261,  -7.7255,\n",
      "          -2.6649,   8.3640, -12.4311, -13.7671,   2.2508,  -6.0729,  13.6349,\n",
      "          -0.1508,   1.5204,   6.7578,  26.3117,  10.4362,  -6.6330, -15.0014,\n",
      "          28.2804,  23.2560,   5.4528,  11.6998,  10.2677,  16.6915,  -1.1460,\n",
      "           5.9619,   1.5386, -24.8667,  20.8418,  13.9992,  11.0321,  12.6234,\n",
      "          -5.7686, -12.2250, -28.3922,   3.3775,  -7.0768,   6.9663,  20.9153,\n",
      "           3.7988,   0.5143]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0040e+01,  1.3242e+02,  2.4151e+01, -8.6870e+00, -2.0479e+01,\n",
      "          1.7276e+00, -5.8006e+00, -1.5383e+01,  2.4283e+01,  4.6497e+00,\n",
      "         -1.3860e+01,  1.1023e+00,  8.2963e+00,  5.1638e-01,  5.8867e+00,\n",
      "          8.0638e+00, -6.2123e+00,  2.0568e+00,  2.3322e+00,  2.2133e+01,\n",
      "          1.0558e+01,  1.9510e+00, -1.3361e+00, -6.4607e-01,  9.3321e+00,\n",
      "          2.2586e-01,  4.8691e+00,  9.6110e-01, -6.2211e+00, -1.0689e+00,\n",
      "          1.0144e+01, -2.6990e+01, -3.3586e+00, -2.7748e+00,  4.6343e+00,\n",
      "         -1.0440e+01, -8.5916e+00,  4.7371e-02, -1.1723e+01,  1.5215e+01,\n",
      "         -2.7338e+00,  3.8760e+00, -1.1430e+01,  2.6316e+01,  1.9637e+01,\n",
      "         -5.4987e+00,  1.3876e+01, -5.2787e+00, -1.2215e+01,  1.4189e+01,\n",
      "          5.5935e+00, -1.8822e+00, -9.7205e+00, -1.5064e+01, -1.6023e+01,\n",
      "         -7.7517e+00, -7.3620e+00, -9.7803e+00, -1.8848e+00, -4.7795e+00,\n",
      "         -1.0406e+01, -1.5711e+01, -2.0385e+00, -6.5991e+00, -6.1729e+00,\n",
      "          3.1789e+01,  6.9985e-01,  5.3077e+00, -2.1475e+01,  6.2434e+00,\n",
      "         -1.5875e+01,  1.7113e+00,  8.9281e+00,  1.1943e+01,  1.5315e+01,\n",
      "         -4.3107e+00,  1.6274e+01, -1.4007e+01,  2.4755e+01,  6.7537e+00,\n",
      "         -1.0697e+01,  2.0317e+01, -1.3662e+01, -7.1643e+00,  7.2134e+00,\n",
      "          2.0571e-01, -6.0832e+00,  7.4120e-01, -5.8416e+00, -1.4893e+01,\n",
      "         -8.3503e+00, -3.8006e+00,  7.5483e+00, -1.1736e+01, -1.1536e+01,\n",
      "          1.7118e+00, -7.3021e+00,  1.2829e+01, -1.8668e+00, -2.6890e-01,\n",
      "          5.5102e+00,  2.7074e+01,  1.0974e+01, -6.6106e+00, -1.5686e+01,\n",
      "          2.8652e+01,  2.2943e+01,  5.5258e+00,  1.3558e+01,  9.5131e+00,\n",
      "          1.5524e+01, -1.0623e-01,  4.7260e+00,  7.1004e-01, -2.6497e+01,\n",
      "          2.1196e+01,  1.3221e+01,  9.9147e+00,  1.2453e+01, -5.7020e+00,\n",
      "         -1.1874e+01, -2.7142e+01,  1.8332e+00, -8.4419e+00,  6.6562e+00,\n",
      "          1.9506e+01,  1.7668e+00,  1.8347e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.4304e+00,  1.3246e+02,  2.2201e+01, -7.7525e+00, -2.1651e+01,\n",
      "          9.5123e-01, -5.9258e+00, -1.4228e+01,  2.2299e+01,  5.7486e+00,\n",
      "         -1.2847e+01,  1.0261e+00,  8.6692e+00,  2.1522e+00,  6.5058e+00,\n",
      "          9.1680e+00, -7.4443e+00,  2.5363e+00,  2.4723e+00,  2.2273e+01,\n",
      "          9.2969e+00,  2.5958e+00, -1.1216e+00, -1.0571e+00,  9.8310e+00,\n",
      "         -1.1718e-01,  5.3263e+00,  7.6745e-02, -5.9003e+00, -9.1094e-01,\n",
      "          9.0978e+00, -2.6574e+01, -3.5646e+00, -3.4243e+00,  3.8744e+00,\n",
      "         -1.0028e+01, -1.1374e+01, -1.4462e+00, -1.2446e+01,  1.6423e+01,\n",
      "         -3.3687e+00,  3.2487e+00, -1.1674e+01,  2.6221e+01,  1.9323e+01,\n",
      "         -6.3243e+00,  1.3102e+01, -5.8489e+00, -1.1564e+01,  1.5034e+01,\n",
      "          4.8820e+00, -2.2599e+00, -8.7614e+00, -1.3770e+01, -1.5827e+01,\n",
      "         -8.8745e+00, -7.3319e+00, -1.1414e+01, -3.2690e+00, -6.4516e+00,\n",
      "         -9.6905e+00, -1.6015e+01, -1.6180e+00, -4.9524e+00, -6.4854e+00,\n",
      "          3.1891e+01,  4.9099e-01,  6.0747e+00, -2.1152e+01,  6.5807e+00,\n",
      "         -1.4723e+01,  1.1551e+00,  8.3405e+00,  1.1462e+01,  1.5323e+01,\n",
      "         -4.3269e+00,  1.7302e+01, -1.5357e+01,  2.5271e+01,  7.0238e+00,\n",
      "         -1.0703e+01,  2.0060e+01, -1.3103e+01, -6.9960e+00,  6.8531e+00,\n",
      "          8.7132e-02, -5.8823e+00, -7.2823e-01, -5.7109e+00, -1.7113e+01,\n",
      "         -8.1142e+00, -3.0040e+00,  9.1154e+00, -1.2761e+01, -1.1194e+01,\n",
      "          1.7144e+00, -5.4580e+00,  1.3973e+01, -1.6138e+00,  1.3937e+00,\n",
      "          5.2534e+00,  2.5939e+01,  1.0806e+01, -7.3628e+00, -1.5411e+01,\n",
      "          2.7809e+01,  2.2786e+01,  5.1375e+00,  1.2712e+01,  7.9747e+00,\n",
      "          1.5957e+01,  3.1000e-01,  4.4469e+00,  1.6032e+00, -2.5778e+01,\n",
      "          2.0219e+01,  1.3812e+01,  1.0853e+01,  1.2347e+01, -5.5260e+00,\n",
      "         -1.2102e+01, -2.6949e+01,  3.9148e+00, -7.2654e+00,  6.9487e+00,\n",
      "          2.0517e+01,  2.2632e+00,  1.8001e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0190e+01,  1.3232e+02,  2.3728e+01, -8.9175e+00, -2.0117e+01,\n",
      "          2.1981e+00, -5.5917e+00, -1.6032e+01,  2.2686e+01,  6.4160e+00,\n",
      "         -1.2930e+01,  1.0825e+00,  8.6566e+00,  2.3072e+00,  7.7004e+00,\n",
      "          8.9141e+00, -7.1564e+00,  1.2444e-01,  4.0222e+00,  2.3452e+01,\n",
      "          1.1668e+01,  1.8795e+00, -1.9639e+00, -2.3963e-01,  9.3460e+00,\n",
      "          2.4399e-01,  4.8436e+00,  3.1617e-01, -5.9745e+00, -1.6139e+00,\n",
      "          1.0312e+01, -2.6500e+01, -3.9564e+00, -2.1952e+00,  4.6994e+00,\n",
      "         -1.0561e+01, -9.9349e+00, -1.6580e+00, -1.2509e+01,  1.5606e+01,\n",
      "         -3.0685e+00,  3.1164e+00, -1.3261e+01,  2.6698e+01,  2.0797e+01,\n",
      "         -5.2840e+00,  1.4523e+01, -5.4808e+00, -1.1518e+01,  1.4242e+01,\n",
      "          6.6824e+00, -3.2945e+00, -8.7749e+00, -1.4334e+01, -1.5530e+01,\n",
      "         -8.4525e+00, -7.6934e+00, -1.0015e+01, -3.2919e+00, -5.4700e+00,\n",
      "         -9.5574e+00, -1.7698e+01, -1.7086e-01, -5.6082e+00, -5.8577e+00,\n",
      "          3.2715e+01,  4.0949e-01,  5.2798e+00, -2.2371e+01,  6.8984e+00,\n",
      "         -1.5987e+01,  8.1797e-01,  8.1194e+00,  9.9453e+00,  1.4353e+01,\n",
      "         -4.7155e+00,  1.6825e+01, -1.5305e+01,  2.5328e+01,  7.1588e+00,\n",
      "         -9.1535e+00,  1.8667e+01, -1.3795e+01, -7.2666e+00,  5.0392e+00,\n",
      "          1.2136e+00, -5.4257e+00,  1.5484e+00, -4.9726e+00, -1.4679e+01,\n",
      "         -9.8332e+00, -4.3703e+00,  8.7963e+00, -1.1008e+01, -1.1659e+01,\n",
      "          1.5020e+00, -5.7903e+00,  1.2372e+01, -4.5135e-01,  1.3291e+00,\n",
      "          5.4573e+00,  2.6075e+01,  1.0742e+01, -7.4886e+00, -1.5037e+01,\n",
      "          2.8147e+01,  2.3243e+01,  4.6524e+00,  1.2883e+01,  1.0563e+01,\n",
      "          1.6132e+01, -4.5573e-01,  4.3912e+00,  2.1658e-01, -2.6514e+01,\n",
      "          2.0129e+01,  1.2596e+01,  1.1456e+01,  1.2261e+01, -5.3285e+00,\n",
      "         -1.1186e+01, -2.8927e+01,  3.9105e+00, -6.6030e+00,  6.9928e+00,\n",
      "          2.0664e+01,  5.1038e-01,  1.1301e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 11.0991, 132.2596,  24.7895,  -8.9137, -20.6005,   0.7858,  -5.7174,\n",
      "         -15.4756,  21.7381,   5.5324, -12.2162,   1.2139,   8.5893,   2.3329,\n",
      "           6.4018,   9.1574,  -8.4209,   0.9000,   2.4399,  20.7909,  10.6757,\n",
      "           2.8305,  -0.7701,  -0.2063,   8.7153,   0.5181,   4.5854,   0.4556,\n",
      "          -6.6325,  -0.4941,  10.0941, -26.2840,  -5.2513,  -2.0699,   4.8102,\n",
      "         -10.2263,  -8.8212,  -1.3740, -12.2501,  15.2681,  -2.6064,   3.1857,\n",
      "         -12.8149,  25.6707,  20.4142,  -6.4588,  13.6728,  -4.9014, -10.8498,\n",
      "          15.8927,   5.6639,  -4.0594,  -8.1892, -13.9414, -16.9802,  -8.8441,\n",
      "          -6.7201, -11.0674,  -4.0077,  -6.0641,  -9.7437, -16.4227,  -0.5629,\n",
      "          -3.9212,  -7.1198,  32.1329,   0.5669,   6.0350, -20.8085,   9.3580,\n",
      "         -15.3044,   1.5840,  10.0137,  11.9515,  14.4626,  -3.7646,  17.0457,\n",
      "         -15.2747,  25.0343,   7.5613,  -9.4222,  20.0297, -13.2368,  -5.8341,\n",
      "           6.6151,   1.2808,  -3.3722,  -1.3206,  -6.0221, -15.4098,  -7.8077,\n",
      "          -2.7064,   8.3269, -12.5046, -13.6622,   2.1515,  -5.8850,  13.6174,\n",
      "          -0.1569,   1.5285,   6.9261,  26.5704,  10.5510,  -6.6685, -14.9155,\n",
      "          28.4985,  23.0815,   5.0939,  11.7237,  10.2148,  16.4805,  -1.4319,\n",
      "           5.6674,   1.3418, -25.0268,  20.7807,  14.1163,  11.0791,  12.7027,\n",
      "          -5.7377, -12.3898, -28.6267,   3.3808,  -6.9671,   6.7875,  21.2791,\n",
      "           3.4880,   0.5830]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0031e+01,  1.3241e+02,  2.4346e+01, -8.5873e+00, -2.0265e+01,\n",
      "          1.7901e+00, -5.4621e+00, -1.5545e+01,  2.4172e+01,  4.5456e+00,\n",
      "         -1.3816e+01,  1.2548e+00,  8.3705e+00,  5.9965e-01,  5.7991e+00,\n",
      "          8.1730e+00, -6.4169e+00,  1.5926e+00,  2.4418e+00,  2.2110e+01,\n",
      "          1.0704e+01,  2.1237e+00, -1.3954e+00, -5.8532e-01,  9.4086e+00,\n",
      "         -4.1505e-02,  4.7447e+00,  7.9323e-01, -6.2812e+00, -1.2480e+00,\n",
      "          1.0056e+01, -2.6762e+01, -3.3349e+00, -2.7696e+00,  4.8774e+00,\n",
      "         -1.0488e+01, -8.9016e+00, -1.8203e-01, -1.1657e+01,  1.5358e+01,\n",
      "         -2.5549e+00,  3.8650e+00, -1.1425e+01,  2.6355e+01,  1.9648e+01,\n",
      "         -5.5372e+00,  1.3705e+01, -5.1744e+00, -1.2056e+01,  1.4546e+01,\n",
      "          5.6959e+00, -1.9403e+00, -9.4795e+00, -1.5008e+01, -1.5951e+01,\n",
      "         -7.8643e+00, -7.3337e+00, -9.9292e+00, -1.9554e+00, -4.9302e+00,\n",
      "         -1.0501e+01, -1.5722e+01, -1.9345e+00, -6.5309e+00, -6.4661e+00,\n",
      "          3.1789e+01,  7.0940e-01,  5.5240e+00, -2.1345e+01,  6.3984e+00,\n",
      "         -1.5775e+01,  1.5907e+00,  9.0415e+00,  1.1612e+01,  1.5216e+01,\n",
      "         -4.2959e+00,  1.6427e+01, -1.4171e+01,  2.4709e+01,  6.6682e+00,\n",
      "         -1.0573e+01,  2.0313e+01, -1.3601e+01, -7.1963e+00,  7.0423e+00,\n",
      "          3.5542e-01, -5.9544e+00,  9.0117e-01, -5.7302e+00, -1.5079e+01,\n",
      "         -8.2687e+00, -3.7256e+00,  7.5650e+00, -1.1770e+01, -1.1579e+01,\n",
      "          1.6270e+00, -7.0501e+00,  1.2905e+01, -1.8683e+00, -1.2686e-01,\n",
      "          5.7304e+00,  2.7246e+01,  1.1009e+01, -6.5966e+00, -1.5591e+01,\n",
      "          2.8785e+01,  2.2843e+01,  5.1940e+00,  1.3361e+01,  9.3686e+00,\n",
      "          1.5498e+01, -3.4232e-01,  4.5712e+00,  4.8819e-01, -2.6582e+01,\n",
      "          2.1145e+01,  1.3370e+01,  1.0106e+01,  1.2586e+01, -5.6655e+00,\n",
      "         -1.2028e+01, -2.7326e+01,  1.9719e+00, -8.2101e+00,  6.5588e+00,\n",
      "          1.9927e+01,  1.7045e+00,  1.7811e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.4192e+00,  1.3249e+02,  2.2419e+01, -7.7820e+00, -2.1354e+01,\n",
      "          1.0979e+00, -5.6251e+00, -1.4435e+01,  2.2410e+01,  5.5697e+00,\n",
      "         -1.2992e+01,  1.1675e+00,  8.7489e+00,  2.0712e+00,  6.3719e+00,\n",
      "          9.2266e+00, -7.5522e+00,  2.0711e+00,  2.6281e+00,  2.2208e+01,\n",
      "          9.5620e+00,  2.8212e+00, -1.1424e+00, -1.0157e+00,  9.9058e+00,\n",
      "         -3.8739e-01,  5.2326e+00, -6.9001e-02, -6.0480e+00, -1.1748e+00,\n",
      "          9.0617e+00, -2.6409e+01, -3.4277e+00, -3.4211e+00,  4.1843e+00,\n",
      "         -1.0116e+01, -1.1584e+01, -1.4914e+00, -1.2310e+01,  1.6537e+01,\n",
      "         -3.1836e+00,  3.2996e+00, -1.1562e+01,  2.6287e+01,  1.9283e+01,\n",
      "         -6.2519e+00,  1.2995e+01, -5.6593e+00, -1.1556e+01,  1.5331e+01,\n",
      "          4.8623e+00, -2.2793e+00, -8.5988e+00, -1.3825e+01, -1.5870e+01,\n",
      "         -8.9273e+00, -7.3947e+00, -1.1489e+01, -3.2628e+00, -6.5028e+00,\n",
      "         -9.8577e+00, -1.6009e+01, -1.6070e+00, -4.9083e+00, -6.6663e+00,\n",
      "          3.1909e+01,  5.1449e-01,  6.1618e+00, -2.1042e+01,  6.7079e+00,\n",
      "         -1.4637e+01,  1.0667e+00,  8.4834e+00,  1.1222e+01,  1.5233e+01,\n",
      "         -4.3058e+00,  1.7401e+01, -1.5376e+01,  2.5129e+01,  6.8444e+00,\n",
      "         -1.0548e+01,  2.0137e+01, -1.3085e+01, -7.0765e+00,  6.8001e+00,\n",
      "          1.0030e-01, -5.9061e+00, -4.8092e-01, -5.6033e+00, -1.7252e+01,\n",
      "         -8.1188e+00, -3.0227e+00,  9.0804e+00, -1.2774e+01, -1.1227e+01,\n",
      "          1.5774e+00, -5.4060e+00,  1.3986e+01, -1.5976e+00,  1.3242e+00,\n",
      "          5.4943e+00,  2.6192e+01,  1.0823e+01, -7.3525e+00, -1.5285e+01,\n",
      "          2.7924e+01,  2.2648e+01,  4.8087e+00,  1.2561e+01,  7.8978e+00,\n",
      "          1.5889e+01,  5.0070e-02,  4.3178e+00,  1.4032e+00, -2.5884e+01,\n",
      "          2.0253e+01,  1.4042e+01,  1.0926e+01,  1.2385e+01, -5.4540e+00,\n",
      "         -1.2282e+01, -2.7048e+01,  3.9187e+00, -7.1129e+00,  6.8214e+00,\n",
      "          2.0872e+01,  2.1975e+00,  1.7626e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0222e+01,  1.3237e+02,  2.3825e+01, -8.9040e+00, -2.0016e+01,\n",
      "          2.2478e+00, -5.3806e+00, -1.6089e+01,  2.2734e+01,  6.2840e+00,\n",
      "         -1.2897e+01,  1.2406e+00,  8.8512e+00,  2.2257e+00,  7.4940e+00,\n",
      "          8.9765e+00, -7.2857e+00, -1.3493e-01,  3.9750e+00,  2.3226e+01,\n",
      "          1.1831e+01,  2.0288e+00, -1.8838e+00, -3.0735e-01,  9.4208e+00,\n",
      "          4.6587e-02,  4.8079e+00,  8.8351e-02, -6.1638e+00, -1.7374e+00,\n",
      "          1.0257e+01, -2.6311e+01, -3.7783e+00, -2.2244e+00,  4.9212e+00,\n",
      "         -1.0666e+01, -1.0235e+01, -1.6848e+00, -1.2390e+01,  1.5721e+01,\n",
      "         -2.9895e+00,  3.1506e+00, -1.3104e+01,  2.6691e+01,  2.0634e+01,\n",
      "         -5.2151e+00,  1.4301e+01, -5.2275e+00, -1.1535e+01,  1.4559e+01,\n",
      "          6.5423e+00, -3.2800e+00, -8.6028e+00, -1.4276e+01, -1.5768e+01,\n",
      "         -8.5416e+00, -7.7323e+00, -1.0143e+01, -3.2888e+00, -5.6111e+00,\n",
      "         -9.7690e+00, -1.7614e+01, -2.1005e-01, -5.5571e+00, -5.9488e+00,\n",
      "          3.2725e+01,  4.4281e-01,  5.3929e+00, -2.2256e+01,  7.0926e+00,\n",
      "         -1.5831e+01,  8.4333e-01,  8.2582e+00,  9.8089e+00,  1.4310e+01,\n",
      "         -4.5995e+00,  1.6900e+01, -1.5323e+01,  2.5146e+01,  6.8817e+00,\n",
      "         -8.9936e+00,  1.8777e+01, -1.3767e+01, -7.3462e+00,  5.1262e+00,\n",
      "          1.1514e+00, -5.5612e+00,  1.4895e+00, -4.9259e+00, -1.4913e+01,\n",
      "         -9.7789e+00, -4.2735e+00,  8.8437e+00, -1.1115e+01, -1.1688e+01,\n",
      "          1.4086e+00, -5.8001e+00,  1.2475e+01, -4.5845e-01,  1.3210e+00,\n",
      "          5.7211e+00,  2.6302e+01,  1.0710e+01, -7.4723e+00, -1.4913e+01,\n",
      "          2.8256e+01,  2.3125e+01,  4.4003e+00,  1.2642e+01,  1.0391e+01,\n",
      "          1.6077e+01, -6.4106e-01,  4.3858e+00,  1.8850e-01, -2.6531e+01,\n",
      "          2.0151e+01,  1.2862e+01,  1.1486e+01,  1.2214e+01, -5.2787e+00,\n",
      "         -1.1353e+01, -2.8928e+01,  3.8990e+00, -6.4199e+00,  6.9409e+00,\n",
      "          2.0973e+01,  6.2573e-01,  1.0836e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0977e+01,  1.3230e+02,  2.4895e+01, -8.9293e+00, -2.0403e+01,\n",
      "          9.0572e-01, -5.4139e+00, -1.5541e+01,  2.1933e+01,  5.4457e+00,\n",
      "         -1.2169e+01,  1.4286e+00,  8.7969e+00,  2.2520e+00,  6.2057e+00,\n",
      "          9.0934e+00, -8.5005e+00,  5.4496e-01,  2.4391e+00,  2.0666e+01,\n",
      "          1.0904e+01,  2.9136e+00, -8.3242e-01, -2.5952e-01,  8.9353e+00,\n",
      "          2.3274e-01,  4.5603e+00,  2.8813e-01, -6.6529e+00, -7.1941e-01,\n",
      "          9.9563e+00, -2.6093e+01, -5.0475e+00, -2.0864e+00,  5.0360e+00,\n",
      "         -1.0236e+01, -9.2162e+00, -1.4352e+00, -1.2093e+01,  1.5510e+01,\n",
      "         -2.4495e+00,  3.2638e+00, -1.2787e+01,  2.5718e+01,  2.0318e+01,\n",
      "         -6.3140e+00,  1.3417e+01, -4.6607e+00, -1.0819e+01,  1.6076e+01,\n",
      "          5.4979e+00, -3.9108e+00, -8.0652e+00, -1.3923e+01, -1.7239e+01,\n",
      "         -8.9359e+00, -6.8000e+00, -1.1080e+01, -3.8487e+00, -6.2350e+00,\n",
      "         -9.9266e+00, -1.6433e+01, -6.1495e-01, -3.9305e+00, -7.2776e+00,\n",
      "          3.2189e+01,  7.4492e-01,  6.1316e+00, -2.0792e+01,  9.4148e+00,\n",
      "         -1.5158e+01,  1.4964e+00,  1.0048e+01,  1.1750e+01,  1.4425e+01,\n",
      "         -3.6579e+00,  1.7133e+01, -1.5246e+01,  2.4830e+01,  7.2395e+00,\n",
      "         -9.2751e+00,  2.0120e+01, -1.3210e+01, -5.9745e+00,  6.5265e+00,\n",
      "          1.1606e+00, -3.6443e+00, -1.1590e+00, -5.9643e+00, -1.5630e+01,\n",
      "         -7.8847e+00, -2.6640e+00,  8.3961e+00, -1.2556e+01, -1.3542e+01,\n",
      "          2.0582e+00, -5.8564e+00,  1.3613e+01, -4.0760e-02,  1.5380e+00,\n",
      "          7.1210e+00,  2.6883e+01,  1.0505e+01, -6.7779e+00, -1.4821e+01,\n",
      "          2.8673e+01,  2.2875e+01,  4.8792e+00,  1.1581e+01,  1.0067e+01,\n",
      "          1.6419e+01, -1.6147e+00,  5.6031e+00,  1.2380e+00, -2.5129e+01,\n",
      "          2.0811e+01,  1.4360e+01,  1.1148e+01,  1.2681e+01, -5.6716e+00,\n",
      "         -1.2515e+01, -2.8674e+01,  3.4121e+00, -6.7509e+00,  6.7880e+00,\n",
      "          2.1566e+01,  3.3978e+00,  5.5284e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.9976e+00,  1.3242e+02,  2.4516e+01, -8.6003e+00, -2.0155e+01,\n",
      "          1.8117e+00, -5.2154e+00, -1.5734e+01,  2.4160e+01,  4.5259e+00,\n",
      "         -1.3553e+01,  1.4360e+00,  8.5435e+00,  6.6783e-01,  5.7784e+00,\n",
      "          8.1791e+00, -6.5931e+00,  1.1267e+00,  2.3672e+00,  2.1918e+01,\n",
      "          1.0899e+01,  2.2214e+00, -1.4150e+00, -6.1928e-01,  9.5860e+00,\n",
      "         -2.4894e-01,  4.6436e+00,  6.6672e-01, -6.2905e+00, -1.3805e+00,\n",
      "          9.8469e+00, -2.6442e+01, -3.2460e+00, -2.6748e+00,  4.9997e+00,\n",
      "         -1.0451e+01, -9.2108e+00, -3.0613e-01, -1.1557e+01,  1.5576e+01,\n",
      "         -2.5154e+00,  3.8136e+00, -1.1589e+01,  2.6388e+01,  1.9624e+01,\n",
      "         -5.5123e+00,  1.3502e+01, -4.9194e+00, -1.1924e+01,  1.4794e+01,\n",
      "          5.4762e+00, -1.9524e+00, -9.3137e+00, -1.4867e+01, -1.6219e+01,\n",
      "         -8.0512e+00, -7.2230e+00, -9.9986e+00, -2.0298e+00, -5.1019e+00,\n",
      "         -1.0605e+01, -1.5778e+01, -1.8401e+00, -6.4118e+00, -6.7303e+00,\n",
      "          3.1792e+01,  8.7457e-01,  5.6506e+00, -2.1314e+01,  6.6468e+00,\n",
      "         -1.5650e+01,  1.4543e+00,  9.0287e+00,  1.1395e+01,  1.5085e+01,\n",
      "         -4.2225e+00,  1.6518e+01, -1.4219e+01,  2.4596e+01,  6.4907e+00,\n",
      "         -1.0282e+01,  2.0313e+01, -1.3484e+01, -7.2591e+00,  6.8179e+00,\n",
      "          2.9288e-01, -5.9736e+00,  8.7038e-01, -5.7134e+00, -1.5299e+01,\n",
      "         -8.2758e+00, -3.6078e+00,  7.6504e+00, -1.1875e+01, -1.1573e+01,\n",
      "          1.5813e+00, -6.8318e+00,  1.3010e+01, -1.6590e+00,  5.7983e-02,\n",
      "          5.9113e+00,  2.7458e+01,  1.0945e+01, -6.6254e+00, -1.5481e+01,\n",
      "          2.8963e+01,  2.2738e+01,  4.9132e+00,  1.3052e+01,  9.2925e+00,\n",
      "          1.5555e+01, -5.0962e-01,  4.5000e+00,  4.3337e-01, -2.6580e+01,\n",
      "          2.1187e+01,  1.3625e+01,  1.0271e+01,  1.2612e+01, -5.6606e+00,\n",
      "         -1.2115e+01, -2.7500e+01,  2.0795e+00, -7.8539e+00,  6.6490e+00,\n",
      "          2.0246e+01,  1.7472e+00,  1.6842e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.3750e+00,  1.3251e+02,  2.2640e+01, -7.8341e+00, -2.1142e+01,\n",
      "          1.2116e+00, -5.3408e+00, -1.4667e+01,  2.2540e+01,  5.4833e+00,\n",
      "         -1.2950e+01,  1.3649e+00,  8.7874e+00,  2.0017e+00,  6.3349e+00,\n",
      "          9.1607e+00, -7.5896e+00,  1.5625e+00,  2.5873e+00,  2.2049e+01,\n",
      "          9.8857e+00,  2.8155e+00, -1.1766e+00, -1.0124e+00,  1.0200e+01,\n",
      "         -6.4025e-01,  5.0455e+00, -1.4343e-01, -5.9503e+00, -1.3648e+00,\n",
      "          8.9281e+00, -2.6196e+01, -3.2873e+00, -3.2982e+00,  4.3150e+00,\n",
      "         -1.0068e+01, -1.1797e+01, -1.4816e+00, -1.2125e+01,  1.6728e+01,\n",
      "         -3.0476e+00,  3.2928e+00, -1.1754e+01,  2.6325e+01,  1.9280e+01,\n",
      "         -6.1888e+00,  1.2915e+01, -5.5213e+00, -1.1481e+01,  1.5504e+01,\n",
      "          4.6921e+00, -2.2348e+00, -8.5274e+00, -1.3813e+01, -1.6130e+01,\n",
      "         -9.0069e+00, -7.2621e+00, -1.1420e+01, -3.3167e+00, -6.6365e+00,\n",
      "         -9.9374e+00, -1.6101e+01, -1.5812e+00, -4.9214e+00, -7.0125e+00,\n",
      "          3.1896e+01,  7.2437e-01,  6.2759e+00, -2.1048e+01,  6.8802e+00,\n",
      "         -1.4535e+01,  8.8394e-01,  8.4351e+00,  1.1033e+01,  1.5146e+01,\n",
      "         -4.2650e+00,  1.7390e+01, -1.5359e+01,  2.4952e+01,  6.6547e+00,\n",
      "         -1.0347e+01,  2.0119e+01, -1.2986e+01, -7.1745e+00,  6.5643e+00,\n",
      "          2.5451e-02, -5.9336e+00, -3.5198e-01, -5.4987e+00, -1.7347e+01,\n",
      "         -8.1814e+00, -3.0684e+00,  9.1159e+00, -1.2819e+01, -1.1140e+01,\n",
      "          1.4997e+00, -5.2844e+00,  1.3963e+01, -1.4096e+00,  1.3390e+00,\n",
      "          5.6208e+00,  2.6496e+01,  1.0774e+01, -7.4247e+00, -1.5167e+01,\n",
      "          2.8160e+01,  2.2522e+01,  4.4993e+00,  1.2383e+01,  7.9368e+00,\n",
      "          1.5893e+01, -1.7773e-01,  4.2074e+00,  1.2633e+00, -2.5937e+01,\n",
      "          2.0344e+01,  1.4229e+01,  1.0945e+01,  1.2441e+01, -5.4107e+00,\n",
      "         -1.2347e+01, -2.7211e+01,  3.9587e+00, -6.8293e+00,  6.9132e+00,\n",
      "          2.1135e+01,  2.0452e+00,  1.7090e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0164e+01,  1.3242e+02,  2.3857e+01, -8.9153e+00, -1.9931e+01,\n",
      "          2.2470e+00, -5.1118e+00, -1.6134e+01,  2.2763e+01,  6.1996e+00,\n",
      "         -1.2897e+01,  1.4622e+00,  8.8610e+00,  2.2110e+00,  7.3997e+00,\n",
      "          9.0149e+00, -7.3083e+00, -4.6123e-01,  3.8343e+00,  2.3091e+01,\n",
      "          1.1970e+01,  2.0253e+00, -1.8381e+00, -3.0234e-01,  9.6677e+00,\n",
      "         -1.5348e-01,  4.6476e+00, -3.2230e-02, -6.1047e+00, -1.8495e+00,\n",
      "          1.0169e+01, -2.6164e+01, -3.6274e+00, -2.1880e+00,  4.9752e+00,\n",
      "         -1.0690e+01, -1.0518e+01, -1.6741e+00, -1.2233e+01,  1.5933e+01,\n",
      "         -2.9199e+00,  3.1115e+00, -1.3129e+01,  2.6680e+01,  2.0515e+01,\n",
      "         -5.2188e+00,  1.4167e+01, -5.1989e+00, -1.1457e+01,  1.4809e+01,\n",
      "          6.3836e+00, -3.2427e+00, -8.5314e+00, -1.4244e+01, -1.6011e+01,\n",
      "         -8.5834e+00, -7.5849e+00, -1.0233e+01, -3.3996e+00, -5.8471e+00,\n",
      "         -9.8482e+00, -1.7626e+01, -2.1914e-01, -5.5487e+00, -6.2434e+00,\n",
      "          3.2731e+01,  5.1459e-01,  5.5308e+00, -2.2149e+01,  7.2291e+00,\n",
      "         -1.5711e+01,  7.0948e-01,  8.2265e+00,  9.6760e+00,  1.4263e+01,\n",
      "         -4.4706e+00,  1.6886e+01, -1.5359e+01,  2.4983e+01,  6.6772e+00,\n",
      "         -8.8812e+00,  1.8834e+01, -1.3698e+01, -7.4395e+00,  5.0086e+00,\n",
      "          1.1189e+00, -5.5997e+00,  1.4546e+00, -4.8308e+00, -1.5081e+01,\n",
      "         -9.8283e+00, -4.2743e+00,  8.9379e+00, -1.1270e+01, -1.1592e+01,\n",
      "          1.3635e+00, -5.7108e+00,  1.2534e+01, -3.3923e-01,  1.3320e+00,\n",
      "          5.9035e+00,  2.6470e+01,  1.0692e+01, -7.5296e+00, -1.4771e+01,\n",
      "          2.8444e+01,  2.3033e+01,  4.1274e+00,  1.2411e+01,  1.0315e+01,\n",
      "          1.6022e+01, -8.6271e-01,  4.3146e+00,  1.1889e-01, -2.6546e+01,\n",
      "          2.0266e+01,  1.3013e+01,  1.1422e+01,  1.2221e+01, -5.2698e+00,\n",
      "         -1.1460e+01, -2.9034e+01,  3.9658e+00, -6.1838e+00,  6.9467e+00,\n",
      "          2.1192e+01,  5.6121e-01,  1.0252e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0768e+01,  1.3234e+02,  2.4834e+01, -8.9785e+00, -2.0190e+01,\n",
      "          9.8706e-01, -5.1055e+00, -1.5520e+01,  2.2051e+01,  5.3253e+00,\n",
      "         -1.2273e+01,  1.6631e+00,  8.7988e+00,  2.2312e+00,  6.1001e+00,\n",
      "          9.1283e+00, -8.5884e+00,  2.2212e-01,  2.4437e+00,  2.0772e+01,\n",
      "          1.1024e+01,  2.9739e+00, -8.7466e-01, -2.0196e-01,  9.1752e+00,\n",
      "         -4.2927e-02,  4.4601e+00,  1.0329e-01, -6.5714e+00, -9.6178e-01,\n",
      "          9.9207e+00, -2.6048e+01, -4.8952e+00, -2.1430e+00,  5.1223e+00,\n",
      "         -1.0247e+01, -9.6393e+00, -1.4458e+00, -1.1909e+01,  1.5790e+01,\n",
      "         -2.2258e+00,  3.2591e+00, -1.2716e+01,  2.5749e+01,  2.0246e+01,\n",
      "         -6.2540e+00,  1.3227e+01, -4.7245e+00, -1.0692e+01,  1.6257e+01,\n",
      "          5.4483e+00, -3.7869e+00, -7.9839e+00, -1.3999e+01, -1.7381e+01,\n",
      "         -8.9593e+00, -6.7810e+00, -1.1154e+01, -3.7603e+00, -6.4632e+00,\n",
      "         -9.9631e+00, -1.6448e+01, -6.8414e-01, -3.9533e+00, -7.4703e+00,\n",
      "          3.2277e+01,  7.9529e-01,  6.2476e+00, -2.0683e+01,  9.3840e+00,\n",
      "         -1.5033e+01,  1.3787e+00,  1.0034e+01,  1.1552e+01,  1.4403e+01,\n",
      "         -3.5395e+00,  1.7110e+01, -1.5317e+01,  2.4658e+01,  6.9602e+00,\n",
      "         -9.2574e+00,  2.0226e+01, -1.3194e+01, -6.1306e+00,  6.4116e+00,\n",
      "          1.1729e+00, -3.8117e+00, -9.1724e-01, -5.8785e+00, -1.5765e+01,\n",
      "         -8.0429e+00, -2.7356e+00,  8.5230e+00, -1.2598e+01, -1.3354e+01,\n",
      "          1.9975e+00, -5.8034e+00,  1.3593e+01,  1.2529e-01,  1.4922e+00,\n",
      "          7.2493e+00,  2.7066e+01,  1.0503e+01, -6.9407e+00, -1.4651e+01,\n",
      "          2.8821e+01,  2.2703e+01,  4.6996e+00,  1.1515e+01,  9.9337e+00,\n",
      "          1.6348e+01, -1.8702e+00,  5.4963e+00,  1.0677e+00, -2.5215e+01,\n",
      "          2.0887e+01,  1.4427e+01,  1.1088e+01,  1.2664e+01, -5.6133e+00,\n",
      "         -1.2664e+01, -2.8731e+01,  3.5080e+00, -6.5580e+00,  6.7366e+00,\n",
      "          2.1802e+01,  3.1608e+00,  4.9047e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[  9.9411, 132.4921,  24.5341,  -8.6904, -19.9929,   1.7769,  -5.0106,\n",
      "         -15.7097,  24.0591,   4.4166, -13.4680,   1.6416,   8.6045,   0.7254,\n",
      "           5.7512,   8.4023,  -6.7411,   0.8222,   2.3147,  21.9323,  10.8622,\n",
      "           2.4385,  -1.3348,  -0.5492,   9.6407,  -0.4755,   4.5864,   0.4715,\n",
      "          -6.3947,  -1.5274,   9.9444, -26.3495,  -3.2174,  -2.6638,   5.1068,\n",
      "         -10.5406,  -9.6040,  -0.3681, -11.4394,  15.8173,  -2.3218,   3.6837,\n",
      "         -11.4957,  26.4377,  19.5919,  -5.5553,  13.3377,  -4.8950, -11.7390,\n",
      "          15.0363,   5.3824,  -2.0138,  -9.1269, -14.8063, -16.3243,  -8.1960,\n",
      "          -7.1297, -10.1658,  -2.1554,  -5.2660, -10.5880, -15.7186,  -1.7735,\n",
      "          -6.2431,  -6.9440,  31.8344,   0.8128,   5.7605, -21.1303,   6.7773,\n",
      "         -15.5158,   1.3511,   9.0623,  11.2145,  14.9643,  -4.0618,  16.5228,\n",
      "         -14.4339,  24.4295,   6.3173, -10.1395,  20.4212, -13.5111,  -7.3881,\n",
      "           6.6715,   0.4423,  -5.9393,   0.9447,  -5.7280, -15.4644,  -8.3000,\n",
      "          -3.5371,   7.7909, -11.9739, -11.6596,   1.5084,  -6.6818,  13.0951,\n",
      "          -1.4300,   0.1734,   6.0815,  27.5292,  10.8752,  -6.7208, -15.2724,\n",
      "          28.9878,  22.5796,   4.7199,  12.8259,   9.1301,  15.5584,  -0.7597,\n",
      "           4.4620,   0.3250, -26.5707,  21.2198,  13.7658,  10.3616,  12.5474,\n",
      "          -5.5998, -12.2335, -27.6180,   2.2428,  -7.6062,   6.6424,  20.5514,\n",
      "           1.7210,   1.5412]], grad_fn=<SliceBackward0>)\n",
      "tensor([[  9.3460, 132.5259,  22.7927,  -7.9509, -20.8732,   1.3362,  -5.1027,\n",
      "         -14.6971,  22.5674,   5.3128, -12.9955,   1.5784,   8.8295,   1.9283,\n",
      "           6.2863,   9.2811,  -7.5715,   1.1713,   2.5561,  22.0238,   9.9977,\n",
      "           3.0003,  -1.1709,  -0.9829,  10.2851,  -0.9504,   5.0640,  -0.2701,\n",
      "          -6.0601,  -1.5005,   9.0442, -26.1392,  -3.2137,  -3.2724,   4.4788,\n",
      "         -10.1904, -12.1157,  -1.4545, -11.9592,  16.8998,  -2.7304,   3.2246,\n",
      "         -11.6946,  26.4137,  19.2514,  -6.1693,  12.7786,  -5.4560, -11.3815,\n",
      "          15.6794,   4.6276,  -2.2436,  -8.4286, -13.8416, -16.3180,  -9.1177,\n",
      "          -7.2402, -11.4198,  -3.2882,  -6.6758, -10.0034, -16.0509,  -1.5178,\n",
      "          -4.8387,  -7.1994,  31.9108,   0.7268,   6.3546, -20.9429,   6.9790,\n",
      "         -14.4649,   0.8141,   8.5278,  10.8522,  15.0822,  -4.1749,  17.3303,\n",
      "         -15.4070,  24.7067,   6.4237, -10.1914,  20.2229, -13.0679,  -7.2663,\n",
      "           6.4749,   0.1364,  -5.9951,  -0.1536,  -5.5140, -17.4257,  -8.1935,\n",
      "          -3.0488,   9.1545, -12.8405, -11.2388,   1.3874,  -5.2059,  13.9268,\n",
      "          -1.2688,   1.3290,   5.7183,  26.7065,  10.7323,  -7.4885, -14.9637,\n",
      "          28.2348,  22.3102,   4.2864,  12.3098,   7.8298,  15.8218,  -0.4411,\n",
      "           4.1501,   1.0843, -26.0029,  20.3799,  14.3753,  10.8804,  12.3677,\n",
      "          -5.3047, -12.4815, -27.2884,   3.9789,  -6.7041,   6.9422,  21.4187,\n",
      "           1.9241,   1.6556]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0117e+01,  1.3245e+02,  2.3918e+01, -8.9247e+00, -1.9804e+01,\n",
      "          2.3186e+00, -4.8454e+00, -1.6031e+01,  2.2686e+01,  6.0798e+00,\n",
      "         -1.2914e+01,  1.6919e+00,  8.9601e+00,  2.1988e+00,  7.2899e+00,\n",
      "          9.1694e+00, -7.1991e+00, -7.0178e-01,  3.7218e+00,  2.2982e+01,\n",
      "          1.1984e+01,  2.1402e+00, -1.8156e+00, -3.6646e-01,  9.8192e+00,\n",
      "         -4.6318e-01,  4.7132e+00, -1.5332e-01, -6.1713e+00, -1.8554e+00,\n",
      "          1.0222e+01, -2.6054e+01, -3.5264e+00, -2.2249e+00,  5.1279e+00,\n",
      "         -1.0832e+01, -1.0880e+01, -1.6709e+00, -1.2162e+01,  1.6067e+01,\n",
      "         -2.7064e+00,  3.0312e+00, -1.3055e+01,  2.6765e+01,  2.0401e+01,\n",
      "         -5.2582e+00,  1.4001e+01, -5.1242e+00, -1.1416e+01,  1.5056e+01,\n",
      "          6.2876e+00, -3.2270e+00, -8.4518e+00, -1.4156e+01, -1.6225e+01,\n",
      "         -8.6869e+00, -7.5483e+00, -1.0324e+01, -3.4248e+00, -5.9111e+00,\n",
      "         -9.9893e+00, -1.7536e+01, -1.3060e-01, -5.4347e+00, -6.4258e+00,\n",
      "          3.2702e+01,  5.1092e-01,  5.6551e+00, -2.2032e+01,  7.3400e+00,\n",
      "         -1.5634e+01,  6.9821e-01,  8.3119e+00,  9.5412e+00,  1.4264e+01,\n",
      "         -4.3908e+00,  1.6854e+01, -1.5334e+01,  2.4778e+01,  6.4408e+00,\n",
      "         -8.7534e+00,  1.8885e+01, -1.3729e+01, -7.4226e+00,  4.9901e+00,\n",
      "          1.2023e+00, -5.6726e+00,  1.4440e+00, -4.9119e+00, -1.5276e+01,\n",
      "         -9.7290e+00, -4.1456e+00,  9.0358e+00, -1.1401e+01, -1.1659e+01,\n",
      "          1.3061e+00, -5.6181e+00,  1.2561e+01, -3.3473e-01,  1.3955e+00,\n",
      "          5.9696e+00,  2.6573e+01,  1.0693e+01, -7.5369e+00, -1.4612e+01,\n",
      "          2.8532e+01,  2.2883e+01,  3.9112e+00,  1.2328e+01,  1.0126e+01,\n",
      "          1.5946e+01, -1.0665e+00,  4.2761e+00, -2.6233e-03, -2.6566e+01,\n",
      "          2.0268e+01,  1.3192e+01,  1.1291e+01,  1.2120e+01, -5.1812e+00,\n",
      "         -1.1580e+01, -2.9047e+01,  4.0118e+00, -6.0693e+00,  6.9930e+00,\n",
      "          2.1487e+01,  5.2782e-01,  9.9733e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0575e+01,  1.3235e+02,  2.4889e+01, -8.9571e+00, -1.9995e+01,\n",
      "          1.1649e+00, -4.7893e+00, -1.5427e+01,  2.2078e+01,  5.2643e+00,\n",
      "         -1.2379e+01,  1.8865e+00,  8.8957e+00,  2.2120e+00,  5.9809e+00,\n",
      "          9.2140e+00, -8.4435e+00, -2.8953e-02,  2.4422e+00,  2.0779e+01,\n",
      "          1.1116e+01,  3.0516e+00, -9.8193e-01, -3.0156e-01,  9.4855e+00,\n",
      "         -3.9581e-01,  4.5039e+00, -3.2232e-02, -6.4927e+00, -1.0604e+00,\n",
      "          9.8939e+00, -2.5942e+01, -4.7275e+00, -2.2020e+00,  5.2912e+00,\n",
      "         -1.0343e+01, -1.0024e+01, -1.4662e+00, -1.1878e+01,  1.5975e+01,\n",
      "         -1.9678e+00,  3.2221e+00, -1.2706e+01,  2.5870e+01,  2.0206e+01,\n",
      "         -6.2358e+00,  1.3105e+01, -4.6905e+00, -1.0710e+01,  1.6437e+01,\n",
      "          5.3976e+00, -3.6319e+00, -7.9246e+00, -1.3948e+01, -1.7547e+01,\n",
      "         -8.9870e+00, -6.7745e+00, -1.1176e+01, -3.7042e+00, -6.5343e+00,\n",
      "         -1.0117e+01, -1.6475e+01, -5.8907e-01, -3.9033e+00, -7.6323e+00,\n",
      "          3.2265e+01,  8.6314e-01,  6.3203e+00, -2.0678e+01,  9.3444e+00,\n",
      "         -1.4977e+01,  1.2964e+00,  1.0066e+01,  1.1317e+01,  1.4426e+01,\n",
      "         -3.5255e+00,  1.7109e+01, -1.5219e+01,  2.4472e+01,  6.7185e+00,\n",
      "         -9.1954e+00,  2.0211e+01, -1.3217e+01, -6.1367e+00,  6.2593e+00,\n",
      "          1.1955e+00, -4.0087e+00, -7.4036e-01, -5.9242e+00, -1.5901e+01,\n",
      "         -7.9921e+00, -2.6704e+00,  8.6494e+00, -1.2656e+01, -1.3266e+01,\n",
      "          1.9607e+00, -5.7218e+00,  1.3507e+01,  1.2049e-01,  1.5457e+00,\n",
      "          7.2175e+00,  2.7162e+01,  1.0546e+01, -7.0550e+00, -1.4543e+01,\n",
      "          2.8936e+01,  2.2533e+01,  4.5039e+00,  1.1533e+01,  9.7589e+00,\n",
      "          1.6282e+01, -2.0667e+00,  5.3643e+00,  8.9653e-01, -2.5273e+01,\n",
      "          2.0867e+01,  1.4579e+01,  1.1009e+01,  1.2609e+01, -5.5291e+00,\n",
      "         -1.2736e+01, -2.8744e+01,  3.5736e+00, -6.4610e+00,  6.7463e+00,\n",
      "          2.2068e+01,  2.9424e+00,  5.1893e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[  9.8608, 132.5468,  24.6583,  -8.6886, -19.8314,   1.8654,  -4.7767,\n",
      "         -15.6403,  23.9115,   4.3958, -13.4118,   1.7848,   8.7450,   0.7540,\n",
      "           5.7244,   8.6153,  -6.7634,   0.6160,   2.3843,  21.8447,  10.9228,\n",
      "           2.5412,  -1.3208,  -0.6231,   9.8870,  -0.7394,   4.5031,   0.2572,\n",
      "          -6.4743,  -1.5783,   9.8721, -26.1732,  -3.1289,  -2.6225,   5.2540,\n",
      "         -10.6930,  -9.8684,  -0.4561, -11.4433,  15.9858,  -2.2480,   3.5320,\n",
      "         -11.5361,  26.5316,  19.6419,  -5.6117,  13.3140,  -4.7884, -11.7195,\n",
      "          15.3330,   5.2611,  -1.9880,  -8.9573, -14.6824, -16.4836,  -8.2522,\n",
      "          -6.9681, -10.3360,  -2.3957,  -5.3674, -10.6965, -15.7819,  -1.5921,\n",
      "          -6.0663,  -7.1049,  31.8119,   0.8043,   5.7885, -21.1191,   6.8776,\n",
      "         -15.4317,   1.2710,   9.0904,  11.0149,  14.9067,  -4.0503,  16.5030,\n",
      "         -14.4441,  24.3187,   6.2574, -10.0304,  20.4150, -13.4569,  -7.3357,\n",
      "           6.4683,   0.4794,  -5.9491,   0.9178,  -5.8640, -15.5712,  -8.2533,\n",
      "          -3.4441,   7.9249, -12.0917, -11.6908,   1.5052,  -6.5770,  13.1721,\n",
      "          -1.3214,   0.3772,   6.1403,  27.5386,  10.8655,  -6.7560, -15.1082,\n",
      "          29.0828,  22.5066,   4.4900,  12.6769,   9.1045,  15.6159,  -1.0038,\n",
      "           4.3693,   0.2825, -26.5079,  21.2526,  14.0783,  10.4149,  12.5072,\n",
      "          -5.5420, -12.3144, -27.7190,   2.3432,  -7.3861,   6.6095,  20.8544,\n",
      "           1.6826,   1.4475]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.2647e+00,  1.3258e+02,  2.2972e+01, -8.0242e+00, -2.0578e+01,\n",
      "          1.4822e+00, -4.9095e+00, -1.4676e+01,  2.2595e+01,  5.2538e+00,\n",
      "         -1.3060e+01,  1.7094e+00,  8.9324e+00,  1.8165e+00,  6.1978e+00,\n",
      "          9.3812e+00, -7.5721e+00,  9.1540e-01,  2.6775e+00,  2.1932e+01,\n",
      "          1.0179e+01,  3.0950e+00, -1.1571e+00, -1.0374e+00,  1.0477e+01,\n",
      "         -1.1730e+00,  4.9165e+00, -4.9119e-01, -6.1564e+00, -1.6528e+00,\n",
      "          8.9961e+00, -2.6041e+01, -3.1335e+00, -3.2960e+00,  4.6289e+00,\n",
      "         -1.0356e+01, -1.2270e+01, -1.4242e+00, -1.1897e+01,  1.7026e+01,\n",
      "         -2.5889e+00,  3.1340e+00, -1.1703e+01,  2.6506e+01,  1.9248e+01,\n",
      "         -6.1705e+00,  1.2806e+01, -5.3204e+00, -1.1396e+01,  1.5905e+01,\n",
      "          4.5621e+00, -2.2072e+00, -8.2670e+00, -1.3843e+01, -1.6508e+01,\n",
      "         -9.0730e+00, -7.1676e+00, -1.1527e+01, -3.4156e+00, -6.6888e+00,\n",
      "         -1.0147e+01, -1.6096e+01, -1.4145e+00, -4.7495e+00, -7.2546e+00,\n",
      "          3.1931e+01,  7.0357e-01,  6.3068e+00, -2.0962e+01,  7.0292e+00,\n",
      "         -1.4435e+01,  7.5153e-01,  8.6316e+00,  1.0675e+01,  1.5016e+01,\n",
      "         -4.1678e+00,  1.7221e+01, -1.5340e+01,  2.4528e+01,  6.3083e+00,\n",
      "         -1.0123e+01,  2.0297e+01, -1.3071e+01, -7.2439e+00,  6.3383e+00,\n",
      "          9.7610e-02, -6.1301e+00, -7.9520e-02, -5.6089e+00, -1.7362e+01,\n",
      "         -8.2296e+00, -3.0829e+00,  9.1782e+00, -1.2893e+01, -1.1241e+01,\n",
      "          1.3400e+00, -5.2569e+00,  1.3922e+01, -1.1477e+00,  1.3036e+00,\n",
      "          5.8586e+00,  2.6814e+01,  1.0713e+01, -7.5318e+00, -1.4799e+01,\n",
      "          2.8356e+01,  2.2227e+01,  4.0563e+00,  1.2230e+01,  7.9286e+00,\n",
      "          1.5862e+01, -7.4700e-01,  4.0460e+00,  1.0382e+00, -2.6017e+01,\n",
      "          2.0483e+01,  1.4663e+01,  1.0815e+01,  1.2353e+01, -5.2923e+00,\n",
      "         -1.2598e+01, -2.7368e+01,  3.9353e+00, -6.5818e+00,  6.8045e+00,\n",
      "          2.1674e+01,  1.8420e+00,  1.6196e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0078e+01,  1.3252e+02,  2.3945e+01, -8.9404e+00, -1.9647e+01,\n",
      "          2.3307e+00, -4.7391e+00, -1.5860e+01,  2.2677e+01,  6.0454e+00,\n",
      "         -1.2869e+01,  1.8018e+00,  9.1053e+00,  2.1410e+00,  7.2040e+00,\n",
      "          9.3009e+00, -7.2575e+00, -8.3176e-01,  3.7924e+00,  2.2830e+01,\n",
      "          1.1998e+01,  2.2216e+00, -1.7266e+00, -4.2610e-01,  9.8930e+00,\n",
      "         -6.3268e-01,  4.6068e+00, -4.0140e-01, -6.3417e+00, -1.9296e+00,\n",
      "          1.0133e+01, -2.6005e+01, -3.5078e+00, -2.3435e+00,  5.2286e+00,\n",
      "         -1.0970e+01, -1.1118e+01, -1.6835e+00, -1.2083e+01,  1.6194e+01,\n",
      "         -2.6306e+00,  2.9284e+00, -1.2971e+01,  2.6810e+01,  2.0263e+01,\n",
      "         -5.3137e+00,  1.3926e+01, -4.9635e+00, -1.1375e+01,  1.5295e+01,\n",
      "          6.1592e+00, -3.2427e+00, -8.2833e+00, -1.4090e+01, -1.6458e+01,\n",
      "         -8.6571e+00, -7.5130e+00, -1.0565e+01, -3.5864e+00, -5.9492e+00,\n",
      "         -1.0103e+01, -1.7451e+01, -1.0813e-01, -5.2970e+00, -6.4019e+00,\n",
      "          3.2732e+01,  4.3463e-01,  5.6481e+00, -2.1966e+01,  7.4284e+00,\n",
      "         -1.5529e+01,  6.8228e-01,  8.4642e+00,  9.4692e+00,  1.4244e+01,\n",
      "         -4.2759e+00,  1.6765e+01, -1.5315e+01,  2.4644e+01,  6.3323e+00,\n",
      "         -8.7452e+00,  1.9072e+01, -1.3721e+01, -7.3788e+00,  5.0043e+00,\n",
      "          1.1254e+00, -5.8272e+00,  1.3061e+00, -5.0694e+00, -1.5361e+01,\n",
      "         -9.7474e+00, -4.0799e+00,  9.0672e+00, -1.1556e+01, -1.1664e+01,\n",
      "          1.2863e+00, -5.6459e+00,  1.2705e+01, -2.4632e-01,  1.3968e+00,\n",
      "          6.1621e+00,  2.6640e+01,  1.0664e+01, -7.5486e+00, -1.4458e+01,\n",
      "          2.8585e+01,  2.2819e+01,  3.7102e+00,  1.2186e+01,  1.0136e+01,\n",
      "          1.5929e+01, -1.3373e+00,  4.2407e+00,  9.8898e-02, -2.6520e+01,\n",
      "          2.0318e+01,  1.3498e+01,  1.1182e+01,  1.2077e+01, -5.2174e+00,\n",
      "         -1.1763e+01, -2.9090e+01,  3.9805e+00, -5.9591e+00,  6.8166e+00,\n",
      "          2.1741e+01,  6.2859e-01,  9.5565e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 10.4710, 132.3939,  24.8706,  -8.9363, -19.7766,   1.2399,  -4.6348,\n",
      "         -15.3073,  22.1564,   5.2993, -12.3268,   1.9958,   9.0475,   2.1388,\n",
      "           5.9863,   9.2680,  -8.4777,  -0.2930,   2.5909,  20.7461,  11.1834,\n",
      "           3.0683,  -1.0465,  -0.3331,   9.6002,  -0.6406,   4.4793,  -0.2467,\n",
      "          -6.5770,  -1.1985,   9.8024, -25.9571,  -4.6873,  -2.3534,   5.4011,\n",
      "         -10.4348, -10.4220,  -1.5278, -11.7517,  16.1534,  -1.7455,   3.1293,\n",
      "         -12.6500,  25.9349,  20.0905,  -6.2166,  13.0141,  -4.5386, -10.6423,\n",
      "          16.5357,   5.3509,  -3.5770,  -7.7797, -13.9151, -17.8006,  -8.9677,\n",
      "          -6.8772, -11.2661,  -3.6752,  -6.5750, -10.1880, -16.4404,  -0.5894,\n",
      "          -3.8658,  -7.6265,  32.3553,   0.8280,   6.3387, -20.6752,   9.3457,\n",
      "         -14.8408,   1.1753,  10.1993,  11.1444,  14.4302,  -3.4380,  17.0255,\n",
      "         -15.2163,  24.3179,   6.5777,  -9.2018,  20.3700, -13.2642,  -6.1577,\n",
      "           6.2102,   1.0980,  -4.2622,  -0.6528,  -6.0027, -16.0178,  -8.1060,\n",
      "          -2.6495,   8.6400, -12.7200, -13.1662,   1.9100,  -5.6825,  13.5675,\n",
      "           0.2525,   1.5169,   7.3323,  27.2663,  10.5249,  -7.1389, -14.3782,\n",
      "          28.9841,  22.3770,   4.3084,  11.4862,   9.7336,  16.1988,  -2.3376,\n",
      "           5.2371,   0.9429, -25.2730,  20.8425,  14.8122,  10.9360,  12.5785,\n",
      "          -5.5671, -12.9414, -28.8181,   3.5719,  -6.3537,   6.6182,  22.3065,\n",
      "           2.8507,   0.5327]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.8721e+00,  1.3256e+02,  2.4701e+01, -8.6386e+00, -1.9672e+01,\n",
      "          1.8419e+00, -4.6065e+00, -1.5659e+01,  2.3797e+01,  4.4633e+00,\n",
      "         -1.3200e+01,  1.8409e+00,  8.9039e+00,  8.1932e-01,  5.8470e+00,\n",
      "          8.6792e+00, -6.8820e+00,  2.4804e-01,  2.5356e+00,  2.1729e+01,\n",
      "          1.0963e+01,  2.5157e+00, -1.3365e+00, -6.3343e-01,  1.0005e+01,\n",
      "         -1.0020e+00,  4.4823e+00,  6.9460e-02, -6.5713e+00, -1.5705e+00,\n",
      "          9.7130e+00, -2.6112e+01, -3.1431e+00, -2.6393e+00,  5.3792e+00,\n",
      "         -1.0748e+01, -1.0221e+01, -6.2101e-01, -1.1374e+01,  1.6156e+01,\n",
      "         -2.0946e+00,  3.3630e+00, -1.1620e+01,  2.6572e+01,  1.9611e+01,\n",
      "         -5.6411e+00,  1.3269e+01, -4.5757e+00, -1.1600e+01,  1.5496e+01,\n",
      "          5.1301e+00, -2.0906e+00, -8.7477e+00, -1.4545e+01, -1.6785e+01,\n",
      "         -8.3929e+00, -6.9701e+00, -1.0421e+01, -2.4957e+00, -5.4655e+00,\n",
      "         -1.0684e+01, -1.5790e+01, -1.5117e+00, -5.9237e+00, -7.2675e+00,\n",
      "          3.1858e+01,  8.1551e-01,  5.9140e+00, -2.1089e+01,  7.1303e+00,\n",
      "         -1.5229e+01,  1.1258e+00,  9.2359e+00,  1.0855e+01,  1.4873e+01,\n",
      "         -3.9602e+00,  1.6497e+01, -1.4544e+01,  2.4236e+01,  6.2626e+00,\n",
      "         -9.9657e+00,  2.0490e+01, -1.3440e+01, -7.2939e+00,  6.3782e+00,\n",
      "          4.6615e-01, -5.9552e+00,  8.7448e-01, -5.9347e+00, -1.5753e+01,\n",
      "         -8.2959e+00, -3.3528e+00,  7.8916e+00, -1.2226e+01, -1.1740e+01,\n",
      "          1.4544e+00, -6.3510e+00,  1.3397e+01, -1.1055e+00,  5.1179e-01,\n",
      "          6.2509e+00,  2.7655e+01,  1.0840e+01, -6.7478e+00, -1.4899e+01,\n",
      "          2.9148e+01,  2.2403e+01,  4.2074e+00,  1.2494e+01,  9.1412e+00,\n",
      "          1.5596e+01, -1.2615e+00,  4.2629e+00,  3.3366e-01, -2.6403e+01,\n",
      "          2.1219e+01,  1.4379e+01,  1.0414e+01,  1.2541e+01, -5.5977e+00,\n",
      "         -1.2515e+01, -2.7912e+01,  2.4010e+00, -7.2112e+00,  6.6256e+00,\n",
      "          2.1166e+01,  1.6846e+00,  1.4203e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.2598e+00,  1.3256e+02,  2.3147e+01, -8.0173e+00, -2.0302e+01,\n",
      "          1.6038e+00, -4.6456e+00, -1.4841e+01,  2.2601e+01,  5.2783e+00,\n",
      "         -1.3020e+01,  1.8014e+00,  8.9918e+00,  1.7690e+00,  6.2784e+00,\n",
      "          9.3085e+00, -7.5967e+00,  4.0746e-01,  2.8186e+00,  2.1856e+01,\n",
      "          1.0387e+01,  3.0249e+00, -1.2634e+00, -1.0171e+00,  1.0687e+01,\n",
      "         -1.4715e+00,  4.8882e+00, -6.2342e-01, -6.1315e+00, -1.6841e+00,\n",
      "          8.8466e+00, -2.5982e+01, -3.0610e+00, -3.2992e+00,  4.7926e+00,\n",
      "         -1.0402e+01, -1.2507e+01, -1.5116e+00, -1.1820e+01,  1.7176e+01,\n",
      "         -2.3262e+00,  3.0148e+00, -1.1846e+01,  2.6524e+01,  1.9269e+01,\n",
      "         -6.1354e+00,  1.2807e+01, -5.2010e+00, -1.1350e+01,  1.6040e+01,\n",
      "          4.5171e+00, -2.2627e+00, -8.1329e+00, -1.3817e+01, -1.6781e+01,\n",
      "         -9.1680e+00, -7.1980e+00, -1.1441e+01, -3.3751e+00, -6.7396e+00,\n",
      "         -1.0182e+01, -1.6177e+01, -1.3498e+00, -4.7251e+00, -7.5034e+00,\n",
      "          3.1940e+01,  7.8917e-01,  6.4521e+00, -2.0964e+01,  7.2290e+00,\n",
      "         -1.4297e+01,  6.1214e-01,  8.7525e+00,  1.0472e+01,  1.5035e+01,\n",
      "         -4.1662e+00,  1.7185e+01, -1.5328e+01,  2.4407e+01,  6.2580e+00,\n",
      "         -1.0054e+01,  2.0263e+01, -1.3049e+01, -7.2240e+00,  6.2533e+00,\n",
      "          8.0404e-02, -6.1305e+00,  7.2931e-02, -5.5779e+00, -1.7416e+01,\n",
      "         -8.3090e+00, -3.0587e+00,  9.0953e+00, -1.2940e+01, -1.1274e+01,\n",
      "          1.2643e+00, -5.1116e+00,  1.4020e+01, -1.0009e+00,  1.2871e+00,\n",
      "          5.9464e+00,  2.7020e+01,  1.0712e+01, -7.5206e+00, -1.4602e+01,\n",
      "          2.8506e+01,  2.2115e+01,  3.7878e+00,  1.2169e+01,  8.0200e+00,\n",
      "          1.5821e+01, -1.0388e+00,  3.9050e+00,  9.3051e-01, -2.6028e+01,\n",
      "          2.0477e+01,  1.4896e+01,  1.0682e+01,  1.2431e+01, -5.3248e+00,\n",
      "         -1.2751e+01, -2.7500e+01,  3.8821e+00, -6.4619e+00,  6.8552e+00,\n",
      "          2.1945e+01,  1.6729e+00,  1.6696e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0027e+01,  1.3251e+02,  2.4021e+01, -8.9045e+00, -1.9532e+01,\n",
      "          2.3651e+00, -4.4911e+00, -1.5915e+01,  2.2628e+01,  6.0443e+00,\n",
      "         -1.2829e+01,  1.9441e+00,  9.1251e+00,  2.1166e+00,  7.2367e+00,\n",
      "          9.2621e+00, -7.3087e+00, -1.1675e+00,  3.8644e+00,  2.2702e+01,\n",
      "          1.2092e+01,  2.1777e+00, -1.7613e+00, -4.0926e-01,  1.0066e+01,\n",
      "         -8.8783e-01,  4.5680e+00, -5.6293e-01, -6.3177e+00, -1.8962e+00,\n",
      "          9.8862e+00, -2.5871e+01, -3.3905e+00, -2.3798e+00,  5.3323e+00,\n",
      "         -1.1008e+01, -1.1360e+01, -1.7882e+00, -1.2026e+01,  1.6382e+01,\n",
      "         -2.5087e+00,  2.8037e+00, -1.2993e+01,  2.6782e+01,  2.0199e+01,\n",
      "         -5.3396e+00,  1.3870e+01, -4.8984e+00, -1.1355e+01,  1.5548e+01,\n",
      "          6.0635e+00, -3.2757e+00, -8.1996e+00, -1.4047e+01, -1.6651e+01,\n",
      "         -8.7572e+00, -7.4625e+00, -1.0636e+01, -3.6063e+00, -6.0592e+00,\n",
      "         -1.0126e+01, -1.7478e+01, -1.0650e-01, -5.2408e+00, -6.6146e+00,\n",
      "          3.2711e+01,  5.0669e-01,  5.8243e+00, -2.1907e+01,  7.5821e+00,\n",
      "         -1.5305e+01,  6.2578e-01,  8.5074e+00,  9.3305e+00,  1.4324e+01,\n",
      "         -4.2603e+00,  1.6829e+01, -1.5335e+01,  2.4589e+01,  6.2643e+00,\n",
      "         -8.7329e+00,  1.9038e+01, -1.3600e+01, -7.3741e+00,  5.0378e+00,\n",
      "          1.0924e+00, -5.7836e+00,  1.3011e+00, -5.0657e+00, -1.5562e+01,\n",
      "         -9.7401e+00, -3.9940e+00,  9.0732e+00, -1.1648e+01, -1.1660e+01,\n",
      "          1.2365e+00, -5.5387e+00,  1.2915e+01, -1.6485e-01,  1.3868e+00,\n",
      "          6.2753e+00,  2.6772e+01,  1.0666e+01, -7.5055e+00, -1.4295e+01,\n",
      "          2.8679e+01,  2.2743e+01,  3.5148e+00,  1.2128e+01,  1.0096e+01,\n",
      "          1.5917e+01, -1.5498e+00,  4.1950e+00,  2.3880e-02, -2.6515e+01,\n",
      "          2.0302e+01,  1.3783e+01,  1.1019e+01,  1.2123e+01, -5.2337e+00,\n",
      "         -1.1907e+01, -2.9104e+01,  3.9746e+00, -5.7608e+00,  6.8672e+00,\n",
      "          2.1974e+01,  5.6048e-01,  9.4681e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 10.2768, 132.3860,  24.8628,  -8.9324, -19.5849,   1.3668,  -4.3804,\n",
      "         -15.3467,  22.2313,   5.2878, -12.4093,   2.1565,   9.0407,   2.0812,\n",
      "           5.9552,   9.2304,  -8.5424,  -0.6033,   2.7508,  20.7449,  11.3083,\n",
      "           3.0854,  -1.1491,  -0.3163,   9.7955,  -0.8713,   4.4544,  -0.4734,\n",
      "          -6.5207,  -1.2662,   9.5888, -25.8028,  -4.4475,  -2.3970,   5.4933,\n",
      "         -10.4782, -10.7700,  -1.6219, -11.6141,  16.4103,  -1.6348,   3.0292,\n",
      "         -12.6324,  25.9462,  20.0191,  -6.1649,  12.9444,  -4.5105, -10.6831,\n",
      "          16.7597,   5.3311,  -3.4845,  -7.7327, -13.9651, -17.9033,  -9.0071,\n",
      "          -6.8628, -11.3119,  -3.5835,  -6.7096, -10.2355, -16.4795,  -0.6256,\n",
      "          -3.9170,  -7.7007,  32.3886,   0.8738,   6.4407, -20.6727,   9.3043,\n",
      "         -14.6505,   1.1701,  10.1941,  10.9264,  14.5258,  -3.4588,  17.0739,\n",
      "         -15.2227,  24.2252,   6.3505,  -9.2080,  20.3463, -13.1571,  -6.2647,\n",
      "           6.2534,   1.0282,  -4.4192,  -0.4533,  -5.9333, -16.1632,  -8.2012,\n",
      "          -2.6275,   8.7112, -12.6741, -12.9805,   1.8656,  -5.6109,  13.6738,\n",
      "           0.3864,   1.4174,   7.4188,  27.3970,  10.5091,  -7.1863, -14.2074,\n",
      "          29.0328,  22.2814,   4.1453,  11.5196,   9.6572,  16.2186,  -2.5304,\n",
      "           5.1903,   0.8243, -25.3920,  20.8362,  15.0707,  10.8148,  12.6157,\n",
      "          -5.5239, -13.0235, -28.7517,   3.5714,  -6.0981,   6.6293,  22.4858,\n",
      "           2.6576,   0.4627]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.8030e+00,  1.3256e+02,  2.4685e+01, -8.6832e+00, -1.9517e+01,\n",
      "          1.9030e+00, -4.4408e+00, -1.5730e+01,  2.3788e+01,  4.3802e+00,\n",
      "         -1.3155e+01,  1.9150e+00,  8.9443e+00,  8.3754e-01,  5.8190e+00,\n",
      "          8.7404e+00, -7.0641e+00, -1.0531e-03,  2.6458e+00,  2.1632e+01,\n",
      "          1.0982e+01,  2.6478e+00, -1.3160e+00, -5.7835e-01,  1.0054e+01,\n",
      "         -1.2088e+00,  4.4794e+00, -2.2962e-01, -6.6408e+00, -1.5576e+00,\n",
      "          9.5284e+00, -2.5977e+01, -3.0100e+00, -2.6233e+00,  5.4628e+00,\n",
      "         -1.0791e+01, -1.0611e+01, -6.8474e-01, -1.1226e+01,  1.6368e+01,\n",
      "         -2.0647e+00,  3.1989e+00, -1.1598e+01,  2.6546e+01,  1.9523e+01,\n",
      "         -5.6171e+00,  1.3180e+01, -4.4379e+00, -1.1626e+01,  1.5743e+01,\n",
      "          5.0404e+00, -2.1194e+00, -8.6501e+00, -1.4528e+01, -1.6937e+01,\n",
      "         -8.5010e+00, -6.8960e+00, -1.0628e+01, -2.4990e+00, -5.5728e+00,\n",
      "         -1.0709e+01, -1.5766e+01, -1.5216e+00, -5.8330e+00, -7.2983e+00,\n",
      "          3.1870e+01,  8.1868e-01,  5.9789e+00, -2.1027e+01,  7.2529e+00,\n",
      "         -1.5040e+01,  1.2184e+00,  9.3104e+00,  1.0703e+01,  1.4821e+01,\n",
      "         -3.8710e+00,  1.6556e+01, -1.4632e+01,  2.4110e+01,  6.0732e+00,\n",
      "         -9.8820e+00,  2.0517e+01, -1.3326e+01, -7.3751e+00,  6.4833e+00,\n",
      "          4.4157e-01, -6.0114e+00,  8.5402e-01, -5.9109e+00, -1.5907e+01,\n",
      "         -8.2747e+00, -3.2505e+00,  7.9610e+00, -1.2275e+01, -1.1707e+01,\n",
      "          1.4167e+00, -6.1404e+00,  1.3606e+01, -8.8113e-01,  5.3143e-01,\n",
      "          6.4098e+00,  2.7788e+01,  1.0791e+01, -6.7369e+00, -1.4717e+01,\n",
      "          2.9151e+01,  2.2355e+01,  3.9687e+00,  1.2373e+01,  9.0500e+00,\n",
      "          1.5697e+01, -1.4868e+00,  4.3067e+00,  3.6110e-01, -2.6434e+01,\n",
      "          2.1228e+01,  1.4663e+01,  1.0387e+01,  1.2519e+01, -5.5865e+00,\n",
      "         -1.2583e+01, -2.7908e+01,  2.4301e+00, -6.9252e+00,  6.6555e+00,\n",
      "          2.1404e+01,  1.7305e+00,  1.2226e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.2395e+00,  1.3254e+02,  2.3234e+01, -8.1309e+00, -1.9999e+01,\n",
      "          1.7204e+00, -4.4944e+00, -1.4959e+01,  2.2710e+01,  5.1404e+00,\n",
      "         -1.3047e+01,  1.9083e+00,  9.0190e+00,  1.7298e+00,  6.2249e+00,\n",
      "          9.3264e+00, -7.6566e+00,  8.1104e-02,  2.9019e+00,  2.1697e+01,\n",
      "          1.0508e+01,  3.1523e+00, -1.2696e+00, -9.4168e-01,  1.0764e+01,\n",
      "         -1.6657e+00,  4.8688e+00, -8.2007e-01, -6.1847e+00, -1.7107e+00,\n",
      "          8.7785e+00, -2.5875e+01, -2.9683e+00, -3.2597e+00,  4.9078e+00,\n",
      "         -1.0445e+01, -1.2805e+01, -1.5104e+00, -1.1542e+01,  1.7338e+01,\n",
      "         -2.2069e+00,  2.9062e+00, -1.1852e+01,  2.6537e+01,  1.9155e+01,\n",
      "         -6.0686e+00,  1.2701e+01, -5.0489e+00, -1.1340e+01,  1.6181e+01,\n",
      "          4.4797e+00, -2.2307e+00, -8.0668e+00, -1.3852e+01, -1.7026e+01,\n",
      "         -9.2368e+00, -7.1432e+00, -1.1486e+01, -3.3265e+00, -6.7782e+00,\n",
      "         -1.0285e+01, -1.6116e+01, -1.3775e+00, -4.7252e+00, -7.5504e+00,\n",
      "          3.1914e+01,  8.3771e-01,  6.4756e+00, -2.0917e+01,  7.3796e+00,\n",
      "         -1.4221e+01,  7.1383e-01,  8.8833e+00,  1.0350e+01,  1.4954e+01,\n",
      "         -4.0691e+00,  1.7092e+01, -1.5332e+01,  2.4194e+01,  5.9884e+00,\n",
      "         -9.9562e+00,  2.0357e+01, -1.3032e+01, -7.2717e+00,  6.3131e+00,\n",
      "          2.4714e-02, -6.2680e+00,  1.5720e-01, -5.5649e+00, -1.7459e+01,\n",
      "         -8.3781e+00, -3.0175e+00,  9.0965e+00, -1.2938e+01, -1.1237e+01,\n",
      "          1.1941e+00, -4.9535e+00,  1.4096e+01, -7.6426e-01,  1.1911e+00,\n",
      "          6.1350e+00,  2.7236e+01,  1.0652e+01, -7.5225e+00, -1.4433e+01,\n",
      "          2.8573e+01,  2.2047e+01,  3.5083e+00,  1.2043e+01,  8.0339e+00,\n",
      "          1.5874e+01, -1.2879e+00,  3.9504e+00,  9.0523e-01, -2.6108e+01,\n",
      "          2.0527e+01,  1.5153e+01,  1.0589e+01,  1.2455e+01, -5.2585e+00,\n",
      "         -1.2836e+01, -2.7527e+01,  3.8265e+00, -6.2838e+00,  6.8696e+00,\n",
      "          2.2162e+01,  1.6908e+00,  1.5153e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0061e+01,  1.3250e+02,  2.4060e+01, -8.9151e+00, -1.9356e+01,\n",
      "          2.4081e+00, -4.3518e+00, -1.5923e+01,  2.2671e+01,  5.9355e+00,\n",
      "         -1.2790e+01,  2.0181e+00,  9.1860e+00,  2.1542e+00,  7.2002e+00,\n",
      "          9.3225e+00, -7.2902e+00, -1.4114e+00,  3.8446e+00,  2.2454e+01,\n",
      "          1.2105e+01,  2.2707e+00, -1.7482e+00, -3.6608e-01,  1.0188e+01,\n",
      "         -1.1277e+00,  4.5739e+00, -6.5550e-01, -6.3538e+00, -1.8469e+00,\n",
      "          9.7986e+00, -2.5796e+01, -3.3914e+00, -2.3681e+00,  5.4023e+00,\n",
      "         -1.1053e+01, -1.1684e+01, -1.8203e+00, -1.1735e+01,  1.6511e+01,\n",
      "         -2.4154e+00,  2.6832e+00, -1.2959e+01,  2.6803e+01,  2.0037e+01,\n",
      "         -5.3658e+00,  1.3713e+01, -4.7339e+00, -1.1279e+01,  1.5685e+01,\n",
      "          5.9518e+00, -3.2317e+00, -8.1548e+00, -1.3990e+01, -1.6947e+01,\n",
      "         -8.8661e+00, -7.3554e+00, -1.0759e+01, -3.6494e+00, -6.1356e+00,\n",
      "         -1.0207e+01, -1.7375e+01, -1.6273e-01, -5.2069e+00, -6.7303e+00,\n",
      "          3.2622e+01,  5.6825e-01,  5.9215e+00, -2.1831e+01,  7.7998e+00,\n",
      "         -1.5158e+01,  6.7799e-01,  8.6396e+00,  9.2851e+00,  1.4257e+01,\n",
      "         -4.1048e+00,  1.6747e+01, -1.5387e+01,  2.4410e+01,  6.0621e+00,\n",
      "         -8.7141e+00,  1.9180e+01, -1.3589e+01, -7.3490e+00,  5.1159e+00,\n",
      "          1.0231e+00, -5.8568e+00,  1.1973e+00, -5.0809e+00, -1.5755e+01,\n",
      "         -9.7175e+00, -3.8779e+00,  9.0752e+00, -1.1793e+01, -1.1637e+01,\n",
      "          1.1797e+00, -5.2932e+00,  1.3085e+01, -1.2693e-02,  1.3913e+00,\n",
      "          6.4706e+00,  2.6951e+01,  1.0619e+01, -7.4954e+00, -1.4185e+01,\n",
      "          2.8760e+01,  2.2658e+01,  3.2191e+00,  1.1940e+01,  1.0057e+01,\n",
      "          1.5911e+01, -1.7554e+00,  4.2395e+00,  6.3731e-02, -2.6485e+01,\n",
      "          2.0312e+01,  1.4063e+01,  1.0910e+01,  1.2156e+01, -5.1743e+00,\n",
      "         -1.2051e+01, -2.9143e+01,  3.9741e+00, -5.6305e+00,  6.9053e+00,\n",
      "          2.2201e+01,  6.6997e-01,  8.5128e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 10.2505, 132.3547,  24.8629,  -8.8582, -19.3457,   1.5243,  -4.1526,\n",
      "         -15.3552,  22.3145,   5.3003, -12.4424,   2.2238,   9.1287,   2.1142,\n",
      "           5.9826,   9.2744,  -8.3901,  -0.9513,   2.8454,  20.6597,  11.3928,\n",
      "           3.1118,  -1.2760,  -0.3087,  10.0320,  -1.1838,   4.4973,  -0.4988,\n",
      "          -6.4513,  -1.2882,   9.5671, -25.7781,  -4.3937,  -2.4113,   5.5598,\n",
      "         -10.5247, -11.1702,  -1.7013, -11.3450,  16.5429,  -1.4233,   2.9313,\n",
      "         -12.6763,  26.0314,  19.9061,  -6.1173,  12.8432,  -4.3923, -10.6131,\n",
      "          16.7990,   5.3260,  -3.3606,  -7.6932, -13.9148, -18.1366,  -9.0931,\n",
      "          -6.8447, -11.2931,  -3.5822,  -6.7915, -10.2834, -16.4692,  -0.6477,\n",
      "          -3.9647,  -7.8719,  32.3274,   0.9453,   6.5416, -20.6820,   9.3961,\n",
      "         -14.5305,   1.1152,  10.2530,  10.7404,  14.4770,  -3.4199,  16.9879,\n",
      "         -15.2602,  24.0460,   6.1690,  -9.1974,  20.3964, -13.2468,  -6.2732,\n",
      "           6.1886,   0.9786,  -4.5562,  -0.3665,  -5.8357, -16.3365,  -8.2569,\n",
      "          -2.5765,   8.7385, -12.7836, -12.8388,   1.8103,  -5.2787,  13.7202,\n",
      "           0.4843,   1.4589,   7.5303,  27.5292,  10.5200,  -7.2519, -14.1483,\n",
      "          29.1542,  22.1633,   3.8378,  11.4135,   9.6383,  16.1374,  -2.7575,\n",
      "           5.0971,   0.7891, -25.3460,  20.7489,  15.2444,  10.7372,  12.6227,\n",
      "          -5.4346, -13.1726, -28.8490,   3.6327,  -6.0214,   6.6999,  22.7077,\n",
      "           2.5425,   0.4276]], grad_fn=<SliceBackward0>)\n",
      "tensor([[  9.8818, 132.5618,  24.6839,  -8.6575, -19.3461,   2.0025,  -4.2157,\n",
      "         -15.7681,  23.7255,   4.3723, -13.0788,   1.9310,   9.0219,   0.8832,\n",
      "           5.8690,   8.8415,  -7.0642,  -0.3566,   2.7828,  21.5725,  11.0578,\n",
      "           2.6504,  -1.3935,  -0.5254,  10.2474,  -1.5110,   4.5116,  -0.3524,\n",
      "          -6.6477,  -1.5849,   9.4671, -25.9514,  -3.0105,  -2.6143,   5.5202,\n",
      "         -10.8653, -11.0343,  -0.7741, -11.0370,  16.4730,  -1.8938,   2.9785,\n",
      "         -11.6245,  26.5595,  19.4247,  -5.6340,  13.0932,  -4.2952, -11.5556,\n",
      "          15.8503,   5.0040,  -2.0974,  -8.5461, -14.4415, -17.1316,  -8.6524,\n",
      "          -6.8341, -10.7593,  -2.6264,  -5.6561, -10.6440, -15.7824,  -1.4481,\n",
      "          -5.7801,  -7.5169,  31.8367,   0.7907,   6.0920, -20.9964,   7.4486,\n",
      "         -14.8799,   1.1727,   9.3653,  10.5064,  14.7050,  -3.8350,  16.5013,\n",
      "         -14.7527,  23.9785,   6.0201,  -9.8085,  20.5253, -13.4084,  -7.3536,\n",
      "           6.4298,   0.5020,  -5.9858,   0.7968,  -5.8450, -16.1128,  -8.2559,\n",
      "          -3.1717,   8.0556, -12.4928, -11.6995,   1.3570,  -5.7711,  13.7238,\n",
      "          -0.7203,   0.7223,   6.5847,  27.8853,  10.7972,  -6.7461, -14.6536,\n",
      "          29.2633,  22.3001,   3.6594,  12.1981,   9.0434,  15.6771,  -1.7818,\n",
      "           4.2094,   0.3817, -26.3023,  21.1166,  14.8362,  10.3187,  12.5092,\n",
      "          -5.5413, -12.6929, -28.0362,   2.5368,  -6.8048,   6.7615,  21.7002,\n",
      "           1.7098,   1.1836]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.2617e+00,  1.3255e+02,  2.3302e+01, -8.1424e+00, -1.9722e+01,\n",
      "          1.8639e+00, -4.2335e+00, -1.4985e+01,  2.2756e+01,  5.1309e+00,\n",
      "         -1.3070e+01,  1.9359e+00,  9.0639e+00,  1.6795e+00,  6.2368e+00,\n",
      "          9.3785e+00, -7.6749e+00, -2.9678e-01,  3.1421e+00,  2.1691e+01,\n",
      "          1.0698e+01,  3.1592e+00, -1.3313e+00, -9.1531e-01,  1.0955e+01,\n",
      "         -1.9168e+00,  4.8787e+00, -9.6302e-01, -6.2132e+00, -1.8197e+00,\n",
      "          8.7855e+00, -2.5862e+01, -2.9218e+00, -3.2858e+00,  4.9934e+00,\n",
      "         -1.0532e+01, -1.3113e+01, -1.5376e+00, -1.1394e+01,  1.7412e+01,\n",
      "         -1.9789e+00,  2.7571e+00, -1.1887e+01,  2.6573e+01,  1.9064e+01,\n",
      "         -6.0221e+00,  1.2650e+01, -4.9301e+00, -1.1284e+01,  1.6299e+01,\n",
      "          4.4999e+00, -2.2097e+00, -7.9329e+00, -1.3865e+01, -1.7177e+01,\n",
      "         -9.3019e+00, -7.1629e+00, -1.1532e+01, -3.4038e+00, -6.7959e+00,\n",
      "         -1.0271e+01, -1.6148e+01, -1.3257e+00, -4.6997e+00, -7.7450e+00,\n",
      "          3.1938e+01,  8.0809e-01,  6.5698e+00, -2.0867e+01,  7.5340e+00,\n",
      "         -1.4117e+01,  7.2041e-01,  8.9717e+00,  1.0161e+01,  1.4887e+01,\n",
      "         -4.0926e+00,  1.6981e+01, -1.5378e+01,  2.4049e+01,  5.9141e+00,\n",
      "         -9.8773e+00,  2.0376e+01, -1.3125e+01, -7.2323e+00,  6.2623e+00,\n",
      "          3.5664e-02, -6.2721e+00,  2.3476e-01, -5.5016e+00, -1.7550e+01,\n",
      "         -8.4311e+00, -2.9984e+00,  9.1552e+00, -1.3073e+01, -1.1245e+01,\n",
      "          1.1175e+00, -4.7609e+00,  1.4182e+01, -6.1042e-01,  1.2583e+00,\n",
      "          6.3348e+00,  2.7356e+01,  1.0657e+01, -7.5429e+00, -1.4327e+01,\n",
      "          2.8731e+01,  2.2013e+01,  3.2730e+00,  1.1935e+01,  8.1086e+00,\n",
      "          1.5827e+01, -1.6244e+00,  3.8609e+00,  8.0946e-01, -2.5989e+01,\n",
      "          2.0466e+01,  1.5287e+01,  1.0425e+01,  1.2453e+01, -5.1663e+00,\n",
      "         -1.3005e+01, -2.7581e+01,  3.8534e+00, -6.2133e+00,  6.9213e+00,\n",
      "          2.2452e+01,  1.6058e+00,  1.4802e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0032e+01,  1.3254e+02,  2.4014e+01, -8.8828e+00, -1.9222e+01,\n",
      "          2.4528e+00, -4.1436e+00, -1.5770e+01,  2.2672e+01,  5.8996e+00,\n",
      "         -1.2751e+01,  2.0211e+00,  9.2592e+00,  2.1038e+00,  7.1582e+00,\n",
      "          9.4141e+00, -7.3820e+00, -1.6037e+00,  4.0226e+00,  2.2388e+01,\n",
      "          1.2157e+01,  2.3341e+00, -1.6935e+00, -3.7787e-01,  1.0323e+01,\n",
      "         -1.3509e+00,  4.6175e+00, -8.4665e-01, -6.4642e+00, -1.9349e+00,\n",
      "          9.7459e+00, -2.5804e+01, -3.3461e+00, -2.4878e+00,  5.4382e+00,\n",
      "         -1.1139e+01, -1.2022e+01, -1.8279e+00, -1.1657e+01,  1.6587e+01,\n",
      "         -2.2646e+00,  2.5490e+00, -1.2881e+01,  2.6799e+01,  1.9866e+01,\n",
      "         -5.3780e+00,  1.3602e+01, -4.5934e+00, -1.1224e+01,  1.5877e+01,\n",
      "          5.8437e+00, -3.2334e+00, -8.0174e+00, -1.3988e+01, -1.7105e+01,\n",
      "         -8.9368e+00, -7.3895e+00, -1.0964e+01, -3.7363e+00, -6.1781e+00,\n",
      "         -1.0186e+01, -1.7331e+01, -1.7873e-01, -5.0740e+00, -6.8280e+00,\n",
      "          3.2655e+01,  5.0539e-01,  6.0295e+00, -2.1704e+01,  7.9380e+00,\n",
      "         -1.4964e+01,  7.3815e-01,  8.7540e+00,  9.2285e+00,  1.4260e+01,\n",
      "         -4.0642e+00,  1.6716e+01, -1.5455e+01,  2.4292e+01,  5.9921e+00,\n",
      "         -8.6974e+00,  1.9328e+01, -1.3616e+01, -7.2864e+00,  5.1965e+00,\n",
      "          9.9044e-01, -5.8762e+00,  1.0994e+00, -5.1098e+00, -1.5964e+01,\n",
      "         -9.6899e+00, -3.7819e+00,  9.1926e+00, -1.1989e+01, -1.1678e+01,\n",
      "          1.1247e+00, -5.1895e+00,  1.3302e+01,  9.1009e-02,  1.4654e+00,\n",
      "          6.6623e+00,  2.7028e+01,  1.0588e+01, -7.5148e+00, -1.4068e+01,\n",
      "          2.8860e+01,  2.2620e+01,  3.0847e+00,  1.1825e+01,  1.0028e+01,\n",
      "          1.5881e+01, -2.0257e+00,  4.2319e+00,  3.1206e-02, -2.6309e+01,\n",
      "          2.0259e+01,  1.4246e+01,  1.0729e+01,  1.2113e+01, -5.0914e+00,\n",
      "         -1.2284e+01, -2.9073e+01,  4.0147e+00, -5.5649e+00,  6.9195e+00,\n",
      "          2.2471e+01,  7.4174e-01,  8.0814e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 10.1196, 132.3925,  24.7628,  -8.8339, -19.1698,   1.6084,  -3.9683,\n",
      "         -15.2013,  22.3873,   5.3428, -12.4154,   2.2341,   9.2525,   2.0598,\n",
      "           5.9843,   9.3449,  -8.4346,  -1.1809,   3.0766,  20.6538,  11.4362,\n",
      "           3.1742,  -1.2894,  -0.3517,  10.1778,  -1.4245,   4.6274,  -0.6999,\n",
      "          -6.5364,  -1.4134,   9.5203, -25.7740,  -4.2543,  -2.5475,   5.5986,\n",
      "         -10.6088, -11.6052,  -1.7129, -11.2794,  16.6759,  -1.2572,   2.8174,\n",
      "         -12.6407,  26.0586,  19.7652,  -6.0794,  12.7497,  -4.2500, -10.5877,\n",
      "          16.9240,   5.2140,  -3.3121,  -7.5858, -13.9265, -18.3235,  -9.1649,\n",
      "          -6.9608, -11.4200,  -3.5534,  -6.7975, -10.2886, -16.4412,  -0.6388,\n",
      "          -3.8934,  -7.8538,  32.4163,   0.8913,   6.5989, -20.6186,   9.4196,\n",
      "         -14.3766,   1.1409,  10.3275,  10.6381,  14.4997,  -3.4430,  16.9655,\n",
      "         -15.2580,  23.8833,   6.0203,  -9.1514,  20.5454, -13.2946,  -6.2675,\n",
      "           6.2194,   0.8927,  -4.7293,  -0.3199,  -5.8873, -16.5318,  -8.3046,\n",
      "          -2.5054,   8.8931, -12.8860, -12.7802,   1.7446,  -5.1870,  13.8556,\n",
      "           0.6163,   1.5161,   7.5924,  27.5838,  10.4837,  -7.3349, -14.0102,\n",
      "          29.2183,  22.0875,   3.7559,  11.3652,   9.5716,  16.1064,  -2.9876,\n",
      "           5.0638,   0.7354, -25.2124,  20.6843,  15.4288,  10.5888,  12.5249,\n",
      "          -5.3349, -13.4008, -28.7839,   3.6646,  -5.9244,   6.7336,  22.8948,\n",
      "           2.5049,   0.4006]], grad_fn=<SliceBackward0>)\n",
      "tensor([[  9.8175, 132.5966,  24.6243,  -8.6503, -19.2011,   2.0007,  -4.0174,\n",
      "         -15.5961,  23.6971,   4.4428, -12.9672,   1.9634,   9.1530,   0.8639,\n",
      "           5.9223,   8.9796,  -7.1361,  -0.6089,   2.9418,  21.4802,  11.0521,\n",
      "           2.7427,  -1.4057,  -0.4998,  10.3948,  -1.7792,   4.6295,  -0.5428,\n",
      "          -6.7971,  -1.6216,   9.3838, -25.9615,  -2.9191,  -2.6513,   5.5572,\n",
      "         -11.0006, -11.4428,  -0.8223, -10.9891,  16.6309,  -1.7944,   2.8122,\n",
      "         -11.6397,  26.5561,  19.3613,  -5.6421,  13.0173,  -4.1508, -11.5106,\n",
      "          16.0619,   4.7434,  -2.1409,  -8.4225, -14.4116, -17.4550,  -8.7964,\n",
      "          -6.8230, -10.9685,  -2.7020,  -5.7341, -10.6346, -15.8131,  -1.3060,\n",
      "          -5.6234,  -7.5575,  31.8583,   0.7273,   6.1648, -20.9341,   7.5944,\n",
      "         -14.6742,   1.1395,   9.4250,  10.4114,  14.7371,  -3.7750,  16.5164,\n",
      "         -14.7553,  23.8449,   5.9385,  -9.7129,  20.7383, -13.4157,  -7.3491,\n",
      "           6.4381,   0.4171,  -6.0224,   0.7531,  -5.9688, -16.3533,  -8.2877,\n",
      "          -3.0739,   8.2129, -12.6544, -11.7744,   1.3094,  -5.6290,  13.8817,\n",
      "          -0.4847,   0.8869,   6.5887,  27.9083,  10.7198,  -6.7870, -14.4755,\n",
      "          29.3222,  22.1898,   3.5514,  12.0960,   9.0253,  15.7052,  -2.0610,\n",
      "           4.1840,   0.3938, -26.1088,  21.1100,  15.1207,  10.1974,  12.4014,\n",
      "          -5.4629, -12.9115, -28.0835,   2.5752,  -6.6948,   6.8499,  21.8961,\n",
      "           1.7336,   1.1149]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.2203e+00,  1.3255e+02,  2.3355e+01, -8.1440e+00, -1.9484e+01,\n",
      "          1.9504e+00, -4.0161e+00, -1.4956e+01,  2.2825e+01,  5.1515e+00,\n",
      "         -1.3001e+01,  1.9946e+00,  9.1263e+00,  1.6183e+00,  6.2705e+00,\n",
      "          9.4299e+00, -7.6554e+00, -6.2978e-01,  3.2689e+00,  2.1570e+01,\n",
      "          1.0771e+01,  3.1652e+00, -1.4098e+00, -8.5724e-01,  1.1158e+01,\n",
      "         -2.2117e+00,  4.9380e+00, -1.0933e+00, -6.2626e+00, -1.8641e+00,\n",
      "          8.6987e+00, -2.5812e+01, -2.8177e+00, -3.2770e+00,  5.0831e+00,\n",
      "         -1.0618e+01, -1.3411e+01, -1.5450e+00, -1.1284e+01,  1.7546e+01,\n",
      "         -1.8352e+00,  2.6244e+00, -1.1983e+01,  2.6563e+01,  1.9047e+01,\n",
      "         -6.0168e+00,  1.2604e+01, -4.8145e+00, -1.1226e+01,  1.6453e+01,\n",
      "          4.3237e+00, -2.2226e+00, -7.8838e+00, -1.3879e+01, -1.7531e+01,\n",
      "         -9.4239e+00, -7.0922e+00, -1.1611e+01, -3.4045e+00, -6.8233e+00,\n",
      "         -1.0344e+01, -1.6167e+01, -1.2023e+00, -4.6534e+00, -7.8494e+00,\n",
      "          3.1922e+01,  8.2172e-01,  6.6498e+00, -2.0826e+01,  7.6914e+00,\n",
      "         -1.4010e+01,  6.7836e-01,  9.0388e+00,  1.0038e+01,  1.4905e+01,\n",
      "         -4.0613e+00,  1.6909e+01, -1.5279e+01,  2.3874e+01,  5.7852e+00,\n",
      "         -9.7887e+00,  2.0520e+01, -1.3151e+01, -7.2225e+00,  6.2311e+00,\n",
      "         -4.2660e-02, -6.3151e+00,  2.8719e-01, -5.5996e+00, -1.7647e+01,\n",
      "         -8.5130e+00, -2.9466e+00,  9.2253e+00, -1.3185e+01, -1.1278e+01,\n",
      "          1.0679e+00, -4.6727e+00,  1.4229e+01, -4.1833e-01,  1.3428e+00,\n",
      "          6.3444e+00,  2.7443e+01,  1.0616e+01, -7.5719e+00, -1.4168e+01,\n",
      "          2.8891e+01,  2.1903e+01,  3.1440e+00,  1.1881e+01,  8.1511e+00,\n",
      "          1.5799e+01, -1.9273e+00,  3.7928e+00,  7.6452e-01, -2.5893e+01,\n",
      "          2.0487e+01,  1.5533e+01,  1.0225e+01,  1.2403e+01, -5.1013e+00,\n",
      "         -1.3172e+01, -2.7706e+01,  3.7874e+00, -6.1305e+00,  6.9829e+00,\n",
      "          2.2606e+01,  1.5192e+00,  1.4556e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0009e+01,  1.3256e+02,  2.4000e+01, -8.8135e+00, -1.9124e+01,\n",
      "          2.4852e+00, -3.9137e+00, -1.5694e+01,  2.2670e+01,  5.8669e+00,\n",
      "         -1.2677e+01,  2.1129e+00,  9.2629e+00,  2.0669e+00,  7.1835e+00,\n",
      "          9.4782e+00, -7.3512e+00, -1.8350e+00,  4.0123e+00,  2.2213e+01,\n",
      "          1.2142e+01,  2.2989e+00, -1.7311e+00, -3.1990e-01,  1.0550e+01,\n",
      "         -1.6793e+00,  4.6149e+00, -9.5977e-01, -6.4518e+00, -1.9446e+00,\n",
      "          9.5713e+00, -2.5741e+01, -3.2372e+00, -2.5182e+00,  5.4844e+00,\n",
      "         -1.1200e+01, -1.2345e+01, -1.8431e+00, -1.1545e+01,  1.6752e+01,\n",
      "         -2.1766e+00,  2.3999e+00, -1.2904e+01,  2.6746e+01,  1.9773e+01,\n",
      "         -5.4629e+00,  1.3521e+01, -4.5352e+00, -1.1150e+01,  1.6066e+01,\n",
      "          5.6240e+00, -3.2283e+00, -8.0286e+00, -1.3986e+01, -1.7423e+01,\n",
      "         -9.0853e+00, -7.2488e+00, -1.1132e+01, -3.7867e+00, -6.2681e+00,\n",
      "         -1.0258e+01, -1.7293e+01, -1.1744e-01, -5.0066e+00, -7.0145e+00,\n",
      "          3.2561e+01,  5.1452e-01,  6.1421e+00, -2.1604e+01,  8.0921e+00,\n",
      "         -1.4794e+01,  6.7759e-01,  8.7665e+00,  9.1739e+00,  1.4289e+01,\n",
      "         -4.0000e+00,  1.6682e+01, -1.5403e+01,  2.4148e+01,  5.8876e+00,\n",
      "         -8.6858e+00,  1.9483e+01, -1.3605e+01, -7.2786e+00,  5.2285e+00,\n",
      "          9.2297e-01, -5.8495e+00,  1.0132e+00, -5.1871e+00, -1.6158e+01,\n",
      "         -9.6866e+00, -3.7275e+00,  9.2622e+00, -1.2202e+01, -1.1681e+01,\n",
      "          1.0998e+00, -5.0801e+00,  1.3395e+01,  1.6277e-01,  1.5300e+00,\n",
      "          6.6692e+00,  2.7100e+01,  1.0579e+01, -7.5272e+00, -1.3960e+01,\n",
      "          2.9001e+01,  2.2504e+01,  2.9256e+00,  1.1753e+01,  9.9832e+00,\n",
      "          1.5845e+01, -2.2898e+00,  4.1365e+00,  6.0827e-02, -2.6225e+01,\n",
      "          2.0251e+01,  1.4480e+01,  1.0507e+01,  1.2091e+01, -5.0703e+00,\n",
      "         -1.2438e+01, -2.9205e+01,  3.9877e+00, -5.4937e+00,  6.9594e+00,\n",
      "          2.2610e+01,  7.0195e-01,  8.2519e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 10.0692, 132.4066,  24.6804,  -8.7513, -19.0468,   1.7151,  -3.7191,\n",
      "         -15.1563,  22.4012,   5.3327, -12.4532,   2.3418,   9.2532,   1.9968,\n",
      "           6.0516,   9.4039,  -8.3849,  -1.4258,   3.1386,  20.6414,  11.4486,\n",
      "           3.1099,  -1.3801,  -0.3235,  10.4010,  -1.7416,   4.6187,  -0.8627,\n",
      "          -6.4887,  -1.4746,   9.3653, -25.7289,  -4.0570,  -2.5902,   5.6442,\n",
      "         -10.7067, -12.0439,  -1.7609, -11.1403,  16.8566,  -1.1427,   2.6686,\n",
      "         -12.6479,  26.0407,  19.6738,  -6.0963,  12.6805,  -4.2602, -10.5610,\n",
      "          17.0608,   5.1156,  -3.2400,  -7.5843, -13.9809, -18.5103,  -9.2734,\n",
      "          -6.9008, -11.5331,  -3.5630,  -6.8762, -10.3568, -16.4436,  -0.6063,\n",
      "          -3.9185,  -8.0065,  32.3450,   0.8590,   6.6621, -20.5702,   9.4191,\n",
      "         -14.2448,   1.0889,  10.2796,  10.4666,  14.4981,  -3.4552,  16.9084,\n",
      "         -15.2366,  23.7519,   5.8729,  -9.1496,  20.6488, -13.3078,  -6.3453,\n",
      "           6.2409,   0.8497,  -4.7828,  -0.2315,  -5.8644, -16.7069,  -8.3993,\n",
      "          -2.5516,   8.9911, -13.0105, -12.6520,   1.6891,  -5.0459,  13.8603,\n",
      "           0.6551,   1.5288,   7.5558,  27.6434,  10.5301,  -7.3824, -13.8903,\n",
      "          29.3534,  21.9698,   3.5900,  11.3710,   9.5082,  16.0756,  -3.2458,\n",
      "           4.9069,   0.7557, -25.1681,  20.6580,  15.5742,  10.3977,  12.5009,\n",
      "          -5.2837, -13.5147, -28.9274,   3.6656,  -5.8344,   6.7278,  23.0083,\n",
      "           2.3238,   0.3964]], grad_fn=<SliceBackward0>)\n",
      "tensor([[  9.8523, 132.6109,  24.5371,  -8.6234, -19.0780,   2.0516,  -3.8175,\n",
      "         -15.4966,  23.5888,   4.3972, -12.9288,   2.0243,   9.1719,   0.8391,\n",
      "           6.0023,   9.1472,  -7.2093,  -0.7798,   3.0174,  21.4412,  11.0620,\n",
      "           2.7540,  -1.4261,  -0.4216,  10.5194,  -2.0801,   4.6235,  -0.7396,\n",
      "          -6.8373,  -1.6601,   9.2435, -25.9840,  -2.8230,  -2.6727,   5.5831,\n",
      "         -11.1700, -11.9205,  -0.8732, -10.8522,  16.7778,  -1.6876,   2.6153,\n",
      "         -11.6340,  26.5463,  19.2767,  -5.7062,  12.9596,  -4.1505, -11.5031,\n",
      "          16.2751,   4.6224,  -2.1372,  -8.3439, -14.4944, -17.6475,  -8.9162,\n",
      "          -6.7578, -11.1984,  -2.8050,  -5.8343, -10.6746, -15.8309,  -1.1950,\n",
      "          -5.5144,  -7.7342,  31.7940,   0.6286,   6.2343, -20.8487,   7.7320,\n",
      "         -14.4912,   1.1104,   9.4635,  10.2915,  14.6891,  -3.7249,  16.4484,\n",
      "         -14.8051,  23.7271,   5.8382,  -9.6738,  20.9185, -13.4331,  -7.3603,\n",
      "           6.4772,   0.4449,  -5.9640,   0.7564,  -5.9296, -16.5307,  -8.3838,\n",
      "          -3.1191,   8.3066, -12.8030, -11.8053,   1.2514,  -5.4620,  13.9143,\n",
      "          -0.3642,   0.9143,   6.6544,  27.9506,  10.7197,  -6.8169, -14.2786,\n",
      "          29.4206,  22.1183,   3.3621,  12.0283,   9.0051,  15.7378,  -2.3772,\n",
      "           4.1044,   0.4624, -26.0153,  21.0976,  15.3679,  10.0158,  12.4100,\n",
      "          -5.3891, -13.0040, -28.2716,   2.5989,  -6.5878,   6.8143,  22.0877,\n",
      "           1.6651,   1.0400]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.2891e+00,  1.3255e+02,  2.3357e+01, -8.1492e+00, -1.9261e+01,\n",
      "          2.0295e+00, -3.8154e+00, -1.4903e+01,  2.2798e+01,  5.0421e+00,\n",
      "         -1.3012e+01,  2.0772e+00,  9.1673e+00,  1.5337e+00,  6.3178e+00,\n",
      "          9.5593e+00, -7.6676e+00, -8.3254e-01,  3.3539e+00,  2.1508e+01,\n",
      "          1.0868e+01,  3.1590e+00, -1.4517e+00, -7.9012e-01,  1.1237e+01,\n",
      "         -2.4966e+00,  4.9686e+00, -1.2937e+00, -6.3536e+00, -1.9129e+00,\n",
      "          8.6312e+00, -2.5873e+01, -2.7312e+00, -3.3170e+00,  5.1831e+00,\n",
      "         -1.0823e+01, -1.3790e+01, -1.5545e+00, -1.1107e+01,  1.7643e+01,\n",
      "         -1.6455e+00,  2.4640e+00, -1.1938e+01,  2.6603e+01,  1.8980e+01,\n",
      "         -5.9993e+00,  1.2517e+01, -4.7750e+00, -1.1232e+01,  1.6634e+01,\n",
      "          4.2449e+00, -2.2065e+00, -7.7859e+00, -1.4015e+01, -1.7777e+01,\n",
      "         -9.5098e+00, -7.0768e+00, -1.1705e+01, -3.4045e+00, -6.8620e+00,\n",
      "         -1.0470e+01, -1.6161e+01, -1.1307e+00, -4.6008e+00, -7.9977e+00,\n",
      "          3.1876e+01,  7.5228e-01,  6.6843e+00, -2.0744e+01,  7.8233e+00,\n",
      "         -1.3903e+01,  7.1171e-01,  9.1697e+00,  9.9196e+00,  1.4860e+01,\n",
      "         -4.0193e+00,  1.6771e+01, -1.5253e+01,  2.3710e+01,  5.6348e+00,\n",
      "         -9.7437e+00,  2.0689e+01, -1.3228e+01, -7.2085e+00,  6.3327e+00,\n",
      "         -3.0774e-02, -6.2980e+00,  4.1342e-01, -5.5800e+00, -1.7727e+01,\n",
      "         -8.6235e+00, -3.0046e+00,  9.2165e+00, -1.3266e+01, -1.1353e+01,\n",
      "          9.8905e-01, -4.6082e+00,  1.4214e+01, -3.2384e-01,  1.3046e+00,\n",
      "          6.4493e+00,  2.7555e+01,  1.0635e+01, -7.5621e+00, -1.3946e+01,\n",
      "          2.9026e+01,  2.1792e+01,  2.9583e+00,  1.1870e+01,  8.1781e+00,\n",
      "          1.5784e+01, -2.2576e+00,  3.7374e+00,  7.9025e-01, -2.5834e+01,\n",
      "          2.0521e+01,  1.5789e+01,  1.0003e+01,  1.2407e+01, -4.9853e+00,\n",
      "         -1.3324e+01, -2.7885e+01,  3.7240e+00, -6.1029e+00,  6.9016e+00,\n",
      "          2.2806e+01,  1.4419e+00,  1.3676e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0054e+01,  1.3257e+02,  2.3979e+01, -8.7783e+00, -1.9027e+01,\n",
      "          2.5304e+00, -3.7056e+00, -1.5580e+01,  2.2618e+01,  5.7378e+00,\n",
      "         -1.2648e+01,  2.2020e+00,  9.3498e+00,  1.9676e+00,  7.1819e+00,\n",
      "          9.5858e+00, -7.3318e+00, -1.9433e+00,  3.9793e+00,  2.2040e+01,\n",
      "          1.2183e+01,  2.3004e+00, -1.7461e+00, -2.9726e-01,  1.0670e+01,\n",
      "         -2.0095e+00,  4.7045e+00, -1.1346e+00, -6.5272e+00, -1.9277e+00,\n",
      "          9.4493e+00, -2.5798e+01, -3.1598e+00, -2.6238e+00,  5.5807e+00,\n",
      "         -1.1396e+01, -1.2726e+01, -1.8391e+00, -1.1399e+01,  1.6844e+01,\n",
      "         -1.9907e+00,  2.2738e+00, -1.2824e+01,  2.6787e+01,  1.9642e+01,\n",
      "         -5.4958e+00,  1.3380e+01, -4.4671e+00, -1.1156e+01,  1.6294e+01,\n",
      "          5.4232e+00, -3.2002e+00, -7.9244e+00, -1.4074e+01, -1.7751e+01,\n",
      "         -9.2240e+00, -7.2431e+00, -1.1258e+01, -3.7891e+00, -6.3453e+00,\n",
      "         -1.0410e+01, -1.7257e+01, -1.0164e-01, -4.8803e+00, -7.1904e+00,\n",
      "          3.2482e+01,  5.1121e-01,  6.2202e+00, -2.1486e+01,  8.2380e+00,\n",
      "         -1.4593e+01,  6.8908e-01,  8.9131e+00,  9.1513e+00,  1.4317e+01,\n",
      "         -3.9224e+00,  1.6617e+01, -1.5375e+01,  2.3971e+01,  5.7302e+00,\n",
      "         -8.6827e+00,  1.9685e+01, -1.3671e+01, -7.2303e+00,  5.4208e+00,\n",
      "          8.8578e-01, -5.8214e+00,  1.0170e+00, -5.2182e+00, -1.6379e+01,\n",
      "         -9.6389e+00, -3.7203e+00,  9.2610e+00, -1.2363e+01, -1.1801e+01,\n",
      "          1.0299e+00, -5.0461e+00,  1.3449e+01,  1.6768e-01,  1.5339e+00,\n",
      "          6.7449e+00,  2.7234e+01,  1.0584e+01, -7.5332e+00, -1.3770e+01,\n",
      "          2.9104e+01,  2.2323e+01,  2.7720e+00,  1.1737e+01,  9.8786e+00,\n",
      "          1.5782e+01, -2.5385e+00,  4.1120e+00,  1.1360e-01, -2.6133e+01,\n",
      "          2.0263e+01,  1.4815e+01,  1.0303e+01,  1.2045e+01, -4.9497e+00,\n",
      "         -1.2661e+01, -2.9301e+01,  3.9515e+00, -5.4727e+00,  6.9187e+00,\n",
      "          2.2825e+01,  7.1504e-01,  7.8396e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0050e+01,  1.3239e+02,  2.4657e+01, -8.6902e+00, -1.8939e+01,\n",
      "          1.8399e+00, -3.5049e+00, -1.5124e+01,  2.2391e+01,  5.3257e+00,\n",
      "         -1.2452e+01,  2.4136e+00,  9.3836e+00,  1.8710e+00,  6.0934e+00,\n",
      "          9.4711e+00, -8.2589e+00, -1.6041e+00,  3.1756e+00,  2.0508e+01,\n",
      "          1.1528e+01,  3.0727e+00, -1.4862e+00, -3.4557e-01,  1.0584e+01,\n",
      "         -2.0928e+00,  4.7431e+00, -1.0300e+00, -6.4914e+00, -1.4480e+00,\n",
      "          9.2312e+00, -2.5739e+01, -3.9040e+00, -2.6923e+00,  5.7581e+00,\n",
      "         -1.0871e+01, -1.2458e+01, -1.7909e+00, -1.1013e+01,  1.6992e+01,\n",
      "         -9.4819e-01,  2.5448e+00, -1.2660e+01,  2.6111e+01,  1.9579e+01,\n",
      "         -6.0688e+00,  1.2583e+01, -4.1980e+00, -1.0631e+01,  1.7220e+01,\n",
      "          4.9554e+00, -3.1371e+00, -7.5044e+00, -1.4022e+01, -1.8840e+01,\n",
      "         -9.4129e+00, -6.9346e+00, -1.1585e+01, -3.5278e+00, -6.9630e+00,\n",
      "         -1.0493e+01, -1.6496e+01, -5.7317e-01, -3.8806e+00, -8.1348e+00,\n",
      "          3.2303e+01,  8.9229e-01,  6.7120e+00, -2.0574e+01,  9.4440e+00,\n",
      "         -1.4050e+01,  1.0232e+00,  1.0336e+01,  1.0347e+01,  1.4532e+01,\n",
      "         -3.4707e+00,  1.6849e+01, -1.5173e+01,  2.3594e+01,  5.6719e+00,\n",
      "         -9.1167e+00,  2.0743e+01, -1.3396e+01, -6.3191e+00,  6.3829e+00,\n",
      "          7.6150e-01, -4.8282e+00, -1.0950e-01, -5.8398e+00, -1.6933e+01,\n",
      "         -8.3804e+00, -2.5538e+00,  9.0329e+00, -1.3114e+01, -1.2681e+01,\n",
      "          1.6198e+00, -4.9773e+00,  1.3835e+01,  6.5869e-01,  1.5609e+00,\n",
      "          7.5418e+00,  2.7746e+01,  1.0568e+01, -7.4408e+00, -1.3747e+01,\n",
      "          2.9464e+01,  2.1756e+01,  3.4576e+00,  1.1430e+01,  9.3786e+00,\n",
      "          1.6002e+01, -3.4639e+00,  4.8303e+00,  7.9365e-01, -2.5052e+01,\n",
      "          2.0609e+01,  1.5885e+01,  1.0270e+01,  1.2399e+01, -5.1490e+00,\n",
      "         -1.3709e+01, -2.9035e+01,  3.6509e+00, -5.7698e+00,  6.7579e+00,\n",
      "          2.3175e+01,  2.2026e+00,  3.6803e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[  9.8459, 132.5853,  24.5528,  -8.5488, -18.9837,   2.1124,  -3.6239,\n",
      "         -15.4692,  23.5049,   4.4446, -12.8568,   2.0338,   9.2822,   0.7382,\n",
      "           6.0568,   9.2479,  -7.1564,  -0.9626,   3.0972,  21.2470,  11.1529,\n",
      "           2.7562,  -1.4701,  -0.4112,  10.7211,  -2.4143,   4.6926,  -0.9232,\n",
      "          -6.7928,  -1.6166,   9.0081, -25.9770,  -2.7020,  -2.7600,   5.6306,\n",
      "         -11.2689, -12.2892,  -0.9019, -10.7855,  16.9535,  -1.5859,   2.4135,\n",
      "         -11.7127,  26.5621,  19.1971,  -5.7141,  12.9031,  -4.0753, -11.5765,\n",
      "          16.4780,   4.4231,  -2.0652,  -8.2593, -14.5122, -18.0235,  -9.0644,\n",
      "          -6.7071, -11.3305,  -2.8582,  -5.9898, -10.7623, -15.9387,  -1.0932,\n",
      "          -5.3635,  -7.8873,  31.7682,   0.6530,   6.2994, -20.8945,   7.8610,\n",
      "         -14.2465,   1.0462,   9.5256,  10.2047,  14.7108,  -3.7224,  16.3874,\n",
      "         -14.7616,  23.5924,   5.6808,  -9.5987,  21.0077, -13.4412,  -7.2568,\n",
      "           6.5449,   0.3737,  -5.9014,   0.7368,  -5.9158, -16.7365,  -8.3607,\n",
      "          -3.0675,   8.3717, -12.9159, -11.8884,   1.2066,  -5.3225,  13.9361,\n",
      "          -0.2323,   0.9770,   6.7052,  27.9926,  10.7256,  -6.8693, -14.0919,\n",
      "          29.5640,  21.9733,   3.1881,  12.0172,   8.9769,  15.7659,  -2.6635,\n",
      "           4.0796,   0.5272, -25.8037,  21.0330,  15.7539,   9.8886,  12.3398,\n",
      "          -5.2840, -13.1633, -28.4246,   2.6276,  -6.4597,   6.9223,  22.3036,\n",
      "           1.6179,   0.9844]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.2636e+00,  1.3253e+02,  2.3455e+01, -8.1452e+00, -1.9079e+01,\n",
      "          2.1337e+00, -3.6555e+00, -1.4918e+01,  2.2802e+01,  5.0611e+00,\n",
      "         -1.2992e+01,  2.1003e+00,  9.2133e+00,  1.3800e+00,  6.3457e+00,\n",
      "          9.6069e+00, -7.6256e+00, -1.0558e+00,  3.4627e+00,  2.1308e+01,\n",
      "          1.1026e+01,  3.1188e+00, -1.4910e+00, -7.5161e-01,  1.1438e+01,\n",
      "         -2.7594e+00,  4.9442e+00, -1.4869e+00, -6.2965e+00, -1.9314e+00,\n",
      "          8.4269e+00, -2.5845e+01, -2.5991e+00, -3.3869e+00,  5.2274e+00,\n",
      "         -1.0900e+01, -1.4014e+01, -1.5322e+00, -1.1026e+01,  1.7814e+01,\n",
      "         -1.5554e+00,  2.2652e+00, -1.2032e+01,  2.6605e+01,  1.8906e+01,\n",
      "         -5.9688e+00,  1.2480e+01, -4.7135e+00, -1.1304e+01,  1.6825e+01,\n",
      "          4.1024e+00, -2.1057e+00, -7.7361e+00, -1.4105e+01, -1.8129e+01,\n",
      "         -9.5680e+00, -6.9833e+00, -1.1805e+01, -3.4489e+00, -6.9656e+00,\n",
      "         -1.0576e+01, -1.6263e+01, -1.0645e+00, -4.5229e+00, -8.1006e+00,\n",
      "          3.1888e+01,  7.8615e-01,  6.7085e+00, -2.0801e+01,  7.9072e+00,\n",
      "         -1.3718e+01,  6.7518e-01,  9.2326e+00,  9.8287e+00,  1.4865e+01,\n",
      "         -4.0346e+00,  1.6654e+01, -1.5173e+01,  2.3568e+01,  5.4454e+00,\n",
      "         -9.6702e+00,  2.0748e+01, -1.3215e+01, -7.1254e+00,  6.3796e+00,\n",
      "         -1.2817e-01, -6.2778e+00,  4.1197e-01, -5.5602e+00, -1.7780e+01,\n",
      "         -8.6497e+00, -2.9842e+00,  9.2511e+00, -1.3321e+01, -1.1386e+01,\n",
      "          9.6270e-01, -4.5713e+00,  1.4187e+01, -1.4910e-01,  1.2624e+00,\n",
      "          6.5490e+00,  2.7635e+01,  1.0625e+01, -7.6057e+00, -1.3757e+01,\n",
      "          2.9223e+01,  2.1681e+01,  2.8046e+00,  1.1890e+01,  8.2328e+00,\n",
      "          1.5832e+01, -2.5906e+00,  3.7134e+00,  8.3273e-01, -2.5690e+01,\n",
      "          2.0516e+01,  1.6131e+01,  9.8270e+00,  1.2373e+01, -4.9069e+00,\n",
      "         -1.3444e+01, -2.8011e+01,  3.6585e+00, -5.9813e+00,  6.9752e+00,\n",
      "          2.2997e+01,  1.3588e+00,  1.2967e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0001e+01,  1.3257e+02,  2.4012e+01, -8.7616e+00, -1.8909e+01,\n",
      "          2.5955e+00, -3.5853e+00, -1.5481e+01,  2.2594e+01,  5.7044e+00,\n",
      "         -1.2612e+01,  2.2506e+00,  9.3502e+00,  1.8265e+00,  7.1667e+00,\n",
      "          9.6611e+00, -7.3463e+00, -2.0543e+00,  4.0123e+00,  2.1786e+01,\n",
      "          1.2264e+01,  2.3206e+00, -1.7023e+00, -2.3639e-01,  1.0867e+01,\n",
      "         -2.2513e+00,  4.6770e+00, -1.2995e+00, -6.5003e+00, -1.9668e+00,\n",
      "          9.2177e+00, -2.5778e+01, -3.0667e+00, -2.7654e+00,  5.5700e+00,\n",
      "         -1.1438e+01, -1.2970e+01, -1.8007e+00, -1.1318e+01,  1.7054e+01,\n",
      "         -1.9559e+00,  2.0938e+00, -1.2831e+01,  2.6767e+01,  1.9490e+01,\n",
      "         -5.5223e+00,  1.3286e+01, -4.4321e+00, -1.1182e+01,  1.6534e+01,\n",
      "          5.2021e+00, -3.1279e+00, -7.8864e+00, -1.4175e+01, -1.8059e+01,\n",
      "         -9.2691e+00, -7.1294e+00, -1.1466e+01, -3.8790e+00, -6.4970e+00,\n",
      "         -1.0484e+01, -1.7285e+01, -9.2455e-02, -4.7374e+00, -7.2738e+00,\n",
      "          3.2471e+01,  5.2911e-01,  6.2470e+00, -2.1460e+01,  8.3001e+00,\n",
      "         -1.4360e+01,  6.5773e-01,  8.9827e+00,  9.1243e+00,  1.4352e+01,\n",
      "         -3.8955e+00,  1.6550e+01, -1.5348e+01,  2.3827e+01,  5.5498e+00,\n",
      "         -8.6708e+00,  1.9840e+01, -1.3629e+01, -7.1599e+00,  5.5361e+00,\n",
      "          7.6271e-01, -5.8231e+00,  8.8872e-01, -5.2158e+00, -1.6521e+01,\n",
      "         -9.6179e+00, -3.6757e+00,  9.3351e+00, -1.2488e+01, -1.1814e+01,\n",
      "          1.0173e+00, -5.0167e+00,  1.3498e+01,  3.2767e-01,  1.4600e+00,\n",
      "          6.8511e+00,  2.7332e+01,  1.0548e+01, -7.5882e+00, -1.3602e+01,\n",
      "          2.9238e+01,  2.2227e+01,  2.6483e+00,  1.1711e+01,  9.8463e+00,\n",
      "          1.5818e+01, -2.8436e+00,  4.0962e+00,  2.1611e-01, -2.5999e+01,\n",
      "          2.0297e+01,  1.5183e+01,  1.0099e+01,  1.2024e+01, -4.8866e+00,\n",
      "         -1.2821e+01, -2.9333e+01,  3.8987e+00, -5.3572e+00,  6.9632e+00,\n",
      "          2.3029e+01,  7.2360e-01,  7.2468e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.9747e+00,  1.3238e+02,  2.4632e+01, -8.6741e+00, -1.8759e+01,\n",
      "          1.9289e+00, -3.4151e+00, -1.5003e+01,  2.2380e+01,  5.3261e+00,\n",
      "         -1.2420e+01,  2.4794e+00,  9.4032e+00,  1.7602e+00,  6.1407e+00,\n",
      "          9.5666e+00, -8.2228e+00, -1.7484e+00,  3.3036e+00,  2.0354e+01,\n",
      "          1.1611e+01,  3.1048e+00, -1.4798e+00, -2.5206e-01,  1.0758e+01,\n",
      "         -2.3095e+00,  4.7780e+00, -1.1483e+00, -6.5066e+00, -1.5331e+00,\n",
      "          9.0744e+00, -2.5728e+01, -3.8166e+00, -2.8421e+00,  5.7365e+00,\n",
      "         -1.0907e+01, -1.2793e+01, -1.7996e+00, -1.0906e+01,  1.7245e+01,\n",
      "         -8.9100e-01,  2.3733e+00, -1.2674e+01,  2.6135e+01,  1.9447e+01,\n",
      "         -6.0360e+00,  1.2486e+01, -4.1756e+00, -1.0624e+01,  1.7373e+01,\n",
      "          4.8100e+00, -3.0659e+00, -7.4729e+00, -1.4111e+01, -1.9056e+01,\n",
      "         -9.4444e+00, -6.8907e+00, -1.1744e+01, -3.5659e+00, -7.1085e+00,\n",
      "         -1.0514e+01, -1.6516e+01, -5.3091e-01, -3.8199e+00, -8.1327e+00,\n",
      "          3.2329e+01,  8.5582e-01,  6.7043e+00, -2.0579e+01,  9.4013e+00,\n",
      "         -1.3857e+01,  9.5828e-01,  1.0360e+01,  1.0237e+01,  1.4558e+01,\n",
      "         -3.4947e+00,  1.6770e+01, -1.5160e+01,  2.3459e+01,  5.4792e+00,\n",
      "         -9.1026e+00,  2.0911e+01, -1.3437e+01, -6.3021e+00,  6.4715e+00,\n",
      "          6.5013e-01, -4.9200e+00, -9.9160e-02, -5.7957e+00, -1.7078e+01,\n",
      "         -8.4723e+00, -2.5450e+00,  9.1478e+00, -1.3183e+01, -1.2622e+01,\n",
      "          1.5988e+00, -4.8886e+00,  1.3825e+01,  8.6263e-01,  1.4755e+00,\n",
      "          7.5953e+00,  2.7848e+01,  1.0551e+01, -7.5205e+00, -1.3574e+01,\n",
      "          2.9560e+01,  2.1662e+01,  3.3397e+00,  1.1442e+01,  9.3426e+00,\n",
      "          1.5999e+01, -3.7464e+00,  4.7602e+00,  8.8727e-01, -2.4938e+01,\n",
      "          2.0629e+01,  1.6192e+01,  1.0098e+01,  1.2347e+01, -5.0431e+00,\n",
      "         -1.3867e+01, -2.9079e+01,  3.6112e+00, -5.6489e+00,  6.7860e+00,\n",
      "          2.3358e+01,  2.1171e+00,  3.0666e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.8669e+00,  1.3257e+02,  2.4559e+01, -8.5548e+00, -1.8774e+01,\n",
      "          2.1179e+00, -3.5327e+00, -1.5352e+01,  2.3370e+01,  4.4419e+00,\n",
      "         -1.2741e+01,  2.1294e+00,  9.3249e+00,  7.1025e-01,  6.1662e+00,\n",
      "          9.4020e+00, -7.1280e+00, -1.1417e+00,  3.2257e+00,  2.1072e+01,\n",
      "          1.1247e+01,  2.8246e+00, -1.4397e+00, -2.3558e-01,  1.0854e+01,\n",
      "         -2.6402e+00,  4.7660e+00, -9.8513e-01, -6.8680e+00, -1.6636e+00,\n",
      "          8.8909e+00, -2.6006e+01, -2.7217e+00, -2.8759e+00,  5.6291e+00,\n",
      "         -1.1292e+01, -1.2679e+01, -9.8156e-01, -1.0693e+01,  1.7189e+01,\n",
      "         -1.4872e+00,  2.1963e+00, -1.1748e+01,  2.6567e+01,  1.9117e+01,\n",
      "         -5.7012e+00,  1.2767e+01, -4.0633e+00, -1.1494e+01,  1.6617e+01,\n",
      "          4.2920e+00, -2.0816e+00, -8.1772e+00, -1.4531e+01, -1.8260e+01,\n",
      "         -9.1861e+00, -6.6450e+00, -1.1499e+01, -2.9326e+00, -6.1963e+00,\n",
      "         -1.0727e+01, -1.5961e+01, -9.5397e-01, -5.2105e+00, -7.9753e+00,\n",
      "          3.1788e+01,  5.8999e-01,  6.3579e+00, -2.0864e+01,  7.9890e+00,\n",
      "         -1.4062e+01,  9.6458e-01,  9.5765e+00,  1.0097e+01,  1.4712e+01,\n",
      "         -3.7020e+00,  1.6328e+01, -1.4814e+01,  2.3449e+01,  5.5518e+00,\n",
      "         -9.5624e+00,  2.1198e+01, -1.3522e+01, -7.1905e+00,  6.5914e+00,\n",
      "          3.5543e-01, -5.8562e+00,  7.1079e-01, -5.8957e+00, -1.6918e+01,\n",
      "         -8.4491e+00, -3.0092e+00,  8.5179e+00, -1.3019e+01, -1.1949e+01,\n",
      "          1.1856e+00, -5.1264e+00,  1.3925e+01,  3.8986e-02,  9.7275e-01,\n",
      "          6.8005e+00,  2.8095e+01,  1.0729e+01, -6.9046e+00, -1.3908e+01,\n",
      "          2.9661e+01,  2.1874e+01,  3.0308e+00,  1.1962e+01,  8.9836e+00,\n",
      "          1.5788e+01, -2.9884e+00,  4.0333e+00,  6.1966e-01, -2.5606e+01,\n",
      "          2.1023e+01,  1.6072e+01,  9.7305e+00,  1.2327e+01, -5.1538e+00,\n",
      "         -1.3340e+01, -2.8579e+01,  2.6653e+00, -6.3719e+00,  7.0067e+00,\n",
      "          2.2540e+01,  1.5890e+00,  9.0706e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.3197e+00,  1.3248e+02,  2.3563e+01, -8.1519e+00, -1.8808e+01,\n",
      "          2.1880e+00, -3.5204e+00, -1.4897e+01,  2.2721e+01,  5.0190e+00,\n",
      "         -1.2898e+01,  2.2262e+00,  9.2335e+00,  1.3093e+00,  6.4518e+00,\n",
      "          9.6884e+00, -7.5341e+00, -1.3368e+00,  3.5953e+00,  2.1143e+01,\n",
      "          1.1195e+01,  3.1397e+00, -1.5274e+00, -5.7498e-01,  1.1582e+01,\n",
      "         -3.0273e+00,  5.0356e+00, -1.4891e+00, -6.3592e+00, -1.9679e+00,\n",
      "          8.3626e+00, -2.5859e+01, -2.6255e+00, -3.4629e+00,  5.2861e+00,\n",
      "         -1.0929e+01, -1.4317e+01, -1.5993e+00, -1.0890e+01,  1.8009e+01,\n",
      "         -1.3700e+00,  2.0768e+00, -1.2087e+01,  2.6635e+01,  1.8860e+01,\n",
      "         -5.9073e+00,  1.2350e+01, -4.6746e+00, -1.1207e+01,  1.6918e+01,\n",
      "          4.0193e+00, -2.1006e+00, -7.6760e+00, -1.4137e+01, -1.8367e+01,\n",
      "         -9.7019e+00, -6.9179e+00, -1.1842e+01, -3.4468e+00, -7.0979e+00,\n",
      "         -1.0563e+01, -1.6271e+01, -9.3053e-01, -4.4679e+00, -8.2480e+00,\n",
      "          3.1874e+01,  7.6070e-01,  6.7999e+00, -2.0758e+01,  8.0625e+00,\n",
      "         -1.3590e+01,  6.1810e-01,  9.2894e+00,  9.6961e+00,  1.4867e+01,\n",
      "         -4.0335e+00,  1.6562e+01, -1.5173e+01,  2.3405e+01,  5.3129e+00,\n",
      "         -9.6197e+00,  2.0870e+01, -1.3340e+01, -7.0554e+00,  6.4183e+00,\n",
      "         -1.2387e-01, -6.2145e+00,  5.0322e-01, -5.5288e+00, -1.7893e+01,\n",
      "         -8.7483e+00, -2.9288e+00,  9.3385e+00, -1.3391e+01, -1.1470e+01,\n",
      "          9.2016e-01, -4.4099e+00,  1.4140e+01,  6.9057e-02,  1.2339e+00,\n",
      "          6.6421e+00,  2.7790e+01,  1.0628e+01, -7.6016e+00, -1.3598e+01,\n",
      "          2.9381e+01,  2.1581e+01,  2.6479e+00,  1.1880e+01,  8.2809e+00,\n",
      "          1.5808e+01, -2.9172e+00,  3.6324e+00,  8.2604e-01, -2.5538e+01,\n",
      "          2.0489e+01,  1.6383e+01,  9.6187e+00,  1.2355e+01, -4.7432e+00,\n",
      "         -1.3625e+01, -2.8170e+01,  3.6454e+00, -5.9511e+00,  7.0850e+00,\n",
      "          2.3228e+01,  1.2816e+00,  1.2447e+00]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0050e+01,  1.3252e+02,  2.4086e+01, -8.7006e+00, -1.8728e+01,\n",
      "          2.6472e+00, -3.3915e+00, -1.5453e+01,  2.2470e+01,  5.6416e+00,\n",
      "         -1.2549e+01,  2.3929e+00,  9.3591e+00,  1.7437e+00,  7.2385e+00,\n",
      "          9.7363e+00, -7.2473e+00, -2.2655e+00,  4.0565e+00,  2.1600e+01,\n",
      "          1.2411e+01,  2.3714e+00, -1.7201e+00, -1.0783e-01,  1.1071e+01,\n",
      "         -2.5909e+00,  4.7878e+00, -1.2832e+00, -6.5280e+00, -1.9722e+00,\n",
      "          9.1040e+00, -2.5756e+01, -3.0426e+00, -2.8952e+00,  5.6469e+00,\n",
      "         -1.1429e+01, -1.3300e+01, -1.8652e+00, -1.1204e+01,  1.7233e+01,\n",
      "         -1.7738e+00,  1.9306e+00, -1.2839e+01,  2.6797e+01,  1.9395e+01,\n",
      "         -5.5123e+00,  1.3124e+01, -4.4057e+00, -1.1098e+01,  1.6664e+01,\n",
      "          5.0543e+00, -3.1247e+00, -7.8404e+00, -1.4158e+01, -1.8252e+01,\n",
      "         -9.4591e+00, -7.0503e+00, -1.1530e+01, -3.8770e+00, -6.6522e+00,\n",
      "         -1.0486e+01, -1.7248e+01, -8.5361e-03, -4.6504e+00, -7.5016e+00,\n",
      "          3.2372e+01,  5.4812e-01,  6.3970e+00, -2.1356e+01,  8.4616e+00,\n",
      "         -1.4190e+01,  6.2562e-01,  9.0101e+00,  9.0214e+00,  1.4391e+01,\n",
      "         -3.9153e+00,  1.6532e+01, -1.5370e+01,  2.3641e+01,  5.4068e+00,\n",
      "         -8.6477e+00,  1.9915e+01, -1.3724e+01, -7.0643e+00,  5.6039e+00,\n",
      "          7.3690e-01, -5.7219e+00,  9.0927e-01, -5.1810e+00, -1.6742e+01,\n",
      "         -9.5944e+00, -3.5983e+00,  9.4569e+00, -1.2620e+01, -1.1885e+01,\n",
      "          9.6215e-01, -4.8561e+00,  1.3517e+01,  4.1364e-01,  1.4473e+00,\n",
      "          6.9108e+00,  2.7467e+01,  1.0546e+01, -7.5840e+00, -1.3489e+01,\n",
      "          2.9375e+01,  2.2103e+01,  2.4865e+00,  1.1711e+01,  9.7840e+00,\n",
      "          1.5802e+01, -3.0987e+00,  3.9988e+00,  1.8896e-01, -2.5835e+01,\n",
      "          2.0230e+01,  1.5430e+01,  9.8708e+00,  1.1988e+01, -4.7070e+00,\n",
      "         -1.3007e+01, -2.9406e+01,  3.9378e+00, -5.3400e+00,  7.1168e+00,\n",
      "          2.3278e+01,  6.8576e-01,  7.1790e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.9631e+00,  1.3232e+02,  2.4656e+01, -8.5834e+00, -1.8572e+01,\n",
      "          2.0664e+00, -3.2005e+00, -1.4988e+01,  2.2294e+01,  5.3257e+00,\n",
      "         -1.2426e+01,  2.5993e+00,  9.4366e+00,  1.6679e+00,  6.2206e+00,\n",
      "          9.6422e+00, -8.1132e+00, -1.9574e+00,  3.4439e+00,  2.0290e+01,\n",
      "          1.1794e+01,  3.1463e+00, -1.5310e+00, -1.7847e-01,  1.0996e+01,\n",
      "         -2.6589e+00,  4.8903e+00, -1.1789e+00, -6.5108e+00, -1.5693e+00,\n",
      "          8.9687e+00, -2.5681e+01, -3.6905e+00, -2.9622e+00,  5.8013e+00,\n",
      "         -1.0902e+01, -1.3133e+01, -1.8714e+00, -1.0834e+01,  1.7431e+01,\n",
      "         -7.4951e-01,  2.2237e+00, -1.2705e+01,  2.6180e+01,  1.9392e+01,\n",
      "         -5.9834e+00,  1.2378e+01, -4.1545e+00, -1.0627e+01,  1.7460e+01,\n",
      "          4.7136e+00, -3.0240e+00, -7.4385e+00, -1.4105e+01, -1.9134e+01,\n",
      "         -9.5896e+00, -6.8567e+00, -1.1778e+01, -3.5581e+00, -7.2293e+00,\n",
      "         -1.0522e+01, -1.6536e+01, -4.5469e-01, -3.8012e+00, -8.2657e+00,\n",
      "          3.2237e+01,  8.5333e-01,  6.8001e+00, -2.0540e+01,  9.4342e+00,\n",
      "         -1.3727e+01,  9.6431e-01,  1.0308e+01,  1.0058e+01,  1.4580e+01,\n",
      "         -3.6047e+00,  1.6759e+01, -1.5152e+01,  2.3325e+01,  5.2972e+00,\n",
      "         -9.0536e+00,  2.0904e+01, -1.3523e+01, -6.2480e+00,  6.4957e+00,\n",
      "          6.0419e-01, -4.9112e+00,  7.9596e-03, -5.7218e+00, -1.7261e+01,\n",
      "         -8.5053e+00, -2.5186e+00,  9.3207e+00, -1.3249e+01, -1.2577e+01,\n",
      "          1.5443e+00, -4.7283e+00,  1.3802e+01,  9.1929e-01,  1.4434e+00,\n",
      "          7.5883e+00,  2.7924e+01,  1.0580e+01, -7.5412e+00, -1.3483e+01,\n",
      "          2.9690e+01,  2.1561e+01,  3.1889e+00,  1.1495e+01,  9.3000e+00,\n",
      "          1.6002e+01, -3.9589e+00,  4.6292e+00,  8.2809e-01, -2.4811e+01,\n",
      "          2.0538e+01,  1.6371e+01,  9.9149e+00,  1.2271e+01, -4.8448e+00,\n",
      "         -1.3992e+01, -2.9109e+01,  3.6534e+00, -5.5891e+00,  6.9437e+00,\n",
      "          2.3575e+01,  1.9841e+00,  3.0873e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.8863e+00,  1.3253e+02,  2.4538e+01, -8.5112e+00, -1.8590e+01,\n",
      "          2.2321e+00, -3.3376e+00, -1.5278e+01,  2.3242e+01,  4.4754e+00,\n",
      "         -1.2749e+01,  2.2268e+00,  9.3727e+00,  6.1044e-01,  6.2643e+00,\n",
      "          9.5383e+00, -7.1415e+00, -1.3013e+00,  3.3795e+00,  2.0996e+01,\n",
      "          1.1411e+01,  2.9280e+00, -1.4324e+00, -1.3243e-01,  1.1094e+01,\n",
      "         -2.9683e+00,  4.8530e+00, -1.1103e+00, -6.9368e+00, -1.6765e+00,\n",
      "          8.7952e+00, -2.5986e+01, -2.6266e+00, -2.9783e+00,  5.6644e+00,\n",
      "         -1.1317e+01, -1.3045e+01, -1.0396e+00, -1.0664e+01,  1.7355e+01,\n",
      "         -1.4042e+00,  2.0220e+00, -1.1787e+01,  2.6537e+01,  1.9075e+01,\n",
      "         -5.6860e+00,  1.2676e+01, -4.0413e+00, -1.1529e+01,  1.6755e+01,\n",
      "          4.1459e+00, -2.0899e+00, -8.0987e+00, -1.4499e+01, -1.8393e+01,\n",
      "         -9.3272e+00, -6.6149e+00, -1.1650e+01, -3.0186e+00, -6.3713e+00,\n",
      "         -1.0729e+01, -1.6048e+01, -8.3984e-01, -5.0743e+00, -8.0589e+00,\n",
      "          3.1719e+01,  5.8827e-01,  6.4348e+00, -2.0799e+01,  8.0989e+00,\n",
      "         -1.3915e+01,  9.8671e-01,  9.5466e+00,  9.9291e+00,  1.4693e+01,\n",
      "         -3.7632e+00,  1.6306e+01, -1.4823e+01,  2.3322e+01,  5.3782e+00,\n",
      "         -9.4600e+00,  2.1243e+01, -1.3553e+01, -7.0919e+00,  6.6182e+00,\n",
      "          2.7923e-01, -5.8223e+00,  7.1558e-01, -5.8745e+00, -1.7113e+01,\n",
      "         -8.4672e+00, -2.9721e+00,  8.7641e+00, -1.3132e+01, -1.1969e+01,\n",
      "          1.1622e+00, -4.9523e+00,  1.3904e+01,  1.9384e-01,  9.9186e-01,\n",
      "          6.8325e+00,  2.8121e+01,  1.0757e+01, -6.9400e+00, -1.3769e+01,\n",
      "          2.9771e+01,  2.1765e+01,  2.8651e+00,  1.1968e+01,  8.9829e+00,\n",
      "          1.5850e+01, -3.2581e+00,  3.9500e+00,  6.1181e-01, -2.5415e+01,\n",
      "          2.0964e+01,  1.6315e+01,  9.5553e+00,  1.2246e+01, -4.9776e+00,\n",
      "         -1.3462e+01, -2.8627e+01,  2.7180e+00, -6.2924e+00,  7.1575e+00,\n",
      "          2.2777e+01,  1.5506e+00,  8.7802e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[  9.3436, 132.4504,  23.6039,  -8.1739, -18.5812,   2.2965,  -3.3855,\n",
      "         -14.8375,  22.7044,   4.9985, -12.9266,   2.2829,   9.3032,   1.1715,\n",
      "           6.4877,   9.7672,  -7.5454,  -1.4805,   3.7394,  21.0357,  11.3675,\n",
      "           3.2113,  -1.5029,  -0.4718,  11.7920,  -3.2907,   5.0866,  -1.6221,\n",
      "          -6.4454,  -1.9976,   8.2862, -25.8547,  -2.5329,  -3.5228,   5.3232,\n",
      "         -10.9832, -14.5814,  -1.5781, -10.8270,  18.1332,  -1.3026,   1.9257,\n",
      "         -12.1295,  26.6090,  18.8115,  -5.8570,  12.2824,  -4.5946, -11.2547,\n",
      "          17.0139,   3.8465,  -2.0780,  -7.5871, -14.1620, -18.5530,  -9.7924,\n",
      "          -6.8909, -11.9192,  -3.4901,  -7.1861, -10.6160, -16.3201,  -0.8672,\n",
      "          -4.3557,  -8.2554,  31.8032,   0.7665,   6.8011, -20.6950,   8.1861,\n",
      "         -13.4864,   0.6990,   9.3087,   9.6073,  14.7950,  -4.0531,  16.4785,\n",
      "         -15.1129,  23.2411,   5.1294,  -9.5095,  20.9736, -13.3759,  -6.9735,\n",
      "           6.4696,  -0.2221,  -6.2739,   0.5158,  -5.5561, -17.9717,  -8.8010,\n",
      "          -2.9114,   9.4938, -13.4714, -11.4763,   0.9008,  -4.3124,  14.0988,\n",
      "           0.2469,   1.1920,   6.7056,  27.8806,  10.6377,  -7.6007, -13.4470,\n",
      "          29.5174,  21.4918,   2.4786,  11.8451,   8.3648,  15.8634,  -3.1954,\n",
      "           3.5863,   0.8273, -25.3819,  20.5165,  16.6220,   9.4149,  12.3116,\n",
      "          -4.5972, -13.7595, -28.2136,   3.5967,  -5.9199,   7.1812,  23.4152,\n",
      "           1.3039,   1.1979]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0083e+01,  1.3251e+02,  2.4096e+01, -8.7058e+00, -1.8576e+01,\n",
      "          2.7057e+00, -3.2797e+00, -1.5333e+01,  2.2479e+01,  5.6055e+00,\n",
      "         -1.2560e+01,  2.4211e+00,  9.4561e+00,  1.5737e+00,  7.2261e+00,\n",
      "          9.7935e+00, -7.2343e+00, -2.3247e+00,  4.1030e+00,  2.1401e+01,\n",
      "          1.2504e+01,  2.4443e+00, -1.6651e+00, -3.5244e-02,  1.1277e+01,\n",
      "         -2.8593e+00,  4.8565e+00, -1.3937e+00, -6.6074e+00, -1.9714e+00,\n",
      "          8.9831e+00, -2.5782e+01, -2.9619e+00, -2.9805e+00,  5.6574e+00,\n",
      "         -1.1459e+01, -1.3622e+01, -1.8088e+00, -1.1101e+01,  1.7350e+01,\n",
      "         -1.6923e+00,  1.8030e+00, -1.2866e+01,  2.6776e+01,  1.9261e+01,\n",
      "         -5.5227e+00,  1.3019e+01, -4.3007e+00, -1.1109e+01,  1.6770e+01,\n",
      "          4.7911e+00, -3.0925e+00, -7.7418e+00, -1.4147e+01, -1.8531e+01,\n",
      "         -9.5923e+00, -7.0194e+00, -1.1613e+01, -3.9035e+00, -6.7677e+00,\n",
      "         -1.0541e+01, -1.7225e+01,  4.0488e-03, -4.4945e+00, -7.5420e+00,\n",
      "          3.2258e+01,  5.9877e-01,  6.4077e+00, -2.1264e+01,  8.6159e+00,\n",
      "         -1.4022e+01,  6.9899e-01,  9.0577e+00,  9.0245e+00,  1.4338e+01,\n",
      "         -3.9057e+00,  1.6478e+01, -1.5331e+01,  2.3405e+01,  5.2349e+00,\n",
      "         -8.5676e+00,  2.0113e+01, -1.3752e+01, -6.9939e+00,  5.6975e+00,\n",
      "          5.8708e-01, -5.8196e+00,  7.9894e-01, -5.2552e+00, -1.6908e+01,\n",
      "         -9.5583e+00, -3.5528e+00,  9.5674e+00, -1.2773e+01, -1.1872e+01,\n",
      "          9.2845e-01, -4.7383e+00,  1.3539e+01,  5.5649e-01,  1.4182e+00,\n",
      "          6.9595e+00,  2.7615e+01,  1.0529e+01, -7.5832e+00, -1.3362e+01,\n",
      "          2.9485e+01,  2.1960e+01,  2.3186e+00,  1.1643e+01,  9.7916e+00,\n",
      "          1.5843e+01, -3.3319e+00,  3.9654e+00,  2.7093e-01, -2.5657e+01,\n",
      "          2.0280e+01,  1.5727e+01,  9.6568e+00,  1.1952e+01, -4.5842e+00,\n",
      "         -1.3191e+01, -2.9425e+01,  3.9075e+00, -5.3474e+00,  7.2293e+00,\n",
      "          2.3448e+01,  8.0030e-01,  6.8808e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.9811e+00,  1.3230e+02,  2.4633e+01, -8.5572e+00, -1.8415e+01,\n",
      "          2.1767e+00, -3.0635e+00, -1.4914e+01,  2.2354e+01,  5.3712e+00,\n",
      "         -1.2435e+01,  2.5909e+00,  9.5466e+00,  1.4984e+00,  6.2599e+00,\n",
      "          9.6500e+00, -7.9930e+00, -2.0827e+00,  3.5626e+00,  2.0168e+01,\n",
      "          1.1905e+01,  3.1211e+00, -1.5668e+00, -1.1894e-01,  1.1227e+01,\n",
      "         -2.9491e+00,  4.9766e+00, -1.2505e+00, -6.5145e+00, -1.5757e+00,\n",
      "          8.8600e+00, -2.5756e+01, -3.5908e+00, -3.0190e+00,  5.7833e+00,\n",
      "         -1.0903e+01, -1.3498e+01, -1.8246e+00, -1.0736e+01,  1.7560e+01,\n",
      "         -6.3488e-01,  2.0909e+00, -1.2814e+01,  2.6178e+01,  1.9293e+01,\n",
      "         -5.9576e+00,  1.2336e+01, -4.0602e+00, -1.0647e+01,  1.7451e+01,\n",
      "          4.5070e+00, -2.9664e+00, -7.3581e+00, -1.4087e+01, -1.9421e+01,\n",
      "         -9.7240e+00, -6.8799e+00, -1.1756e+01, -3.5580e+00, -7.3411e+00,\n",
      "         -1.0534e+01, -1.6567e+01, -4.2574e-01, -3.7249e+00, -8.3102e+00,\n",
      "          3.2166e+01,  9.0251e-01,  6.7919e+00, -2.0539e+01,  9.5002e+00,\n",
      "         -1.3561e+01,  9.5975e-01,  1.0295e+01,  1.0013e+01,  1.4515e+01,\n",
      "         -3.6363e+00,  1.6681e+01, -1.5102e+01,  2.3116e+01,  5.1652e+00,\n",
      "         -8.9633e+00,  2.1057e+01, -1.3601e+01, -6.2308e+00,  6.5086e+00,\n",
      "          4.5352e-01, -5.0409e+00, -1.5780e-02, -5.7506e+00, -1.7401e+01,\n",
      "         -8.5509e+00, -2.5228e+00,  9.3993e+00, -1.3384e+01, -1.2498e+01,\n",
      "          1.5025e+00, -4.5557e+00,  1.3778e+01,  1.0820e+00,  1.4330e+00,\n",
      "          7.5813e+00,  2.8082e+01,  1.0589e+01, -7.5697e+00, -1.3389e+01,\n",
      "          2.9799e+01,  2.1407e+01,  3.0071e+00,  1.1457e+01,  9.3344e+00,\n",
      "          1.5986e+01, -4.1744e+00,  4.5294e+00,  9.0334e-01, -2.4649e+01,\n",
      "          2.0543e+01,  1.6598e+01,  9.7429e+00,  1.2196e+01, -4.7446e+00,\n",
      "         -1.4157e+01, -2.9194e+01,  3.6393e+00, -5.5886e+00,  7.0912e+00,\n",
      "          2.3697e+01,  1.9586e+00,  3.0156e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.9581e+00,  1.3252e+02,  2.4523e+01, -8.4942e+00, -1.8447e+01,\n",
      "          2.2875e+00, -3.1654e+00, -1.5261e+01,  2.3224e+01,  4.5570e+00,\n",
      "         -1.2659e+01,  2.1975e+00,  9.4488e+00,  4.4474e-01,  6.3545e+00,\n",
      "          9.5586e+00, -7.0631e+00, -1.4744e+00,  3.5604e+00,  2.0858e+01,\n",
      "          1.1517e+01,  2.8420e+00, -1.4901e+00, -3.7588e-03,  1.1312e+01,\n",
      "         -3.2474e+00,  4.9215e+00, -1.1954e+00, -6.9165e+00, -1.6455e+00,\n",
      "          8.6821e+00, -2.6071e+01, -2.5869e+00, -3.0053e+00,  5.6729e+00,\n",
      "         -1.1277e+01, -1.3498e+01, -1.0136e+00, -1.0552e+01,  1.7520e+01,\n",
      "         -1.2508e+00,  1.7884e+00, -1.1962e+01,  2.6485e+01,  1.8997e+01,\n",
      "         -5.7039e+00,  1.2662e+01, -3.9848e+00, -1.1518e+01,  1.6768e+01,\n",
      "          3.9993e+00, -2.0685e+00, -7.9984e+00, -1.4414e+01, -1.8736e+01,\n",
      "         -9.5081e+00, -6.5935e+00, -1.1679e+01, -3.1149e+00, -6.5367e+00,\n",
      "         -1.0682e+01, -1.6089e+01, -7.1999e-01, -4.9610e+00, -8.2233e+00,\n",
      "          3.1699e+01,  6.3829e-01,  6.4739e+00, -2.0789e+01,  8.2780e+00,\n",
      "         -1.3672e+01,  9.2477e-01,  9.5188e+00,  9.8566e+00,  1.4626e+01,\n",
      "         -3.7767e+00,  1.6188e+01, -1.4826e+01,  2.3145e+01,  5.3159e+00,\n",
      "         -9.3495e+00,  2.1347e+01, -1.3624e+01, -7.0232e+00,  6.6227e+00,\n",
      "          1.8439e-01, -5.8194e+00,  6.5974e-01, -5.9210e+00, -1.7285e+01,\n",
      "         -8.5129e+00, -2.9529e+00,  8.8467e+00, -1.3357e+01, -1.1959e+01,\n",
      "          1.1423e+00, -4.7149e+00,  1.3902e+01,  4.3998e-01,  1.0595e+00,\n",
      "          6.8819e+00,  2.8239e+01,  1.0779e+01, -6.9614e+00, -1.3651e+01,\n",
      "          2.9882e+01,  2.1612e+01,  2.6657e+00,  1.1893e+01,  9.0548e+00,\n",
      "          1.5840e+01, -3.5639e+00,  3.8145e+00,  7.3307e-01, -2.5175e+01,\n",
      "          2.0889e+01,  1.6578e+01,  9.3702e+00,  1.2175e+01, -4.8939e+00,\n",
      "         -1.3613e+01, -2.8799e+01,  2.7692e+00, -6.2340e+00,  7.3286e+00,\n",
      "          2.2913e+01,  1.5153e+00,  8.5607e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[  9.3878, 132.4325,  23.6417,  -8.1429, -18.4066,   2.3908,  -3.1879,\n",
      "         -14.8582,  22.7329,   5.0646, -12.8912,   2.2554,   9.3202,   0.9686,\n",
      "           6.5760,   9.7241,  -7.4462,  -1.7140,   3.9603,  20.9632,  11.5014,\n",
      "           3.0531,  -1.6083,  -0.3651,  12.0138,  -3.5718,   5.1031,  -1.7144,\n",
      "          -6.3672,  -1.9828,   8.1738, -25.9500,  -2.4590,  -3.5426,   5.3270,\n",
      "         -10.9555, -14.9294,  -1.5376, -10.7378,  18.2611,  -1.1104,   1.7119,\n",
      "         -12.2974,  26.5498,  18.7639,  -5.8249,  12.3096,  -4.5763, -11.2461,\n",
      "          17.0325,   3.7452,  -2.0279,  -7.5066, -14.1807, -18.8459,  -9.9229,\n",
      "          -6.8766, -11.8786,  -3.5429,  -7.2992, -10.5659, -16.3916,  -0.7970,\n",
      "          -4.2980,  -8.4417,  31.7984,   0.8094,   6.8482, -20.6876,   8.2994,\n",
      "         -13.2730,   0.6481,   9.2920,   9.5278,  14.7444,  -4.0850,  16.3449,\n",
      "         -15.0740,  23.0929,   5.1102,  -9.4265,  21.0328, -13.4476,  -6.9242,\n",
      "           6.4665,  -0.2999,  -6.2462,   0.5444,  -5.5783, -18.0392,  -8.8967,\n",
      "          -2.9213,   9.5350, -13.6542, -11.4568,   0.8869,  -4.1501,  14.0965,\n",
      "           0.4764,   1.1924,   6.7700,  28.0105,  10.6789,  -7.6012, -13.3284,\n",
      "          29.6654,  21.3725,   2.3225,  11.8309,   8.4826,  15.8241,  -3.5463,\n",
      "           3.4396,   0.8655, -25.1972,  20.4564,  16.8081,   9.1838,  12.2614,\n",
      "          -4.5320, -13.9243, -28.3685,   3.5881,  -5.8909,   7.3242,  23.5233,\n",
      "           1.1966,   1.1667]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0081e+01,  1.3250e+02,  2.4095e+01, -8.6482e+00, -1.8456e+01,\n",
      "          2.7613e+00, -3.0727e+00, -1.5276e+01,  2.2481e+01,  5.6466e+00,\n",
      "         -1.2569e+01,  2.4090e+00,  9.4560e+00,  1.3510e+00,  7.2937e+00,\n",
      "          9.7633e+00, -7.1674e+00, -2.4739e+00,  4.2762e+00,  2.1356e+01,\n",
      "          1.2561e+01,  2.3495e+00, -1.7301e+00,  4.7277e-02,  1.1488e+01,\n",
      "         -3.1536e+00,  4.8654e+00, -1.5154e+00, -6.5534e+00, -1.9578e+00,\n",
      "          8.8176e+00, -2.5861e+01, -2.8303e+00, -3.0822e+00,  5.6324e+00,\n",
      "         -1.1467e+01, -1.3990e+01, -1.7614e+00, -1.1026e+01,  1.7507e+01,\n",
      "         -1.5132e+00,  1.6035e+00, -1.2942e+01,  2.6699e+01,  1.9143e+01,\n",
      "         -5.5310e+00,  1.3003e+01, -4.3427e+00, -1.1086e+01,  1.6865e+01,\n",
      "          4.6339e+00, -3.0442e+00, -7.6659e+00, -1.4209e+01, -1.8767e+01,\n",
      "         -9.7269e+00, -7.0057e+00, -1.1668e+01, -3.9289e+00, -6.9107e+00,\n",
      "         -1.0472e+01, -1.7260e+01,  1.1587e-02, -4.3921e+00, -7.7212e+00,\n",
      "          3.2231e+01,  6.2754e-01,  6.4822e+00, -2.1195e+01,  8.6866e+00,\n",
      "         -1.3776e+01,  6.7381e-01,  9.0466e+00,  8.9576e+00,  1.4354e+01,\n",
      "         -3.9451e+00,  1.6394e+01, -1.5321e+01,  2.3252e+01,  5.2209e+00,\n",
      "         -8.5500e+00,  2.0216e+01, -1.3779e+01, -6.9515e+00,  5.7746e+00,\n",
      "          4.8254e-01, -5.7959e+00,  7.9815e-01, -5.2972e+00, -1.7050e+01,\n",
      "         -9.6010e+00, -3.5540e+00,  9.6262e+00, -1.2968e+01, -1.1848e+01,\n",
      "          9.0731e-01, -4.6241e+00,  1.3612e+01,  7.3863e-01,  1.3648e+00,\n",
      "          7.0087e+00,  2.7715e+01,  1.0567e+01, -7.5760e+00, -1.3226e+01,\n",
      "          2.9587e+01,  2.1822e+01,  2.2078e+00,  1.1656e+01,  9.8184e+00,\n",
      "          1.5811e+01, -3.6584e+00,  3.8196e+00,  2.8688e-01, -2.5495e+01,\n",
      "          2.0243e+01,  1.5934e+01,  9.3737e+00,  1.1918e+01, -4.5133e+00,\n",
      "         -1.3411e+01, -2.9478e+01,  3.9010e+00, -5.3174e+00,  7.3580e+00,\n",
      "          2.3561e+01,  7.1201e-01,  6.6059e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.9261e+00,  1.3231e+02,  2.4590e+01, -8.5076e+00, -1.8264e+01,\n",
      "          2.2658e+00, -2.8888e+00, -1.4826e+01,  2.2381e+01,  5.4299e+00,\n",
      "         -1.2468e+01,  2.5679e+00,  9.5556e+00,  1.2902e+00,  6.3690e+00,\n",
      "          9.6430e+00, -7.9200e+00, -2.2433e+00,  3.8135e+00,  2.0232e+01,\n",
      "          1.1944e+01,  3.0597e+00, -1.6450e+00, -4.3583e-02,  1.1402e+01,\n",
      "         -3.2303e+00,  5.0087e+00, -1.4069e+00, -6.5086e+00, -1.5801e+00,\n",
      "          8.7251e+00, -2.5840e+01, -3.4010e+00, -3.1291e+00,  5.7336e+00,\n",
      "         -1.0982e+01, -1.3870e+01, -1.8016e+00, -1.0681e+01,  1.7750e+01,\n",
      "         -5.0540e-01,  1.8926e+00, -1.2860e+01,  2.6121e+01,  1.9208e+01,\n",
      "         -5.9278e+00,  1.2335e+01, -4.1271e+00, -1.0655e+01,  1.7509e+01,\n",
      "          4.3624e+00, -2.9050e+00, -7.3023e+00, -1.4207e+01, -1.9580e+01,\n",
      "         -9.8366e+00, -6.9132e+00, -1.1810e+01, -3.5401e+00, -7.4648e+00,\n",
      "         -1.0434e+01, -1.6640e+01, -4.1939e-01, -3.6701e+00, -8.3272e+00,\n",
      "          3.2173e+01,  8.6861e-01,  6.8181e+00, -2.0525e+01,  9.4277e+00,\n",
      "         -1.3361e+01,  9.6260e-01,  1.0244e+01,  9.8936e+00,  1.4549e+01,\n",
      "         -3.7033e+00,  1.6594e+01, -1.5073e+01,  2.3010e+01,  5.1229e+00,\n",
      "         -8.9564e+00,  2.1165e+01, -1.3640e+01, -6.2473e+00,  6.6141e+00,\n",
      "          3.5305e-01, -5.1072e+00,  9.8684e-02, -5.7783e+00, -1.7499e+01,\n",
      "         -8.6865e+00, -2.5678e+00,  9.4983e+00, -1.3493e+01, -1.2442e+01,\n",
      "          1.4864e+00, -4.4674e+00,  1.3818e+01,  1.2985e+00,  1.3383e+00,\n",
      "          7.5774e+00,  2.8159e+01,  1.0636e+01, -7.5678e+00, -1.3226e+01,\n",
      "          2.9840e+01,  2.1284e+01,  2.9193e+00,  1.1523e+01,  9.3814e+00,\n",
      "          1.5945e+01, -4.4621e+00,  4.3950e+00,  8.7241e-01, -2.4569e+01,\n",
      "          2.0509e+01,  1.6760e+01,  9.4623e+00,  1.2138e+01, -4.6555e+00,\n",
      "         -1.4365e+01, -2.9209e+01,  3.6064e+00, -5.5218e+00,  7.2011e+00,\n",
      "          2.3770e+01,  1.7926e+00,  2.5268e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.9248e+00,  1.3251e+02,  2.4495e+01, -8.4182e+00, -1.8290e+01,\n",
      "          2.3558e+00, -3.0089e+00, -1.5097e+01,  2.3211e+01,  4.6517e+00,\n",
      "         -1.2683e+01,  2.1632e+00,  9.4963e+00,  2.8487e-01,  6.4782e+00,\n",
      "          9.6124e+00, -7.0220e+00, -1.6207e+00,  3.8369e+00,  2.0862e+01,\n",
      "          1.1509e+01,  2.8481e+00, -1.5159e+00,  4.6495e-02,  1.1464e+01,\n",
      "         -3.5271e+00,  5.0225e+00, -1.3532e+00, -7.0070e+00, -1.6012e+00,\n",
      "          8.5669e+00, -2.6164e+01, -2.4332e+00, -3.0962e+00,  5.6283e+00,\n",
      "         -1.1405e+01, -1.3896e+01, -9.8804e-01, -1.0519e+01,  1.7684e+01,\n",
      "         -1.1249e+00,  1.6342e+00, -1.2023e+01,  2.6434e+01,  1.8920e+01,\n",
      "         -5.6581e+00,  1.2664e+01, -4.0148e+00, -1.1518e+01,  1.6879e+01,\n",
      "          3.8140e+00, -2.0631e+00, -7.9091e+00, -1.4520e+01, -1.8942e+01,\n",
      "         -9.6307e+00, -6.6321e+00, -1.1793e+01, -3.1280e+00, -6.7059e+00,\n",
      "         -1.0591e+01, -1.6194e+01, -6.5851e-01, -4.8159e+00, -8.2358e+00,\n",
      "          3.1682e+01,  6.3613e-01,  6.5293e+00, -2.0795e+01,  8.2993e+00,\n",
      "         -1.3437e+01,  9.7767e-01,  9.5230e+00,  9.7439e+00,  1.4719e+01,\n",
      "         -3.7845e+00,  1.6135e+01, -1.4812e+01,  2.3005e+01,  5.2941e+00,\n",
      "         -9.3029e+00,  2.1518e+01, -1.3646e+01, -6.9938e+00,  6.7439e+00,\n",
      "          7.8629e-02, -5.8566e+00,  7.1125e-01, -5.9760e+00, -1.7418e+01,\n",
      "         -8.6211e+00, -2.9356e+00,  8.9910e+00, -1.3463e+01, -1.1996e+01,\n",
      "          1.1449e+00, -4.5707e+00,  1.3970e+01,  7.1681e-01,  1.0237e+00,\n",
      "          6.8948e+00,  2.8280e+01,  1.0800e+01, -6.9809e+00, -1.3458e+01,\n",
      "          2.9924e+01,  2.1477e+01,  2.5829e+00,  1.1943e+01,  9.1019e+00,\n",
      "          1.5817e+01, -3.8628e+00,  3.7292e+00,  7.5153e-01, -2.5024e+01,\n",
      "          2.0809e+01,  1.6842e+01,  9.1120e+00,  1.2105e+01, -4.7652e+00,\n",
      "         -1.3841e+01, -2.8840e+01,  2.7744e+00, -6.1541e+00,  7.4436e+00,\n",
      "          2.3024e+01,  1.4236e+00,  7.7682e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[  9.3748, 132.4096,  23.7047,  -8.1101, -18.2033,   2.4779,  -3.0582,\n",
      "         -14.7552,  22.7711,   5.1021, -12.9195,   2.2525,   9.3506,   0.7949,\n",
      "           6.6685,   9.7394,  -7.3190,  -1.8904,   4.1849,  20.9069,  11.5199,\n",
      "           3.0186,  -1.6765,  -0.3118,  12.1528,  -3.8329,   5.2084,  -1.8251,\n",
      "          -6.4637,  -1.9124,   8.0817, -26.0007,  -2.3103,  -3.5766,   5.3168,\n",
      "         -11.0981, -15.2348,  -1.4880, -10.6339,  18.3991,  -0.9762,   1.5519,\n",
      "         -12.3563,  26.4984,  18.7091,  -5.7563,  12.3023,  -4.5736, -11.2539,\n",
      "          17.1232,   3.5888,  -1.9804,  -7.4715, -14.2960, -19.1197, -10.0217,\n",
      "          -6.8541, -11.9047,  -3.4874,  -7.4111, -10.5334, -16.4473,  -0.7296,\n",
      "          -4.2461,  -8.4357,  31.7684,   0.8119,   6.8806, -20.7169,   8.3180,\n",
      "         -13.1079,   0.7069,   9.3397,   9.4251,  14.8293,  -4.0639,  16.2484,\n",
      "         -14.9710,  22.9316,   5.0566,  -9.3908,  21.2154, -13.5097,  -6.8968,\n",
      "           6.5847,  -0.3926,  -6.3141,   0.6336,  -5.6774, -18.0876,  -9.0197,\n",
      "          -2.9038,   9.6005, -13.7163, -11.4929,   0.8850,  -4.0669,  14.1047,\n",
      "           0.7471,   1.1332,   6.7733,  28.1131,  10.6909,  -7.5787, -13.1554,\n",
      "          29.7484,  21.2321,   2.2280,  11.9049,   8.5607,  15.7841,  -3.8410,\n",
      "           3.3484,   0.8554, -25.0963,  20.4068,  17.0750,   8.9154,  12.2109,\n",
      "          -4.3983, -14.1277, -28.4528,   3.4983,  -5.8328,   7.4153,  23.5934,\n",
      "           1.0782,   1.0830]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0062e+01,  1.3248e+02,  2.4165e+01, -8.5749e+00, -1.8295e+01,\n",
      "          2.8492e+00, -2.9093e+00, -1.5176e+01,  2.2509e+01,  5.6651e+00,\n",
      "         -1.2618e+01,  2.4334e+00,  9.4731e+00,  1.1678e+00,  7.3290e+00,\n",
      "          9.7711e+00, -6.9606e+00, -2.6053e+00,  4.3883e+00,  2.1215e+01,\n",
      "          1.2551e+01,  2.3281e+00, -1.8049e+00,  5.8687e-02,  1.1684e+01,\n",
      "         -3.4557e+00,  4.9760e+00, -1.5851e+00, -6.6033e+00, -1.8646e+00,\n",
      "          8.6781e+00, -2.5858e+01, -2.6672e+00, -3.1460e+00,  5.6247e+00,\n",
      "         -1.1581e+01, -1.4319e+01, -1.6989e+00, -1.0879e+01,  1.7669e+01,\n",
      "         -1.3794e+00,  1.4465e+00, -1.2999e+01,  2.6642e+01,  1.9030e+01,\n",
      "         -5.5306e+00,  1.2960e+01, -4.3475e+00, -1.1067e+01,  1.6992e+01,\n",
      "          4.4577e+00, -2.9744e+00, -7.6584e+00, -1.4265e+01, -1.9074e+01,\n",
      "         -9.8504e+00, -6.9357e+00, -1.1715e+01, -3.8731e+00, -7.0490e+00,\n",
      "         -1.0480e+01, -1.7257e+01,  6.2285e-02, -4.3503e+00, -7.7898e+00,\n",
      "          3.2154e+01,  6.5347e-01,  6.5491e+00, -2.1204e+01,  8.7144e+00,\n",
      "         -1.3610e+01,  6.9143e-01,  9.0941e+00,  8.8732e+00,  1.4467e+01,\n",
      "         -3.9396e+00,  1.6308e+01, -1.5193e+01,  2.3062e+01,  5.1383e+00,\n",
      "         -8.5516e+00,  2.0429e+01, -1.3852e+01, -6.9103e+00,  5.9010e+00,\n",
      "          3.6130e-01, -5.8581e+00,  8.1885e-01, -5.4236e+00, -1.7173e+01,\n",
      "         -9.6291e+00, -3.5120e+00,  9.6597e+00, -1.3071e+01, -1.1838e+01,\n",
      "          8.8426e-01, -4.5285e+00,  1.3637e+01,  9.2141e-01,  1.3141e+00,\n",
      "          6.9814e+00,  2.7834e+01,  1.0582e+01, -7.5584e+00, -1.3097e+01,\n",
      "          2.9690e+01,  2.1638e+01,  2.0818e+00,  1.1730e+01,  9.8063e+00,\n",
      "          1.5769e+01, -3.9188e+00,  3.6847e+00,  2.9809e-01, -2.5392e+01,\n",
      "          2.0203e+01,  1.6245e+01,  9.1187e+00,  1.1884e+01, -4.3745e+00,\n",
      "         -1.3630e+01, -2.9560e+01,  3.8186e+00, -5.2791e+00,  7.4567e+00,\n",
      "          2.3644e+01,  5.9018e-01,  6.2928e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.8895e+00,  1.3228e+02,  2.4625e+01, -8.4054e+00, -1.8095e+01,\n",
      "          2.4075e+00, -2.7131e+00, -1.4761e+01,  2.2406e+01,  5.5040e+00,\n",
      "         -1.2534e+01,  2.5990e+00,  9.5690e+00,  1.1328e+00,  6.4562e+00,\n",
      "          9.6427e+00, -7.6452e+00, -2.4273e+00,  3.9761e+00,  2.0164e+01,\n",
      "          1.1980e+01,  2.9698e+00, -1.7774e+00, -7.6599e-02,  1.1633e+01,\n",
      "         -3.5288e+00,  5.0791e+00, -1.4848e+00, -6.4912e+00, -1.5096e+00,\n",
      "          8.6012e+00, -2.5837e+01, -3.2170e+00, -3.1652e+00,  5.7202e+00,\n",
      "         -1.1104e+01, -1.4183e+01, -1.7838e+00, -1.0556e+01,  1.7938e+01,\n",
      "         -4.0159e-01,  1.7222e+00, -1.2964e+01,  2.6083e+01,  1.9136e+01,\n",
      "         -5.8976e+00,  1.2324e+01, -4.1488e+00, -1.0668e+01,  1.7570e+01,\n",
      "          4.2360e+00, -2.8087e+00, -7.3022e+00, -1.4249e+01, -1.9810e+01,\n",
      "         -9.9307e+00, -6.8665e+00, -1.1805e+01, -3.5360e+00, -7.5856e+00,\n",
      "         -1.0452e+01, -1.6694e+01, -3.6758e-01, -3.7038e+00, -8.3763e+00,\n",
      "          3.2096e+01,  8.5999e-01,  6.8417e+00, -2.0595e+01,  9.3634e+00,\n",
      "         -1.3243e+01,  9.2150e-01,  1.0202e+01,  9.7404e+00,  1.4628e+01,\n",
      "         -3.7530e+00,  1.6499e+01, -1.4937e+01,  2.2886e+01,  5.0584e+00,\n",
      "         -8.9556e+00,  2.1315e+01, -1.3755e+01, -6.2639e+00,  6.6821e+00,\n",
      "          2.3738e-01, -5.2040e+00,  1.8030e-01, -5.8400e+00, -1.7584e+01,\n",
      "         -8.7738e+00, -2.5758e+00,  9.5573e+00, -1.3580e+01, -1.2366e+01,\n",
      "          1.4597e+00, -4.3414e+00,  1.3781e+01,  1.4495e+00,  1.3003e+00,\n",
      "          7.5110e+00,  2.8271e+01,  1.0688e+01, -7.5767e+00, -1.3124e+01,\n",
      "          2.9953e+01,  2.1122e+01,  2.7377e+00,  1.1615e+01,  9.4188e+00,\n",
      "          1.5890e+01, -4.7068e+00,  4.2004e+00,  8.8838e-01, -2.4492e+01,\n",
      "          2.0434e+01,  1.6989e+01,  9.2710e+00,  1.2095e+01, -4.5360e+00,\n",
      "         -1.4532e+01, -2.9339e+01,  3.5340e+00, -5.4879e+00,  7.2816e+00,\n",
      "          2.3849e+01,  1.5625e+00,  2.4318e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.9382e+00,  1.3249e+02,  2.4487e+01, -8.3050e+00, -1.8111e+01,\n",
      "          2.4696e+00, -2.8293e+00, -1.4998e+01,  2.3150e+01,  4.7494e+00,\n",
      "         -1.2731e+01,  2.1715e+00,  9.5114e+00,  1.7155e-01,  6.5417e+00,\n",
      "          9.6608e+00, -6.8297e+00, -1.7972e+00,  4.0842e+00,  2.0769e+01,\n",
      "          1.1566e+01,  2.7507e+00, -1.6246e+00,  1.5702e-02,  1.1662e+01,\n",
      "         -3.8016e+00,  5.0543e+00, -1.5120e+00, -7.0209e+00, -1.5569e+00,\n",
      "          8.4214e+00, -2.6180e+01, -2.3102e+00, -3.1673e+00,  5.6007e+00,\n",
      "         -1.1511e+01, -1.4249e+01, -1.0073e+00, -1.0413e+01,  1.7837e+01,\n",
      "         -1.0410e+00,  1.4398e+00, -1.2118e+01,  2.6391e+01,  1.8820e+01,\n",
      "         -5.6286e+00,  1.2645e+01, -4.0088e+00, -1.1522e+01,  1.6977e+01,\n",
      "          3.7276e+00, -1.9957e+00, -7.8576e+00, -1.4531e+01, -1.9140e+01,\n",
      "         -9.7292e+00, -6.6006e+00, -1.1884e+01, -3.2119e+00, -6.8612e+00,\n",
      "         -1.0575e+01, -1.6274e+01, -5.6457e-01, -4.7862e+00, -8.2892e+00,\n",
      "          3.1643e+01,  5.6428e-01,  6.5643e+00, -2.0857e+01,  8.3015e+00,\n",
      "         -1.3316e+01,  9.7486e-01,  9.5144e+00,  9.5923e+00,  1.4744e+01,\n",
      "         -3.8396e+00,  1.6017e+01, -1.4717e+01,  2.2916e+01,  5.2552e+00,\n",
      "         -9.2867e+00,  2.1676e+01, -1.3752e+01, -6.9502e+00,  6.8253e+00,\n",
      "          6.6887e-03, -5.8968e+00,  7.0592e-01, -5.9986e+00, -1.7507e+01,\n",
      "         -8.7409e+00, -2.9297e+00,  9.0934e+00, -1.3576e+01, -1.1950e+01,\n",
      "          1.1289e+00, -4.3958e+00,  1.3953e+01,  8.8776e-01,  1.0365e+00,\n",
      "          6.9166e+00,  2.8355e+01,  1.0866e+01, -6.9767e+00, -1.3356e+01,\n",
      "          3.0046e+01,  2.1371e+01,  2.3846e+00,  1.1972e+01,  9.1843e+00,\n",
      "          1.5809e+01, -4.1801e+00,  3.5874e+00,  8.1758e-01, -2.4885e+01,\n",
      "          2.0692e+01,  1.7088e+01,  8.9261e+00,  1.2109e+01, -4.6535e+00,\n",
      "         -1.3999e+01, -2.9010e+01,  2.7798e+00, -6.0986e+00,  7.4943e+00,\n",
      "          2.3161e+01,  1.2680e+00,  7.5869e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[  9.4050, 132.4015,  23.7170,  -8.0455, -17.9819,   2.5787,  -2.9013,\n",
      "         -14.6586,  22.7502,   5.1580, -12.9431,   2.2727,   9.3889,   0.6476,\n",
      "           6.7216,   9.7611,  -7.1715,  -2.0790,   4.4493,  20.8385,  11.6165,\n",
      "           2.9036,  -1.7801,  -0.3484,  12.2889,  -4.0427,   5.2159,  -2.0049,\n",
      "          -6.5298,  -1.9088,   7.9848, -26.0462,  -2.2090,  -3.6485,   5.3166,\n",
      "         -11.2337, -15.5154,  -1.4910, -10.5391,  18.5020,  -0.8811,   1.3606,\n",
      "         -12.3966,  26.4674,  18.6177,  -5.6829,  12.2612,  -4.5195, -11.2629,\n",
      "          17.2031,   3.5195,  -1.9012,  -7.4019, -14.3353, -19.2882, -10.0834,\n",
      "          -6.8509, -11.9767,  -3.5318,  -7.4942, -10.5338, -16.4870,  -0.6753,\n",
      "          -4.2559,  -8.4366,  31.7353,   0.7058,   6.8827, -20.7494,   8.3233,\n",
      "         -13.0311,   0.7403,   9.3578,   9.2853,  14.8104,  -4.0994,  16.1087,\n",
      "         -14.8811,  22.8438,   5.0190,  -9.3751,  21.3831, -13.6194,  -6.8683,\n",
      "           6.6989,  -0.4559,  -6.3875,   0.6407,  -5.6942, -18.1040,  -9.1800,\n",
      "          -2.8994,   9.6706, -13.8142, -11.4788,   0.8661,  -3.9654,  14.0760,\n",
      "           0.9043,   1.1209,   6.8328,  28.2269,  10.7412,  -7.5455, -13.0418,\n",
      "          29.8855,  21.1619,   2.0364,  11.9309,   8.7077,  15.7766,  -4.1721,\n",
      "           3.2122,   0.9085, -24.9881,  20.3180,  17.2800,   8.7189,  12.2323,\n",
      "          -4.3035, -14.2752, -28.5977,   3.4491,  -5.8192,   7.4143,  23.7282,\n",
      "           0.9699,   1.0475]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0094e+01,  1.3247e+02,  2.4138e+01, -8.5026e+00, -1.8117e+01,\n",
      "          2.9233e+00, -2.7505e+00, -1.5034e+01,  2.2483e+01,  5.6947e+00,\n",
      "         -1.2626e+01,  2.4552e+00,  9.5522e+00,  9.8576e-01,  7.3596e+00,\n",
      "          9.7843e+00, -6.8787e+00, -2.7547e+00,  4.5954e+00,  2.1104e+01,\n",
      "          1.2621e+01,  2.2628e+00, -1.8613e+00, -5.2158e-03,  1.1805e+01,\n",
      "         -3.6703e+00,  5.0325e+00, -1.7628e+00, -6.7215e+00, -1.8757e+00,\n",
      "          8.5587e+00, -2.5914e+01, -2.5640e+00, -3.2904e+00,  5.6244e+00,\n",
      "         -1.1691e+01, -1.4653e+01, -1.6794e+00, -1.0790e+01,  1.7790e+01,\n",
      "         -1.2673e+00,  1.2848e+00, -1.2981e+01,  2.6615e+01,  1.8880e+01,\n",
      "         -5.4952e+00,  1.2849e+01, -4.2712e+00, -1.1047e+01,  1.7104e+01,\n",
      "          4.3181e+00, -2.9059e+00, -7.5581e+00, -1.4279e+01, -1.9264e+01,\n",
      "         -9.9523e+00, -6.9858e+00, -1.1822e+01, -3.8618e+00, -7.1420e+00,\n",
      "         -1.0484e+01, -1.7231e+01,  6.6735e-02, -4.3007e+00, -7.7818e+00,\n",
      "          3.2103e+01,  5.6587e-01,  6.6043e+00, -2.1188e+01,  8.7610e+00,\n",
      "         -1.3488e+01,  7.5753e-01,  9.1306e+00,  8.7803e+00,  1.4488e+01,\n",
      "         -3.9718e+00,  1.6199e+01, -1.5137e+01,  2.2921e+01,  5.0652e+00,\n",
      "         -8.5470e+00,  2.0653e+01, -1.3935e+01, -6.8546e+00,  6.0791e+00,\n",
      "          2.4095e-01, -5.9641e+00,  7.5552e-01, -5.4784e+00, -1.7279e+01,\n",
      "         -9.7225e+00, -3.4583e+00,  9.7308e+00, -1.3192e+01, -1.1833e+01,\n",
      "          8.5496e-01, -4.4415e+00,  1.3666e+01,  1.0338e+00,  1.2986e+00,\n",
      "          7.0271e+00,  2.7977e+01,  1.0596e+01, -7.5266e+00, -1.2973e+01,\n",
      "          2.9808e+01,  2.1526e+01,  1.9306e+00,  1.1753e+01,  9.8619e+00,\n",
      "          1.5764e+01, -4.1970e+00,  3.5605e+00,  3.7961e-01, -2.5283e+01,\n",
      "          2.0117e+01,  1.6497e+01,  8.8984e+00,  1.1905e+01, -4.2663e+00,\n",
      "         -1.3838e+01, -2.9611e+01,  3.7881e+00, -5.2948e+00,  7.4840e+00,\n",
      "          2.3801e+01,  5.7907e-01,  6.1054e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.9251e+00,  1.3227e+02,  2.4571e+01, -8.3339e+00, -1.7935e+01,\n",
      "          2.5120e+00, -2.5834e+00, -1.4683e+01,  2.2397e+01,  5.5832e+00,\n",
      "         -1.2483e+01,  2.5883e+00,  9.6730e+00,  9.3427e-01,  6.5678e+00,\n",
      "          9.6412e+00, -7.5620e+00, -2.6517e+00,  4.2244e+00,  2.0086e+01,\n",
      "          1.2096e+01,  2.8693e+00, -1.8514e+00, -1.4172e-01,  1.1752e+01,\n",
      "         -3.7368e+00,  5.1789e+00, -1.6515e+00, -6.5975e+00, -1.5246e+00,\n",
      "          8.4934e+00, -2.5898e+01, -3.0897e+00, -3.2784e+00,  5.7124e+00,\n",
      "         -1.1207e+01, -1.4532e+01, -1.7724e+00, -1.0490e+01,  1.8090e+01,\n",
      "         -3.1357e-01,  1.5436e+00, -1.2970e+01,  2.6067e+01,  1.9031e+01,\n",
      "         -5.8347e+00,  1.2240e+01, -4.0518e+00, -1.0689e+01,  1.7618e+01,\n",
      "          4.0902e+00, -2.7326e+00, -7.2158e+00, -1.4252e+01, -2.0021e+01,\n",
      "         -1.0062e+01, -6.9737e+00, -1.1838e+01, -3.4931e+00, -7.6574e+00,\n",
      "         -1.0451e+01, -1.6712e+01, -3.4864e-01, -3.7011e+00, -8.3148e+00,\n",
      "          3.2067e+01,  7.7105e-01,  6.8971e+00, -2.0643e+01,  9.3759e+00,\n",
      "         -1.3113e+01,  9.5717e-01,  1.0171e+01,  9.6171e+00,  1.4658e+01,\n",
      "         -3.8336e+00,  1.6397e+01, -1.4874e+01,  2.2761e+01,  4.9762e+00,\n",
      "         -8.9135e+00,  2.1482e+01, -1.3856e+01, -6.2378e+00,  6.8361e+00,\n",
      "          8.6645e-02, -5.3460e+00,  1.8119e-01, -5.8805e+00, -1.7697e+01,\n",
      "         -8.9042e+00, -2.5261e+00,  9.6281e+00, -1.3667e+01, -1.2342e+01,\n",
      "          1.4271e+00, -4.2455e+00,  1.3777e+01,  1.5886e+00,  1.2960e+00,\n",
      "          7.5008e+00,  2.8418e+01,  1.0694e+01, -7.5475e+00, -1.2989e+01,\n",
      "          3.0042e+01,  2.1001e+01,  2.6141e+00,  1.1670e+01,  9.4692e+00,\n",
      "          1.5869e+01, -4.9370e+00,  4.0685e+00,  9.6406e-01, -2.4404e+01,\n",
      "          2.0297e+01,  1.7223e+01,  9.0749e+00,  1.2073e+01, -4.4249e+00,\n",
      "         -1.4713e+01, -2.9387e+01,  3.4971e+00, -5.4701e+00,  7.3701e+00,\n",
      "          2.3977e+01,  1.5001e+00,  2.2227e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.9696e+00,  1.3246e+02,  2.4434e+01, -8.2422e+00, -1.7943e+01,\n",
      "          2.5451e+00, -2.6659e+00, -1.4918e+01,  2.3081e+01,  4.8712e+00,\n",
      "         -1.2657e+01,  2.1827e+00,  9.5821e+00,  2.8110e-02,  6.6723e+00,\n",
      "          9.6680e+00, -6.7872e+00, -2.0600e+00,  4.3264e+00,  2.0631e+01,\n",
      "          1.1694e+01,  2.6574e+00, -1.7087e+00, -2.5208e-02,  1.1823e+01,\n",
      "         -4.0242e+00,  5.1558e+00, -1.6600e+00, -7.0773e+00, -1.5728e+00,\n",
      "          8.2481e+00, -2.6206e+01, -2.2122e+00, -3.2741e+00,  5.5654e+00,\n",
      "         -1.1560e+01, -1.4608e+01, -1.0363e+00, -1.0401e+01,  1.7976e+01,\n",
      "         -9.7551e-01,  1.2773e+00, -1.2193e+01,  2.6325e+01,  1.8738e+01,\n",
      "         -5.5812e+00,  1.2545e+01, -3.9109e+00, -1.1524e+01,  1.7069e+01,\n",
      "          3.5571e+00, -1.9613e+00, -7.7703e+00, -1.4502e+01, -1.9410e+01,\n",
      "         -9.9256e+00, -6.6798e+00, -1.1946e+01, -3.1843e+00, -7.0128e+00,\n",
      "         -1.0548e+01, -1.6338e+01, -4.9834e-01, -4.7010e+00, -8.2743e+00,\n",
      "          3.1634e+01,  5.0305e-01,  6.6743e+00, -2.0911e+01,  8.3784e+00,\n",
      "         -1.3148e+01,  9.8258e-01,  9.4934e+00,  9.4869e+00,  1.4790e+01,\n",
      "         -3.9323e+00,  1.5959e+01, -1.4630e+01,  2.2816e+01,  5.1469e+00,\n",
      "         -9.2083e+00,  2.1812e+01, -1.3804e+01, -6.8612e+00,  6.9504e+00,\n",
      "         -1.3821e-01, -5.9427e+00,  6.6498e-01, -6.0321e+00, -1.7671e+01,\n",
      "         -8.8604e+00, -2.8389e+00,  9.2227e+00, -1.3665e+01, -1.1954e+01,\n",
      "          1.1123e+00, -4.2541e+00,  1.3947e+01,  1.0882e+00,  1.0673e+00,\n",
      "          6.9237e+00,  2.8469e+01,  1.0871e+01, -6.9586e+00, -1.3193e+01,\n",
      "          3.0166e+01,  2.1234e+01,  2.2684e+00,  1.2031e+01,  9.2322e+00,\n",
      "          1.5835e+01, -4.4354e+00,  3.5222e+00,  8.7985e-01, -2.4737e+01,\n",
      "          2.0558e+01,  1.7349e+01,  8.7217e+00,  1.2100e+01, -4.5279e+00,\n",
      "         -1.4164e+01, -2.9089e+01,  2.7863e+00, -6.0556e+00,  7.6164e+00,\n",
      "          2.3298e+01,  1.2306e+00,  7.4769e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[  9.4079, 132.3681,  23.7493,  -8.0043, -17.8100,   2.6620,  -2.7604,\n",
      "         -14.6589,  22.7443,   5.2495, -12.8485,   2.2899,   9.4270,   0.4826,\n",
      "           6.8378,   9.7308,  -7.1133,  -2.3559,   4.6568,  20.6695,  11.7858,\n",
      "           2.7724,  -1.8747,  -0.3671,  12.4606,  -4.2469,   5.2589,  -2.1343,\n",
      "          -6.5219,  -1.9233,   7.7852, -26.0275,  -2.0819,  -3.6963,   5.2884,\n",
      "         -11.2516, -15.7551,  -1.4829, -10.5176,  18.6315,  -0.8287,   1.1848,\n",
      "         -12.4972,  26.3863,  18.5813,  -5.6117,  12.1884,  -4.4180, -11.3009,\n",
      "          17.3075,   3.3513,  -1.8174,  -7.3776, -14.3398, -19.5719, -10.2455,\n",
      "          -6.8391, -11.9936,  -3.4875,  -7.6017, -10.5292, -16.5498,  -0.6296,\n",
      "          -4.2313,  -8.4387,  31.7228,   0.6817,   6.9785, -20.8016,   8.4092,\n",
      "         -12.8867,   0.7429,   9.3193,   9.2028,  14.8425,  -4.2010,  16.0501,\n",
      "         -14.7426,  22.7537,   4.8977,  -9.3010,  21.4676, -13.6346,  -6.8065,\n",
      "           6.7916,  -0.5857,  -6.4159,   0.6072,  -5.7265, -18.1902,  -9.2983,\n",
      "          -2.7943,   9.7525, -13.8606, -11.4499,   0.8761,  -3.8790,  14.0305,\n",
      "           1.0998,   1.1129,   6.8332,  28.3514,  10.7495,  -7.4928, -12.8933,\n",
      "          30.0530,  21.0584,   1.9487,  11.9913,   8.7834,  15.8241,  -4.4328,\n",
      "           3.1558,   0.9301, -24.8700,  20.2146,  17.5257,   8.5237,  12.2390,\n",
      "          -4.2001, -14.3899, -28.6836,   3.3920,  -5.7384,   7.5457,  23.8065,\n",
      "           0.9032,   1.0185]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0052e+01,  1.3244e+02,  2.4165e+01, -8.4486e+00, -1.7987e+01,\n",
      "          3.0000e+00, -2.6061e+00, -1.5022e+01,  2.2481e+01,  5.7566e+00,\n",
      "         -1.2586e+01,  2.4976e+00,  9.5517e+00,  8.1594e-01,  7.4116e+00,\n",
      "          9.7561e+00, -6.8313e+00, -2.9543e+00,  4.7145e+00,  2.0881e+01,\n",
      "          1.2768e+01,  2.1606e+00, -1.9128e+00, -3.6933e-02,  1.2023e+01,\n",
      "         -3.8923e+00,  5.0329e+00, -1.8916e+00, -6.6676e+00, -1.8847e+00,\n",
      "          8.3067e+00, -2.5866e+01, -2.3922e+00, -3.3570e+00,  5.5740e+00,\n",
      "         -1.1666e+01, -1.4918e+01, -1.6390e+00, -1.0752e+01,  1.7978e+01,\n",
      "         -1.2419e+00,  1.1307e+00, -1.3067e+01,  2.6531e+01,  1.8798e+01,\n",
      "         -5.4714e+00,  1.2743e+01, -4.2187e+00, -1.1079e+01,  1.7265e+01,\n",
      "          4.0797e+00, -2.7876e+00, -7.5522e+00, -1.4291e+01, -1.9518e+01,\n",
      "         -1.0111e+01, -6.9234e+00, -1.1877e+01, -3.8416e+00, -7.2973e+00,\n",
      "         -1.0497e+01, -1.7252e+01,  5.5841e-02, -4.2577e+00, -7.8245e+00,\n",
      "          3.2052e+01,  5.8007e-01,  6.7147e+00, -2.1196e+01,  8.8415e+00,\n",
      "         -1.3311e+01,  7.7867e-01,  9.0659e+00,  8.7356e+00,  1.4533e+01,\n",
      "         -4.0756e+00,  1.6158e+01, -1.5014e+01,  2.2808e+01,  4.9035e+00,\n",
      "         -8.4986e+00,  2.0762e+01, -1.3878e+01, -6.8089e+00,  6.1924e+00,\n",
      "          7.8691e-02, -6.0129e+00,  6.4667e-01, -5.5036e+00, -1.7422e+01,\n",
      "         -9.7714e+00, -3.3380e+00,  9.8214e+00, -1.3257e+01, -1.1745e+01,\n",
      "          8.7002e-01, -4.3517e+00,  1.3655e+01,  1.1969e+00,  1.2381e+00,\n",
      "          6.9993e+00,  2.8123e+01,  1.0602e+01, -7.4824e+00, -1.2841e+01,\n",
      "          2.9979e+01,  2.1425e+01,  1.8416e+00,  1.1775e+01,  9.8473e+00,\n",
      "          1.5840e+01, -4.4285e+00,  3.4971e+00,  4.1631e-01, -2.5182e+01,\n",
      "          2.0059e+01,  1.6770e+01,  8.6835e+00,  1.1947e+01, -4.1696e+00,\n",
      "         -1.3950e+01, -2.9624e+01,  3.7494e+00, -5.1945e+00,  7.6546e+00,\n",
      "          2.3882e+01,  5.3627e-01,  5.8823e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.8833e+00,  1.3225e+02,  2.4575e+01, -8.2919e+00, -1.7783e+01,\n",
      "          2.6125e+00, -2.4682e+00, -1.4698e+01,  2.2404e+01,  5.6372e+00,\n",
      "         -1.2475e+01,  2.6240e+00,  9.6416e+00,  7.8970e-01,  6.6484e+00,\n",
      "          9.6368e+00, -7.4991e+00, -2.8306e+00,  4.3725e+00,  1.9950e+01,\n",
      "          1.2258e+01,  2.7502e+00, -1.8837e+00, -1.4155e-01,  1.1948e+01,\n",
      "         -3.9253e+00,  5.1470e+00, -1.7851e+00, -6.5641e+00, -1.5529e+00,\n",
      "          8.3020e+00, -2.5874e+01, -2.8918e+00, -3.3070e+00,  5.6488e+00,\n",
      "         -1.1207e+01, -1.4822e+01, -1.7404e+00, -1.0447e+01,  1.8289e+01,\n",
      "         -3.3931e-01,  1.3759e+00, -1.3041e+01,  2.6005e+01,  1.8959e+01,\n",
      "         -5.7628e+00,  1.2161e+01, -4.0381e+00, -1.0741e+01,  1.7704e+01,\n",
      "          3.8886e+00, -2.5989e+00, -7.2360e+00, -1.4295e+01, -2.0194e+01,\n",
      "         -1.0182e+01, -6.9162e+00, -1.1882e+01, -3.4871e+00, -7.8171e+00,\n",
      "         -1.0456e+01, -1.6755e+01, -3.5723e-01, -3.7343e+00, -8.3023e+00,\n",
      "          3.2027e+01,  7.5363e-01,  6.9403e+00, -2.0677e+01,  9.3630e+00,\n",
      "         -1.2980e+01,  9.8426e-01,  1.0057e+01,  9.5307e+00,  1.4668e+01,\n",
      "         -3.9393e+00,  1.6331e+01, -1.4793e+01,  2.2673e+01,  4.8133e+00,\n",
      "         -8.8709e+00,  2.1587e+01, -1.3802e+01, -6.2703e+00,  6.9218e+00,\n",
      "         -4.6564e-02, -5.4444e+00,  1.2833e-01, -5.8587e+00, -1.7793e+01,\n",
      "         -9.0233e+00, -2.4679e+00,  9.7434e+00, -1.3700e+01, -1.2198e+01,\n",
      "          1.4254e+00, -4.1448e+00,  1.3730e+01,  1.7815e+00,  1.2149e+00,\n",
      "          7.4462e+00,  2.8564e+01,  1.0708e+01, -7.5087e+00, -1.2857e+01,\n",
      "          3.0192e+01,  2.0931e+01,  2.4834e+00,  1.1685e+01,  9.4653e+00,\n",
      "          1.5959e+01, -5.1436e+00,  3.9894e+00,  1.0093e+00, -2.4351e+01,\n",
      "          2.0256e+01,  1.7439e+01,  8.8963e+00,  1.2117e+01, -4.3241e+00,\n",
      "         -1.4768e+01, -2.9406e+01,  3.4662e+00, -5.3392e+00,  7.5151e+00,\n",
      "          2.4038e+01,  1.3983e+00,  1.8223e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.9594e+00,  1.3242e+02,  2.4405e+01, -8.1903e+00, -1.7773e+01,\n",
      "          2.6245e+00, -2.5807e+00, -1.4899e+01,  2.3029e+01,  4.9222e+00,\n",
      "         -1.2635e+01,  2.2396e+00,  9.5498e+00, -4.4070e-02,  6.7945e+00,\n",
      "          9.7227e+00, -6.7471e+00, -2.2290e+00,  4.4848e+00,  2.0498e+01,\n",
      "          1.1837e+01,  2.5685e+00, -1.7155e+00,  1.1928e-02,  1.1971e+01,\n",
      "         -4.2387e+00,  5.1632e+00, -1.7925e+00, -7.1090e+00, -1.5943e+00,\n",
      "          8.0853e+00, -2.6231e+01, -2.0902e+00, -3.3284e+00,  5.4731e+00,\n",
      "         -1.1554e+01, -1.4953e+01, -1.0306e+00, -1.0332e+01,  1.8176e+01,\n",
      "         -9.4568e-01,  1.1267e+00, -1.2276e+01,  2.6248e+01,  1.8655e+01,\n",
      "         -5.5031e+00,  1.2444e+01, -3.9036e+00, -1.1502e+01,  1.7125e+01,\n",
      "          3.3838e+00, -1.8796e+00, -7.7797e+00, -1.4533e+01, -1.9625e+01,\n",
      "         -1.0061e+01, -6.6472e+00, -1.2035e+01, -3.2149e+00, -7.2256e+00,\n",
      "         -1.0529e+01, -1.6397e+01, -4.6146e-01, -4.6699e+00, -8.2745e+00,\n",
      "          3.1656e+01,  4.6484e-01,  6.7289e+00, -2.0919e+01,  8.4536e+00,\n",
      "         -1.3035e+01,  1.0149e+00,  9.4443e+00,  9.4344e+00,  1.4780e+01,\n",
      "         -4.0008e+00,  1.5852e+01, -1.4550e+01,  2.2719e+01,  4.9954e+00,\n",
      "         -9.1384e+00,  2.1977e+01, -1.3820e+01, -6.8332e+00,  7.0545e+00,\n",
      "         -2.2808e-01, -5.9834e+00,  6.0493e-01, -6.0184e+00, -1.7769e+01,\n",
      "         -9.0027e+00, -2.7829e+00,  9.3645e+00, -1.3736e+01, -1.1891e+01,\n",
      "          1.1121e+00, -4.1035e+00,  1.3898e+01,  1.3285e+00,  1.0097e+00,\n",
      "          6.9179e+00,  2.8596e+01,  1.0904e+01, -6.9417e+00, -1.3042e+01,\n",
      "          3.0299e+01,  2.1130e+01,  2.1230e+00,  1.2027e+01,  9.2464e+00,\n",
      "          1.5894e+01, -4.6919e+00,  3.4818e+00,  9.7654e-01, -2.4616e+01,\n",
      "          2.0500e+01,  1.7588e+01,  8.5461e+00,  1.2124e+01, -4.4095e+00,\n",
      "         -1.4289e+01, -2.9184e+01,  2.7967e+00, -5.9572e+00,  7.7433e+00,\n",
      "          2.3383e+01,  1.1790e+00,  7.1235e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[  9.4513, 132.3237,  23.7768,  -7.9629, -17.6098,   2.7297,  -2.6835,\n",
      "         -14.6521,  22.7256,   5.2453, -12.8177,   2.3438,   9.4000,   0.3741,\n",
      "           6.9466,   9.7710,  -7.0149,  -2.5226,   4.7960,  20.5326,  11.9166,\n",
      "           2.6848,  -1.9069,  -0.3067,  12.5718,  -4.4618,   5.3032,  -2.2150,\n",
      "          -6.5846,  -1.9214,   7.6928, -26.1023,  -1.9924,  -3.7141,   5.2233,\n",
      "         -11.2736, -16.0454,  -1.4559, -10.4035,  18.7747,  -0.7329,   1.0474,\n",
      "         -12.5517,  26.3365,  18.5095,  -5.5206,  12.0848,  -4.3850, -11.2625,\n",
      "          17.3234,   3.2258,  -1.7133,  -7.3903, -14.3982, -19.8121, -10.3774,\n",
      "          -6.8056, -12.0034,  -3.4492,  -7.7579, -10.5199, -16.5841,  -0.5904,\n",
      "          -4.2534,  -8.4555,  31.7265,   0.6435,   7.0250, -20.8008,   8.4964,\n",
      "         -12.8078,   0.7916,   9.3257,   9.1607,  14.8250,  -4.2397,  15.9185,\n",
      "         -14.6720,  22.6222,   4.7748,  -9.2494,  21.6576, -13.7074,  -6.7741,\n",
      "           6.8807,  -0.6263,  -6.4421,   0.5863,  -5.7344, -18.2421,  -9.4321,\n",
      "          -2.7440,   9.8076, -13.9080, -11.4252,   0.8577,  -3.7440,  13.9665,\n",
      "           1.3124,   1.0654,   6.8378,  28.5090,  10.7878,  -7.4547, -12.7534,\n",
      "          30.2135,  20.9524,   1.8137,  11.9979,   8.8185,  15.8540,  -4.6859,\n",
      "           3.1166,   1.0027, -24.7514,  20.1712,  17.7368,   8.3604,  12.2612,\n",
      "          -4.0666, -14.5362, -28.8181,   3.3689,  -5.7206,   7.6420,  23.8789,\n",
      "           0.8661,   0.9715]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0096e+01,  1.3239e+02,  2.4178e+01, -8.3635e+00, -1.7828e+01,\n",
      "          3.0626e+00, -2.4798e+00, -1.4996e+01,  2.2446e+01,  5.7549e+00,\n",
      "         -1.2588e+01,  2.5447e+00,  9.5398e+00,  6.6748e-01,  7.4861e+00,\n",
      "          9.7790e+00, -6.6906e+00, -3.0879e+00,  4.7809e+00,  2.0708e+01,\n",
      "          1.2844e+01,  2.1053e+00, -1.9673e+00, -2.3717e-02,  1.2181e+01,\n",
      "         -4.1741e+00,  5.1284e+00, -1.9351e+00, -6.7021e+00, -1.8369e+00,\n",
      "          8.2207e+00, -2.5953e+01, -2.2832e+00, -3.4059e+00,  5.5272e+00,\n",
      "         -1.1678e+01, -1.5261e+01, -1.6092e+00, -1.0622e+01,  1.8115e+01,\n",
      "         -1.0874e+00,  1.0190e+00, -1.3112e+01,  2.6513e+01,  1.8684e+01,\n",
      "         -5.4408e+00,  1.2607e+01, -4.1994e+00, -1.1030e+01,  1.7298e+01,\n",
      "          3.9162e+00, -2.6677e+00, -7.5272e+00, -1.4330e+01, -1.9780e+01,\n",
      "         -1.0294e+01, -6.9272e+00, -1.1864e+01, -3.7822e+00, -7.4611e+00,\n",
      "         -1.0504e+01, -1.7261e+01,  6.9320e-02, -4.2533e+00, -7.9280e+00,\n",
      "          3.2009e+01,  5.7324e-01,  6.8146e+00, -2.1162e+01,  8.9349e+00,\n",
      "         -1.3189e+01,  8.1617e-01,  9.0887e+00,  8.7068e+00,  1.4549e+01,\n",
      "         -4.1199e+00,  1.6047e+01, -1.4966e+01,  2.2625e+01,  4.7780e+00,\n",
      "         -8.4756e+00,  2.0953e+01, -1.3960e+01, -6.7408e+00,  6.3048e+00,\n",
      "          2.1055e-03, -6.0244e+00,  5.8890e-01, -5.5238e+00, -1.7568e+01,\n",
      "         -9.7906e+00, -3.2652e+00,  9.8607e+00, -1.3355e+01, -1.1738e+01,\n",
      "          8.4021e-01, -4.1878e+00,  1.3630e+01,  1.3240e+00,  1.2203e+00,\n",
      "          6.9764e+00,  2.8286e+01,  1.0650e+01, -7.4645e+00, -1.2724e+01,\n",
      "          3.0149e+01,  2.1275e+01,  1.7221e+00,  1.1782e+01,  9.7881e+00,\n",
      "          1.5840e+01, -4.6460e+00,  3.4334e+00,  4.8371e-01, -2.5025e+01,\n",
      "          1.9999e+01,  1.6994e+01,  8.5089e+00,  1.1948e+01, -4.0146e+00,\n",
      "         -1.4156e+01, -2.9713e+01,  3.7575e+00, -5.2422e+00,  7.7954e+00,\n",
      "          2.3979e+01,  5.3216e-01,  5.6508e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.9088e+00,  1.3221e+02,  2.4569e+01, -8.1790e+00, -1.7637e+01,\n",
      "          2.7334e+00, -2.3026e+00, -1.4699e+01,  2.2373e+01,  5.6911e+00,\n",
      "         -1.2487e+01,  2.6298e+00,  9.6545e+00,  6.2271e-01,  6.7677e+00,\n",
      "          9.6666e+00, -7.2964e+00, -2.9815e+00,  4.4977e+00,  1.9878e+01,\n",
      "          1.2349e+01,  2.6594e+00, -1.9905e+00, -1.7003e-01,  1.2131e+01,\n",
      "         -4.2377e+00,  5.2316e+00, -1.8358e+00, -6.5539e+00, -1.4977e+00,\n",
      "          8.2539e+00, -2.5975e+01, -2.7344e+00, -3.3279e+00,  5.6223e+00,\n",
      "         -1.1254e+01, -1.5139e+01, -1.7325e+00, -1.0368e+01,  1.8397e+01,\n",
      "         -2.0412e-01,  1.2540e+00, -1.3109e+01,  2.6022e+01,  1.8887e+01,\n",
      "         -5.6966e+00,  1.2090e+01, -4.0215e+00, -1.0762e+01,  1.7673e+01,\n",
      "          3.7555e+00, -2.4632e+00, -7.2248e+00, -1.4324e+01, -2.0411e+01,\n",
      "         -1.0353e+01, -6.9522e+00, -1.1837e+01, -3.4386e+00, -7.9506e+00,\n",
      "         -1.0449e+01, -1.6835e+01, -3.2822e-01, -3.7732e+00, -8.3861e+00,\n",
      "          3.1980e+01,  7.3725e-01,  7.0155e+00, -2.0705e+01,  9.3711e+00,\n",
      "         -1.2865e+01,  9.7601e-01,  1.0011e+01,  9.4430e+00,  1.4682e+01,\n",
      "         -4.0379e+00,  1.6236e+01, -1.4747e+01,  2.2533e+01,  4.7271e+00,\n",
      "         -8.8455e+00,  2.1682e+01, -1.3909e+01, -6.2341e+00,  6.9794e+00,\n",
      "         -1.1350e-01, -5.4728e+00,  1.2088e-01, -5.8265e+00, -1.7911e+01,\n",
      "         -9.0631e+00, -2.4399e+00,  9.8065e+00, -1.3783e+01, -1.2171e+01,\n",
      "          1.3973e+00, -3.9724e+00,  1.3662e+01,  1.8611e+00,  1.2416e+00,\n",
      "          7.3787e+00,  2.8685e+01,  1.0789e+01, -7.5056e+00, -1.2765e+01,\n",
      "          3.0353e+01,  2.0795e+01,  2.3618e+00,  1.1734e+01,  9.4406e+00,\n",
      "          1.5943e+01, -5.3324e+00,  3.8955e+00,  1.0352e+00, -2.4203e+01,\n",
      "          2.0149e+01,  1.7599e+01,  8.7657e+00,  1.2063e+01, -4.1742e+00,\n",
      "         -1.4919e+01, -2.9505e+01,  3.4919e+00, -5.3914e+00,  7.6787e+00,\n",
      "          2.4113e+01,  1.3008e+00,  1.6576e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.9663e+00,  1.3238e+02,  2.4421e+01, -8.0767e+00, -1.7621e+01,\n",
      "          2.7311e+00, -2.3976e+00, -1.4853e+01,  2.2932e+01,  5.0276e+00,\n",
      "         -1.2637e+01,  2.2359e+00,  9.5532e+00, -1.9646e-01,  6.9323e+00,\n",
      "          9.7916e+00, -6.6264e+00, -2.3880e+00,  4.6787e+00,  2.0418e+01,\n",
      "          1.1931e+01,  2.4846e+00, -1.8045e+00, -1.8981e-02,  1.2169e+01,\n",
      "         -4.5430e+00,  5.2118e+00, -1.8818e+00, -7.1034e+00, -1.5703e+00,\n",
      "          7.9986e+00, -2.6305e+01, -1.9432e+00, -3.3577e+00,  5.4412e+00,\n",
      "         -1.1629e+01, -1.5274e+01, -1.0622e+00, -1.0293e+01,  1.8299e+01,\n",
      "         -8.5033e-01,  9.7711e-01, -1.2363e+01,  2.6249e+01,  1.8591e+01,\n",
      "         -5.4422e+00,  1.2390e+01, -3.8803e+00, -1.1545e+01,  1.7166e+01,\n",
      "          3.2498e+00, -1.7556e+00, -7.7361e+00, -1.4550e+01, -1.9857e+01,\n",
      "         -1.0212e+01, -6.6741e+00, -1.2081e+01, -3.2485e+00, -7.3946e+00,\n",
      "         -1.0493e+01, -1.6529e+01, -3.7193e-01, -4.6460e+00, -8.3512e+00,\n",
      "          3.1659e+01,  4.1620e-01,  6.8058e+00, -2.0975e+01,  8.4876e+00,\n",
      "         -1.2875e+01,  9.6155e-01,  9.4063e+00,  9.3388e+00,  1.4809e+01,\n",
      "         -4.1065e+00,  1.5743e+01, -1.4495e+01,  2.2628e+01,  4.9207e+00,\n",
      "         -9.1027e+00,  2.2024e+01, -1.3904e+01, -6.7266e+00,  7.1282e+00,\n",
      "         -2.8930e-01, -5.9675e+00,  5.8159e-01, -5.9901e+00, -1.7886e+01,\n",
      "         -9.0650e+00, -2.7316e+00,  9.4806e+00, -1.3841e+01, -1.1905e+01,\n",
      "          1.1093e+00, -3.9468e+00,  1.3833e+01,  1.4590e+00,  1.0747e+00,\n",
      "          6.9150e+00,  2.8653e+01,  1.0967e+01, -6.9608e+00, -1.2892e+01,\n",
      "          3.0457e+01,  2.0999e+01,  1.9865e+00,  1.2076e+01,  9.2810e+00,\n",
      "          1.5894e+01, -4.9497e+00,  3.4402e+00,  1.0201e+00, -2.4419e+01,\n",
      "          2.0359e+01,  1.7810e+01,  8.4064e+00,  1.2066e+01, -4.2488e+00,\n",
      "         -1.4418e+01, -2.9285e+01,  2.8421e+00, -5.9469e+00,  7.8753e+00,\n",
      "          2.3487e+01,  1.1003e+00,  6.7234e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[  9.4263, 132.2919,  23.8407,  -7.9095, -17.4414,   2.8411,  -2.5394,\n",
      "         -14.5865,  22.6758,   5.3260, -12.8197,   2.3095,   9.4486,   0.1939,\n",
      "           7.0474,   9.8170,  -6.9306,  -2.6368,   5.0176,  20.4600,  12.0062,\n",
      "           2.5984,  -1.9652,  -0.3480,  12.7464,  -4.7092,   5.3120,  -2.3391,\n",
      "          -6.6087,  -1.9212,   7.6056, -26.1763,  -1.8449,  -3.7434,   5.1942,\n",
      "         -11.3808, -16.2635,  -1.4459, -10.4111,  18.8538,  -0.6667,   0.8980,\n",
      "         -12.6275,  26.3164,  18.4684,  -5.4511,  12.0563,  -4.3457, -11.3349,\n",
      "          17.3834,   3.0911,  -1.5763,  -7.3466, -14.4384, -20.0169, -10.4594,\n",
      "          -6.8026, -12.0785,  -3.4639,  -7.8363, -10.4966, -16.6936,  -0.5204,\n",
      "          -4.2195,  -8.4614,  31.7451,   0.5935,   7.0613, -20.8644,   8.5131,\n",
      "         -12.6686,   0.7677,   9.3159,   9.0998,  14.8399,  -4.3480,  15.7958,\n",
      "         -14.5791,  22.5574,   4.7227,  -9.2183,  21.7185, -13.7468,  -6.6722,\n",
      "           6.9491,  -0.6949,  -6.4509,   0.5293,  -5.7502, -18.2691,  -9.4982,\n",
      "          -2.6977,   9.8977, -13.9783, -11.4490,   0.8672,  -3.6686,  13.9033,\n",
      "           1.4508,   1.0966,   6.8415,  28.5646,  10.8235,  -7.4456, -12.5977,\n",
      "          30.3844,  20.8534,   1.7103,  12.0528,   8.9129,  15.8916,  -4.9662,\n",
      "           3.0928,   1.0300, -24.5692,  20.0980,  17.9565,   8.2159,  12.2336,\n",
      "          -3.9528, -14.6362, -28.8769,   3.3336,  -5.7056,   7.7416,  23.9593,\n",
      "           0.8162,   0.9247]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0041e+01,  1.3236e+02,  2.4213e+01, -8.3194e+00, -1.7664e+01,\n",
      "          3.1410e+00, -2.3841e+00, -1.4872e+01,  2.2418e+01,  5.8156e+00,\n",
      "         -1.2616e+01,  2.4929e+00,  9.6175e+00,  4.8063e-01,  7.5172e+00,\n",
      "          9.8168e+00, -6.6440e+00, -3.1146e+00,  4.9616e+00,  2.0569e+01,\n",
      "          1.2864e+01,  2.0635e+00, -1.9745e+00, -8.2621e-02,  1.2362e+01,\n",
      "         -4.3943e+00,  5.1556e+00, -2.0787e+00, -6.7601e+00, -1.8428e+00,\n",
      "          8.1017e+00, -2.6023e+01, -2.1475e+00, -3.4988e+00,  5.4818e+00,\n",
      "         -1.1764e+01, -1.5512e+01, -1.5589e+00, -1.0646e+01,  1.8219e+01,\n",
      "         -1.0338e+00,  9.0083e-01, -1.3166e+01,  2.6483e+01,  1.8588e+01,\n",
      "         -5.4275e+00,  1.2551e+01, -4.1669e+00, -1.1095e+01,  1.7380e+01,\n",
      "          3.7061e+00, -2.5233e+00, -7.4586e+00, -1.4356e+01, -1.9991e+01,\n",
      "         -1.0369e+01, -6.9369e+00, -1.1980e+01, -3.7685e+00, -7.5352e+00,\n",
      "         -1.0503e+01, -1.7290e+01,  8.9949e-02, -4.1544e+00, -7.9035e+00,\n",
      "          3.2014e+01,  5.3738e-01,  6.8491e+00, -2.1189e+01,  8.9409e+00,\n",
      "         -1.3024e+01,  8.3414e-01,  9.1364e+00,  8.7037e+00,  1.4574e+01,\n",
      "         -4.2334e+00,  1.5931e+01, -1.4851e+01,  2.2518e+01,  4.7018e+00,\n",
      "         -8.4669e+00,  2.1101e+01, -1.3957e+01, -6.6210e+00,  6.4200e+00,\n",
      "         -1.4548e-01, -6.0880e+00,  4.4630e-01, -5.5953e+00, -1.7638e+01,\n",
      "         -9.7778e+00, -3.1922e+00,  9.9425e+00, -1.3457e+01, -1.1751e+01,\n",
      "          8.4224e-01, -4.1216e+00,  1.3631e+01,  1.4646e+00,  1.2201e+00,\n",
      "          6.9592e+00,  2.8360e+01,  1.0660e+01, -7.4586e+00, -1.2566e+01,\n",
      "          3.0285e+01,  2.1163e+01,  1.6455e+00,  1.1820e+01,  9.8041e+00,\n",
      "          1.5900e+01, -4.9056e+00,  3.4072e+00,  5.6169e-01, -2.4837e+01,\n",
      "          1.9989e+01,  1.7271e+01,  8.3367e+00,  1.1936e+01, -3.9243e+00,\n",
      "         -1.4294e+01, -2.9691e+01,  3.6887e+00, -5.2541e+00,  7.8886e+00,\n",
      "          2.4065e+01,  5.7570e-01,  5.4941e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.8742e+00,  1.3218e+02,  2.4576e+01, -8.1417e+00, -1.7452e+01,\n",
      "          2.8268e+00, -2.2570e+00, -1.4594e+01,  2.2373e+01,  5.7706e+00,\n",
      "         -1.2496e+01,  2.5551e+00,  9.7358e+00,  4.5517e-01,  6.8540e+00,\n",
      "          9.7197e+00, -7.1871e+00, -3.0140e+00,  4.7152e+00,  1.9774e+01,\n",
      "          1.2352e+01,  2.5841e+00, -2.0161e+00, -1.8388e-01,  1.2276e+01,\n",
      "         -4.4504e+00,  5.2770e+00, -1.9515e+00, -6.6294e+00, -1.5203e+00,\n",
      "          8.1471e+00, -2.6052e+01, -2.6184e+00, -3.4163e+00,  5.5570e+00,\n",
      "         -1.1322e+01, -1.5387e+01, -1.6895e+00, -1.0396e+01,  1.8513e+01,\n",
      "         -1.8229e-01,  1.1202e+00, -1.3175e+01,  2.6004e+01,  1.8795e+01,\n",
      "         -5.6664e+00,  1.2073e+01, -3.9903e+00, -1.0812e+01,  1.7661e+01,\n",
      "          3.5717e+00, -2.3241e+00, -7.2106e+00, -1.4339e+01, -2.0614e+01,\n",
      "         -1.0419e+01, -6.9663e+00, -1.1919e+01, -3.4004e+00, -8.0058e+00,\n",
      "         -1.0443e+01, -1.6859e+01, -2.9050e-01, -3.7006e+00, -8.2976e+00,\n",
      "          3.2013e+01,  6.8519e-01,  7.0073e+00, -2.0776e+01,  9.3121e+00,\n",
      "         -1.2730e+01,  9.7395e-01,  1.0037e+01,  9.4309e+00,  1.4704e+01,\n",
      "         -4.1778e+00,  1.6105e+01, -1.4605e+01,  2.2433e+01,  4.6613e+00,\n",
      "         -8.8283e+00,  2.1837e+01, -1.3943e+01, -6.1534e+00,  7.0368e+00,\n",
      "         -2.5866e-01, -5.5721e+00,  9.7187e-03, -5.8958e+00, -1.7953e+01,\n",
      "         -9.1105e+00, -2.4021e+00,  9.8600e+00, -1.3855e+01, -1.2152e+01,\n",
      "          1.3820e+00, -3.8933e+00,  1.3642e+01,  2.0273e+00,  1.2338e+00,\n",
      "          7.3136e+00,  2.8743e+01,  1.0807e+01, -7.4983e+00, -1.2610e+01,\n",
      "          3.0443e+01,  2.0678e+01,  2.2761e+00,  1.1789e+01,  9.4630e+00,\n",
      "          1.5979e+01, -5.5580e+00,  3.8395e+00,  1.1250e+00, -2.4051e+01,\n",
      "          2.0131e+01,  1.7856e+01,  8.6104e+00,  1.2015e+01, -4.0915e+00,\n",
      "         -1.5030e+01, -2.9530e+01,  3.4103e+00, -5.3982e+00,  7.7540e+00,\n",
      "          2.4150e+01,  1.2976e+00,  1.8726e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.9541e+00,  1.3234e+02,  2.4467e+01, -8.0231e+00, -1.7421e+01,\n",
      "          2.8023e+00, -2.3562e+00, -1.4760e+01,  2.2916e+01,  5.1495e+00,\n",
      "         -1.2582e+01,  2.1778e+00,  9.5949e+00, -3.5517e-01,  7.0738e+00,\n",
      "          9.8328e+00, -6.5184e+00, -2.4985e+00,  4.9130e+00,  2.0242e+01,\n",
      "          1.1898e+01,  2.3988e+00, -1.8469e+00,  2.4490e-02,  1.2300e+01,\n",
      "         -4.7716e+00,  5.2740e+00, -1.9827e+00, -7.1849e+00, -1.5567e+00,\n",
      "          7.8767e+00, -2.6380e+01, -1.8996e+00, -3.4005e+00,  5.3608e+00,\n",
      "         -1.1670e+01, -1.5540e+01, -1.0602e+00, -1.0253e+01,  1.8467e+01,\n",
      "         -7.8281e-01,  8.2237e-01, -1.2491e+01,  2.6209e+01,  1.8509e+01,\n",
      "         -5.4368e+00,  1.2359e+01, -3.8693e+00, -1.1515e+01,  1.7163e+01,\n",
      "          3.1140e+00, -1.6321e+00, -7.7018e+00, -1.4513e+01, -2.0154e+01,\n",
      "         -1.0312e+01, -6.6632e+00, -1.2159e+01, -3.2378e+00, -7.5179e+00,\n",
      "         -1.0476e+01, -1.6581e+01, -3.0286e-01, -4.5622e+00, -8.2928e+00,\n",
      "          3.1722e+01,  3.8929e-01,  6.8336e+00, -2.1052e+01,  8.5136e+00,\n",
      "         -1.2717e+01,  9.0256e-01,  9.4302e+00,  9.3188e+00,  1.4862e+01,\n",
      "         -4.2246e+00,  1.5611e+01, -1.4359e+01,  2.2540e+01,  4.8561e+00,\n",
      "         -9.1018e+00,  2.2196e+01, -1.3947e+01, -6.6284e+00,  7.1929e+00,\n",
      "         -4.2017e-01, -6.0198e+00,  4.6912e-01, -6.0693e+00, -1.7956e+01,\n",
      "         -9.1346e+00, -2.6653e+00,  9.5121e+00, -1.3930e+01, -1.1909e+01,\n",
      "          1.1041e+00, -3.8198e+00,  1.3811e+01,  1.6736e+00,  1.1026e+00,\n",
      "          6.8787e+00,  2.8705e+01,  1.0998e+01, -6.9587e+00, -1.2712e+01,\n",
      "          3.0577e+01,  2.0855e+01,  1.8733e+00,  1.2112e+01,  9.3343e+00,\n",
      "          1.5898e+01, -5.2318e+00,  3.3857e+00,  1.1389e+00, -2.4203e+01,\n",
      "          2.0295e+01,  1.8117e+01,  8.2539e+00,  1.2017e+01, -4.1529e+00,\n",
      "         -1.4579e+01, -2.9395e+01,  2.7895e+00, -5.9384e+00,  7.9482e+00,\n",
      "          2.3521e+01,  1.0995e+00,  6.9222e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.4455e+00,  1.3224e+02,  2.3946e+01, -7.8406e+00, -1.7244e+01,\n",
      "          2.9111e+00, -2.4845e+00, -1.4555e+01,  2.2666e+01,  5.4206e+00,\n",
      "         -1.2744e+01,  2.2810e+00,  9.4586e+00,  1.1063e-02,  7.2204e+00,\n",
      "          9.8226e+00, -6.7635e+00, -2.8078e+00,  5.2294e+00,  2.0290e+01,\n",
      "          1.1986e+01,  2.4738e+00, -2.0485e+00, -2.7254e-01,  1.2858e+01,\n",
      "         -4.9578e+00,  5.3529e+00, -2.3913e+00, -6.6719e+00, -1.8797e+00,\n",
      "          7.4633e+00, -2.6238e+01, -1.8057e+00, -3.7609e+00,  5.1379e+00,\n",
      "         -1.1404e+01, -1.6457e+01, -1.4606e+00, -1.0353e+01,  1.9011e+01,\n",
      "         -5.6798e-01,  7.3204e-01, -1.2758e+01,  2.6267e+01,  1.8423e+01,\n",
      "         -5.4275e+00,  1.2039e+01, -4.3368e+00, -1.1283e+01,  1.7373e+01,\n",
      "          2.9873e+00, -1.4566e+00, -7.3540e+00, -1.4412e+01, -2.0310e+01,\n",
      "         -1.0566e+01, -6.7327e+00, -1.2093e+01, -3.4162e+00, -7.9347e+00,\n",
      "         -1.0477e+01, -1.6740e+01, -4.4826e-01, -4.1853e+00, -8.4600e+00,\n",
      "          3.1778e+01,  5.7423e-01,  7.0994e+00, -2.0929e+01,  8.5460e+00,\n",
      "         -1.2530e+01,  6.7730e-01,  9.3276e+00,  9.0577e+00,  1.4896e+01,\n",
      "         -4.4499e+00,  1.5682e+01, -1.4425e+01,  2.2483e+01,  4.6975e+00,\n",
      "         -9.2314e+00,  2.1862e+01, -1.3814e+01, -6.6064e+00,  6.9978e+00,\n",
      "         -7.7985e-01, -6.4500e+00,  4.6407e-01, -5.8130e+00, -1.8301e+01,\n",
      "         -9.5813e+00, -2.6283e+00,  9.8731e+00, -1.4052e+01, -1.1467e+01,\n",
      "          8.6955e-01, -3.5499e+00,  1.3858e+01,  1.6246e+00,  1.1031e+00,\n",
      "          6.7912e+00,  2.8638e+01,  1.0888e+01, -7.4074e+00, -1.2441e+01,\n",
      "          3.0536e+01,  2.0708e+01,  1.5936e+00,  1.2115e+01,  8.9931e+00,\n",
      "          1.5862e+01, -5.2669e+00,  2.9991e+00,  1.1132e+00, -2.4370e+01,\n",
      "          2.0020e+01,  1.8217e+01,  8.0608e+00,  1.2193e+01, -3.8703e+00,\n",
      "         -1.4794e+01, -2.9056e+01,  3.2555e+00, -5.7167e+00,  7.8063e+00,\n",
      "          2.3970e+01,  7.7053e-01,  9.4683e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0060e+01,  1.3230e+02,  2.4305e+01, -8.1864e+00, -1.7492e+01,\n",
      "          3.2002e+00, -2.2815e+00, -1.4855e+01,  2.2377e+01,  5.8921e+00,\n",
      "         -1.2587e+01,  2.4944e+00,  9.6109e+00,  2.9046e-01,  7.6626e+00,\n",
      "          9.8055e+00, -6.4783e+00, -3.2686e+00,  5.1255e+00,  2.0426e+01,\n",
      "          1.2843e+01,  1.9481e+00, -2.0684e+00, -3.4231e-02,  1.2505e+01,\n",
      "         -4.6701e+00,  5.1705e+00, -2.1247e+00, -6.8071e+00, -1.7903e+00,\n",
      "          7.9144e+00, -2.6063e+01, -2.0497e+00, -3.5549e+00,  5.4500e+00,\n",
      "         -1.1777e+01, -1.5750e+01, -1.5958e+00, -1.0600e+01,  1.8391e+01,\n",
      "         -9.3599e-01,  7.5821e-01, -1.3240e+01,  2.6426e+01,  1.8529e+01,\n",
      "         -5.4116e+00,  1.2510e+01, -4.1943e+00, -1.1037e+01,  1.7397e+01,\n",
      "          3.5800e+00, -2.3966e+00, -7.4558e+00, -1.4341e+01, -2.0218e+01,\n",
      "         -1.0495e+01, -6.8842e+00, -1.1992e+01, -3.6895e+00, -7.6730e+00,\n",
      "         -1.0499e+01, -1.7307e+01,  1.1247e-01, -4.1350e+00, -7.9759e+00,\n",
      "          3.1977e+01,  5.1619e-01,  6.9339e+00, -2.1212e+01,  8.9529e+00,\n",
      "         -1.2861e+01,  7.6024e-01,  9.1319e+00,  8.6401e+00,  1.4644e+01,\n",
      "         -4.3356e+00,  1.5860e+01, -1.4727e+01,  2.2421e+01,  4.6917e+00,\n",
      "         -8.5195e+00,  2.1239e+01, -1.4010e+01, -6.5703e+00,  6.5095e+00,\n",
      "         -2.5431e-01, -6.0720e+00,  3.9241e-01, -5.6241e+00, -1.7728e+01,\n",
      "         -9.8010e+00, -3.1123e+00,  9.9139e+00, -1.3557e+01, -1.1749e+01,\n",
      "          8.3407e-01, -3.9850e+00,  1.3626e+01,  1.5576e+00,  1.2077e+00,\n",
      "          6.8961e+00,  2.8461e+01,  1.0749e+01, -7.4138e+00, -1.2425e+01,\n",
      "          3.0432e+01,  2.1003e+01,  1.5092e+00,  1.1901e+01,  9.8158e+00,\n",
      "          1.5862e+01, -5.1853e+00,  3.2683e+00,  6.3485e-01, -2.4661e+01,\n",
      "          1.9899e+01,  1.7517e+01,  8.1668e+00,  1.1929e+01, -3.8478e+00,\n",
      "         -1.4478e+01, -2.9833e+01,  3.6271e+00, -5.2933e+00,  7.9615e+00,\n",
      "          2.4096e+01,  5.2135e-01,  5.8614e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.9079e+00,  1.3214e+02,  2.4622e+01, -8.0017e+00, -1.7293e+01,\n",
      "          2.9362e+00, -2.1267e+00, -1.4601e+01,  2.2314e+01,  5.8388e+00,\n",
      "         -1.2495e+01,  2.5429e+00,  9.7352e+00,  2.5872e-01,  7.0210e+00,\n",
      "          9.7292e+00, -7.0216e+00, -3.1691e+00,  4.9413e+00,  1.9768e+01,\n",
      "          1.2400e+01,  2.4574e+00, -2.1143e+00, -1.3758e-01,  1.2398e+01,\n",
      "         -4.7114e+00,  5.2613e+00, -2.0312e+00, -6.6901e+00, -1.4993e+00,\n",
      "          7.9710e+00, -2.6095e+01, -2.4566e+00, -3.4830e+00,  5.5492e+00,\n",
      "         -1.1378e+01, -1.5630e+01, -1.7615e+00, -1.0388e+01,  1.8653e+01,\n",
      "         -1.6108e-01,  9.7542e-01, -1.3199e+01,  2.5951e+01,  1.8763e+01,\n",
      "         -5.5842e+00,  1.2052e+01, -4.0391e+00, -1.0802e+01,  1.7656e+01,\n",
      "          3.4783e+00, -2.2112e+00, -7.2337e+00, -1.4362e+01, -2.0712e+01,\n",
      "         -1.0521e+01, -6.9529e+00, -1.1940e+01, -3.3263e+00, -8.1309e+00,\n",
      "         -1.0444e+01, -1.6911e+01, -2.7583e-01, -3.7316e+00, -8.3166e+00,\n",
      "          3.1949e+01,  6.2438e-01,  7.0668e+00, -2.0827e+01,  9.2240e+00,\n",
      "         -1.2590e+01,  9.4107e-01,  9.9655e+00,  9.3060e+00,  1.4762e+01,\n",
      "         -4.2995e+00,  1.6049e+01, -1.4513e+01,  2.2384e+01,  4.6713e+00,\n",
      "         -8.8622e+00,  2.1937e+01, -1.4002e+01, -6.1612e+00,  7.1236e+00,\n",
      "         -3.3951e-01, -5.5710e+00,  3.9272e-02, -5.8571e+00, -1.8015e+01,\n",
      "         -9.2184e+00, -2.3928e+00,  9.8756e+00, -1.3896e+01, -1.2117e+01,\n",
      "          1.3460e+00, -3.7839e+00,  1.3609e+01,  2.0775e+00,  1.2061e+00,\n",
      "          7.2297e+00,  2.8842e+01,  1.0907e+01, -7.4379e+00, -1.2460e+01,\n",
      "          3.0557e+01,  2.0544e+01,  2.1134e+00,  1.1910e+01,  9.5115e+00,\n",
      "          1.5947e+01, -5.8006e+00,  3.6894e+00,  1.1479e+00, -2.3952e+01,\n",
      "          2.0022e+01,  1.8018e+01,  8.4445e+00,  1.2018e+01, -4.0152e+00,\n",
      "         -1.5153e+01, -2.9649e+01,  3.3607e+00, -5.4117e+00,  7.8063e+00,\n",
      "          2.4186e+01,  1.1604e+00,  2.1325e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.9983e+00,  1.3227e+02,  2.4483e+01, -7.8842e+00, -1.7245e+01,\n",
      "          2.9100e+00, -2.2268e+00, -1.4736e+01,  2.2827e+01,  5.2067e+00,\n",
      "         -1.2589e+01,  2.1502e+00,  9.6217e+00, -5.0506e-01,  7.1985e+00,\n",
      "          9.8309e+00, -6.4376e+00, -2.6403e+00,  5.1931e+00,  2.0176e+01,\n",
      "          1.1983e+01,  2.3254e+00, -1.9079e+00,  3.5992e-02,  1.2462e+01,\n",
      "         -5.0312e+00,  5.2941e+00, -2.1281e+00, -7.2678e+00, -1.5243e+00,\n",
      "          7.7010e+00, -2.6400e+01, -1.7586e+00, -3.4716e+00,  5.3540e+00,\n",
      "         -1.1720e+01, -1.5802e+01, -1.1219e+00, -1.0285e+01,  1.8561e+01,\n",
      "         -7.6884e-01,  7.3977e-01, -1.2537e+01,  2.6133e+01,  1.8466e+01,\n",
      "         -5.3478e+00,  1.2308e+01, -3.8894e+00, -1.1508e+01,  1.7193e+01,\n",
      "          3.0042e+00, -1.5562e+00, -7.6784e+00, -1.4514e+01, -2.0252e+01,\n",
      "         -1.0437e+01, -6.6974e+00, -1.2236e+01, -3.1694e+00, -7.6729e+00,\n",
      "         -1.0476e+01, -1.6642e+01, -2.8050e-01, -4.5277e+00, -8.2669e+00,\n",
      "          3.1662e+01,  3.6715e-01,  6.9182e+00, -2.1080e+01,  8.4932e+00,\n",
      "         -1.2582e+01,  9.4432e-01,  9.4191e+00,  9.2171e+00,  1.4889e+01,\n",
      "         -4.3374e+00,  1.5585e+01, -1.4288e+01,  2.2473e+01,  4.8219e+00,\n",
      "         -9.0869e+00,  2.2328e+01, -1.3986e+01, -6.5769e+00,  7.3209e+00,\n",
      "         -5.0554e-01, -6.0079e+00,  4.5410e-01, -5.9798e+00, -1.8036e+01,\n",
      "         -9.2441e+00, -2.6464e+00,  9.6099e+00, -1.3963e+01, -1.1917e+01,\n",
      "          1.0553e+00, -3.6835e+00,  1.3786e+01,  1.7530e+00,  1.0821e+00,\n",
      "          6.8348e+00,  2.8817e+01,  1.1067e+01, -6.9284e+00, -1.2546e+01,\n",
      "          3.0693e+01,  2.0750e+01,  1.7076e+00,  1.2197e+01,  9.3751e+00,\n",
      "          1.5913e+01, -5.4731e+00,  3.2927e+00,  1.1444e+00, -2.4089e+01,\n",
      "          2.0194e+01,  1.8309e+01,  8.0827e+00,  1.2068e+01, -4.0594e+00,\n",
      "         -1.4705e+01, -2.9475e+01,  2.7750e+00, -5.9326e+00,  8.0197e+00,\n",
      "          2.3611e+01,  1.0258e+00,  7.1403e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[  9.5115, 132.1766,  24.0044,  -7.7476, -17.0789,   3.0101,  -2.3939,\n",
      "         -14.5447,  22.6062,   5.4158, -12.7037,   2.2527,   9.5189,  -0.1816,\n",
      "           7.3196,   9.8004,  -6.6715,  -2.9377,   5.4756,  20.1839,  12.0852,\n",
      "           2.4121,  -2.0950,  -0.2440,  12.9795,  -5.1885,   5.4090,  -2.5324,\n",
      "          -6.8049,  -1.8320,   7.2933, -26.2509,  -1.6603,  -3.8076,   5.1587,\n",
      "         -11.4723, -16.6718,  -1.4971, -10.3517,  19.0825,  -0.5596,   0.6457,\n",
      "         -12.7931,  26.1938,  18.3934,  -5.3231,  11.9584,  -4.3025, -11.2972,\n",
      "          17.4213,   2.8429,  -1.3802,  -7.3397, -14.4276, -20.4410, -10.6986,\n",
      "          -6.7336, -12.1432,  -3.3307,  -8.0425, -10.5060, -16.7778,  -0.4285,\n",
      "          -4.1704,  -8.3909,  31.7165,   0.5626,   7.1498, -20.9537,   8.5341,\n",
      "         -12.4053,   0.7454,   9.3516,   8.9852,  14.9098,  -4.5240,  15.6476,\n",
      "         -14.3283,  22.3971,   4.6321,  -9.1820,  22.0092, -13.8721,  -6.5612,\n",
      "           7.1672,  -0.8569,  -6.4624,   0.4554,  -5.7676, -18.3457,  -9.6899,\n",
      "          -2.5952,   9.9368, -14.0654, -11.4985,   0.8182,  -3.4700,  13.8099,\n",
      "           1.7078,   1.0711,   6.7587,  28.7875,  10.9308,  -7.3522, -12.2676,\n",
      "          30.6568,  20.5823,   1.4400,  12.1931,   9.0500,  15.8864,  -5.4918,\n",
      "           2.9281,   1.1261, -24.2789,  19.9479,  18.4344,   7.9019,  12.2296,\n",
      "          -3.7594, -14.9063, -29.1286,   3.1852,  -5.7108,   7.8637,  24.0432,\n",
      "           0.7436,   0.9407]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0114e+01,  1.3224e+02,  2.4361e+01, -8.0881e+00, -1.7358e+01,\n",
      "          3.2797e+00, -2.1935e+00, -1.4846e+01,  2.2352e+01,  5.8787e+00,\n",
      "         -1.2560e+01,  2.4671e+00,  9.6836e+00,  7.2168e-02,  7.7128e+00,\n",
      "          9.7705e+00, -6.3489e+00, -3.3526e+00,  5.2818e+00,  2.0244e+01,\n",
      "          1.2892e+01,  1.8984e+00, -2.1041e+00, -2.6346e-02,  1.2658e+01,\n",
      "         -4.9076e+00,  5.2703e+00, -2.2414e+00, -6.9395e+00, -1.7129e+00,\n",
      "          7.7373e+00, -2.6059e+01, -1.8860e+00, -3.6059e+00,  5.4711e+00,\n",
      "         -1.1823e+01, -1.6002e+01, -1.5971e+00, -1.0551e+01,  1.8488e+01,\n",
      "         -9.0617e-01,  6.7786e-01, -1.3264e+01,  2.6370e+01,  1.8449e+01,\n",
      "         -5.3450e+00,  1.2399e+01, -4.1430e+00, -1.1069e+01,  1.7449e+01,\n",
      "          3.3752e+00, -2.2717e+00, -7.4329e+00, -1.4330e+01, -2.0421e+01,\n",
      "         -1.0647e+01, -6.8749e+00, -1.2024e+01, -3.5808e+00, -7.8077e+00,\n",
      "         -1.0576e+01, -1.7311e+01,  9.3872e-02, -4.1275e+00, -7.9465e+00,\n",
      "          3.1903e+01,  5.3329e-01,  6.9913e+00, -2.1217e+01,  8.9491e+00,\n",
      "         -1.2712e+01,  8.1308e-01,  9.1851e+00,  8.6084e+00,  1.4669e+01,\n",
      "         -4.3885e+00,  1.5824e+01, -1.4615e+01,  2.2266e+01,  4.5706e+00,\n",
      "         -8.4950e+00,  2.1418e+01, -1.4073e+01, -6.5172e+00,  6.6985e+00,\n",
      "         -3.9809e-01, -6.1323e+00,  3.4222e-01, -5.6142e+00, -1.7824e+01,\n",
      "         -9.8152e+00, -3.0351e+00,  9.9358e+00, -1.3614e+01, -1.1761e+01,\n",
      "          7.6838e-01, -3.8929e+00,  1.3596e+01,  1.6258e+00,  1.1900e+00,\n",
      "          6.8468e+00,  2.8638e+01,  1.0782e+01, -7.3857e+00, -1.2278e+01,\n",
      "          3.0544e+01,  2.0819e+01,  1.3546e+00,  1.1950e+01,  9.7758e+00,\n",
      "          1.5861e+01, -5.3671e+00,  3.1932e+00,  6.8291e-01, -2.4551e+01,\n",
      "          1.9832e+01,  1.7812e+01,  8.0306e+00,  1.1949e+01, -3.7108e+00,\n",
      "         -1.4617e+01, -2.9877e+01,  3.5495e+00, -5.2968e+00,  8.0376e+00,\n",
      "          2.4148e+01,  5.4063e-01,  6.0031e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.9686e+00,  1.3208e+02,  2.4664e+01, -7.9067e+00, -1.7185e+01,\n",
      "          3.0572e+00, -2.0405e+00, -1.4646e+01,  2.2318e+01,  5.8696e+00,\n",
      "         -1.2488e+01,  2.4936e+00,  9.7909e+00,  3.9848e-02,  7.1313e+00,\n",
      "          9.7162e+00, -6.7875e+00, -3.2847e+00,  5.0937e+00,  1.9615e+01,\n",
      "          1.2464e+01,  2.3481e+00, -2.1812e+00, -1.1884e-01,  1.2571e+01,\n",
      "         -4.9507e+00,  5.3517e+00, -2.1037e+00, -6.7621e+00, -1.4102e+00,\n",
      "          7.8190e+00, -2.6112e+01, -2.2763e+00, -3.4918e+00,  5.5588e+00,\n",
      "         -1.1413e+01, -1.5853e+01, -1.7565e+00, -1.0321e+01,  1.8765e+01,\n",
      "         -1.5579e-01,  8.5746e-01, -1.3263e+01,  2.5927e+01,  1.8699e+01,\n",
      "         -5.4844e+00,  1.1995e+01, -4.0125e+00, -1.0880e+01,  1.7643e+01,\n",
      "          3.2885e+00, -2.0563e+00, -7.2624e+00, -1.4331e+01, -2.0942e+01,\n",
      "         -1.0657e+01, -6.9121e+00, -1.1917e+01, -3.2690e+00, -8.2756e+00,\n",
      "         -1.0524e+01, -1.6984e+01, -2.7415e-01, -3.7666e+00, -8.3014e+00,\n",
      "          3.1882e+01,  6.4952e-01,  7.0843e+00, -2.0890e+01,  9.1770e+00,\n",
      "         -1.2461e+01,  9.2265e-01,  9.9425e+00,  9.2536e+00,  1.4781e+01,\n",
      "         -4.3594e+00,  1.5984e+01, -1.4379e+01,  2.2253e+01,  4.5655e+00,\n",
      "         -8.8299e+00,  2.2054e+01, -1.4100e+01, -6.1471e+00,  7.2385e+00,\n",
      "         -4.7991e-01, -5.6493e+00,  3.0505e-02, -5.8095e+00, -1.8086e+01,\n",
      "         -9.2815e+00, -2.3399e+00,  9.8852e+00, -1.3950e+01, -1.2089e+01,\n",
      "          1.2903e+00, -3.6707e+00,  1.3518e+01,  2.1414e+00,  1.2136e+00,\n",
      "          7.1315e+00,  2.8985e+01,  1.0964e+01, -7.4336e+00, -1.2349e+01,\n",
      "          3.0665e+01,  2.0362e+01,  1.9301e+00,  1.1952e+01,  9.4924e+00,\n",
      "          1.5909e+01, -5.9589e+00,  3.5896e+00,  1.2051e+00, -2.3837e+01,\n",
      "          1.9918e+01,  1.8281e+01,  8.3488e+00,  1.2001e+01, -3.8735e+00,\n",
      "         -1.5242e+01, -2.9755e+01,  3.3073e+00, -5.4015e+00,  7.9074e+00,\n",
      "          2.4190e+01,  1.0892e+00,  2.2023e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0075e+01,  1.3220e+02,  2.4530e+01, -7.7646e+00, -1.7125e+01,\n",
      "          2.9992e+00, -2.1459e+00, -1.4788e+01,  2.2803e+01,  5.2776e+00,\n",
      "         -1.2566e+01,  2.0858e+00,  9.6231e+00, -6.9480e-01,  7.3052e+00,\n",
      "          9.8381e+00, -6.2291e+00, -2.7720e+00,  5.3815e+00,  1.9964e+01,\n",
      "          1.2047e+01,  2.2045e+00, -1.9919e+00,  6.9415e-02,  1.2649e+01,\n",
      "         -5.2545e+00,  5.3401e+00, -2.2005e+00, -7.2895e+00, -1.4370e+00,\n",
      "          7.5431e+00, -2.6429e+01, -1.6328e+00, -3.4957e+00,  5.3321e+00,\n",
      "         -1.1706e+01, -1.6045e+01, -1.1072e+00, -1.0189e+01,  1.8710e+01,\n",
      "         -7.5043e-01,  5.8720e-01, -1.2657e+01,  2.6073e+01,  1.8372e+01,\n",
      "         -5.2645e+00,  1.2256e+01, -3.8812e+00, -1.1566e+01,  1.7173e+01,\n",
      "          2.8602e+00, -1.3970e+00, -7.6944e+00, -1.4427e+01, -2.0545e+01,\n",
      "         -1.0554e+01, -6.6214e+00, -1.2259e+01, -3.1828e+00, -7.8783e+00,\n",
      "         -1.0521e+01, -1.6735e+01, -2.2635e-01, -4.5445e+00, -8.2743e+00,\n",
      "          3.1641e+01,  3.8987e-01,  6.9497e+00, -2.1140e+01,  8.5113e+00,\n",
      "         -1.2434e+01,  9.0947e-01,  9.3949e+00,  9.1579e+00,  1.4878e+01,\n",
      "         -4.3933e+00,  1.5475e+01, -1.4145e+01,  2.2365e+01,  4.7225e+00,\n",
      "         -9.0647e+00,  2.2418e+01, -1.4083e+01, -6.5047e+00,  7.4262e+00,\n",
      "         -6.5536e-01, -6.0347e+00,  4.1591e-01, -5.9078e+00, -1.8108e+01,\n",
      "         -9.3061e+00, -2.5775e+00,  9.6247e+00, -1.4059e+01, -1.1898e+01,\n",
      "          1.0286e+00, -3.5167e+00,  1.3691e+01,  1.8741e+00,  1.1052e+00,\n",
      "          6.7910e+00,  2.8915e+01,  1.1138e+01, -6.9494e+00, -1.2441e+01,\n",
      "          3.0821e+01,  2.0586e+01,  1.5060e+00,  1.2200e+01,  9.3753e+00,\n",
      "          1.5867e+01, -5.7147e+00,  3.2038e+00,  1.2419e+00, -2.3899e+01,\n",
      "          2.0067e+01,  1.8573e+01,  7.9634e+00,  1.2056e+01, -3.9098e+00,\n",
      "         -1.4806e+01, -2.9628e+01,  2.7889e+00, -5.9123e+00,  8.1251e+00,\n",
      "          2.3620e+01,  9.7327e-01,  7.1229e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[  9.5756, 132.1171,  24.0716,  -7.6483, -16.9443,   3.0978,  -2.3312,\n",
      "         -14.5675,  22.5860,   5.4741, -12.6707,   2.1948,   9.5162,  -0.3751,\n",
      "           7.4325,   9.7924,  -6.4685,  -3.0770,   5.6914,  20.0055,  12.1751,\n",
      "           2.2713,  -2.1679,  -0.2193,  13.1546,  -5.3788,   5.4166,  -2.5909,\n",
      "          -6.8170,  -1.7643,   7.1527, -26.3140,  -1.5449,  -3.8120,   5.1087,\n",
      "         -11.4786, -16.8420,  -1.4690, -10.2813,  19.2215,  -0.5371,   0.4943,\n",
      "         -12.9159,  26.1375,  18.3211,  -5.2159,  11.9243,  -4.3038, -11.3470,\n",
      "          17.4014,   2.7072,  -1.2207,  -7.3562, -14.3875, -20.6912, -10.7759,\n",
      "          -6.6273, -12.1618,  -3.3761,  -8.2175, -10.4956, -16.8890,  -0.3654,\n",
      "          -4.2006,  -8.3978,  31.6992,   0.5793,   7.1630, -21.0303,   8.5399,\n",
      "         -12.2738,   0.7016,   9.3157,   8.9360,  14.8837,  -4.5776,  15.5364,\n",
      "         -14.1977,  22.3189,   4.5956,  -9.1513,  22.0935, -13.9739,  -6.5098,\n",
      "           7.2552,  -0.9827,  -6.4719,   0.4252,  -5.6830, -18.3512,  -9.7929,\n",
      "          -2.5431,   9.9670, -14.1587, -11.4901,   0.8161,  -3.3240,  13.7017,\n",
      "           1.8501,   1.0628,   6.7422,  28.8858,  10.9954,  -7.3624, -12.1677,\n",
      "          30.8132,  20.4688,   1.2629,  12.1968,   9.1204,  15.8569,  -5.7648,\n",
      "           2.8414,   1.2168, -24.0978,  19.8441,  18.6429,   7.7737,  12.2360,\n",
      "          -3.6390, -14.9965, -29.2826,   3.1791,  -5.7109,   7.9715,  24.0501,\n",
      "           0.6789,   0.9080]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0144e+01,  1.3220e+02,  2.4378e+01, -7.9834e+00, -1.7210e+01,\n",
      "          3.3334e+00, -2.1276e+00, -1.4789e+01,  2.2329e+01,  5.9153e+00,\n",
      "         -1.2539e+01,  2.4164e+00,  9.6872e+00, -1.2281e-01,  7.7957e+00,\n",
      "          9.7677e+00, -6.2024e+00, -3.4372e+00,  5.5096e+00,  2.0107e+01,\n",
      "          1.2952e+01,  1.7915e+00, -2.1390e+00, -3.7493e-02,  1.2831e+01,\n",
      "         -5.0925e+00,  5.2842e+00, -2.3155e+00, -6.9829e+00, -1.6833e+00,\n",
      "          7.6045e+00, -2.6159e+01, -1.7732e+00, -3.6630e+00,  5.3924e+00,\n",
      "         -1.1842e+01, -1.6227e+01, -1.5487e+00, -1.0507e+01,  1.8640e+01,\n",
      "         -8.7867e-01,  5.4556e-01, -1.3312e+01,  2.6319e+01,  1.8344e+01,\n",
      "         -5.2547e+00,  1.2335e+01, -4.1586e+00, -1.1095e+01,  1.7427e+01,\n",
      "          3.2087e+00, -2.0979e+00, -7.4137e+00, -1.4326e+01, -2.0607e+01,\n",
      "         -1.0715e+01, -6.8155e+00, -1.2090e+01, -3.5980e+00, -7.9845e+00,\n",
      "         -1.0526e+01, -1.7378e+01,  1.0815e-01, -4.1439e+00, -7.9504e+00,\n",
      "          3.1879e+01,  5.2078e-01,  7.0280e+00, -2.1267e+01,  8.9339e+00,\n",
      "         -1.2576e+01,  8.0169e-01,  9.1757e+00,  8.5802e+00,  1.4646e+01,\n",
      "         -4.4425e+00,  1.5714e+01, -1.4536e+01,  2.2171e+01,  4.5549e+00,\n",
      "         -8.4930e+00,  2.1555e+01, -1.4147e+01, -6.4524e+00,  6.8145e+00,\n",
      "         -5.6419e-01, -6.1721e+00,  2.9339e-01, -5.5490e+00, -1.7857e+01,\n",
      "         -9.9028e+00, -2.9766e+00,  9.9941e+00, -1.3737e+01, -1.1748e+01,\n",
      "          7.5127e-01, -3.7487e+00,  1.3553e+01,  1.7739e+00,  1.1663e+00,\n",
      "          6.8527e+00,  2.8739e+01,  1.0832e+01, -7.3951e+00, -1.2168e+01,\n",
      "          3.0689e+01,  2.0727e+01,  1.2116e+00,  1.1955e+01,  9.8150e+00,\n",
      "          1.5853e+01, -5.6252e+00,  3.0995e+00,  7.6788e-01, -2.4390e+01,\n",
      "          1.9754e+01,  1.8011e+01,  7.8641e+00,  1.1976e+01, -3.6012e+00,\n",
      "         -1.4749e+01, -2.9941e+01,  3.5403e+00, -5.3362e+00,  8.1444e+00,\n",
      "          2.4168e+01,  5.2026e-01,  5.8600e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0002e+01,  1.3205e+02,  2.4622e+01, -7.8213e+00, -1.7033e+01,\n",
      "          3.1225e+00, -1.9946e+00, -1.4558e+01,  2.2287e+01,  5.9041e+00,\n",
      "         -1.2434e+01,  2.4316e+00,  9.8045e+00, -1.5436e-01,  7.2758e+00,\n",
      "          9.7457e+00, -6.6444e+00, -3.3928e+00,  5.3847e+00,  1.9566e+01,\n",
      "          1.2548e+01,  2.2316e+00, -2.1944e+00, -1.2803e-01,  1.2693e+01,\n",
      "         -5.1389e+00,  5.4011e+00, -2.1904e+00, -6.8457e+00, -1.4138e+00,\n",
      "          7.7221e+00, -2.6242e+01, -2.1652e+00, -3.5640e+00,  5.4723e+00,\n",
      "         -1.1464e+01, -1.6114e+01, -1.7181e+00, -1.0295e+01,  1.8905e+01,\n",
      "         -1.5428e-01,  6.9605e-01, -1.3268e+01,  2.5898e+01,  1.8608e+01,\n",
      "         -5.3685e+00,  1.1935e+01, -4.0242e+00, -1.0898e+01,  1.7588e+01,\n",
      "          3.1379e+00, -1.9083e+00, -7.2605e+00, -1.4352e+01, -2.1071e+01,\n",
      "         -1.0730e+01, -6.9027e+00, -1.1984e+01, -3.2594e+00, -8.4108e+00,\n",
      "         -1.0437e+01, -1.7052e+01, -2.4484e-01, -3.8039e+00, -8.2348e+00,\n",
      "          3.1888e+01,  5.9149e-01,  7.1176e+00, -2.0966e+01,  9.1143e+00,\n",
      "         -1.2358e+01,  9.1684e-01,  9.9070e+00,  9.2002e+00,  1.4774e+01,\n",
      "         -4.4286e+00,  1.5868e+01, -1.4338e+01,  2.2170e+01,  4.5703e+00,\n",
      "         -8.8029e+00,  2.2190e+01, -1.4190e+01, -6.1032e+00,  7.3369e+00,\n",
      "         -6.2176e-01, -5.7230e+00,  2.6977e-02, -5.7581e+00, -1.8101e+01,\n",
      "         -9.4573e+00, -2.3082e+00,  9.9815e+00, -1.4031e+01, -1.2079e+01,\n",
      "          1.2504e+00, -3.5561e+00,  1.3473e+01,  2.3058e+00,  1.1897e+00,\n",
      "          7.1143e+00,  2.9063e+01,  1.0993e+01, -7.4200e+00, -1.2200e+01,\n",
      "          3.0773e+01,  2.0298e+01,  1.7950e+00,  1.1996e+01,  9.5652e+00,\n",
      "          1.5909e+01, -6.1849e+00,  3.4900e+00,  1.2432e+00, -2.3731e+01,\n",
      "          1.9815e+01,  1.8426e+01,  8.1572e+00,  1.2002e+01, -3.7605e+00,\n",
      "         -1.5357e+01, -2.9798e+01,  3.2952e+00, -5.4319e+00,  8.0246e+00,\n",
      "          2.4207e+01,  1.0259e+00,  2.0682e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0120e+01,  1.3215e+02,  2.4519e+01, -7.6629e+00, -1.6968e+01,\n",
      "          3.0591e+00, -2.0731e+00, -1.4674e+01,  2.2724e+01,  5.3423e+00,\n",
      "         -1.2472e+01,  2.0586e+00,  9.6229e+00, -8.5036e-01,  7.4728e+00,\n",
      "          9.8826e+00, -6.1358e+00, -2.9036e+00,  5.6489e+00,  1.9880e+01,\n",
      "          1.2121e+01,  2.1077e+00, -2.0108e+00,  8.5215e-02,  1.2768e+01,\n",
      "         -5.4676e+00,  5.4498e+00, -2.2487e+00, -7.4222e+00, -1.4526e+00,\n",
      "          7.4442e+00, -2.6534e+01, -1.5408e+00, -3.5609e+00,  5.2434e+00,\n",
      "         -1.1745e+01, -1.6351e+01, -1.1083e+00, -1.0168e+01,  1.8832e+01,\n",
      "         -7.1454e-01,  4.3715e-01, -1.2676e+01,  2.6030e+01,  1.8289e+01,\n",
      "         -5.1638e+00,  1.2165e+01, -3.8759e+00, -1.1527e+01,  1.7129e+01,\n",
      "          2.7242e+00, -1.3105e+00, -7.6798e+00, -1.4442e+01, -2.0700e+01,\n",
      "         -1.0676e+01, -6.6232e+00, -1.2345e+01, -3.1599e+00, -8.0548e+00,\n",
      "         -1.0421e+01, -1.6798e+01, -1.4474e-01, -4.5346e+00, -8.2260e+00,\n",
      "          3.1671e+01,  3.3819e-01,  7.0110e+00, -2.1195e+01,  8.5061e+00,\n",
      "         -1.2317e+01,  9.3051e-01,  9.3774e+00,  9.0994e+00,  1.4888e+01,\n",
      "         -4.4569e+00,  1.5396e+01, -1.4117e+01,  2.2266e+01,  4.6911e+00,\n",
      "         -9.0122e+00,  2.2557e+01, -1.4162e+01, -6.4218e+00,  7.5302e+00,\n",
      "         -7.7186e-01, -6.0636e+00,  3.8947e-01, -5.8801e+00, -1.8175e+01,\n",
      "         -9.4811e+00, -2.5225e+00,  9.7634e+00, -1.4137e+01, -1.1920e+01,\n",
      "          9.9550e-01, -3.3835e+00,  1.3651e+01,  2.0856e+00,  1.1032e+00,\n",
      "          6.7717e+00,  2.8972e+01,  1.1148e+01, -6.9345e+00, -1.2270e+01,\n",
      "          3.0941e+01,  2.0490e+01,  1.4040e+00,  1.2247e+01,  9.4352e+00,\n",
      "          1.5871e+01, -5.9533e+00,  3.1314e+00,  1.2918e+00, -2.3745e+01,\n",
      "          1.9944e+01,  1.8743e+01,  7.7608e+00,  1.2025e+01, -3.7493e+00,\n",
      "         -1.4945e+01, -2.9680e+01,  2.8100e+00, -5.9103e+00,  8.2633e+00,\n",
      "          2.3661e+01,  9.4649e-01,  6.9579e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[  9.6127, 132.0591,  24.1073,  -7.5500, -16.8164,   3.1650,  -2.2524,\n",
      "         -14.4922,  22.5155,   5.5117, -12.5656,   2.1923,   9.5114,  -0.5438,\n",
      "           7.5965,   9.8228,  -6.3347,  -3.2405,   5.8984,  19.8891,  12.2460,\n",
      "           2.1651,  -2.1769,  -0.1904,  13.2717,  -5.6151,   5.5588,  -2.6098,\n",
      "          -6.9321,  -1.7407,   7.0492, -26.3842,  -1.4321,  -3.8236,   5.0421,\n",
      "         -11.5103, -17.0952,  -1.4588, -10.2518,  19.3422,  -0.4879,   0.3308,\n",
      "         -12.9527,  26.0974,  18.2799,  -5.1329,  11.8336,  -4.2709, -11.3265,\n",
      "          17.3827,   2.5607,  -1.1440,  -7.3812, -14.4053, -20.8774, -10.9131,\n",
      "          -6.5732, -12.1984,  -3.3173,  -8.3447, -10.4173, -16.9421,  -0.2623,\n",
      "          -4.2100,  -8.3486,  31.7131,   0.5368,   7.2240, -21.0809,   8.5602,\n",
      "         -12.1774,   0.7117,   9.2852,   8.8920,  14.9191,  -4.6269,  15.4756,\n",
      "         -14.1289,  22.2064,   4.5434,  -9.0961,  22.2153, -14.0425,  -6.4397,\n",
      "           7.3571,  -1.0468,  -6.4820,   0.4024,  -5.6937, -18.3995,  -9.9281,\n",
      "          -2.4492,  10.0807, -14.2060, -11.5201,   0.8117,  -3.2045,  13.6202,\n",
      "           2.0418,   1.0689,   6.6680,  28.9603,  11.0097,  -7.3154, -11.9943,\n",
      "          30.9646,  20.3659,   1.1744,  12.2549,   9.1765,  15.8641,  -5.9959,\n",
      "           2.7691,   1.2229, -23.9522,  19.7179,  18.8014,   7.5801,  12.1898,\n",
      "          -3.4818, -15.1148, -29.3598,   3.1655,  -5.6949,   8.1463,  24.0629,\n",
      "           0.6420,   0.8751]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0136e+01,  1.3214e+02,  2.4398e+01, -7.8598e+00, -1.7119e+01,\n",
      "          3.4099e+00, -2.0255e+00, -1.4719e+01,  2.2272e+01,  5.9408e+00,\n",
      "         -1.2514e+01,  2.4275e+00,  9.6625e+00, -2.8683e-01,  7.9139e+00,\n",
      "          9.7984e+00, -6.0348e+00, -3.5623e+00,  5.6318e+00,  1.9958e+01,\n",
      "          1.2981e+01,  1.7168e+00, -2.1353e+00, -4.7070e-02,  1.3016e+01,\n",
      "         -5.3546e+00,  5.4313e+00, -2.3298e+00, -7.0425e+00, -1.6371e+00,\n",
      "          7.4741e+00, -2.6183e+01, -1.6069e+00, -3.6605e+00,  5.3267e+00,\n",
      "         -1.1846e+01, -1.6483e+01, -1.5167e+00, -1.0490e+01,  1.8794e+01,\n",
      "         -8.3842e-01,  3.9333e-01, -1.3340e+01,  2.6284e+01,  1.8304e+01,\n",
      "         -5.2254e+00,  1.2243e+01, -4.1498e+00, -1.1117e+01,  1.7433e+01,\n",
      "          3.0090e+00, -1.9834e+00, -7.4582e+00, -1.4338e+01, -2.0790e+01,\n",
      "         -1.0852e+01, -6.7436e+00, -1.2111e+01, -3.5292e+00, -8.1024e+00,\n",
      "         -1.0498e+01, -1.7415e+01,  1.7403e-01, -4.1457e+00, -7.9268e+00,\n",
      "          3.1848e+01,  4.7944e-01,  7.0966e+00, -2.1298e+01,  8.9449e+00,\n",
      "         -1.2481e+01,  8.0919e-01,  9.1220e+00,  8.5752e+00,  1.4698e+01,\n",
      "         -4.5081e+00,  1.5673e+01, -1.4426e+01,  2.2036e+01,  4.4577e+00,\n",
      "         -8.4668e+00,  2.1680e+01, -1.4183e+01, -6.3917e+00,  6.9156e+00,\n",
      "         -6.5313e-01, -6.2007e+00,  2.3443e-01, -5.5711e+00, -1.7946e+01,\n",
      "         -9.9456e+00, -2.8429e+00,  1.0108e+01, -1.3800e+01, -1.1731e+01,\n",
      "          7.5472e-01, -3.6087e+00,  1.3471e+01,  1.9047e+00,  1.1701e+00,\n",
      "          6.7131e+00,  2.8819e+01,  1.0864e+01, -7.3650e+00, -1.2013e+01,\n",
      "          3.0845e+01,  2.0615e+01,  1.1302e+00,  1.2005e+01,  9.7918e+00,\n",
      "          1.5870e+01, -5.8189e+00,  3.0221e+00,  7.6498e-01, -2.4248e+01,\n",
      "          1.9645e+01,  1.8188e+01,  7.6753e+00,  1.1940e+01, -3.4532e+00,\n",
      "         -1.4857e+01, -2.9975e+01,  3.5266e+00, -5.3360e+00,  8.3456e+00,\n",
      "          2.4155e+01,  4.9962e-01,  5.7885e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.9995e+00,  1.3201e+02,  2.4614e+01, -7.7169e+00, -1.6960e+01,\n",
      "          3.2274e+00, -1.9105e+00, -1.4510e+01,  2.2236e+01,  5.9345e+00,\n",
      "         -1.2465e+01,  2.4271e+00,  9.7711e+00, -3.0680e-01,  7.4293e+00,\n",
      "          9.7969e+00, -6.4344e+00, -3.5090e+00,  5.5237e+00,  1.9459e+01,\n",
      "          1.2606e+01,  2.1334e+00, -2.1927e+00, -1.4233e-01,  1.2889e+01,\n",
      "         -5.3758e+00,  5.5042e+00, -2.2270e+00, -6.8732e+00, -1.3763e+00,\n",
      "          7.6040e+00, -2.6255e+01, -1.9658e+00, -3.5269e+00,  5.3975e+00,\n",
      "         -1.1494e+01, -1.6329e+01, -1.6774e+00, -1.0300e+01,  1.9061e+01,\n",
      "         -1.7428e-01,  5.2130e-01, -1.3309e+01,  2.5869e+01,  1.8583e+01,\n",
      "         -5.3306e+00,  1.1882e+01, -4.0467e+00, -1.0978e+01,  1.7564e+01,\n",
      "          2.9482e+00, -1.7820e+00, -7.3514e+00, -1.4360e+01, -2.1201e+01,\n",
      "         -1.0828e+01, -6.8116e+00, -1.2000e+01, -3.2435e+00, -8.4922e+00,\n",
      "         -1.0439e+01, -1.7119e+01, -1.7994e-01, -3.8294e+00, -8.1576e+00,\n",
      "          3.1835e+01,  5.3709e-01,  7.1408e+00, -2.1028e+01,  9.0774e+00,\n",
      "         -1.2298e+01,  9.1980e-01,  9.7751e+00,  9.1823e+00,  1.4811e+01,\n",
      "         -4.5322e+00,  1.5819e+01, -1.4211e+01,  2.2071e+01,  4.4828e+00,\n",
      "         -8.7616e+00,  2.2285e+01, -1.4213e+01, -6.0967e+00,  7.3849e+00,\n",
      "         -6.9665e-01, -5.7820e+00, -1.8578e-02, -5.7638e+00, -1.8148e+01,\n",
      "         -9.5317e+00, -2.2154e+00,  1.0113e+01, -1.4060e+01, -1.2013e+01,\n",
      "          1.2467e+00, -3.4335e+00,  1.3348e+01,  2.3993e+00,  1.1726e+00,\n",
      "          6.9311e+00,  2.9111e+01,  1.1037e+01, -7.3889e+00, -1.2054e+01,\n",
      "          3.0916e+01,  2.0216e+01,  1.6853e+00,  1.2054e+01,  9.5688e+00,\n",
      "          1.5952e+01, -6.3451e+00,  3.4043e+00,  1.2369e+00, -2.3635e+01,\n",
      "          1.9721e+01,  1.8564e+01,  7.9827e+00,  1.1987e+01, -3.6365e+00,\n",
      "         -1.5396e+01, -2.9842e+01,  3.2866e+00, -5.4254e+00,  8.2172e+00,\n",
      "          2.4172e+01,  9.4137e-01,  2.0866e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0129e+01,  1.3211e+02,  2.4506e+01, -7.5393e+00, -1.6871e+01,\n",
      "          3.1540e+00, -2.0005e+00, -1.4578e+01,  2.2634e+01,  5.4108e+00,\n",
      "         -1.2488e+01,  2.0499e+00,  9.5701e+00, -9.8021e-01,  7.6018e+00,\n",
      "          9.9518e+00, -5.9705e+00, -2.9898e+00,  5.8247e+00,  1.9740e+01,\n",
      "          1.2186e+01,  2.0335e+00, -2.0073e+00,  6.9040e-02,  1.2952e+01,\n",
      "         -5.7020e+00,  5.5273e+00, -2.3177e+00, -7.4785e+00, -1.4277e+00,\n",
      "          7.3165e+00, -2.6556e+01, -1.3924e+00, -3.5571e+00,  5.1436e+00,\n",
      "         -1.1782e+01, -1.6563e+01, -1.0844e+00, -1.0161e+01,  1.8994e+01,\n",
      "         -7.3260e-01,  2.7667e-01, -1.2744e+01,  2.5990e+01,  1.8255e+01,\n",
      "         -5.1315e+00,  1.2128e+01, -3.8840e+00, -1.1589e+01,  1.7125e+01,\n",
      "          2.5443e+00, -1.2146e+00, -7.7345e+00, -1.4443e+01, -2.0845e+01,\n",
      "         -1.0753e+01, -6.5428e+00, -1.2416e+01, -3.1946e+00, -8.1779e+00,\n",
      "         -1.0433e+01, -1.6885e+01, -5.4526e-02, -4.5302e+00, -8.1300e+00,\n",
      "          3.1648e+01,  2.6946e-01,  7.0184e+00, -2.1241e+01,  8.4989e+00,\n",
      "         -1.2242e+01,  9.4287e-01,  9.2807e+00,  9.0854e+00,  1.4899e+01,\n",
      "         -4.5663e+00,  1.5334e+01, -1.3973e+01,  2.2198e+01,  4.6030e+00,\n",
      "         -8.9675e+00,  2.2698e+01, -1.4218e+01, -6.3787e+00,  7.5885e+00,\n",
      "         -8.6312e-01, -6.1013e+00,  3.1163e-01, -5.8818e+00, -1.8201e+01,\n",
      "         -9.5796e+00, -2.4512e+00,  9.8993e+00, -1.4188e+01, -1.1874e+01,\n",
      "          9.9839e-01, -3.2767e+00,  1.3526e+01,  2.2081e+00,  1.0759e+00,\n",
      "          6.6490e+00,  2.8988e+01,  1.1188e+01, -6.9162e+00, -1.2125e+01,\n",
      "          3.1079e+01,  2.0390e+01,  1.3044e+00,  1.2295e+01,  9.4686e+00,\n",
      "          1.5917e+01, -6.1756e+00,  3.0844e+00,  1.3405e+00, -2.3605e+01,\n",
      "          1.9865e+01,  1.8929e+01,  7.5847e+00,  1.2009e+01, -3.6280e+00,\n",
      "         -1.4999e+01, -2.9753e+01,  2.8171e+00, -5.9046e+00,  8.3975e+00,\n",
      "          2.3644e+01,  8.9409e-01,  7.0709e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[  9.6500, 132.0264,  24.1117,  -7.4817, -16.6842,   3.2337,  -2.2044,\n",
      "         -14.3947,  22.4529,   5.5331, -12.5410,   2.1735,   9.4847,  -0.6913,\n",
      "           7.7069,   9.8790,  -6.1952,  -3.2923,   6.0768,  19.7551,  12.3103,\n",
      "           2.0859,  -2.1773,  -0.1929,  13.3894,  -5.8089,   5.6263,  -2.6899,\n",
      "          -7.0309,  -1.7263,   6.9420, -26.4549,  -1.3213,  -3.8257,   4.9600,\n",
      "         -11.5719, -17.2761,  -1.4056, -10.2299,  19.4764,  -0.4787,   0.1627,\n",
      "         -12.9966,  26.0641,  18.2414,  -5.1057,  11.7925,  -4.2452, -11.3814,\n",
      "          17.3546,   2.3903,  -1.0436,  -7.4202, -14.4151, -21.0207, -10.9877,\n",
      "          -6.4973, -12.2734,  -3.3246,  -8.4202, -10.4356, -16.9814,  -0.1826,\n",
      "          -4.2102,  -8.2267,  31.6787,   0.4540,   7.1957, -21.1116,   8.5619,\n",
      "         -12.1112,   0.7411,   9.2359,   8.8952,  14.8907,  -4.7185,  15.3905,\n",
      "         -14.0019,  22.1252,   4.4791,  -9.0521,  22.3942, -14.1168,  -6.3976,\n",
      "           7.4365,  -1.1330,  -6.5284,   0.3186,  -5.7323, -18.3744, -10.0241,\n",
      "          -2.3961,  10.1569, -14.2629, -11.5060,   0.8121,  -3.1370,  13.5062,\n",
      "           2.1669,   1.0360,   6.5879,  29.0024,  11.0458,  -7.2712, -11.8573,\n",
      "          31.0938,  20.2700,   1.0770,  12.2986,   9.2484,  15.9257,  -6.2179,\n",
      "           2.7223,   1.3067, -23.8357,  19.6787,  18.9991,   7.4108,  12.1861,\n",
      "          -3.3901, -15.1628, -29.4557,   3.1323,  -5.7312,   8.2256,  24.0455,\n",
      "           0.6334,   0.8845]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0177e+01,  1.3212e+02,  2.4361e+01, -7.7916e+00, -1.6974e+01,\n",
      "          3.4524e+00, -1.9599e+00, -1.4597e+01,  2.2237e+01,  5.9556e+00,\n",
      "         -1.2490e+01,  2.3986e+00,  9.6603e+00, -4.5279e-01,  8.0128e+00,\n",
      "          9.8419e+00, -5.9112e+00, -3.5846e+00,  5.7850e+00,  1.9822e+01,\n",
      "          1.2999e+01,  1.6290e+00, -2.1622e+00, -7.7345e-02,  1.3128e+01,\n",
      "         -5.5563e+00,  5.5300e+00, -2.4125e+00, -7.1496e+00, -1.6211e+00,\n",
      "          7.3538e+00, -2.6295e+01, -1.5079e+00, -3.7059e+00,  5.2598e+00,\n",
      "         -1.1897e+01, -1.6734e+01, -1.4484e+00, -1.0465e+01,  1.8920e+01,\n",
      "         -7.8260e-01,  2.3918e-01, -1.3350e+01,  2.6263e+01,  1.8238e+01,\n",
      "         -5.2290e+00,  1.2172e+01, -4.1264e+00, -1.1170e+01,  1.7387e+01,\n",
      "          2.7989e+00, -1.8504e+00, -7.4599e+00, -1.4353e+01, -2.0948e+01,\n",
      "         -1.0956e+01, -6.7381e+00, -1.2169e+01, -3.4810e+00, -8.1746e+00,\n",
      "         -1.0529e+01, -1.7401e+01,  2.1067e-01, -4.1312e+00, -7.8507e+00,\n",
      "          3.1796e+01,  3.9775e-01,  7.0839e+00, -2.1296e+01,  8.9390e+00,\n",
      "         -1.2386e+01,  8.4131e-01,  9.1252e+00,  8.6021e+00,  1.4662e+01,\n",
      "         -4.5973e+00,  1.5579e+01, -1.4317e+01,  2.1919e+01,  4.3988e+00,\n",
      "         -8.4436e+00,  2.1895e+01, -1.4257e+01, -6.3292e+00,  7.0341e+00,\n",
      "         -8.0053e-01, -6.2685e+00,  1.2426e-01, -5.6358e+00, -1.7977e+01,\n",
      "         -1.0003e+01, -2.7751e+00,  1.0143e+01, -1.3903e+01, -1.1723e+01,\n",
      "          7.3772e-01, -3.5331e+00,  1.3410e+01,  2.0094e+00,  1.1544e+00,\n",
      "          6.6394e+00,  2.8888e+01,  1.0911e+01, -7.3277e+00, -1.1880e+01,\n",
      "          3.0951e+01,  2.0493e+01,  1.0428e+00,  1.2051e+01,  9.8105e+00,\n",
      "          1.5911e+01, -6.0137e+00,  2.9463e+00,  8.9067e-01, -2.4124e+01,\n",
      "          1.9603e+01,  1.8423e+01,  7.4873e+00,  1.1930e+01, -3.3794e+00,\n",
      "         -1.4943e+01, -3.0046e+01,  3.4839e+00, -5.4246e+00,  8.4020e+00,\n",
      "          2.4131e+01,  5.4676e-01,  6.2809e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0070e+01,  1.3198e+02,  2.4563e+01, -7.6512e+00, -1.6826e+01,\n",
      "          3.2939e+00, -1.8296e+00, -1.4444e+01,  2.2213e+01,  5.9825e+00,\n",
      "         -1.2425e+01,  2.3743e+00,  9.7796e+00, -4.8653e-01,  7.6040e+00,\n",
      "          9.8402e+00, -6.2633e+00, -3.5814e+00,  5.7003e+00,  1.9378e+01,\n",
      "          1.2649e+01,  1.9761e+00, -2.2671e+00, -1.5686e-01,  1.2997e+01,\n",
      "         -5.5978e+00,  5.6191e+00, -2.3025e+00, -6.9584e+00, -1.3582e+00,\n",
      "          7.4706e+00, -2.6396e+01, -1.8568e+00, -3.5655e+00,  5.3487e+00,\n",
      "         -1.1564e+01, -1.6584e+01, -1.6142e+00, -1.0285e+01,  1.9162e+01,\n",
      "         -1.1155e-01,  3.4838e-01, -1.3333e+01,  2.5861e+01,  1.8523e+01,\n",
      "         -5.3078e+00,  1.1851e+01, -4.0344e+00, -1.1045e+01,  1.7467e+01,\n",
      "          2.7693e+00, -1.6510e+00, -7.3822e+00, -1.4371e+01, -2.1383e+01,\n",
      "         -1.0944e+01, -6.8312e+00, -1.2021e+01, -3.1883e+00, -8.5539e+00,\n",
      "         -1.0462e+01, -1.7146e+01, -1.2242e-01, -3.8333e+00, -8.1010e+00,\n",
      "          3.1802e+01,  4.6552e-01,  7.1262e+00, -2.1056e+01,  9.0486e+00,\n",
      "         -1.2201e+01,  8.9624e-01,  9.7439e+00,  9.1695e+00,  1.4784e+01,\n",
      "         -4.6410e+00,  1.5715e+01, -1.4110e+01,  2.1968e+01,  4.4651e+00,\n",
      "         -8.7231e+00,  2.2447e+01, -1.4313e+01, -6.0568e+00,  7.4679e+00,\n",
      "         -8.3152e-01, -5.8401e+00, -8.5650e-02, -5.8019e+00, -1.8190e+01,\n",
      "         -9.6401e+00, -2.1825e+00,  1.0127e+01, -1.4145e+01, -1.2005e+01,\n",
      "          1.2139e+00, -3.3587e+00,  1.3270e+01,  2.4884e+00,  1.1766e+00,\n",
      "          6.8344e+00,  2.9160e+01,  1.1101e+01, -7.3435e+00, -1.1921e+01,\n",
      "          3.1011e+01,  2.0086e+01,  1.5820e+00,  1.2133e+01,  9.6003e+00,\n",
      "          1.5953e+01, -6.5199e+00,  3.2831e+00,  1.3493e+00, -2.3528e+01,\n",
      "          1.9643e+01,  1.8775e+01,  7.7974e+00,  1.1943e+01, -3.5742e+00,\n",
      "         -1.5470e+01, -2.9962e+01,  3.2532e+00, -5.5039e+00,  8.2797e+00,\n",
      "          2.4138e+01,  9.0297e-01,  2.7820e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0189e+01,  1.3206e+02,  2.4499e+01, -7.4561e+00, -1.6722e+01,\n",
      "          3.2048e+00, -1.8886e+00, -1.4543e+01,  2.2554e+01,  5.5278e+00,\n",
      "         -1.2428e+01,  2.0081e+00,  9.5414e+00, -1.1134e+00,  7.8083e+00,\n",
      "          9.9898e+00, -5.8343e+00, -3.1034e+00,  6.0220e+00,  1.9623e+01,\n",
      "          1.2258e+01,  1.8527e+00, -2.1168e+00,  7.6915e-02,  1.3083e+01,\n",
      "         -5.9290e+00,  5.6255e+00, -2.3459e+00, -7.5174e+00, -1.4114e+00,\n",
      "          7.1223e+00, -2.6663e+01, -1.3023e+00, -3.6122e+00,  5.0911e+00,\n",
      "         -1.1816e+01, -1.6826e+01, -1.0660e+00, -1.0173e+01,  1.9087e+01,\n",
      "         -6.6294e-01,  1.1092e-01, -1.2832e+01,  2.5966e+01,  1.8208e+01,\n",
      "         -5.1019e+00,  1.2117e+01, -3.8795e+00, -1.1642e+01,  1.7070e+01,\n",
      "          2.4172e+00, -1.1079e+00, -7.7378e+00, -1.4451e+01, -2.1062e+01,\n",
      "         -1.0882e+01, -6.5798e+00, -1.2438e+01, -3.1516e+00, -8.2851e+00,\n",
      "         -1.0425e+01, -1.6965e+01,  6.9262e-02, -4.5127e+00, -8.1245e+00,\n",
      "          3.1660e+01,  2.1809e-01,  7.0376e+00, -2.1285e+01,  8.5224e+00,\n",
      "         -1.2097e+01,  8.7934e-01,  9.2729e+00,  9.0469e+00,  1.4899e+01,\n",
      "         -4.7029e+00,  1.5252e+01, -1.3867e+01,  2.2137e+01,  4.6027e+00,\n",
      "         -8.9296e+00,  2.2769e+01, -1.4308e+01, -6.2694e+00,  7.6720e+00,\n",
      "         -9.7709e-01, -6.0788e+00,  2.4800e-01, -5.9070e+00, -1.8268e+01,\n",
      "         -9.6825e+00, -2.3971e+00,  9.9173e+00, -1.4268e+01, -1.1875e+01,\n",
      "          1.0066e+00, -3.1918e+00,  1.3459e+01,  2.3179e+00,  1.0933e+00,\n",
      "          6.5885e+00,  2.8994e+01,  1.1260e+01, -6.8776e+00, -1.1974e+01,\n",
      "          3.1196e+01,  2.0267e+01,  1.2035e+00,  1.2386e+01,  9.5250e+00,\n",
      "          1.5922e+01, -6.3872e+00,  2.9996e+00,  1.4663e+00, -2.3444e+01,\n",
      "          1.9749e+01,  1.9165e+01,  7.3871e+00,  1.1974e+01, -3.5460e+00,\n",
      "         -1.5083e+01, -2.9902e+01,  2.8273e+00, -5.9360e+00,  8.4422e+00,\n",
      "          2.3631e+01,  8.4196e-01,  7.6832e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.6773e+00,  1.3198e+02,  2.4152e+01, -7.4170e+00, -1.6548e+01,\n",
      "          3.2925e+00, -2.1019e+00, -1.4390e+01,  2.2394e+01,  5.6373e+00,\n",
      "         -1.2490e+01,  2.1284e+00,  9.4636e+00, -8.3571e-01,  7.8998e+00,\n",
      "          9.8904e+00, -6.0805e+00, -3.4119e+00,  6.2857e+00,  1.9637e+01,\n",
      "          1.2398e+01,  1.8882e+00, -2.2756e+00, -1.9172e-01,  1.3528e+01,\n",
      "         -6.0283e+00,  5.6919e+00, -2.7375e+00, -7.0499e+00, -1.7028e+00,\n",
      "          6.7298e+00, -2.6546e+01, -1.2005e+00, -3.8609e+00,  4.9142e+00,\n",
      "         -1.1627e+01, -1.7454e+01, -1.3705e+00, -1.0265e+01,  1.9562e+01,\n",
      "         -4.2282e-01,  1.3378e-03, -1.3081e+01,  2.6021e+01,  1.8215e+01,\n",
      "         -5.0639e+00,  1.1796e+01, -4.2354e+00, -1.1458e+01,  1.7333e+01,\n",
      "          2.2525e+00, -9.2368e-01, -7.4408e+00, -1.4456e+01, -2.1238e+01,\n",
      "         -1.1086e+01, -6.4926e+00, -1.2304e+01, -3.2852e+00, -8.5025e+00,\n",
      "         -1.0414e+01, -1.7087e+01, -7.3645e-02, -4.1934e+00, -8.2066e+00,\n",
      "          3.1690e+01,  4.2422e-01,  7.2098e+00, -2.1177e+01,  8.5865e+00,\n",
      "         -1.1963e+01,  6.7174e-01,  9.2148e+00,  8.8798e+00,  1.4918e+01,\n",
      "         -4.8474e+00,  1.5327e+01, -1.3880e+01,  2.2085e+01,  4.5064e+00,\n",
      "         -9.0275e+00,  2.2448e+01, -1.4174e+01, -6.3080e+00,  7.5252e+00,\n",
      "         -1.2293e+00, -6.4826e+00,  2.6675e-01, -5.7567e+00, -1.8404e+01,\n",
      "         -1.0104e+01, -2.3417e+00,  1.0172e+01, -1.4311e+01, -1.1523e+01,\n",
      "          8.3729e-01, -3.0818e+00,  1.3433e+01,  2.2771e+00,  1.0335e+00,\n",
      "          6.5185e+00,  2.9026e+01,  1.1117e+01, -7.2166e+00, -1.1717e+01,\n",
      "          3.1226e+01,  2.0164e+01,  9.9998e-01,  1.2395e+01,  9.3216e+00,\n",
      "          1.5939e+01, -6.4314e+00,  2.6522e+00,  1.3927e+00, -2.3693e+01,\n",
      "          1.9584e+01,  1.9230e+01,  7.2346e+00,  1.2173e+01, -3.3328e+00,\n",
      "         -1.5247e+01, -2.9587e+01,  3.1171e+00, -5.7423e+00,  8.2978e+00,\n",
      "          2.4030e+01,  5.6050e-01,  9.2240e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0147e+01,  1.3208e+02,  2.4367e+01, -7.7244e+00, -1.6855e+01,\n",
      "          3.4978e+00, -1.8919e+00, -1.4560e+01,  2.2208e+01,  6.0370e+00,\n",
      "         -1.2490e+01,  2.3484e+00,  9.6364e+00, -6.0740e-01,  8.1536e+00,\n",
      "          9.8455e+00, -5.8502e+00, -3.6456e+00,  5.9835e+00,  1.9688e+01,\n",
      "          1.3037e+01,  1.4619e+00, -2.2180e+00, -1.1318e-01,  1.3284e+01,\n",
      "         -5.7508e+00,  5.5784e+00, -2.5076e+00, -7.1655e+00, -1.5930e+00,\n",
      "          7.1233e+00, -2.6368e+01, -1.3502e+00, -3.7591e+00,  5.1997e+00,\n",
      "         -1.1956e+01, -1.6929e+01, -1.3855e+00, -1.0509e+01,  1.9039e+01,\n",
      "         -7.6845e-01,  8.8122e-02, -1.3392e+01,  2.6201e+01,  1.8193e+01,\n",
      "         -5.2074e+00,  1.2147e+01, -4.1409e+00, -1.1282e+01,  1.7409e+01,\n",
      "          2.5920e+00, -1.6886e+00, -7.4659e+00, -1.4436e+01, -2.1138e+01,\n",
      "         -1.1027e+01, -6.7434e+00, -1.2240e+01, -3.4424e+00, -8.2571e+00,\n",
      "         -1.0513e+01, -1.7478e+01,  2.5248e-01, -4.0996e+00, -7.8087e+00,\n",
      "          3.1803e+01,  3.6577e-01,  7.1020e+00, -2.1355e+01,  8.9309e+00,\n",
      "         -1.2224e+01,  8.1253e-01,  9.1104e+00,  8.6314e+00,  1.4713e+01,\n",
      "         -4.7146e+00,  1.5524e+01, -1.4181e+01,  2.1878e+01,  4.3994e+00,\n",
      "         -8.4534e+00,  2.1995e+01, -1.4254e+01, -6.2578e+00,  7.1903e+00,\n",
      "         -9.4597e-01, -6.2656e+00,  4.5391e-02, -5.6705e+00, -1.8030e+01,\n",
      "         -1.0038e+01, -2.6970e+00,  1.0179e+01, -1.3957e+01, -1.1726e+01,\n",
      "          7.5715e-01, -3.4928e+00,  1.3370e+01,  2.1301e+00,  1.1083e+00,\n",
      "          6.5496e+00,  2.8939e+01,  1.0974e+01, -7.2837e+00, -1.1734e+01,\n",
      "          3.1055e+01,  2.0402e+01,  9.9405e-01,  1.2141e+01,  9.8257e+00,\n",
      "          1.5937e+01, -6.2069e+00,  2.8948e+00,  9.7959e-01, -2.3994e+01,\n",
      "          1.9537e+01,  1.8684e+01,  7.2976e+00,  1.1946e+01, -3.3408e+00,\n",
      "         -1.5048e+01, -3.0082e+01,  3.4374e+00, -5.4321e+00,  8.4956e+00,\n",
      "          2.4103e+01,  5.2661e-01,  6.5446e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0043e+01,  1.3195e+02,  2.4544e+01, -7.5984e+00, -1.6689e+01,\n",
      "          3.3457e+00, -1.8187e+00, -1.4408e+01,  2.2205e+01,  6.0477e+00,\n",
      "         -1.2420e+01,  2.3031e+00,  9.7507e+00, -6.4083e-01,  7.7554e+00,\n",
      "          9.8727e+00, -6.1928e+00, -3.6229e+00,  5.9345e+00,  1.9272e+01,\n",
      "          1.2683e+01,  1.8148e+00, -2.2938e+00, -1.5909e-01,  1.3101e+01,\n",
      "         -5.7600e+00,  5.6515e+00, -2.4234e+00, -7.0041e+00, -1.3568e+00,\n",
      "          7.2614e+00, -2.6466e+01, -1.6903e+00, -3.6216e+00,  5.2763e+00,\n",
      "         -1.1649e+01, -1.6785e+01, -1.5452e+00, -1.0309e+01,  1.9284e+01,\n",
      "         -1.6554e-01,  1.7410e-01, -1.3352e+01,  2.5803e+01,  1.8459e+01,\n",
      "         -5.2624e+00,  1.1822e+01, -4.0599e+00, -1.1151e+01,  1.7472e+01,\n",
      "          2.5727e+00, -1.4923e+00, -7.4290e+00, -1.4477e+01, -2.1528e+01,\n",
      "         -1.0996e+01, -6.8186e+00, -1.2127e+01, -3.1543e+00, -8.6295e+00,\n",
      "         -1.0440e+01, -1.7203e+01, -9.5396e-02, -3.8281e+00, -7.9803e+00,\n",
      "          3.1833e+01,  4.0733e-01,  7.1115e+00, -2.1149e+01,  8.9819e+00,\n",
      "         -1.2081e+01,  9.0189e-01,  9.7013e+00,  9.1984e+00,  1.4843e+01,\n",
      "         -4.7528e+00,  1.5631e+01, -1.3975e+01,  2.1938e+01,  4.4347e+00,\n",
      "         -8.7267e+00,  2.2575e+01, -1.4294e+01, -6.0289e+00,  7.6399e+00,\n",
      "         -9.6388e-01, -5.8818e+00, -1.3780e-01, -5.8272e+00, -1.8199e+01,\n",
      "         -9.7490e+00, -2.1379e+00,  1.0167e+01, -1.4149e+01, -1.1983e+01,\n",
      "          1.2055e+00, -3.3408e+00,  1.3217e+01,  2.6391e+00,  1.0925e+00,\n",
      "          6.7408e+00,  2.9204e+01,  1.1140e+01, -7.2815e+00, -1.1760e+01,\n",
      "          3.1077e+01,  2.0012e+01,  1.5082e+00,  1.2236e+01,  9.6287e+00,\n",
      "          1.5997e+01, -6.6976e+00,  3.2406e+00,  1.4313e+00, -2.3461e+01,\n",
      "          1.9587e+01,  1.9025e+01,  7.5980e+00,  1.1971e+01, -3.5262e+00,\n",
      "         -1.5543e+01, -2.9990e+01,  3.1853e+00, -5.4821e+00,  8.3587e+00,\n",
      "          2.4094e+01,  8.6543e-01,  2.8511e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0168e+01,  1.3200e+02,  2.4491e+01, -7.3700e+00, -1.6579e+01,\n",
      "          3.2463e+00, -1.9062e+00, -1.4503e+01,  2.2534e+01,  5.6037e+00,\n",
      "         -1.2382e+01,  1.9499e+00,  9.5172e+00, -1.2193e+00,  7.9477e+00,\n",
      "          1.0006e+01, -5.7814e+00, -3.1627e+00,  6.2522e+00,  1.9461e+01,\n",
      "          1.2287e+01,  1.7056e+00, -2.1257e+00,  7.0019e-02,  1.3169e+01,\n",
      "         -6.1065e+00,  5.6767e+00, -2.4561e+00, -7.5663e+00, -1.3849e+00,\n",
      "          6.9308e+00, -2.6734e+01, -1.1880e+00, -3.6565e+00,  4.9860e+00,\n",
      "         -1.1861e+01, -1.7052e+01, -1.0001e+00, -1.0143e+01,  1.9225e+01,\n",
      "         -6.8866e-01, -3.0948e-02, -1.2901e+01,  2.5890e+01,  1.8131e+01,\n",
      "         -5.0397e+00,  1.2053e+01, -3.8623e+00, -1.1689e+01,  1.7056e+01,\n",
      "          2.2457e+00, -9.8220e-01, -7.7679e+00, -1.4532e+01, -2.1261e+01,\n",
      "         -1.0951e+01, -6.5865e+00, -1.2534e+01, -3.1024e+00, -8.4076e+00,\n",
      "         -1.0403e+01, -1.7002e+01,  9.0870e-02, -4.5078e+00, -7.9903e+00,\n",
      "          3.1700e+01,  1.9672e-01,  7.0347e+00, -2.1390e+01,  8.5269e+00,\n",
      "         -1.1989e+01,  9.1231e-01,  9.2674e+00,  9.0836e+00,  1.4953e+01,\n",
      "         -4.7948e+00,  1.5182e+01, -1.3727e+01,  2.2091e+01,  4.5534e+00,\n",
      "         -8.9207e+00,  2.2919e+01, -1.4327e+01, -6.2058e+00,  7.8705e+00,\n",
      "         -1.1110e+00, -6.1220e+00,  1.6674e-01, -5.9389e+00, -1.8261e+01,\n",
      "         -9.7695e+00, -2.3340e+00,  9.9636e+00, -1.4281e+01, -1.1873e+01,\n",
      "          1.0186e+00, -3.1275e+00,  1.3398e+01,  2.4996e+00,  1.0188e+00,\n",
      "          6.5397e+00,  2.9049e+01,  1.1300e+01, -6.8270e+00, -1.1806e+01,\n",
      "          3.1282e+01,  2.0190e+01,  1.1040e+00,  1.2472e+01,  9.5729e+00,\n",
      "          1.5963e+01, -6.5761e+00,  2.9952e+00,  1.5905e+00, -2.3338e+01,\n",
      "          1.9664e+01,  1.9418e+01,  7.2005e+00,  1.2000e+01, -3.4983e+00,\n",
      "         -1.5197e+01, -2.9958e+01,  2.7763e+00, -5.9229e+00,  8.5491e+00,\n",
      "          2.3588e+01,  8.5227e-01,  7.6164e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.6814e+00,  1.3192e+02,  2.4206e+01, -7.3333e+00, -1.6375e+01,\n",
      "          3.3272e+00, -2.1217e+00, -1.4386e+01,  2.2376e+01,  5.6970e+00,\n",
      "         -1.2402e+01,  2.0995e+00,  9.4296e+00, -9.2904e-01,  8.0448e+00,\n",
      "          9.8952e+00, -5.9674e+00, -3.4897e+00,  6.4772e+00,  1.9446e+01,\n",
      "          1.2422e+01,  1.7419e+00, -2.3071e+00, -1.4977e-01,  1.3591e+01,\n",
      "         -6.2090e+00,  5.7477e+00, -2.7726e+00, -7.1034e+00, -1.6590e+00,\n",
      "          6.5661e+00, -2.6613e+01, -1.1188e+00, -3.8724e+00,  4.8207e+00,\n",
      "         -1.1660e+01, -1.7635e+01, -1.3285e+00, -1.0183e+01,  1.9687e+01,\n",
      "         -4.3252e-01, -1.3995e-01, -1.3153e+01,  2.5962e+01,  1.8143e+01,\n",
      "         -4.9896e+00,  1.1714e+01, -4.1930e+00, -1.1464e+01,  1.7299e+01,\n",
      "          2.1075e+00, -8.0222e-01, -7.4981e+00, -1.4529e+01, -2.1451e+01,\n",
      "         -1.1175e+01, -6.4453e+00, -1.2358e+01, -3.2173e+00, -8.6296e+00,\n",
      "         -1.0384e+01, -1.7095e+01, -4.5649e-02, -4.2325e+00, -8.1056e+00,\n",
      "          3.1700e+01,  4.1247e-01,  7.2070e+00, -2.1290e+01,  8.6047e+00,\n",
      "         -1.1877e+01,  6.9131e-01,  9.2169e+00,  8.9051e+00,  1.4972e+01,\n",
      "         -4.9068e+00,  1.5266e+01, -1.3743e+01,  2.2018e+01,  4.4589e+00,\n",
      "         -9.0345e+00,  2.2608e+01, -1.4230e+01, -6.2579e+00,  7.6985e+00,\n",
      "         -1.3227e+00, -6.4999e+00,  2.0281e-01, -5.7876e+00, -1.8385e+01,\n",
      "         -1.0188e+01, -2.2779e+00,  1.0185e+01, -1.4312e+01, -1.1528e+01,\n",
      "          8.5217e-01, -2.9867e+00,  1.3359e+01,  2.4670e+00,  9.6869e-01,\n",
      "          6.4813e+00,  2.9114e+01,  1.1157e+01, -7.1477e+00, -1.1573e+01,\n",
      "          3.1329e+01,  2.0083e+01,  8.7811e-01,  1.2474e+01,  9.3808e+00,\n",
      "          1.5970e+01, -6.6218e+00,  2.6297e+00,  1.5037e+00, -2.3585e+01,\n",
      "          1.9485e+01,  1.9480e+01,  7.0821e+00,  1.2188e+01, -3.2700e+00,\n",
      "         -1.5353e+01, -2.9706e+01,  3.0426e+00, -5.7464e+00,  8.3969e+00,\n",
      "          2.3983e+01,  5.6542e-01,  9.0959e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0152e+01,  1.3201e+02,  2.4428e+01, -7.6017e+00, -1.6671e+01,\n",
      "          3.5330e+00, -1.8725e+00, -1.4573e+01,  2.2189e+01,  6.1024e+00,\n",
      "         -1.2434e+01,  2.3276e+00,  9.5803e+00, -6.8871e-01,  8.3055e+00,\n",
      "          9.8526e+00, -5.6989e+00, -3.7380e+00,  6.1209e+00,  1.9493e+01,\n",
      "          1.3028e+01,  1.3352e+00, -2.2862e+00, -8.3911e-02,  1.3391e+01,\n",
      "         -5.9646e+00,  5.6464e+00, -2.4939e+00, -7.1938e+00, -1.5341e+00,\n",
      "          6.9568e+00, -2.6423e+01, -1.2645e+00, -3.7688e+00,  5.1200e+00,\n",
      "         -1.1957e+01, -1.7140e+01, -1.3713e+00, -1.0407e+01,  1.9160e+01,\n",
      "         -7.5247e-01, -4.8555e-02, -1.3441e+01,  2.6163e+01,  1.8123e+01,\n",
      "         -5.1451e+00,  1.2048e+01, -4.1241e+00, -1.1276e+01,  1.7367e+01,\n",
      "          2.4419e+00, -1.5417e+00, -7.5229e+00, -1.4502e+01, -2.1338e+01,\n",
      "         -1.1136e+01, -6.6946e+00, -1.2264e+01, -3.3623e+00, -8.3966e+00,\n",
      "         -1.0481e+01, -1.7474e+01,  2.5641e-01, -4.1590e+00, -7.7945e+00,\n",
      "          3.1769e+01,  3.5286e-01,  7.1408e+00, -2.1454e+01,  8.9466e+00,\n",
      "         -1.2127e+01,  8.0838e-01,  9.1165e+00,  8.6360e+00,  1.4772e+01,\n",
      "         -4.7720e+00,  1.5488e+01, -1.4062e+01,  2.1790e+01,  4.3494e+00,\n",
      "         -8.5025e+00,  2.2136e+01, -1.4325e+01, -6.2194e+00,  7.3488e+00,\n",
      "         -1.0484e+00, -6.2681e+00, -2.9653e-02, -5.6745e+00, -1.8074e+01,\n",
      "         -1.0076e+01, -2.6056e+00,  1.0192e+01, -1.3980e+01, -1.1697e+01,\n",
      "          7.6018e-01, -3.3375e+00,  1.3319e+01,  2.2790e+00,  1.0718e+00,\n",
      "          6.4888e+00,  2.9034e+01,  1.1035e+01, -7.2345e+00, -1.1621e+01,\n",
      "          3.1169e+01,  2.0312e+01,  8.6000e-01,  1.2218e+01,  9.8306e+00,\n",
      "          1.5953e+01, -6.3822e+00,  2.8425e+00,  1.0965e+00, -2.3848e+01,\n",
      "          1.9405e+01,  1.8937e+01,  7.1644e+00,  1.1959e+01, -3.2629e+00,\n",
      "         -1.5166e+01, -3.0199e+01,  3.3856e+00, -5.4651e+00,  8.6022e+00,\n",
      "          2.4069e+01,  5.2707e-01,  6.6645e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0077e+01,  1.3189e+02,  2.4590e+01, -7.4650e+00, -1.6499e+01,\n",
      "          3.4271e+00, -1.7548e+00, -1.4439e+01,  2.2178e+01,  6.1231e+00,\n",
      "         -1.2410e+01,  2.2675e+00,  9.6904e+00, -7.3368e-01,  7.9511e+00,\n",
      "          9.8997e+00, -5.9740e+00, -3.7583e+00,  6.1039e+00,  1.9157e+01,\n",
      "          1.2714e+01,  1.6698e+00, -2.3916e+00, -1.2608e-01,  1.3222e+01,\n",
      "         -5.9903e+00,  5.7174e+00, -2.4016e+00, -7.0278e+00, -1.3110e+00,\n",
      "          7.1207e+00, -2.6525e+01, -1.5754e+00, -3.6195e+00,  5.2181e+00,\n",
      "         -1.1671e+01, -1.6971e+01, -1.5525e+00, -1.0220e+01,  1.9387e+01,\n",
      "         -1.6240e-01,  2.0251e-02, -1.3388e+01,  2.5796e+01,  1.8406e+01,\n",
      "         -5.1622e+00,  1.1756e+01, -4.0758e+00, -1.1154e+01,  1.7398e+01,\n",
      "          2.4638e+00, -1.3547e+00, -7.5222e+00, -1.4527e+01, -2.1662e+01,\n",
      "         -1.1095e+01, -6.7666e+00, -1.2126e+01, -3.1004e+00, -8.7462e+00,\n",
      "         -1.0408e+01, -1.7245e+01, -7.8066e-02, -3.9148e+00, -7.9808e+00,\n",
      "          3.1772e+01,  3.7485e-01,  7.1523e+00, -2.1261e+01,  8.9597e+00,\n",
      "         -1.2005e+01,  8.7453e-01,  9.6289e+00,  9.1527e+00,  1.4913e+01,\n",
      "         -4.8392e+00,  1.5599e+01, -1.3881e+01,  2.1871e+01,  4.4101e+00,\n",
      "         -8.7716e+00,  2.2669e+01, -1.4397e+01, -6.0448e+00,  7.7514e+00,\n",
      "         -1.0256e+00, -5.8949e+00, -1.7178e-01, -5.7717e+00, -1.8235e+01,\n",
      "         -9.8436e+00, -2.0768e+00,  1.0207e+01, -1.4151e+01, -1.1921e+01,\n",
      "          1.1833e+00, -3.1724e+00,  1.3144e+01,  2.7257e+00,  1.0778e+00,\n",
      "          6.6495e+00,  2.9270e+01,  1.1220e+01, -7.2380e+00, -1.1661e+01,\n",
      "          3.1194e+01,  1.9932e+01,  1.3380e+00,  1.2341e+01,  9.6654e+00,\n",
      "          1.6001e+01, -6.8480e+00,  3.1513e+00,  1.5115e+00, -2.3338e+01,\n",
      "          1.9418e+01,  1.9223e+01,  7.4774e+00,  1.1974e+01, -3.4241e+00,\n",
      "         -1.5618e+01, -3.0119e+01,  3.1723e+00, -5.5249e+00,  8.4647e+00,\n",
      "          2.4081e+01,  7.7555e-01,  3.1450e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0224e+01,  1.3193e+02,  2.4528e+01, -7.2379e+00, -1.6385e+01,\n",
      "          3.3242e+00, -1.8181e+00, -1.4520e+01,  2.2465e+01,  5.6852e+00,\n",
      "         -1.2404e+01,  1.9249e+00,  9.4729e+00, -1.2786e+00,  8.1149e+00,\n",
      "          1.0042e+01, -5.6142e+00, -3.2988e+00,  6.4695e+00,  1.9343e+01,\n",
      "          1.2363e+01,  1.5834e+00, -2.2105e+00,  7.5839e-02,  1.3318e+01,\n",
      "         -6.3230e+00,  5.7423e+00, -2.4677e+00, -7.6086e+00, -1.3566e+00,\n",
      "          6.8044e+00, -2.6767e+01, -1.0911e+00, -3.6703e+00,  4.9375e+00,\n",
      "         -1.1867e+01, -1.7242e+01, -1.0249e+00, -1.0090e+01,  1.9307e+01,\n",
      "         -6.6282e-01, -1.6628e-01, -1.2927e+01,  2.5867e+01,  1.8075e+01,\n",
      "         -4.9395e+00,  1.1976e+01, -3.8621e+00, -1.1687e+01,  1.6992e+01,\n",
      "          2.1787e+00, -8.6672e-01, -7.8154e+00, -1.4527e+01, -2.1364e+01,\n",
      "         -1.1052e+01, -6.5580e+00, -1.2554e+01, -3.0633e+00, -8.5306e+00,\n",
      "         -1.0357e+01, -1.7044e+01,  1.4337e-01, -4.5649e+00, -7.9685e+00,\n",
      "          3.1650e+01,  1.3651e-01,  7.0863e+00, -2.1477e+01,  8.5482e+00,\n",
      "         -1.1924e+01,  9.0917e-01,  9.2260e+00,  9.0216e+00,  1.4987e+01,\n",
      "         -4.9038e+00,  1.5162e+01, -1.3649e+01,  2.2047e+01,  4.5205e+00,\n",
      "         -8.9583e+00,  2.2986e+01, -1.4452e+01, -6.1854e+00,  7.9949e+00,\n",
      "         -1.1507e+00, -6.1132e+00,  1.2277e-01, -5.8576e+00, -1.8301e+01,\n",
      "         -9.8535e+00, -2.2624e+00,  1.0051e+01, -1.4293e+01, -1.1837e+01,\n",
      "          9.9777e-01, -2.9572e+00,  1.3337e+01,  2.5768e+00,  1.0306e+00,\n",
      "          6.4836e+00,  2.9094e+01,  1.1392e+01, -6.7968e+00, -1.1716e+01,\n",
      "          3.1398e+01,  2.0134e+01,  9.3737e-01,  1.2542e+01,  9.6143e+00,\n",
      "          1.5985e+01, -6.7360e+00,  2.9409e+00,  1.6544e+00, -2.3175e+01,\n",
      "          1.9486e+01,  1.9593e+01,  7.0826e+00,  1.2022e+01, -3.3775e+00,\n",
      "         -1.5270e+01, -3.0070e+01,  2.8138e+00, -5.9492e+00,  8.6567e+00,\n",
      "          2.3625e+01,  7.8494e-01,  7.8878e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.7303e+00,  1.3186e+02,  2.4264e+01, -7.2338e+00, -1.6176e+01,\n",
      "          3.4031e+00, -2.0576e+00, -1.4384e+01,  2.2322e+01,  5.7420e+00,\n",
      "         -1.2387e+01,  2.0659e+00,  9.4341e+00, -1.0201e+00,  8.1695e+00,\n",
      "          9.9210e+00, -5.8541e+00, -3.5878e+00,  6.7261e+00,  1.9339e+01,\n",
      "          1.2521e+01,  1.6488e+00, -2.3545e+00, -1.4565e-01,  1.3704e+01,\n",
      "         -6.3878e+00,  5.8102e+00, -2.8072e+00, -7.1999e+00, -1.6544e+00,\n",
      "          6.4568e+00, -2.6655e+01, -1.0274e+00, -3.8874e+00,  4.7944e+00,\n",
      "         -1.1699e+01, -1.7786e+01, -1.3321e+00, -1.0155e+01,  1.9747e+01,\n",
      "         -4.2182e-01, -2.5863e-01, -1.3155e+01,  2.5944e+01,  1.8100e+01,\n",
      "         -4.8883e+00,  1.1628e+01, -4.1538e+00, -1.1469e+01,  1.7261e+01,\n",
      "          2.0268e+00, -6.8621e-01, -7.5156e+00, -1.4530e+01, -2.1530e+01,\n",
      "         -1.1271e+01, -6.4234e+00, -1.2397e+01, -3.1662e+00, -8.7020e+00,\n",
      "         -1.0348e+01, -1.7117e+01,  1.5477e-03, -4.2781e+00, -8.0257e+00,\n",
      "          3.1650e+01,  3.4773e-01,  7.2376e+00, -2.1366e+01,  8.6256e+00,\n",
      "         -1.1811e+01,  7.2570e-01,  9.1907e+00,  8.8686e+00,  1.4996e+01,\n",
      "         -5.0130e+00,  1.5243e+01, -1.3677e+01,  2.1976e+01,  4.4375e+00,\n",
      "         -9.0550e+00,  2.2701e+01, -1.4339e+01, -6.2275e+00,  7.8473e+00,\n",
      "         -1.3660e+00, -6.5061e+00,  1.6120e-01, -5.7411e+00, -1.8394e+01,\n",
      "         -1.0264e+01, -2.2037e+00,  1.0271e+01, -1.4319e+01, -1.1526e+01,\n",
      "          8.3337e-01, -2.8809e+00,  1.3310e+01,  2.5427e+00,  9.7583e-01,\n",
      "          6.4591e+00,  2.9185e+01,  1.1219e+01, -7.0976e+00, -1.1476e+01,\n",
      "          3.1451e+01,  2.0042e+01,  7.3790e-01,  1.2547e+01,  9.4516e+00,\n",
      "          1.6011e+01, -6.7811e+00,  2.5831e+00,  1.5504e+00, -2.3438e+01,\n",
      "          1.9331e+01,  1.9649e+01,  6.9685e+00,  1.2203e+01, -3.1544e+00,\n",
      "         -1.5426e+01, -2.9776e+01,  3.0371e+00, -5.7791e+00,  8.4842e+00,\n",
      "          2.4032e+01,  5.4040e-01,  9.1734e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0167e+01,  1.3197e+02,  2.4454e+01, -7.4937e+00, -1.6483e+01,\n",
      "          3.5860e+00, -1.8389e+00, -1.4529e+01,  2.2171e+01,  6.1314e+00,\n",
      "         -1.2395e+01,  2.2796e+00,  9.6139e+00, -7.9360e-01,  8.3970e+00,\n",
      "          9.8862e+00, -5.6480e+00, -3.7885e+00,  6.3562e+00,  1.9364e+01,\n",
      "          1.3100e+01,  1.2791e+00, -2.3047e+00, -1.1488e-01,  1.3492e+01,\n",
      "         -6.1329e+00,  5.7221e+00, -2.5508e+00, -7.3083e+00, -1.5481e+00,\n",
      "          6.8298e+00, -2.6472e+01, -1.1743e+00, -3.8062e+00,  5.0863e+00,\n",
      "         -1.1984e+01, -1.7325e+01, -1.3510e+00, -1.0397e+01,  1.9224e+01,\n",
      "         -7.5135e-01, -1.4320e-01, -1.3414e+01,  2.6147e+01,  1.8071e+01,\n",
      "         -5.0772e+00,  1.1932e+01, -4.0571e+00, -1.1302e+01,  1.7347e+01,\n",
      "          2.2974e+00, -1.3906e+00, -7.5055e+00, -1.4517e+01, -2.1437e+01,\n",
      "         -1.1244e+01, -6.7176e+00, -1.2312e+01, -3.2854e+00, -8.4487e+00,\n",
      "         -1.0475e+01, -1.7456e+01,  2.7119e-01, -4.1706e+00, -7.6877e+00,\n",
      "          3.1733e+01,  2.9919e-01,  7.1772e+00, -2.1498e+01,  8.9683e+00,\n",
      "         -1.2034e+01,  8.7700e-01,  9.1306e+00,  8.6463e+00,  1.4792e+01,\n",
      "         -4.8907e+00,  1.5472e+01, -1.3980e+01,  2.1737e+01,  4.3080e+00,\n",
      "         -8.5174e+00,  2.2270e+01, -1.4392e+01, -6.1608e+00,  7.5249e+00,\n",
      "         -1.1602e+00, -6.3099e+00, -1.2036e-01, -5.6780e+00, -1.8130e+01,\n",
      "         -1.0102e+01, -2.4886e+00,  1.0269e+01, -1.4012e+01, -1.1695e+01,\n",
      "          7.4354e-01, -3.2542e+00,  1.3311e+01,  2.3574e+00,  1.0653e+00,\n",
      "          6.4718e+00,  2.9120e+01,  1.1079e+01, -7.1830e+00, -1.1513e+01,\n",
      "          3.1277e+01,  2.0261e+01,  7.5170e-01,  1.2279e+01,  9.8583e+00,\n",
      "          1.5999e+01, -6.5224e+00,  2.8049e+00,  1.1599e+00, -2.3694e+01,\n",
      "          1.9268e+01,  1.9144e+01,  7.0460e+00,  1.1960e+01, -3.1640e+00,\n",
      "         -1.5270e+01, -3.0198e+01,  3.3443e+00, -5.5150e+00,  8.6849e+00,\n",
      "          2.4108e+01,  5.8398e-01,  6.8382e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0098e+01,  1.3185e+02,  2.4594e+01, -7.3708e+00, -1.6326e+01,\n",
      "          3.4884e+00, -1.7402e+00, -1.4404e+01,  2.2185e+01,  6.1778e+00,\n",
      "         -1.2328e+01,  2.1937e+00,  9.7345e+00, -8.5385e-01,  8.0879e+00,\n",
      "          9.9394e+00, -5.8797e+00, -3.8282e+00,  6.3392e+00,  1.9036e+01,\n",
      "          1.2808e+01,  1.5793e+00, -2.4147e+00, -1.2744e-01,  1.3316e+01,\n",
      "         -6.1677e+00,  5.8109e+00, -2.4458e+00, -7.1222e+00, -1.3323e+00,\n",
      "          6.9921e+00, -2.6589e+01, -1.4774e+00, -3.6425e+00,  5.1619e+00,\n",
      "         -1.1692e+01, -1.7144e+01, -1.5197e+00, -1.0219e+01,  1.9450e+01,\n",
      "         -1.9320e-01, -9.0189e-02, -1.3402e+01,  2.5790e+01,  1.8355e+01,\n",
      "         -5.0822e+00,  1.1663e+01, -4.0090e+00, -1.1199e+01,  1.7342e+01,\n",
      "          2.2967e+00, -1.2103e+00, -7.5442e+00, -1.4536e+01, -2.1797e+01,\n",
      "         -1.1219e+01, -6.7994e+00, -1.2153e+01, -3.0342e+00, -8.7904e+00,\n",
      "         -1.0408e+01, -1.7250e+01, -4.0371e-02, -3.9312e+00, -7.8574e+00,\n",
      "          3.1763e+01,  3.4964e-01,  7.1689e+00, -2.1320e+01,  8.9681e+00,\n",
      "         -1.1918e+01,  9.2489e-01,  9.5896e+00,  9.1683e+00,  1.4947e+01,\n",
      "         -4.9779e+00,  1.5566e+01, -1.3766e+01,  2.1824e+01,  4.3617e+00,\n",
      "         -8.7416e+00,  2.2791e+01, -1.4455e+01, -5.9930e+00,  7.8779e+00,\n",
      "         -1.1463e+00, -5.9569e+00, -2.5775e-01, -5.7868e+00, -1.8288e+01,\n",
      "         -9.9302e+00, -1.9825e+00,  1.0273e+01, -1.4170e+01, -1.1899e+01,\n",
      "          1.1689e+00, -3.1015e+00,  1.3103e+01,  2.8144e+00,  1.0649e+00,\n",
      "          6.5995e+00,  2.9336e+01,  1.1257e+01, -7.1738e+00, -1.1551e+01,\n",
      "          3.1294e+01,  1.9875e+01,  1.2258e+00,  1.2403e+01,  9.7165e+00,\n",
      "          1.6039e+01, -6.9624e+00,  3.0961e+00,  1.5659e+00, -2.3201e+01,\n",
      "          1.9272e+01,  1.9415e+01,  7.3446e+00,  1.1948e+01, -3.3268e+00,\n",
      "         -1.5697e+01, -3.0139e+01,  3.1130e+00, -5.5676e+00,  8.5668e+00,\n",
      "          2.4084e+01,  7.9193e-01,  3.4806e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0237e+01,  1.3188e+02,  2.4560e+01, -7.1678e+00, -1.6229e+01,\n",
      "          3.3765e+00, -1.7903e+00, -1.4496e+01,  2.2489e+01,  5.7892e+00,\n",
      "         -1.2307e+01,  1.8624e+00,  9.4865e+00, -1.3985e+00,  8.2641e+00,\n",
      "          1.0073e+01, -5.5255e+00, -3.3978e+00,  6.6508e+00,  1.9172e+01,\n",
      "          1.2415e+01,  1.4928e+00, -2.2646e+00,  8.9197e-02,  1.3427e+01,\n",
      "         -6.4993e+00,  5.8270e+00, -2.4940e+00, -7.6644e+00, -1.3614e+00,\n",
      "          6.6707e+00, -2.6823e+01, -1.0225e+00, -3.6525e+00,  4.8701e+00,\n",
      "         -1.1866e+01, -1.7408e+01, -1.0050e+00, -1.0062e+01,  1.9383e+01,\n",
      "         -6.6391e-01, -2.6727e-01, -1.3009e+01,  2.5822e+01,  1.8028e+01,\n",
      "         -4.9015e+00,  1.1886e+01, -3.8047e+00, -1.1716e+01,  1.6929e+01,\n",
      "          2.0175e+00, -7.4674e-01, -7.8302e+00, -1.4485e+01, -2.1586e+01,\n",
      "         -1.1186e+01, -6.5661e+00, -1.2582e+01, -3.0261e+00, -8.6178e+00,\n",
      "         -1.0377e+01, -1.7077e+01,  1.8746e-01, -4.5702e+00, -7.8683e+00,\n",
      "          3.1648e+01,  1.4552e-01,  7.1132e+00, -2.1520e+01,  8.6154e+00,\n",
      "         -1.1807e+01,  9.0362e-01,  9.1852e+00,  9.0293e+00,  1.5014e+01,\n",
      "         -5.0221e+00,  1.5148e+01, -1.3508e+01,  2.2010e+01,  4.4469e+00,\n",
      "         -8.9170e+00,  2.3093e+01, -1.4490e+01, -6.1355e+00,  8.0904e+00,\n",
      "         -1.2880e+00, -6.1498e+00,  5.6233e-03, -5.8827e+00, -1.8394e+01,\n",
      "         -9.9128e+00, -2.1612e+00,  1.0116e+01, -1.4340e+01, -1.1811e+01,\n",
      "          1.0008e+00, -2.8745e+00,  1.3283e+01,  2.7013e+00,  1.0484e+00,\n",
      "          6.4301e+00,  2.9141e+01,  1.1428e+01, -6.7627e+00, -1.1602e+01,\n",
      "          3.1515e+01,  2.0037e+01,  8.1852e-01,  1.2569e+01,  9.6677e+00,\n",
      "          1.5998e+01, -6.8809e+00,  2.8987e+00,  1.7254e+00, -2.2984e+01,\n",
      "          1.9358e+01,  1.9800e+01,  6.9640e+00,  1.1973e+01, -3.2876e+00,\n",
      "         -1.5335e+01, -3.0136e+01,  2.7725e+00, -5.9753e+00,  8.7586e+00,\n",
      "          2.3619e+01,  8.0778e-01,  8.2665e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.7413e+00,  1.3181e+02,  2.4328e+01, -7.1829e+00, -1.6036e+01,\n",
      "          3.4557e+00, -2.0250e+00, -1.4399e+01,  2.2354e+01,  5.8354e+00,\n",
      "         -1.2284e+01,  2.0111e+00,  9.4300e+00, -1.1465e+00,  8.3204e+00,\n",
      "          9.9193e+00, -5.7228e+00, -3.6914e+00,  6.8784e+00,  1.9166e+01,\n",
      "          1.2570e+01,  1.5191e+00, -2.4137e+00, -9.9714e-02,  1.3819e+01,\n",
      "         -6.5642e+00,  5.8662e+00, -2.8071e+00, -7.2255e+00, -1.6450e+00,\n",
      "          6.3114e+00, -2.6710e+01, -9.5073e-01, -3.8318e+00,  4.7242e+00,\n",
      "         -1.1685e+01, -1.7898e+01, -1.3049e+00, -1.0119e+01,  1.9820e+01,\n",
      "         -4.1504e-01, -3.6369e-01, -1.3270e+01,  2.5903e+01,  1.8063e+01,\n",
      "         -4.8460e+00,  1.1571e+01, -4.1149e+00, -1.1502e+01,  1.7195e+01,\n",
      "          1.8688e+00, -5.6493e-01, -7.5665e+00, -1.4497e+01, -2.1762e+01,\n",
      "         -1.1392e+01, -6.3712e+00, -1.2402e+01, -3.1425e+00, -8.7844e+00,\n",
      "         -1.0351e+01, -1.7169e+01,  4.8072e-02, -4.2917e+00, -7.9730e+00,\n",
      "          3.1636e+01,  3.7658e-01,  7.2523e+00, -2.1415e+01,  8.6972e+00,\n",
      "         -1.1691e+01,  6.9128e-01,  9.1145e+00,  8.8905e+00,  1.5024e+01,\n",
      "         -5.1176e+00,  1.5246e+01, -1.3525e+01,  2.1934e+01,  4.3909e+00,\n",
      "         -9.0257e+00,  2.2791e+01, -1.4384e+01, -6.2162e+00,  7.9083e+00,\n",
      "         -1.4626e+00, -6.5106e+00,  4.5277e-02, -5.7488e+00, -1.8456e+01,\n",
      "         -1.0320e+01, -2.1207e+00,  1.0320e+01, -1.4371e+01, -1.1483e+01,\n",
      "          8.6289e-01, -2.7867e+00,  1.3226e+01,  2.6655e+00,  9.9109e-01,\n",
      "          6.3859e+00,  2.9245e+01,  1.1270e+01, -7.0573e+00, -1.1384e+01,\n",
      "          3.1585e+01,  1.9948e+01,  6.2708e-01,  1.2566e+01,  9.5205e+00,\n",
      "          1.6023e+01, -6.9391e+00,  2.5315e+00,  1.6227e+00, -2.3253e+01,\n",
      "          1.9217e+01,  1.9839e+01,  6.8675e+00,  1.2156e+01, -3.0809e+00,\n",
      "         -1.5461e+01, -2.9891e+01,  2.9999e+00, -5.8011e+00,  8.5911e+00,\n",
      "          2.3999e+01,  5.3303e-01,  9.4003e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0157e+01,  1.3194e+02,  2.4480e+01, -7.4250e+00, -1.6356e+01,\n",
      "          3.6248e+00, -1.7902e+00, -1.4537e+01,  2.2209e+01,  6.1900e+00,\n",
      "         -1.2334e+01,  2.2193e+00,  9.5789e+00, -9.2238e-01,  8.5255e+00,\n",
      "          9.8811e+00, -5.5431e+00, -3.8518e+00,  6.4854e+00,  1.9214e+01,\n",
      "          1.3107e+01,  1.1451e+00, -2.3502e+00, -8.3758e-02,  1.3627e+01,\n",
      "         -6.3142e+00,  5.7475e+00, -2.5723e+00, -7.3118e+00, -1.5495e+00,\n",
      "          6.6551e+00, -2.6533e+01, -1.0701e+00, -3.7575e+00,  5.0069e+00,\n",
      "         -1.1949e+01, -1.7479e+01, -1.3100e+00, -1.0364e+01,  1.9311e+01,\n",
      "         -7.4970e-01, -2.4859e-01, -1.3485e+01,  2.6106e+01,  1.8018e+01,\n",
      "         -5.0565e+00,  1.1876e+01, -4.0621e+00, -1.1339e+01,  1.7292e+01,\n",
      "          2.1223e+00, -1.2326e+00, -7.5554e+00, -1.4529e+01, -2.1627e+01,\n",
      "         -1.1348e+01, -6.6620e+00, -1.2332e+01, -3.2568e+00, -8.5328e+00,\n",
      "         -1.0470e+01, -1.7488e+01,  2.7264e-01, -4.1752e+00, -7.6779e+00,\n",
      "          3.1708e+01,  3.1365e-01,  7.2069e+00, -2.1528e+01,  9.0067e+00,\n",
      "         -1.1892e+01,  8.5270e-01,  9.0518e+00,  8.6891e+00,  1.4816e+01,\n",
      "         -4.9884e+00,  1.5485e+01, -1.3849e+01,  2.1686e+01,  4.2725e+00,\n",
      "         -8.5282e+00,  2.2372e+01, -1.4409e+01, -6.1782e+00,  7.5923e+00,\n",
      "         -1.2637e+00, -6.3132e+00, -2.5678e-01, -5.6728e+00, -1.8212e+01,\n",
      "         -1.0130e+01, -2.4011e+00,  1.0312e+01, -1.4082e+01, -1.1612e+01,\n",
      "          7.6485e-01, -3.1483e+00,  1.3257e+01,  2.4704e+00,  1.0537e+00,\n",
      "          6.3941e+00,  2.9188e+01,  1.1142e+01, -7.1559e+00, -1.1419e+01,\n",
      "          3.1408e+01,  2.0169e+01,  6.5573e-01,  1.2297e+01,  9.8736e+00,\n",
      "          1.6021e+01, -6.6808e+00,  2.7488e+00,  1.2544e+00, -2.3521e+01,\n",
      "          1.9174e+01,  1.9335e+01,  6.9418e+00,  1.1940e+01, -3.1135e+00,\n",
      "         -1.5306e+01, -3.0279e+01,  3.3200e+00, -5.5480e+00,  8.7777e+00,\n",
      "          2.4061e+01,  5.9406e-01,  7.0993e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0114e+01,  1.3183e+02,  2.4569e+01, -7.3047e+00, -1.6203e+01,\n",
      "          3.5396e+00, -1.6925e+00, -1.4417e+01,  2.2203e+01,  6.2060e+00,\n",
      "         -1.2282e+01,  2.1057e+00,  9.6889e+00, -1.0012e+00,  8.2295e+00,\n",
      "          9.9446e+00, -5.7761e+00, -3.8750e+00,  6.5090e+00,  1.8970e+01,\n",
      "          1.2835e+01,  1.4299e+00, -2.4363e+00, -6.7685e-02,  1.3419e+01,\n",
      "         -6.3402e+00,  5.8260e+00, -2.5079e+00, -7.1467e+00, -1.3587e+00,\n",
      "          6.8295e+00, -2.6668e+01, -1.3525e+00, -3.6142e+00,  5.0767e+00,\n",
      "         -1.1684e+01, -1.7325e+01, -1.4764e+00, -1.0188e+01,  1.9528e+01,\n",
      "         -2.2913e-01, -2.2995e-01, -1.3435e+01,  2.5752e+01,  1.8286e+01,\n",
      "         -5.0324e+00,  1.1616e+01, -4.0558e+00, -1.1226e+01,  1.7275e+01,\n",
      "          2.1533e+00, -1.0671e+00, -7.6138e+00, -1.4588e+01, -2.1916e+01,\n",
      "         -1.1314e+01, -6.7574e+00, -1.2203e+01, -2.9956e+00, -8.8638e+00,\n",
      "         -1.0383e+01, -1.7281e+01, -3.8459e-02, -3.9604e+00, -7.8220e+00,\n",
      "          3.1754e+01,  3.2760e-01,  7.1861e+00, -2.1365e+01,  8.9494e+00,\n",
      "         -1.1800e+01,  9.3001e-01,  9.4715e+00,  9.1937e+00,  1.4977e+01,\n",
      "         -5.0765e+00,  1.5542e+01, -1.3673e+01,  2.1780e+01,  4.3385e+00,\n",
      "         -8.7513e+00,  2.2905e+01, -1.4474e+01, -6.0414e+00,  7.9546e+00,\n",
      "         -1.2116e+00, -5.9709e+00, -3.4779e-01, -5.7639e+00, -1.8321e+01,\n",
      "         -1.0044e+01, -1.9552e+00,  1.0325e+01, -1.4205e+01, -1.1805e+01,\n",
      "          1.1476e+00, -3.0303e+00,  1.3036e+01,  2.9224e+00,  1.0225e+00,\n",
      "          6.5277e+00,  2.9391e+01,  1.1307e+01, -7.1318e+00, -1.1426e+01,\n",
      "          3.1415e+01,  1.9796e+01,  1.1164e+00,  1.2455e+01,  9.7468e+00,\n",
      "          1.6078e+01, -7.1100e+00,  3.0309e+00,  1.6426e+00, -2.3083e+01,\n",
      "          1.9178e+01,  1.9553e+01,  7.2140e+00,  1.1946e+01, -3.2701e+00,\n",
      "         -1.5713e+01, -3.0214e+01,  3.0865e+00, -5.5961e+00,  8.6398e+00,\n",
      "          2.4031e+01,  7.5270e-01,  3.7425e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0261e+01,  1.3185e+02,  2.4543e+01, -7.0981e+00, -1.6092e+01,\n",
      "          3.4177e+00, -1.7413e+00, -1.4479e+01,  2.2469e+01,  5.8170e+00,\n",
      "         -1.2233e+01,  1.7855e+00,  9.4464e+00, -1.5178e+00,  8.4099e+00,\n",
      "          1.0088e+01, -5.4723e+00, -3.4348e+00,  6.8298e+00,  1.9093e+01,\n",
      "          1.2443e+01,  1.3849e+00, -2.2926e+00,  1.4051e-01,  1.3510e+01,\n",
      "         -6.6678e+00,  5.8748e+00, -2.5631e+00, -7.7202e+00, -1.3883e+00,\n",
      "          6.5483e+00, -2.6898e+01, -9.2400e-01, -3.6398e+00,  4.7827e+00,\n",
      "         -1.1865e+01, -1.7606e+01, -9.6906e-01, -1.0046e+01,  1.9450e+01,\n",
      "         -6.4128e-01, -3.9037e-01, -1.3032e+01,  2.5779e+01,  1.7956e+01,\n",
      "         -4.8629e+00,  1.1822e+01, -3.8398e+00, -1.1711e+01,  1.6867e+01,\n",
      "          1.9033e+00, -6.3281e-01, -7.8633e+00, -1.4540e+01, -2.1695e+01,\n",
      "         -1.1297e+01, -6.5686e+00, -1.2653e+01, -2.9875e+00, -8.6983e+00,\n",
      "         -1.0353e+01, -1.7093e+01,  2.0085e-01, -4.5706e+00, -7.8289e+00,\n",
      "          3.1674e+01,  1.2285e-01,  7.1446e+00, -2.1529e+01,  8.6383e+00,\n",
      "         -1.1686e+01,  9.3354e-01,  9.1235e+00,  9.0568e+00,  1.5025e+01,\n",
      "         -5.1178e+00,  1.5139e+01, -1.3441e+01,  2.1954e+01,  4.4006e+00,\n",
      "         -8.9026e+00,  2.3227e+01, -1.4526e+01, -6.1490e+00,  8.1966e+00,\n",
      "         -1.3358e+00, -6.1359e+00, -8.7711e-02, -5.8660e+00, -1.8430e+01,\n",
      "         -1.0004e+01, -2.1242e+00,  1.0174e+01, -1.4397e+01, -1.1768e+01,\n",
      "          9.7454e-01, -2.8028e+00,  1.3218e+01,  2.8259e+00,  9.9295e-01,\n",
      "          6.3940e+00,  2.9193e+01,  1.1462e+01, -6.7361e+00, -1.1454e+01,\n",
      "          3.1608e+01,  1.9934e+01,  7.2886e-01,  1.2609e+01,  9.6778e+00,\n",
      "          1.6043e+01, -7.0366e+00,  2.8649e+00,  1.8099e+00, -2.2862e+01,\n",
      "          1.9250e+01,  1.9956e+01,  6.8492e+00,  1.1969e+01, -3.2170e+00,\n",
      "         -1.5385e+01, -3.0191e+01,  2.7569e+00, -5.9882e+00,  8.8246e+00,\n",
      "          2.3596e+01,  7.9463e-01,  8.4917e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.7892e+00,  1.3178e+02,  2.4344e+01, -7.0966e+00, -1.5904e+01,\n",
      "          3.4932e+00, -1.9759e+00, -1.4384e+01,  2.2316e+01,  5.8397e+00,\n",
      "         -1.2176e+01,  1.9523e+00,  9.4037e+00, -1.2857e+00,  8.4479e+00,\n",
      "          9.9258e+00, -5.6443e+00, -3.7111e+00,  7.0356e+00,  1.9079e+01,\n",
      "          1.2598e+01,  1.4146e+00, -2.4477e+00, -3.3387e-02,  1.3863e+01,\n",
      "         -6.7455e+00,  5.9432e+00, -2.8589e+00, -7.3082e+00, -1.6343e+00,\n",
      "          6.2111e+00, -2.6793e+01, -8.5581e-01, -3.8083e+00,  4.6544e+00,\n",
      "         -1.1709e+01, -1.8084e+01, -1.2718e+00, -1.0082e+01,  1.9866e+01,\n",
      "         -3.8605e-01, -4.9027e-01, -1.3279e+01,  2.5871e+01,  1.7997e+01,\n",
      "         -4.7931e+00,  1.1488e+01, -4.1184e+00, -1.1500e+01,  1.7145e+01,\n",
      "          1.7571e+00, -4.7842e-01, -7.6091e+00, -1.4559e+01, -2.1895e+01,\n",
      "         -1.1532e+01, -6.3664e+00, -1.2452e+01, -3.0599e+00, -8.8601e+00,\n",
      "         -1.0333e+01, -1.7170e+01,  7.9371e-02, -4.3214e+00, -7.9290e+00,\n",
      "          3.1644e+01,  3.6367e-01,  7.2772e+00, -2.1428e+01,  8.7191e+00,\n",
      "         -1.1574e+01,  7.4263e-01,  9.0790e+00,  8.9075e+00,  1.5054e+01,\n",
      "         -5.2003e+00,  1.5234e+01, -1.3455e+01,  2.1858e+01,  4.3485e+00,\n",
      "         -9.0093e+00,  2.2935e+01, -1.4434e+01, -6.2150e+00,  8.0525e+00,\n",
      "         -1.4859e+00, -6.4801e+00, -1.7146e-02, -5.7619e+00, -1.8473e+01,\n",
      "         -1.0396e+01, -2.0885e+00,  1.0360e+01, -1.4411e+01, -1.1480e+01,\n",
      "          8.3949e-01, -2.7298e+00,  1.3148e+01,  2.7815e+00,  9.5047e-01,\n",
      "          6.3519e+00,  2.9316e+01,  1.1298e+01, -7.0006e+00, -1.1234e+01,\n",
      "          3.1686e+01,  1.9835e+01,  5.4951e-01,  1.2638e+01,  9.5361e+00,\n",
      "          1.6071e+01, -7.0910e+00,  2.5072e+00,  1.6864e+00, -2.3149e+01,\n",
      "          1.9106e+01,  1.9999e+01,  6.7531e+00,  1.2131e+01, -2.9903e+00,\n",
      "         -1.5516e+01, -2.9965e+01,  2.9487e+00, -5.8245e+00,  8.6754e+00,\n",
      "          2.3973e+01,  5.1849e-01,  9.3934e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0170e+01,  1.3190e+02,  2.4486e+01, -7.3152e+00, -1.6238e+01,\n",
      "          3.6614e+00, -1.7175e+00, -1.4503e+01,  2.2180e+01,  6.1891e+00,\n",
      "         -1.2258e+01,  2.1801e+00,  9.5434e+00, -1.0741e+00,  8.6320e+00,\n",
      "          9.9021e+00, -5.4314e+00, -3.8398e+00,  6.5866e+00,  1.9108e+01,\n",
      "          1.3096e+01,  1.0618e+00, -2.4019e+00, -5.3333e-02,  1.3700e+01,\n",
      "         -6.5300e+00,  5.8492e+00, -2.6100e+00, -7.3815e+00, -1.5013e+00,\n",
      "          6.5510e+00, -2.6610e+01, -9.4920e-01, -3.7352e+00,  4.9494e+00,\n",
      "         -1.1967e+01, -1.7693e+01, -1.2727e+00, -1.0317e+01,  1.9360e+01,\n",
      "         -7.1082e-01, -3.7780e-01, -1.3464e+01,  2.6100e+01,  1.7953e+01,\n",
      "         -5.0212e+00,  1.1780e+01, -4.0715e+00, -1.1381e+01,  1.7258e+01,\n",
      "          1.9720e+00, -1.1136e+00, -7.6003e+00, -1.4590e+01, -2.1797e+01,\n",
      "         -1.1497e+01, -6.6569e+00, -1.2368e+01, -3.1490e+00, -8.6098e+00,\n",
      "         -1.0485e+01, -1.7481e+01,  2.9828e-01, -4.2109e+00, -7.6712e+00,\n",
      "          3.1691e+01,  3.1137e-01,  7.2438e+00, -2.1536e+01,  9.0051e+00,\n",
      "         -1.1765e+01,  8.8895e-01,  9.0340e+00,  8.7055e+00,  1.4868e+01,\n",
      "         -5.0692e+00,  1.5480e+01, -1.3746e+01,  2.1596e+01,  4.2072e+00,\n",
      "         -8.5406e+00,  2.2513e+01, -1.4449e+01, -6.1579e+00,  7.7536e+00,\n",
      "         -1.3199e+00, -6.2979e+00, -3.1384e-01, -5.7039e+00, -1.8276e+01,\n",
      "         -1.0141e+01, -2.3385e+00,  1.0345e+01, -1.4138e+01, -1.1616e+01,\n",
      "          7.4407e-01, -3.0787e+00,  1.3179e+01,  2.5536e+00,  1.0307e+00,\n",
      "          6.3139e+00,  2.9261e+01,  1.1184e+01, -7.1073e+00, -1.1284e+01,\n",
      "          3.1509e+01,  2.0031e+01,  5.8696e-01,  1.2393e+01,  9.8377e+00,\n",
      "          1.6051e+01, -6.8135e+00,  2.7239e+00,  1.3011e+00, -2.3405e+01,\n",
      "          1.9055e+01,  1.9537e+01,  6.8247e+00,  1.1893e+01, -3.0044e+00,\n",
      "         -1.5372e+01, -3.0326e+01,  3.2634e+00, -5.5915e+00,  8.8881e+00,\n",
      "          2.4025e+01,  5.8834e-01,  7.1630e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0127e+01,  1.3180e+02,  2.4565e+01, -7.2107e+00, -1.6108e+01,\n",
      "          3.6045e+00, -1.6134e+00, -1.4391e+01,  2.2179e+01,  6.2184e+00,\n",
      "         -1.2249e+01,  2.0627e+00,  9.6518e+00, -1.1689e+00,  8.3551e+00,\n",
      "          9.9737e+00, -5.5790e+00, -3.8737e+00,  6.5992e+00,  1.8888e+01,\n",
      "          1.2842e+01,  1.3262e+00, -2.5000e+00, -4.1871e-02,  1.3530e+01,\n",
      "         -6.5605e+00,  5.9236e+00, -2.5474e+00, -7.1924e+00, -1.2908e+00,\n",
      "          6.7357e+00, -2.6744e+01, -1.1929e+00, -3.5738e+00,  5.0185e+00,\n",
      "         -1.1722e+01, -1.7499e+01, -1.4272e+00, -1.0151e+01,  1.9581e+01,\n",
      "         -2.1971e-01, -3.7525e-01, -1.3436e+01,  2.5761e+01,  1.8234e+01,\n",
      "         -4.9728e+00,  1.1556e+01, -4.0981e+00, -1.1309e+01,  1.7222e+01,\n",
      "          2.0035e+00, -9.4097e-01, -7.6988e+00, -1.4630e+01, -2.2097e+01,\n",
      "         -1.1450e+01, -6.7215e+00, -1.2220e+01, -2.9208e+00, -8.9440e+00,\n",
      "         -1.0408e+01, -1.7332e+01,  1.2517e-02, -4.0094e+00, -7.8056e+00,\n",
      "          3.1722e+01,  3.3186e-01,  7.1973e+00, -2.1416e+01,  8.9127e+00,\n",
      "         -1.1697e+01,  9.3170e-01,  9.3783e+00,  9.1890e+00,  1.5052e+01,\n",
      "         -5.1518e+00,  1.5522e+01, -1.3541e+01,  2.1708e+01,  4.2726e+00,\n",
      "         -8.7609e+00,  2.3008e+01, -1.4532e+01, -6.0490e+00,  8.0804e+00,\n",
      "         -1.2563e+00, -5.9850e+00, -3.6548e-01, -5.7738e+00, -1.8363e+01,\n",
      "         -1.0084e+01, -1.9285e+00,  1.0379e+01, -1.4240e+01, -1.1794e+01,\n",
      "          1.1379e+00, -2.9764e+00,  1.2905e+01,  2.9708e+00,  1.0122e+00,\n",
      "          6.3906e+00,  2.9435e+01,  1.1369e+01, -7.1015e+00, -1.1320e+01,\n",
      "          3.1513e+01,  1.9657e+01,  1.0299e+00,  1.2577e+01,  9.7338e+00,\n",
      "          1.6095e+01, -7.2106e+00,  2.9848e+00,  1.6714e+00, -2.2977e+01,\n",
      "          1.9050e+01,  1.9726e+01,  7.0992e+00,  1.1890e+01, -3.1477e+00,\n",
      "         -1.5736e+01, -3.0285e+01,  3.0452e+00, -5.6479e+00,  8.7675e+00,\n",
      "          2.3981e+01,  6.6915e-01,  3.8114e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0249e+01,  1.3181e+02,  2.4562e+01, -6.9882e+00, -1.5999e+01,\n",
      "          3.4797e+00, -1.6852e+00, -1.4418e+01,  2.2420e+01,  5.8725e+00,\n",
      "         -1.2223e+01,  1.7354e+00,  9.3888e+00, -1.6552e+00,  8.5084e+00,\n",
      "          1.0141e+01, -5.2828e+00, -3.4365e+00,  6.9308e+00,  1.8956e+01,\n",
      "          1.2463e+01,  1.3013e+00, -2.3395e+00,  1.2661e-01,  1.3636e+01,\n",
      "         -6.8617e+00,  5.9217e+00, -2.6116e+00, -7.7454e+00, -1.3357e+00,\n",
      "          6.4437e+00, -2.6952e+01, -7.9200e-01, -3.6195e+00,  4.7048e+00,\n",
      "         -1.1899e+01, -1.7735e+01, -9.3383e-01, -1.0013e+01,  1.9517e+01,\n",
      "         -6.4738e-01, -5.2638e-01, -1.3070e+01,  2.5785e+01,  1.7901e+01,\n",
      "         -4.8321e+00,  1.1780e+01, -3.8730e+00, -1.1795e+01,  1.6866e+01,\n",
      "          1.7609e+00, -4.9617e-01, -7.9267e+00, -1.4573e+01, -2.1891e+01,\n",
      "         -1.1390e+01, -6.5007e+00, -1.2690e+01, -2.9763e+00, -8.8012e+00,\n",
      "         -1.0406e+01, -1.7161e+01,  2.7732e-01, -4.5927e+00, -7.7838e+00,\n",
      "          3.1664e+01,  1.1689e-01,  7.1468e+00, -2.1597e+01,  8.5998e+00,\n",
      "         -1.1573e+01,  9.1617e-01,  9.0619e+00,  9.0549e+00,  1.5094e+01,\n",
      "         -5.2015e+00,  1.5116e+01, -1.3293e+01,  2.1905e+01,  4.3152e+00,\n",
      "         -8.9164e+00,  2.3313e+01, -1.4581e+01, -6.1153e+00,  8.2855e+00,\n",
      "         -1.4054e+00, -6.1240e+00, -1.5005e-01, -5.8663e+00, -1.8450e+01,\n",
      "         -1.0026e+01, -2.0779e+00,  1.0231e+01, -1.4420e+01, -1.1755e+01,\n",
      "          9.9031e-01, -2.7728e+00,  1.3090e+01,  2.8989e+00,  9.6381e-01,\n",
      "          6.2947e+00,  2.9204e+01,  1.1507e+01, -6.7357e+00, -1.1345e+01,\n",
      "          3.1713e+01,  1.9789e+01,  6.4525e-01,  1.2711e+01,  9.6781e+00,\n",
      "          1.6071e+01, -7.1789e+00,  2.8556e+00,  1.8537e+00, -2.2723e+01,\n",
      "          1.9125e+01,  2.0169e+01,  6.7507e+00,  1.1913e+01, -3.0964e+00,\n",
      "         -1.5398e+01, -3.0271e+01,  2.7313e+00, -6.0094e+00,  8.9151e+00,\n",
      "          2.3569e+01,  7.3867e-01,  8.3925e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.7744e+00,  1.3176e+02,  2.4382e+01, -7.0253e+00, -1.5803e+01,\n",
      "          3.5510e+00, -1.9625e+00, -1.4312e+01,  2.2283e+01,  5.8768e+00,\n",
      "         -1.2154e+01,  1.8894e+00,  9.3676e+00, -1.4310e+00,  8.5160e+00,\n",
      "          9.9699e+00, -5.4844e+00, -3.6825e+00,  7.1652e+00,  1.8934e+01,\n",
      "          1.2609e+01,  1.3339e+00, -2.4606e+00, -4.8557e-02,  1.3961e+01,\n",
      "         -6.8932e+00,  5.9494e+00, -2.9322e+00, -7.3533e+00, -1.6066e+00,\n",
      "          6.1179e+00, -2.6860e+01, -7.5280e-01, -3.7871e+00,  4.5745e+00,\n",
      "         -1.1769e+01, -1.8152e+01, -1.2078e+00, -1.0054e+01,  1.9931e+01,\n",
      "         -4.1089e-01, -6.2049e-01, -1.3304e+01,  2.5878e+01,  1.7937e+01,\n",
      "         -4.7724e+00,  1.1468e+01, -4.1314e+00, -1.1581e+01,  1.7151e+01,\n",
      "          1.6339e+00, -3.2840e-01, -7.6631e+00, -1.4597e+01, -2.2072e+01,\n",
      "         -1.1585e+01, -6.2788e+00, -1.2522e+01, -3.0792e+00, -8.9308e+00,\n",
      "         -1.0382e+01, -1.7227e+01,  1.5263e-01, -4.3381e+00, -7.8343e+00,\n",
      "          3.1646e+01,  3.5007e-01,  7.2464e+00, -2.1509e+01,  8.6824e+00,\n",
      "         -1.1471e+01,  7.3246e-01,  9.0222e+00,  8.9316e+00,  1.5106e+01,\n",
      "         -5.2748e+00,  1.5189e+01, -1.3318e+01,  2.1820e+01,  4.2889e+00,\n",
      "         -9.0355e+00,  2.3051e+01, -1.4484e+01, -6.1890e+00,  8.1384e+00,\n",
      "         -1.5529e+00, -6.4819e+00, -1.0190e-01, -5.7816e+00, -1.8450e+01,\n",
      "         -1.0411e+01, -2.0573e+00,  1.0407e+01, -1.4432e+01, -1.1470e+01,\n",
      "          8.7861e-01, -2.7240e+00,  1.3020e+01,  2.8700e+00,  9.0421e-01,\n",
      "          6.2887e+00,  2.9342e+01,  1.1337e+01, -6.9953e+00, -1.1131e+01,\n",
      "          3.1793e+01,  1.9723e+01,  4.8286e-01,  1.2728e+01,  9.5730e+00,\n",
      "          1.6117e+01, -7.2444e+00,  2.4966e+00,  1.7556e+00, -2.3020e+01,\n",
      "          1.9017e+01,  2.0215e+01,  6.6747e+00,  1.2092e+01, -2.9068e+00,\n",
      "         -1.5515e+01, -3.0048e+01,  2.8939e+00, -5.8496e+00,  8.7255e+00,\n",
      "          2.3945e+01,  4.8299e-01,  9.1530e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0130e+01,  1.3189e+02,  2.4483e+01, -7.2415e+00, -1.6117e+01,\n",
      "          3.6892e+00, -1.7313e+00, -1.4387e+01,  2.2175e+01,  6.2030e+00,\n",
      "         -1.2217e+01,  2.1009e+00,  9.5148e+00, -1.2262e+00,  8.6921e+00,\n",
      "          9.9587e+00, -5.3267e+00, -3.7835e+00,  6.7394e+00,  1.8958e+01,\n",
      "          1.3061e+01,  1.0016e+00, -2.4026e+00, -9.5054e-02,  1.3780e+01,\n",
      "         -6.6632e+00,  5.8492e+00, -2.7104e+00, -7.4453e+00, -1.4990e+00,\n",
      "          6.4377e+00, -2.6700e+01, -8.7856e-01, -3.7472e+00,  4.8622e+00,\n",
      "         -1.2017e+01, -1.7795e+01, -1.1918e+00, -1.0289e+01,  1.9441e+01,\n",
      "         -7.4196e-01, -5.0939e-01, -1.3436e+01,  2.6111e+01,  1.7877e+01,\n",
      "         -5.0253e+00,  1.1744e+01, -4.0729e+00, -1.1457e+01,  1.7256e+01,\n",
      "          1.8310e+00, -9.2682e-01, -7.6211e+00, -1.4648e+01, -2.1956e+01,\n",
      "         -1.1529e+01, -6.6074e+00, -1.2469e+01, -3.1577e+00, -8.6524e+00,\n",
      "         -1.0522e+01, -1.7489e+01,  3.2916e-01, -4.2148e+00, -7.5515e+00,\n",
      "          3.1707e+01,  2.7212e-01,  7.2205e+00, -2.1597e+01,  8.9568e+00,\n",
      "         -1.1652e+01,  8.9251e-01,  9.0179e+00,  8.7512e+00,  1.4910e+01,\n",
      "         -5.1382e+00,  1.5416e+01, -1.3622e+01,  2.1563e+01,  4.1574e+00,\n",
      "         -8.5915e+00,  2.2681e+01, -1.4475e+01, -6.1205e+00,  7.8642e+00,\n",
      "         -1.4298e+00, -6.3412e+00, -4.3147e-01, -5.7549e+00, -1.8276e+01,\n",
      "         -1.0153e+01, -2.2772e+00,  1.0373e+01, -1.4179e+01, -1.1592e+01,\n",
      "          7.7937e-01, -3.0680e+00,  1.3099e+01,  2.6590e+00,  9.6825e-01,\n",
      "          6.2842e+00,  2.9292e+01,  1.1220e+01, -7.1001e+00, -1.1170e+01,\n",
      "          3.1602e+01,  1.9942e+01,  5.3912e-01,  1.2469e+01,  9.8581e+00,\n",
      "          1.6102e+01, -6.9702e+00,  2.7025e+00,  1.4096e+00, -2.3276e+01,\n",
      "          1.8987e+01,  1.9781e+01,  6.7370e+00,  1.1874e+01, -2.9603e+00,\n",
      "         -1.5403e+01, -3.0364e+01,  3.1855e+00, -5.6439e+00,  8.8960e+00,\n",
      "          2.3987e+01,  6.1582e-01,  7.1334e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0119e+01,  1.3178e+02,  2.4538e+01, -7.1308e+00, -1.5980e+01,\n",
      "          3.6282e+00, -1.6382e+00, -1.4280e+01,  2.2157e+01,  6.2475e+00,\n",
      "         -1.2161e+01,  1.9794e+00,  9.6306e+00, -1.3134e+00,  8.4664e+00,\n",
      "          1.0034e+01, -5.4611e+00, -3.8490e+00,  6.7887e+00,  1.8771e+01,\n",
      "          1.2829e+01,  1.2332e+00, -2.5156e+00, -5.1976e-02,  1.3583e+01,\n",
      "         -6.6924e+00,  5.9442e+00, -2.6363e+00, -7.2750e+00, -1.3003e+00,\n",
      "          6.6261e+00, -2.6853e+01, -1.1537e+00, -3.6057e+00,  4.9203e+00,\n",
      "         -1.1783e+01, -1.7608e+01, -1.3615e+00, -1.0129e+01,  1.9665e+01,\n",
      "         -2.6346e-01, -5.2255e-01, -1.3412e+01,  2.5779e+01,  1.8151e+01,\n",
      "         -4.9457e+00,  1.1526e+01, -4.0898e+00, -1.1355e+01,  1.7168e+01,\n",
      "          1.8866e+00, -7.8723e-01, -7.7265e+00, -1.4683e+01, -2.2238e+01,\n",
      "         -1.1487e+01, -6.7125e+00, -1.2322e+01, -2.9205e+00, -8.9835e+00,\n",
      "         -1.0418e+01, -1.7340e+01,  5.5650e-02, -4.0373e+00, -7.6599e+00,\n",
      "          3.1758e+01,  2.7831e-01,  7.1771e+00, -2.1486e+01,  8.8560e+00,\n",
      "         -1.1607e+01,  9.2770e-01,  9.3332e+00,  9.2064e+00,  1.5103e+01,\n",
      "         -5.2230e+00,  1.5435e+01, -1.3430e+01,  2.1688e+01,  4.2542e+00,\n",
      "         -8.7972e+00,  2.3179e+01, -1.4586e+01, -6.0123e+00,  8.1773e+00,\n",
      "         -1.3505e+00, -6.0490e+00, -4.5714e-01, -5.8191e+00, -1.8349e+01,\n",
      "         -1.0172e+01, -1.8927e+00,  1.0398e+01, -1.4272e+01, -1.1777e+01,\n",
      "          1.1551e+00, -2.9746e+00,  1.2823e+01,  3.0859e+00,  9.4692e-01,\n",
      "          6.3715e+00,  2.9451e+01,  1.1391e+01, -7.0814e+00, -1.1190e+01,\n",
      "          3.1596e+01,  1.9585e+01,  9.6452e-01,  1.2666e+01,  9.7850e+00,\n",
      "          1.6122e+01, -7.3519e+00,  2.9313e+00,  1.7799e+00, -2.2877e+01,\n",
      "          1.8961e+01,  1.9929e+01,  6.9912e+00,  1.1868e+01, -3.1103e+00,\n",
      "         -1.5769e+01, -3.0339e+01,  2.9651e+00, -5.7095e+00,  8.7713e+00,\n",
      "          2.3935e+01,  6.5816e-01,  4.0810e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0264e+01,  1.3177e+02,  2.4586e+01, -6.9184e+00, -1.5856e+01,\n",
      "          3.4950e+00, -1.6935e+00, -1.4332e+01,  2.2341e+01,  5.9546e+00,\n",
      "         -1.2087e+01,  1.6932e+00,  9.3738e+00, -1.7623e+00,  8.6740e+00,\n",
      "          1.0199e+01, -5.1653e+00, -3.4583e+00,  7.0939e+00,  1.8814e+01,\n",
      "          1.2481e+01,  1.2052e+00, -2.3925e+00,  1.4566e-01,  1.3680e+01,\n",
      "         -6.9808e+00,  5.9614e+00, -2.6287e+00, -7.8441e+00, -1.3414e+00,\n",
      "          6.3217e+00, -2.7027e+01, -7.8245e-01, -3.6506e+00,  4.6091e+00,\n",
      "         -1.1939e+01, -1.7851e+01, -9.3654e-01, -1.0000e+01,  1.9577e+01,\n",
      "         -6.4956e-01, -6.7910e-01, -1.3082e+01,  2.5798e+01,  1.7829e+01,\n",
      "         -4.8117e+00,  1.1728e+01, -3.8642e+00, -1.1791e+01,  1.6795e+01,\n",
      "          1.7050e+00, -3.7874e-01, -7.9336e+00, -1.4594e+01, -2.2029e+01,\n",
      "         -1.1457e+01, -6.5005e+00, -1.2769e+01, -2.9712e+00, -8.8654e+00,\n",
      "         -1.0390e+01, -1.7173e+01,  3.6347e-01, -4.6155e+00, -7.6650e+00,\n",
      "          3.1708e+01,  6.2293e-02,  7.1563e+00, -2.1664e+01,  8.5849e+00,\n",
      "         -1.1480e+01,  8.9766e-01,  9.0322e+00,  9.0352e+00,  1.5134e+01,\n",
      "         -5.2969e+00,  1.5067e+01, -1.3214e+01,  2.1882e+01,  4.2936e+00,\n",
      "         -8.9304e+00,  2.3432e+01, -1.4639e+01, -6.0505e+00,  8.3531e+00,\n",
      "         -1.4775e+00, -6.1328e+00, -2.5635e-01, -5.8994e+00, -1.8469e+01,\n",
      "         -1.0115e+01, -2.0193e+00,  1.0262e+01, -1.4439e+01, -1.1759e+01,\n",
      "          1.0153e+00, -2.7479e+00,  1.3016e+01,  3.0245e+00,  9.1050e-01,\n",
      "          6.2934e+00,  2.9207e+01,  1.1520e+01, -6.7016e+00, -1.1218e+01,\n",
      "          3.1808e+01,  1.9719e+01,  5.9076e-01,  1.2785e+01,  9.7414e+00,\n",
      "          1.6111e+01, -7.3270e+00,  2.8103e+00,  1.9585e+00, -2.2587e+01,\n",
      "          1.9013e+01,  2.0360e+01,  6.6446e+00,  1.1893e+01, -3.0357e+00,\n",
      "         -1.5447e+01, -3.0347e+01,  2.6861e+00, -6.0380e+00,  8.9493e+00,\n",
      "          2.3542e+01,  7.2984e-01,  8.6638e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.7971e+00,  1.3172e+02,  2.4446e+01, -6.9614e+00, -1.5678e+01,\n",
      "          3.5633e+00, -1.9399e+00, -1.4280e+01,  2.2193e+01,  5.9620e+00,\n",
      "         -1.2010e+01,  1.8647e+00,  9.3422e+00, -1.5418e+00,  8.6966e+00,\n",
      "          1.0006e+01, -5.3591e+00, -3.7443e+00,  7.3239e+00,  1.8793e+01,\n",
      "          1.2655e+01,  1.2223e+00, -2.5214e+00, -4.9356e-03,  1.3996e+01,\n",
      "         -7.0208e+00,  5.9973e+00, -2.9130e+00, -7.4455e+00, -1.5941e+00,\n",
      "          5.9901e+00, -2.6915e+01, -7.3111e-01, -3.7926e+00,  4.5119e+00,\n",
      "         -1.1803e+01, -1.8232e+01, -1.2273e+00, -1.0044e+01,  1.9984e+01,\n",
      "         -4.1185e-01, -7.7028e-01, -1.3327e+01,  2.5897e+01,  1.7876e+01,\n",
      "         -4.7407e+00,  1.1427e+01, -4.1000e+00, -1.1594e+01,  1.7093e+01,\n",
      "          1.5778e+00, -2.3664e-01, -7.7014e+00, -1.4602e+01, -2.2204e+01,\n",
      "         -1.1662e+01, -6.2492e+00, -1.2583e+01, -3.0645e+00, -8.9859e+00,\n",
      "         -1.0349e+01, -1.7259e+01,  2.6416e-01, -4.3782e+00, -7.7482e+00,\n",
      "          3.1666e+01,  3.0547e-01,  7.2640e+00, -2.1571e+01,  8.6870e+00,\n",
      "         -1.1371e+01,  6.9205e-01,  8.9689e+00,  8.9043e+00,  1.5162e+01,\n",
      "         -5.3692e+00,  1.5185e+01, -1.3241e+01,  2.1798e+01,  4.2874e+00,\n",
      "         -9.0455e+00,  2.3132e+01, -1.4538e+01, -6.1293e+00,  8.2004e+00,\n",
      "         -1.6058e+00, -6.4470e+00, -1.7983e-01, -5.7909e+00, -1.8479e+01,\n",
      "         -1.0477e+01, -1.9934e+00,  1.0450e+01, -1.4441e+01, -1.1491e+01,\n",
      "          9.1716e-01, -2.6899e+00,  1.2939e+01,  2.9839e+00,  8.6524e-01,\n",
      "          6.2673e+00,  2.9355e+01,  1.1352e+01, -6.9383e+00, -1.1013e+01,\n",
      "          3.1897e+01,  1.9662e+01,  4.2820e-01,  1.2814e+01,  9.6451e+00,\n",
      "          1.6160e+01, -7.3905e+00,  2.4444e+00,  1.8206e+00, -2.2890e+01,\n",
      "          1.8893e+01,  2.0391e+01,  6.5757e+00,  1.2062e+01, -2.8429e+00,\n",
      "         -1.5542e+01, -3.0134e+01,  2.8572e+00, -5.8624e+00,  8.7916e+00,\n",
      "          2.3919e+01,  4.5371e-01,  9.3071e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0101e+01,  1.3185e+02,  2.4520e+01, -7.1735e+00, -1.6015e+01,\n",
      "          3.6968e+00, -1.6877e+00, -1.4363e+01,  2.2119e+01,  6.2623e+00,\n",
      "         -1.2130e+01,  2.0714e+00,  9.4600e+00, -1.3474e+00,  8.8610e+00,\n",
      "          9.9898e+00, -5.2306e+00, -3.8504e+00,  6.8987e+00,  1.8815e+01,\n",
      "          1.3103e+01,  9.1430e-01, -2.4494e+00, -8.6492e-02,  1.3844e+01,\n",
      "         -6.8035e+00,  5.9006e+00, -2.7136e+00, -7.5038e+00, -1.4828e+00,\n",
      "          6.2689e+00, -2.6728e+01, -7.9827e-01, -3.7331e+00,  4.8122e+00,\n",
      "         -1.2028e+01, -1.7887e+01, -1.1987e+00, -1.0276e+01,  1.9530e+01,\n",
      "         -7.5564e-01, -6.6025e-01, -1.3425e+01,  2.6132e+01,  1.7816e+01,\n",
      "         -5.0137e+00,  1.1694e+01, -4.0532e+00, -1.1525e+01,  1.7237e+01,\n",
      "          1.7285e+00, -7.9418e-01, -7.6800e+00, -1.4669e+01, -2.2066e+01,\n",
      "         -1.1593e+01, -6.5642e+00, -1.2526e+01, -3.1362e+00, -8.6827e+00,\n",
      "         -1.0504e+01, -1.7523e+01,  4.1660e-01, -4.2583e+00, -7.4911e+00,\n",
      "          3.1709e+01,  2.2030e-01,  7.2524e+00, -2.1642e+01,  8.9587e+00,\n",
      "         -1.1533e+01,  8.4845e-01,  8.9514e+00,  8.7514e+00,  1.4985e+01,\n",
      "         -5.2429e+00,  1.5456e+01, -1.3525e+01,  2.1543e+01,  4.1341e+00,\n",
      "         -8.6162e+00,  2.2751e+01, -1.4481e+01, -6.0852e+00,  7.9508e+00,\n",
      "         -1.5190e+00, -6.3221e+00, -5.0515e-01, -5.7482e+00, -1.8354e+01,\n",
      "         -1.0169e+01, -2.1758e+00,  1.0435e+01, -1.4184e+01, -1.1575e+01,\n",
      "          8.1678e-01, -3.0172e+00,  1.3037e+01,  2.7494e+00,  9.0618e-01,\n",
      "          6.2211e+00,  2.9310e+01,  1.1245e+01, -7.0488e+00, -1.1039e+01,\n",
      "          3.1698e+01,  1.9887e+01,  4.8513e-01,  1.2559e+01,  9.8870e+00,\n",
      "          1.6162e+01, -7.0970e+00,  2.6594e+00,  1.4502e+00, -2.3147e+01,\n",
      "          1.8864e+01,  1.9989e+01,  6.6333e+00,  1.1861e+01, -2.9088e+00,\n",
      "         -1.5415e+01, -3.0378e+01,  3.1479e+00, -5.6494e+00,  8.9827e+00,\n",
      "          2.3948e+01,  6.0765e-01,  7.2983e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0086e+01,  1.3175e+02,  2.4543e+01, -7.0808e+00, -1.5901e+01,\n",
      "          3.6509e+00, -1.6046e+00, -1.4269e+01,  2.2122e+01,  6.2871e+00,\n",
      "         -1.2109e+01,  1.9323e+00,  9.5610e+00, -1.4428e+00,  8.6296e+00,\n",
      "          1.0056e+01, -5.3713e+00, -3.9192e+00,  6.9833e+00,  1.8655e+01,\n",
      "          1.2905e+01,  1.1435e+00, -2.5286e+00, -3.9439e-02,  1.3653e+01,\n",
      "         -6.8206e+00,  5.9897e+00, -2.6861e+00, -7.3245e+00, -1.2985e+00,\n",
      "          6.4501e+00, -2.6862e+01, -1.0178e+00, -3.5651e+00,  4.8606e+00,\n",
      "         -1.1805e+01, -1.7682e+01, -1.3555e+00, -1.0114e+01,  1.9780e+01,\n",
      "         -3.3042e-01, -6.7513e-01, -1.3407e+01,  2.5794e+01,  1.8086e+01,\n",
      "         -4.9170e+00,  1.1484e+01, -4.0864e+00, -1.1452e+01,  1.7157e+01,\n",
      "          1.7740e+00, -6.5789e-01, -7.8179e+00, -1.4719e+01, -2.2303e+01,\n",
      "         -1.1542e+01, -6.6532e+00, -1.2389e+01, -2.9184e+00, -9.0058e+00,\n",
      "         -1.0410e+01, -1.7394e+01,  1.3514e-01, -4.1033e+00, -7.5518e+00,\n",
      "          3.1767e+01,  2.2834e-01,  7.1889e+00, -2.1540e+01,  8.8461e+00,\n",
      "         -1.1502e+01,  9.1498e-01,  9.2033e+00,  9.2180e+00,  1.5188e+01,\n",
      "         -5.3340e+00,  1.5476e+01, -1.3321e+01,  2.1690e+01,  4.2062e+00,\n",
      "         -8.7979e+00,  2.3239e+01, -1.4566e+01, -6.0282e+00,  8.2747e+00,\n",
      "         -1.4339e+00, -6.0700e+00, -5.0696e-01, -5.7911e+00, -1.8400e+01,\n",
      "         -1.0223e+01, -1.8282e+00,  1.0492e+01, -1.4246e+01, -1.1716e+01,\n",
      "          1.1832e+00, -2.9460e+00,  1.2742e+01,  3.1679e+00,  8.5071e-01,\n",
      "          6.2840e+00,  2.9467e+01,  1.1405e+01, -7.0301e+00, -1.1039e+01,\n",
      "          3.1678e+01,  1.9543e+01,  8.8720e-01,  1.2758e+01,  9.8308e+00,\n",
      "          1.6203e+01, -7.4436e+00,  2.9025e+00,  1.8004e+00, -2.2796e+01,\n",
      "          1.8846e+01,  2.0117e+01,  6.8757e+00,  1.1875e+01, -3.0573e+00,\n",
      "         -1.5736e+01, -3.0325e+01,  2.9215e+00, -5.6907e+00,  8.8616e+00,\n",
      "          2.3882e+01,  6.2059e-01,  4.1507e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0227e+01,  1.3173e+02,  2.4572e+01, -6.8729e+00, -1.5785e+01,\n",
      "          3.5070e+00, -1.6804e+00, -1.4299e+01,  2.2302e+01,  5.9891e+00,\n",
      "         -1.2027e+01,  1.6676e+00,  9.3269e+00, -1.8631e+00,  8.8052e+00,\n",
      "          1.0206e+01, -5.0984e+00, -3.5173e+00,  7.2792e+00,  1.8661e+01,\n",
      "          1.2577e+01,  1.1440e+00, -2.3739e+00,  1.2751e-01,  1.3754e+01,\n",
      "         -7.1163e+00,  6.0041e+00, -2.7107e+00, -7.8962e+00, -1.3335e+00,\n",
      "          6.1622e+00, -2.7009e+01, -6.5665e-01, -3.6000e+00,  4.5329e+00,\n",
      "         -1.1940e+01, -1.7917e+01, -9.3034e-01, -9.9682e+00,  1.9696e+01,\n",
      "         -7.1320e-01, -7.9530e-01, -1.3098e+01,  2.5789e+01,  1.7770e+01,\n",
      "         -4.7874e+00,  1.1674e+01, -3.8324e+00, -1.1864e+01,  1.6781e+01,\n",
      "          1.5887e+00, -2.7371e-01, -8.0138e+00, -1.4597e+01, -2.2111e+01,\n",
      "         -1.1520e+01, -6.4473e+00, -1.2829e+01, -2.9506e+00, -8.9028e+00,\n",
      "         -1.0403e+01, -1.7201e+01,  4.1510e-01, -4.6670e+00, -7.5015e+00,\n",
      "          3.1726e+01,  1.9188e-02,  7.1610e+00, -2.1706e+01,  8.6037e+00,\n",
      "         -1.1386e+01,  9.0898e-01,  8.9368e+00,  9.0709e+00,  1.5194e+01,\n",
      "         -5.3986e+00,  1.5112e+01, -1.3096e+01,  2.1877e+01,  4.1941e+00,\n",
      "         -8.9079e+00,  2.3519e+01, -1.4633e+01, -6.0521e+00,  8.4701e+00,\n",
      "         -1.5650e+00, -6.1650e+00, -3.2468e-01, -5.8823e+00, -1.8494e+01,\n",
      "         -1.0147e+01, -1.9411e+00,  1.0377e+01, -1.4401e+01, -1.1705e+01,\n",
      "          1.0558e+00, -2.7145e+00,  1.2918e+01,  3.1115e+00,  8.1295e-01,\n",
      "          6.2253e+00,  2.9228e+01,  1.1528e+01, -6.6637e+00, -1.1062e+01,\n",
      "          3.1881e+01,  1.9656e+01,  5.0709e-01,  1.2855e+01,  9.7972e+00,\n",
      "          1.6215e+01, -7.4138e+00,  2.8329e+00,  1.9790e+00, -2.2507e+01,\n",
      "          1.8909e+01,  2.0545e+01,  6.5491e+00,  1.1905e+01, -2.9903e+00,\n",
      "         -1.5420e+01, -3.0324e+01,  2.6456e+00, -6.0100e+00,  9.0528e+00,\n",
      "          2.3487e+01,  7.2494e-01,  8.5338e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.7876e+00,  1.3168e+02,  2.4461e+01, -6.9352e+00, -1.5599e+01,\n",
      "          3.5620e+00, -1.9549e+00, -1.4261e+01,  2.2175e+01,  5.9699e+00,\n",
      "         -1.1902e+01,  1.8379e+00,  9.3052e+00, -1.6438e+00,  8.8008e+00,\n",
      "          1.0003e+01, -5.2892e+00, -3.7641e+00,  7.4753e+00,  1.8614e+01,\n",
      "          1.2737e+01,  1.1757e+00, -2.4953e+00,  1.2647e-02,  1.4030e+01,\n",
      "         -7.1388e+00,  6.0371e+00, -2.9645e+00, -7.5107e+00, -1.5796e+00,\n",
      "          5.8515e+00, -2.6915e+01, -6.3780e-01, -3.7268e+00,  4.4353e+00,\n",
      "         -1.1797e+01, -1.8278e+01, -1.2124e+00, -9.9785e+00,  2.0085e+01,\n",
      "         -4.7392e-01, -8.7266e-01, -1.3355e+01,  2.5892e+01,  1.7815e+01,\n",
      "         -4.7208e+00,  1.1368e+01, -4.0385e+00, -1.1655e+01,  1.7056e+01,\n",
      "          1.4584e+00, -1.3064e-01, -7.7819e+00, -1.4608e+01, -2.2303e+01,\n",
      "         -1.1738e+01, -6.1879e+00, -1.2627e+01, -3.0256e+00, -9.0177e+00,\n",
      "         -1.0371e+01, -1.7261e+01,  2.9642e-01, -4.4327e+00, -7.5723e+00,\n",
      "          3.1668e+01,  2.7979e-01,  7.2455e+00, -2.1597e+01,  8.7240e+00,\n",
      "         -1.1279e+01,  7.3593e-01,  8.9017e+00,  8.9689e+00,  1.5190e+01,\n",
      "         -5.4534e+00,  1.5208e+01, -1.3128e+01,  2.1776e+01,  4.1865e+00,\n",
      "         -9.0157e+00,  2.3251e+01, -1.4543e+01, -6.1216e+00,  8.3166e+00,\n",
      "         -1.6828e+00, -6.4768e+00, -2.5968e-01, -5.8051e+00, -1.8490e+01,\n",
      "         -1.0493e+01, -1.9162e+00,  1.0523e+01, -1.4411e+01, -1.1444e+01,\n",
      "          9.6435e-01, -2.6475e+00,  1.2841e+01,  3.0902e+00,  7.7423e-01,\n",
      "          6.2203e+00,  2.9407e+01,  1.1351e+01, -6.8841e+00, -1.0873e+01,\n",
      "          3.1968e+01,  1.9605e+01,  3.4622e-01,  1.2852e+01,  9.7187e+00,\n",
      "          1.6271e+01, -7.4735e+00,  2.4923e+00,  1.8664e+00, -2.2821e+01,\n",
      "          1.8818e+01,  2.0578e+01,  6.5066e+00,  1.2071e+01, -2.7949e+00,\n",
      "         -1.5514e+01, -3.0135e+01,  2.7981e+00, -5.8507e+00,  8.8810e+00,\n",
      "          2.3855e+01,  4.9437e-01,  8.9635e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0095e+01,  1.3182e+02,  2.4524e+01, -7.1378e+00, -1.5922e+01,\n",
      "          3.6839e+00, -1.7057e+00, -1.4346e+01,  2.2131e+01,  6.2626e+00,\n",
      "         -1.2028e+01,  2.0321e+00,  9.4185e+00, -1.4542e+00,  8.9641e+00,\n",
      "          9.9935e+00, -5.1451e+00, -3.8459e+00,  7.0053e+00,  1.8612e+01,\n",
      "          1.3145e+01,  8.7284e-01, -2.4541e+00, -7.3339e-02,  1.3894e+01,\n",
      "         -6.9300e+00,  5.9485e+00, -2.7309e+00, -7.5435e+00, -1.4518e+00,\n",
      "          6.1230e+00, -2.6759e+01, -7.2256e-01, -3.6640e+00,  4.7254e+00,\n",
      "         -1.1991e+01, -1.7976e+01, -1.1714e+00, -1.0180e+01,  1.9610e+01,\n",
      "         -7.8405e-01, -7.6304e-01, -1.3446e+01,  2.6138e+01,  1.7748e+01,\n",
      "         -5.0166e+00,  1.1619e+01, -3.9997e+00, -1.1597e+01,  1.7166e+01,\n",
      "          1.5908e+00, -6.3828e-01, -7.7498e+00, -1.4685e+01, -2.2201e+01,\n",
      "         -1.1680e+01, -6.5142e+00, -1.2537e+01, -3.0727e+00, -8.7138e+00,\n",
      "         -1.0528e+01, -1.7504e+01,  4.1721e-01, -4.3214e+00, -7.3723e+00,\n",
      "          3.1687e+01,  2.1133e-01,  7.2465e+00, -2.1652e+01,  9.0009e+00,\n",
      "         -1.1423e+01,  8.9235e-01,  8.9184e+00,  8.8378e+00,  1.4993e+01,\n",
      "         -5.3269e+00,  1.5464e+01, -1.3423e+01,  2.1495e+01,  4.0406e+00,\n",
      "         -8.6119e+00,  2.2885e+01, -1.4476e+01, -6.0621e+00,  8.0535e+00,\n",
      "         -1.6241e+00, -6.3567e+00, -6.1322e-01, -5.7707e+00, -1.8411e+01,\n",
      "         -1.0152e+01, -2.0732e+00,  1.0466e+01, -1.4178e+01, -1.1509e+01,\n",
      "          8.5062e-01, -2.9265e+00,  1.2957e+01,  2.8529e+00,  8.2494e-01,\n",
      "          6.1625e+00,  2.9377e+01,  1.1258e+01, -7.0019e+00, -1.0919e+01,\n",
      "          3.1780e+01,  1.9830e+01,  4.0134e-01,  1.2576e+01,  9.9289e+00,\n",
      "          1.6264e+01, -7.1703e+00,  2.6986e+00,  1.5275e+00, -2.3049e+01,\n",
      "          1.8795e+01,  2.0194e+01,  6.5713e+00,  1.1882e+01, -2.8623e+00,\n",
      "         -1.5405e+01, -3.0376e+01,  3.0966e+00, -5.6788e+00,  9.0804e+00,\n",
      "          2.3867e+01,  6.8817e-01,  7.1728e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0121e+01,  1.3172e+02,  2.4543e+01, -7.0392e+00, -1.5803e+01,\n",
      "          3.6612e+00, -1.6015e+00, -1.4289e+01,  2.2130e+01,  6.3222e+00,\n",
      "         -1.2020e+01,  1.8736e+00,  9.5058e+00, -1.5513e+00,  8.7789e+00,\n",
      "          1.0057e+01, -5.2187e+00, -3.9439e+00,  7.0797e+00,  1.8489e+01,\n",
      "          1.2962e+01,  1.0534e+00, -2.5713e+00,  3.0628e-03,  1.3737e+01,\n",
      "         -6.9618e+00,  6.0413e+00, -2.6687e+00, -7.3381e+00, -1.2575e+00,\n",
      "          6.3227e+00, -2.6929e+01, -9.4586e-01, -3.4962e+00,  4.7658e+00,\n",
      "         -1.1771e+01, -1.7771e+01, -1.3222e+00, -1.0023e+01,  1.9829e+01,\n",
      "         -3.4885e-01, -7.9525e-01, -1.3462e+01,  2.5811e+01,  1.8017e+01,\n",
      "         -4.8945e+00,  1.1438e+01, -4.0629e+00, -1.1523e+01,  1.7031e+01,\n",
      "          1.6506e+00, -5.0759e-01, -7.9051e+00, -1.4727e+01, -2.2454e+01,\n",
      "         -1.1641e+01, -6.6058e+00, -1.2369e+01, -2.8796e+00, -9.0551e+00,\n",
      "         -1.0419e+01, -1.7424e+01,  1.5793e-01, -4.1832e+00, -7.4807e+00,\n",
      "          3.1737e+01,  2.3794e-01,  7.1803e+00, -2.1565e+01,  8.8844e+00,\n",
      "         -1.1406e+01,  9.2772e-01,  9.1244e+00,  9.2760e+00,  1.5185e+01,\n",
      "         -5.4193e+00,  1.5454e+01, -1.3235e+01,  2.1641e+01,  4.1436e+00,\n",
      "         -8.7923e+00,  2.3331e+01, -1.4595e+01, -6.0152e+00,  8.3263e+00,\n",
      "         -1.5241e+00, -6.0948e+00, -6.0402e-01, -5.7748e+00, -1.8448e+01,\n",
      "         -1.0254e+01, -1.7714e+00,  1.0516e+01, -1.4256e+01, -1.1643e+01,\n",
      "          1.2069e+00, -2.8363e+00,  1.2644e+01,  3.2593e+00,  7.9358e-01,\n",
      "          6.2027e+00,  2.9515e+01,  1.1432e+01, -6.9943e+00, -1.0944e+01,\n",
      "          3.1773e+01,  1.9490e+01,  7.7545e-01,  1.2775e+01,  9.8968e+00,\n",
      "          1.6274e+01, -7.5080e+00,  2.9026e+00,  1.8748e+00, -2.2688e+01,\n",
      "          1.8757e+01,  2.0275e+01,  6.7969e+00,  1.1883e+01, -2.9958e+00,\n",
      "         -1.5713e+01, -3.0371e+01,  2.9007e+00, -5.7392e+00,  8.9765e+00,\n",
      "          2.3798e+01,  6.4059e-01,  4.2787e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0285e+01,  1.3169e+02,  2.4577e+01, -6.8418e+00, -1.5684e+01,\n",
      "          3.5092e+00, -1.6601e+00, -1.4351e+01,  2.2274e+01,  6.0648e+00,\n",
      "         -1.1986e+01,  1.6354e+00,  9.2492e+00, -1.9464e+00,  8.9947e+00,\n",
      "          1.0241e+01, -4.9555e+00, -3.5635e+00,  7.3747e+00,  1.8498e+01,\n",
      "          1.2635e+01,  1.0380e+00, -2.4425e+00,  1.9537e-01,  1.3844e+01,\n",
      "         -7.2459e+00,  6.0282e+00, -2.6609e+00, -7.8669e+00, -1.3041e+00,\n",
      "          6.0607e+00, -2.7065e+01, -6.0100e-01, -3.5261e+00,  4.4462e+00,\n",
      "         -1.1876e+01, -1.7993e+01, -9.1070e-01, -9.8797e+00,  1.9735e+01,\n",
      "         -6.9702e-01, -9.2546e-01, -1.3156e+01,  2.5800e+01,  1.7696e+01,\n",
      "         -4.7621e+00,  1.1636e+01, -3.8259e+00, -1.1944e+01,  1.6667e+01,\n",
      "          1.5113e+00, -1.3634e-01, -8.0897e+00, -1.4572e+01, -2.2284e+01,\n",
      "         -1.1595e+01, -6.4003e+00, -1.2805e+01, -2.9575e+00, -8.9708e+00,\n",
      "         -1.0400e+01, -1.7267e+01,  4.8850e-01, -4.7351e+00, -7.4675e+00,\n",
      "          3.1737e+01,  4.8412e-03,  7.1534e+00, -2.1711e+01,  8.6778e+00,\n",
      "         -1.1286e+01,  8.5101e-01,  8.8771e+00,  9.1072e+00,  1.5185e+01,\n",
      "         -5.4892e+00,  1.5077e+01, -1.3022e+01,  2.1857e+01,  4.1209e+00,\n",
      "         -8.9093e+00,  2.3554e+01, -1.4683e+01, -6.0205e+00,  8.5191e+00,\n",
      "         -1.6277e+00, -6.1442e+00, -4.1312e-01, -5.8240e+00, -1.8557e+01,\n",
      "         -1.0176e+01, -1.8830e+00,  1.0400e+01, -1.4446e+01, -1.1639e+01,\n",
      "          1.1048e+00, -2.5751e+00,  1.2815e+01,  3.2208e+00,  7.7334e-01,\n",
      "          6.1557e+00,  2.9246e+01,  1.1595e+01, -6.6491e+00, -1.0957e+01,\n",
      "          3.1959e+01,  1.9595e+01,  3.7175e-01,  1.2845e+01,  9.8560e+00,\n",
      "          1.6246e+01, -7.5132e+00,  2.8214e+00,  2.0581e+00, -2.2370e+01,\n",
      "          1.8784e+01,  2.0695e+01,  6.4855e+00,  1.1892e+01, -2.9067e+00,\n",
      "         -1.5385e+01, -3.0410e+01,  2.6633e+00, -6.0211e+00,  9.1528e+00,\n",
      "          2.3421e+01,  7.1448e-01,  8.3773e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 9.8291e+00,  1.3165e+02,  2.4477e+01, -6.9106e+00, -1.5496e+01,\n",
      "          3.5765e+00, -1.9243e+00, -1.4305e+01,  2.2151e+01,  6.0430e+00,\n",
      "         -1.1875e+01,  1.7819e+00,  9.2400e+00, -1.7374e+00,  8.9618e+00,\n",
      "          1.0029e+01, -5.1854e+00, -3.7833e+00,  7.6167e+00,  1.8496e+01,\n",
      "          1.2794e+01,  1.0593e+00, -2.5442e+00,  6.7462e-02,  1.4118e+01,\n",
      "         -7.2657e+00,  6.0472e+00, -2.9367e+00, -7.4936e+00, -1.5609e+00,\n",
      "          5.7643e+00, -2.6990e+01, -5.7823e-01, -3.6544e+00,  4.3612e+00,\n",
      "         -1.1770e+01, -1.8337e+01, -1.1683e+00, -9.9190e+00,  2.0103e+01,\n",
      "         -4.6754e-01, -9.9253e-01, -1.3396e+01,  2.5904e+01,  1.7738e+01,\n",
      "         -4.6967e+00,  1.1357e+01, -4.0210e+00, -1.1740e+01,  1.6951e+01,\n",
      "          1.3961e+00,  2.5116e-03, -7.8406e+00, -1.4600e+01, -2.2438e+01,\n",
      "         -1.1788e+01, -6.1528e+00, -1.2632e+01, -3.0454e+00, -9.0760e+00,\n",
      "         -1.0342e+01, -1.7344e+01,  3.7302e-01, -4.4924e+00, -7.5330e+00,\n",
      "          3.1679e+01,  2.6532e-01,  7.2305e+00, -2.1618e+01,  8.7840e+00,\n",
      "         -1.1179e+01,  6.8361e-01,  8.8397e+00,  9.0161e+00,  1.5188e+01,\n",
      "         -5.5460e+00,  1.5177e+01, -1.3084e+01,  2.1754e+01,  4.1644e+00,\n",
      "         -9.0246e+00,  2.3286e+01, -1.4589e+01, -6.0871e+00,  8.3620e+00,\n",
      "         -1.7372e+00, -6.4424e+00, -3.3502e-01, -5.7431e+00, -1.8523e+01,\n",
      "         -1.0512e+01, -1.8869e+00,  1.0566e+01, -1.4453e+01, -1.1406e+01,\n",
      "          1.0149e+00, -2.5305e+00,  1.2763e+01,  3.2039e+00,  7.4713e-01,\n",
      "          6.1869e+00,  2.9425e+01,  1.1417e+01, -6.8709e+00, -1.0773e+01,\n",
      "          3.2055e+01,  1.9572e+01,  2.3155e-01,  1.2857e+01,  9.7911e+00,\n",
      "          1.6306e+01, -7.5791e+00,  2.4758e+00,  1.9186e+00, -2.2690e+01,\n",
      "          1.8712e+01,  2.0721e+01,  6.4509e+00,  1.2053e+01, -2.7240e+00,\n",
      "         -1.5483e+01, -3.0209e+01,  2.8125e+00, -5.8608e+00,  8.9741e+00,\n",
      "          2.3801e+01,  4.7137e-01,  8.7453e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0078e+01,  1.3180e+02,  2.4493e+01, -7.1069e+00, -1.5823e+01,\n",
      "          3.6781e+00, -1.6935e+00, -1.4334e+01,  2.2139e+01,  6.3120e+00,\n",
      "         -1.2012e+01,  1.9393e+00,  9.3645e+00, -1.5680e+00,  9.0920e+00,\n",
      "          1.0029e+01, -5.0944e+00, -3.8114e+00,  7.1773e+00,  1.8515e+01,\n",
      "          1.3164e+01,  7.7891e-01, -2.4750e+00, -6.7308e-02,  1.3978e+01,\n",
      "         -7.0560e+00,  5.9631e+00, -2.7572e+00, -7.5469e+00, -1.4449e+00,\n",
      "          6.0138e+00, -2.6857e+01, -6.3694e-01, -3.6096e+00,  4.6491e+00,\n",
      "         -1.1985e+01, -1.8085e+01, -1.0979e+00, -1.0135e+01,  1.9630e+01,\n",
      "         -7.8543e-01, -8.8400e-01, -1.3434e+01,  2.6147e+01,  1.7662e+01,\n",
      "         -5.0146e+00,  1.1599e+01, -3.9821e+00, -1.1710e+01,  1.7074e+01,\n",
      "          1.4963e+00, -4.6475e-01, -7.7850e+00, -1.4719e+01, -2.2315e+01,\n",
      "         -1.1706e+01, -6.5140e+00, -1.2578e+01, -3.0687e+00, -8.7419e+00,\n",
      "         -1.0482e+01, -1.7555e+01,  4.5590e-01, -4.3657e+00, -7.3034e+00,\n",
      "          3.1708e+01,  1.7813e-01,  7.2346e+00, -2.1673e+01,  9.0209e+00,\n",
      "         -1.1303e+01,  8.6029e-01,  8.8874e+00,  8.9183e+00,  1.4999e+01,\n",
      "         -5.4193e+00,  1.5440e+01, -1.3383e+01,  2.1468e+01,  4.0416e+00,\n",
      "         -8.6390e+00,  2.2957e+01, -1.4486e+01, -6.0221e+00,  8.1374e+00,\n",
      "         -1.7179e+00, -6.3586e+00, -6.9556e-01, -5.7343e+00, -1.8464e+01,\n",
      "         -1.0145e+01, -2.0225e+00,  1.0517e+01, -1.4213e+01, -1.1479e+01,\n",
      "          8.9435e-01, -2.8391e+00,  1.2920e+01,  2.9662e+00,  7.8222e-01,\n",
      "          6.1377e+00,  2.9388e+01,  1.1312e+01, -6.9909e+00, -1.0795e+01,\n",
      "          3.1852e+01,  1.9810e+01,  3.2295e-01,  1.2603e+01,  9.9777e+00,\n",
      "          1.6316e+01, -7.2709e+00,  2.6932e+00,  1.5704e+00, -2.2910e+01,\n",
      "          1.8713e+01,  2.0360e+01,  6.4994e+00,  1.1877e+01, -2.8221e+00,\n",
      "         -1.5401e+01, -3.0372e+01,  3.0904e+00, -5.7045e+00,  9.1607e+00,\n",
      "          2.3794e+01,  7.0751e-01,  7.0264e-01]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 1.0094e+01,  1.3170e+02,  2.4487e+01, -7.0080e+00, -1.5703e+01,\n",
      "          3.6571e+00, -1.6142e+00, -1.4233e+01,  2.2140e+01,  6.3736e+00,\n",
      "         -1.1980e+01,  1.7483e+00,  9.4643e+00, -1.6697e+00,  8.8996e+00,\n",
      "          1.0093e+01, -5.1504e+00, -3.9079e+00,  7.2744e+00,  1.8412e+01,\n",
      "          1.2978e+01,  9.5406e-01, -2.5766e+00,  3.7173e-03,  1.3800e+01,\n",
      "         -7.0932e+00,  6.0868e+00, -2.7194e+00, -7.3732e+00, -1.2563e+00,\n",
      "          6.2131e+00, -2.7048e+01, -8.5171e-01, -3.4645e+00,  4.6726e+00,\n",
      "         -1.1806e+01, -1.7902e+01, -1.2376e+00, -1.0001e+01,  1.9848e+01,\n",
      "         -3.7880e-01, -9.2779e-01, -1.3462e+01,  2.5824e+01,  1.7932e+01,\n",
      "         -4.8835e+00,  1.1425e+01, -4.0424e+00, -1.1626e+01,  1.6926e+01,\n",
      "          1.5277e+00, -3.5772e-01, -7.9497e+00, -1.4789e+01, -2.2556e+01,\n",
      "         -1.1679e+01, -6.6335e+00, -1.2422e+01, -2.8602e+00, -9.0596e+00,\n",
      "         -1.0358e+01, -1.7463e+01,  1.9880e-01, -4.2155e+00, -7.3566e+00,\n",
      "          3.1776e+01,  1.9887e-01,  7.1576e+00, -2.1608e+01,  8.8628e+00,\n",
      "         -1.1301e+01,  9.3040e-01,  9.0720e+00,  9.3633e+00,  1.5207e+01,\n",
      "         -5.5146e+00,  1.5414e+01, -1.3167e+01,  2.1623e+01,  4.1595e+00,\n",
      "         -8.7896e+00,  2.3420e+01, -1.4605e+01, -5.9784e+00,  8.4192e+00,\n",
      "         -1.6145e+00, -6.1345e+00, -6.7387e-01, -5.7741e+00, -1.8465e+01,\n",
      "         -1.0295e+01, -1.7407e+00,  1.0575e+01, -1.4269e+01, -1.1630e+01,\n",
      "          1.2362e+00, -2.7925e+00,  1.2608e+01,  3.3813e+00,  7.3781e-01,\n",
      "          6.1656e+00,  2.9507e+01,  1.1457e+01, -6.9694e+00, -1.0806e+01,\n",
      "          3.1823e+01,  1.9471e+01,  7.1484e-01,  1.2833e+01,  9.9669e+00,\n",
      "          1.6334e+01, -7.5955e+00,  2.9140e+00,  1.9037e+00, -2.2576e+01,\n",
      "          1.8689e+01,  2.0419e+01,  6.6811e+00,  1.1875e+01, -2.9607e+00,\n",
      "         -1.5716e+01, -3.0348e+01,  2.8744e+00, -5.7750e+00,  9.0637e+00,\n",
      "          2.3710e+01,  6.5096e-01,  4.2421e-01]], grad_fn=<SliceBackward0>)\n",
      "JULIET:\n",
      "O Romeo, Romeo! wherefore art thou                                                                                                                                                                                                                      \n"
     ]
    }
   ],
   "source": [
    "input_str = \"JULIET:\\nO Romeo, Romeo! wherefore art thou \" # the classic line\n",
    "max_useable_output_len = config.max_seq_len - len(input_str)\n",
    "output = model.generate(input_str, output_len = max_useable_output_len)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0fbfcd28-9488-42f4-9b46-e498cbaba7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50192ad-3dea-4a04-b642-199da49d4b14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
