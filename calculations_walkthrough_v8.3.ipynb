{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0f25dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/tunadorable/local-repos/next-concept-predictor/venv/lib/python3.11/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a829654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db342b0",
   "metadata": {},
   "source": [
    "# regular GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b5bd74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=2\n",
    "n=5\n",
    "d=3\n",
    "v=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d35e3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S:  torch.Size([2, 5]) tensor([[0, 3, 6, 2, 6],\n",
      "        [6, 7, 1, 9, 1]])\n",
      "E:  torch.Size([10, 3]) tensor([[ 1.4142, -0.7139, -0.7003],\n",
      "        [-1.3562,  0.3310,  1.0252],\n",
      "        [-0.8545, -0.5486,  1.4031],\n",
      "        [-0.8196, -0.5883,  1.4079],\n",
      "        [-0.1093, -1.1664,  1.2757],\n",
      "        [-1.0950,  1.3226, -0.2276],\n",
      "        [ 0.9015,  0.4929, -1.3944],\n",
      "        [-1.3350,  1.0717,  0.2633],\n",
      "        [ 1.3191, -1.1010, -0.2181],\n",
      "        [-1.3979,  0.5137,  0.8842]], grad_fn=<NativeLayerNormBackward0>)\n",
      "X:  torch.Size([2, 5, 3]) tensor([[[ 1.4142, -0.7139, -0.7003],\n",
      "         [-0.8196, -0.5883,  1.4079],\n",
      "         [ 0.9015,  0.4929, -1.3944],\n",
      "         [-0.8545, -0.5486,  1.4031],\n",
      "         [ 0.9015,  0.4929, -1.3944]],\n",
      "\n",
      "        [[ 0.9015,  0.4929, -1.3944],\n",
      "         [-1.3350,  1.0717,  0.2633],\n",
      "         [-1.3562,  0.3310,  1.0252],\n",
      "         [-1.3979,  0.5137,  0.8842],\n",
      "         [-1.3562,  0.3310,  1.0252]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# create sequence & embedding matrix\n",
    "S = torch.randint(low=0, high=v, size=(b, n))\n",
    "E = torch.randn(v,d)\n",
    "\n",
    "# Create a LayerNorm instance\n",
    "layer_norm = nn.LayerNorm(d)\n",
    "\n",
    "# Apply LayerNorm to E\n",
    "E = layer_norm(E)\n",
    "\n",
    "# Look up the embeddings\n",
    "X = F.embedding(S, E)\n",
    "\n",
    "print(\"S: \", S.shape, S)\n",
    "print(\"E: \", E.shape, E)\n",
    "print(\"X: \", X.shape, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33f54e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xf:  torch.Size([2, 5, 3]) tensor([[[ 1.4142, -0.7139, -0.7003],\n",
      "         [-0.8196, -0.5883,  1.4079],\n",
      "         [ 0.9015,  0.4929, -1.3944],\n",
      "         [-0.8545, -0.5486,  1.4031],\n",
      "         [ 0.9015,  0.4929, -1.3944]],\n",
      "\n",
      "        [[ 0.9015,  0.4929, -1.3944],\n",
      "         [-1.3350,  1.0717,  0.2633],\n",
      "         [-1.3562,  0.3310,  1.0252],\n",
      "         [-1.3979,  0.5137,  0.8842],\n",
      "         [-1.3562,  0.3310,  1.0252]]], grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Apply layer normalization to X before each residual add\n",
    "Xf = layer_norm(X)\n",
    "\n",
    "print(\"Xf: \", Xf.shape, Xf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20b4cb4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z:  torch.Size([2, 5, 10]) tensor([[[ 3.0000, -2.8721, -1.7994, -1.7250, -0.2152, -2.3333,  1.8994,\n",
      "          -2.8374,  2.8043, -2.9628],\n",
      "         [-1.7250,  2.3602,  2.9986,  2.9999,  2.5718, -0.2010, -2.9920,\n",
      "           0.8344, -0.7406,  2.0884],\n",
      "         [ 1.8994, -2.4889, -2.9973, -2.9920, -2.4524, -0.0178,  3.0000,\n",
      "          -1.0423,  0.9506, -2.2398],\n",
      "         [-1.7994,  2.4158,  3.0000,  2.9985,  2.5233, -0.1092, -2.9973,\n",
      "           0.9223, -0.8293,  2.1534],\n",
      "         [ 1.8994, -2.4889, -2.9973, -2.9920, -2.4524, -0.0178,  3.0000,\n",
      "          -1.0423,  0.9506, -2.2398]],\n",
      "\n",
      "        [[ 1.8994, -2.4889, -2.9973, -2.9920, -2.4524, -0.0178,  3.0000,\n",
      "          -1.0423,  0.9506, -2.2398],\n",
      "         [-2.8374,  2.4351,  0.9223,  0.8344, -0.7682,  2.8192, -1.0423,\n",
      "           3.0000, -2.9984,  2.6495],\n",
      "         [-2.8722,  2.9999,  2.4159,  2.3602,  1.0700,  1.6895, -2.4890,\n",
      "           2.4352, -2.3771,  2.9724],\n",
      "         [-2.9629,  2.9724,  2.1534,  2.0884,  0.6816,  2.0089, -2.2399,\n",
      "           2.6496, -2.6026,  2.9999],\n",
      "         [-2.8722,  2.9999,  2.4159,  2.3602,  1.0700,  1.6895, -2.4890,\n",
      "           2.4352, -2.3771,  2.9724]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "Z = torch.matmul(Xf,E.T)\n",
    "\n",
    "print(\"Z: \", Z.shape, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "353add01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zn:  torch.Size([2, 10]) tensor([[ 1.8994, -2.4889, -2.9973, -2.9920, -2.4524, -0.0178,  3.0000, -1.0423,\n",
      "          0.9506, -2.2398],\n",
      "        [-2.8722,  2.9999,  2.4159,  2.3602,  1.0700,  1.6895, -2.4890,  2.4352,\n",
      "         -2.3771,  2.9724]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "Zn = Z[:,-1]\n",
    "print(\"Zn: \", Zn.shape, Zn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ecab99",
   "metadata": {},
   "source": [
    "### only used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92e4ecde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:  torch.Size([2, 10]) tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Generate random indices for one-hot positions\n",
    "# Each index is between 0 and v-1\n",
    "ideal_indices = torch.randint(low=0, high=v, size=(b,))\n",
    "\n",
    "# Create the one-hot matrix\n",
    "Q = torch.nn.functional.one_hot(ideal_indices, num_classes=v).float()\n",
    "\n",
    "print(\"Q: \", Q.shape, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dffd8a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.8813, grad_fn=<DivBackward1>) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# cross-entropy loss function includes within it the softmax function\n",
    "loss = torch.nn.functional.cross_entropy(Zn,Q)\n",
    "print(loss, loss.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc669d9",
   "metadata": {},
   "source": [
    "### only used for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37631b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:  torch.Size([2, 10]) tensor([[0.2151, 0.0027, 0.0016, 0.0016, 0.0028, 0.0316, 0.6465, 0.0114, 0.0833,\n",
      "         0.0034],\n",
      "        [0.0007, 0.2467, 0.1376, 0.1301, 0.0358, 0.0665, 0.0010, 0.1403, 0.0011,\n",
      "         0.2400]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor(-8.3805, grad_fn=<SumBackward1>) tensor(1.0000, grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Apply softmax along the last dimension (v)\n",
    "P = F.softmax(Zn, dim=-1)\n",
    "print(\"P: \", P.shape, P)\n",
    "print(torch.sum(Zn[0], dim=-1), torch.sum(P[0], dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9562812d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_probs:  torch.Size([2]) tensor([0.6465, 0.2467], grad_fn=<MaxBackward0>)\n",
      "indices:  torch.Size([2]) tensor([6, 1])\n"
     ]
    }
   ],
   "source": [
    "# finding tokens using greedy decoding\n",
    "max_probs, indices = torch.max(P, dim=1)\n",
    "print(\"max_probs: \", max_probs.shape, max_probs)\n",
    "print(\"indices: \", indices.shape, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f193a50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_nplus1:  torch.Size([2, 6]) tensor([[0, 3, 6, 2, 6, 6],\n",
      "        [6, 7, 1, 9, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "# appending tokens to s\n",
    "# Reshape new tokens to shape (b, 1)\n",
    "indices = indices.unsqueeze(1)  # Adds a new dimension\n",
    "\n",
    "# Concatenate the tensors\n",
    "S_nplus1 = torch.cat((S, indices), dim=1)  # Concatenate along the sequence length dimension\n",
    "print(\"S: \", S.shape, S)\n",
    "print(\"S_nplus1: \", S_nplus1.shape, S_nplus1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca48fab",
   "metadata": {},
   "source": [
    "# stage 1: implementing cosine norm, sin, & cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d383d909",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=2\n",
    "n=5\n",
    "d=3\n",
    "v=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e22eaade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S:  torch.Size([2, 5]) tensor([[8, 8, 9, 1, 8],\n",
      "        [1, 4, 2, 7, 3]])\n",
      "E:  torch.Size([10, 3]) tensor([[-0.9611, -0.2614, -0.0892],\n",
      "        [-0.0176,  0.6797, -0.7333],\n",
      "        [-0.3649,  0.8837,  0.2932],\n",
      "        [ 0.8743, -0.4573,  0.1626],\n",
      "        [ 0.5383,  0.7788,  0.3219],\n",
      "        [ 0.4626,  0.6339,  0.6198],\n",
      "        [-0.7114, -0.6084,  0.3519],\n",
      "        [ 0.1640, -0.6483,  0.7436],\n",
      "        [ 0.1038,  0.1118,  0.9883],\n",
      "        [ 0.4164,  0.8637,  0.2838]])\n",
      "X:  torch.Size([2, 5, 3]) tensor([[[ 0.1038,  0.1118,  0.9883],\n",
      "         [ 0.1038,  0.1118,  0.9883],\n",
      "         [ 0.4164,  0.8637,  0.2838],\n",
      "         [-0.0176,  0.6797, -0.7333],\n",
      "         [ 0.1038,  0.1118,  0.9883]],\n",
      "\n",
      "        [[-0.0176,  0.6797, -0.7333],\n",
      "         [ 0.5383,  0.7788,  0.3219],\n",
      "         [-0.3649,  0.8837,  0.2932],\n",
      "         [ 0.1640, -0.6483,  0.7436],\n",
      "         [ 0.8743, -0.4573,  0.1626]]])\n"
     ]
    }
   ],
   "source": [
    "# create sequence & embedding matrix\n",
    "S = torch.randint(low=0, high=v, size=(b, n))\n",
    "E = torch.randn(v,d)\n",
    "\n",
    "# cosine norm for E\n",
    "E = E / torch.norm(E, p=2, dim=1, keepdim=True) \n",
    "\n",
    "# Look up the embeddings\n",
    "X = F.embedding(S, E)\n",
    "\n",
    "print(\"S: \", S.shape, S)\n",
    "print(\"E: \", E.shape, E)\n",
    "print(\"X: \", X.shape, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89c2e342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xi:  torch.Size([2, 5, 3]) tensor([[[ 0.3202,  0.3440,  0.0367],\n",
      "         [ 0.3202,  0.3440,  0.0367],\n",
      "         [ 0.9657,  0.4151,  0.7782],\n",
      "         [-0.0552,  0.8448, -0.7433],\n",
      "         [ 0.3202,  0.3440,  0.0367]],\n",
      "\n",
      "        [[-0.0552,  0.8448, -0.7433],\n",
      "         [ 0.9928,  0.6403,  0.8476],\n",
      "         [-0.9113,  0.3574,  0.7963],\n",
      "         [ 0.4926, -0.8935,  0.7213],\n",
      "         [ 0.3847, -0.9910,  0.4889]]])\n"
     ]
    }
   ],
   "source": [
    "Xi=torch.sin(torch.pi*X)\n",
    "print(\"Xi: \", Xi.shape, Xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7f3c82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norms:  torch.Size([2, 5, 1]) tensor([[[0.4714],\n",
      "         [0.4714],\n",
      "         [1.3079],\n",
      "         [1.1266],\n",
      "         [0.4714]],\n",
      "\n",
      "        [[1.1266],\n",
      "         [1.4539],\n",
      "         [1.2618],\n",
      "         [1.2495],\n",
      "         [1.1701]]])\n",
      "Xf:  torch.Size([2, 5, 3]) tensor([[[ 0.6793,  0.7297,  0.0779],\n",
      "         [ 0.6793,  0.7297,  0.0779],\n",
      "         [ 0.7384,  0.3174,  0.5950],\n",
      "         [-0.0490,  0.7499, -0.6597],\n",
      "         [ 0.6793,  0.7297,  0.0779]],\n",
      "\n",
      "        [[-0.0490,  0.7499, -0.6597],\n",
      "         [ 0.6828,  0.4404,  0.5830],\n",
      "         [-0.7222,  0.2832,  0.6311],\n",
      "         [ 0.3942, -0.7151,  0.5773],\n",
      "         [ 0.3288, -0.8470,  0.4178]]])\n"
     ]
    }
   ],
   "source": [
    "# Normalize each vector to have a unit length\n",
    "norms = torch.norm(Xi, p=2, dim=2, keepdim=True)\n",
    "Xf = Xi / norms\n",
    "print(\"norms: \", norms.shape, norms)\n",
    "print(\"Xf: \", Xf.shape, Xf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0707e316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each row is normalized: True\n",
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "# let's check that it worked just making sure\n",
    "\n",
    "# Calculate the L2 norm for each row in X_normalized\n",
    "norms_after_normalization = torch.norm(Xf, p=2, dim=2)\n",
    "\n",
    "# Check if each norm is approximately equal to 1\n",
    "# We use a small threshold to account for numerical precision issues\n",
    "is_normalized = torch.isclose(norms_after_normalization, torch.ones_like(norms_after_normalization), atol=1e-6)\n",
    "\n",
    "# Print the result\n",
    "print(\"Each row is normalized:\", is_normalized.all().item())\n",
    "print(norms_after_normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf144673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:  torch.Size([2, 2, 3]) tensor([[[ 0.1036, -0.0548,  0.1386],\n",
      "         [-1.7745, -0.5268, -1.2985]],\n",
      "\n",
      "        [[-0.6565,  2.1135, -1.8130],\n",
      "         [-0.4623, -0.9411,  0.4970]]])\n"
     ]
    }
   ],
   "source": [
    "W = torch.randn(b,n)\n",
    "C = torch.matmul(W,Xf)\n",
    "print(\"C: \", C.shape, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f293a45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_select:  torch.Size([2, 3]) tensor([[-0.6565,  2.1135, -1.8130],\n",
      "        [-0.4623, -0.9411,  0.4970]])\n",
      "C_norms:  torch.Size([2, 1]) tensor([[2.8609],\n",
      "        [1.1603]])\n",
      "C_prime:  torch.Size([2, 3]) tensor([[-0.2295,  0.7387, -0.6337],\n",
      "        [-0.3984, -0.8111,  0.4283]])\n"
     ]
    }
   ],
   "source": [
    "# Normalize each vector to have a unit length & select only final row\n",
    "C_select = C[-1]\n",
    "print(\"C_select: \", C_select.shape, C_select)\n",
    "\n",
    "C_norms = torch.norm(C_select, p=2, dim=1, keepdim=True)\n",
    "print(\"C_norms: \", C_norms.shape, C_norms)\n",
    "\n",
    "C_prime = C_select / C_norms\n",
    "print(\"C_prime: \", C_prime.shape, C_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ca90781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E.T:  torch.Size([3, 10]) tensor([[-0.9611, -0.0176, -0.3649,  0.8743,  0.5383,  0.4626, -0.7114,  0.1640,\n",
      "          0.1038,  0.4164],\n",
      "        [-0.2614,  0.6797,  0.8837, -0.4573,  0.7788,  0.6339, -0.6084, -0.6483,\n",
      "          0.1118,  0.8637],\n",
      "        [-0.0892, -0.7333,  0.2932,  0.1626,  0.3219,  0.6198,  0.3519,  0.7436,\n",
      "          0.9883,  0.2838]])\n",
      "Y:  torch.Size([2, 10]) tensor([[ 0.0839,  0.9709,  0.5507, -0.6415,  0.2478, -0.0307, -0.5092, -0.9877,\n",
      "         -0.5675,  0.3626],\n",
      "        [ 0.5567, -0.8584, -0.4458,  0.0922, -0.7083, -0.4329,  0.9276,  0.7789,\n",
      "          0.2913, -0.7449]])\n",
      "Y Max: tensor([0.9709, 0.9276])\n",
      "Y Min: tensor([-0.9877, -0.8584])\n",
      "Y Mean: tensor([-0.0521, -0.0543])\n"
     ]
    }
   ],
   "source": [
    "# Perform cosine similarity, which simplifies down to dot product\n",
    "# We transpose E to get shape (d, v) and then use torch.matmul for batched matrix multiplication\n",
    "Y = torch.matmul(C_prime, E.T)\n",
    "print(\"E.T: \", E.T.shape, E.T)\n",
    "print(\"Y: \", Y.shape, Y)\n",
    "\n",
    "# let's make sure Y looks good\n",
    "# Calculating statistics\n",
    "max_values = torch.max(Y, dim=1).values\n",
    "min_values = torch.min(Y, dim=1).values\n",
    "mean_values = torch.mean(Y, dim=1)\n",
    "median_values = torch.median(Y, dim=1).values\n",
    "\n",
    "print(\"Y Max:\", max_values)\n",
    "print(\"Y Min:\", min_values)\n",
    "print(\"Y Mean:\", mean_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e668d114",
   "metadata": {},
   "source": [
    "### only used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c7301d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:  torch.Size([2, 10]) tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Generate random indices for one-hot positions\n",
    "# Each index is between 0 and v-1\n",
    "ideal_indices = torch.randint(low=0, high=v, size=(b,))\n",
    "\n",
    "# Create the one-hot matrix\n",
    "Q = torch.nn.functional.one_hot(ideal_indices, num_classes=v).float()\n",
    "\n",
    "print(\"Q: \", Q.shape, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dbb0877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_prime:  torch.Size([2, 10]) tensor([[-1., -1., -1., -1., -1.,  1., -1., -1., -1., -1.],\n",
      "        [ 1., -1., -1., -1., -1., -1., -1., -1., -1., -1.]])\n"
     ]
    }
   ],
   "source": [
    "# Create a mask where zeros are marked\n",
    "zero_mask = Q == 0\n",
    "\n",
    "# Replace zeros with -1\n",
    "Q[zero_mask] = -1\n",
    "print(\"Q_prime: \", Q.shape, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f48ec4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-20.5206) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# cross-entropy loss function includes within it the softmax function\n",
    "loss = torch.nn.functional.cross_entropy(Y,Q)\n",
    "print(loss, loss.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90c9032",
   "metadata": {},
   "source": [
    "### only used for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03258830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:  torch.Size([2, 10]) tensor([[0.0730, 0.0447, 0.0368, 0.0468, 0.2062, 0.1478, 0.1027, 0.2300, 0.0788,\n",
      "         0.0334],\n",
      "        [0.0564, 0.0384, 0.0354, 0.0585, 0.1769, 0.1807, 0.1176, 0.2029, 0.0992,\n",
      "         0.0340]])\n",
      "tensor(-1.1254) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Apply softmax along the last dimension (v)\n",
    "P = F.softmax(Y, dim=-1)\n",
    "print(\"P: \", P.shape, P)\n",
    "print(torch.sum(Y[0], dim=-1), torch.sum(P[0], dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06b61dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max probs:  torch.Size([2]) tensor([0.2300, 0.2029])\n",
      "indices:  torch.Size([2]) tensor([7, 7])\n"
     ]
    }
   ],
   "source": [
    "# finding tokens using greedy decoding\n",
    "max_probs, indices = torch.max(P, dim=1)\n",
    "print(\"max probs: \", max_probs.shape, max_probs)\n",
    "print(\"indices: \", indices.shape, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdc14eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S:  torch.Size([2, 5]) tensor([[9, 6, 3, 8, 9],\n",
      "        [3, 5, 1, 5, 9]])\n",
      "S_nplus1:  torch.Size([2, 6]) tensor([[9, 6, 3, 8, 9, 7],\n",
      "        [3, 5, 1, 5, 9, 7]])\n"
     ]
    }
   ],
   "source": [
    "# appending tokens to s\n",
    "# Reshape new tokens to shape (b, 1)\n",
    "indices = indices.unsqueeze(1)  # Adds a new dimension\n",
    "\n",
    "# Concatenate the tensors\n",
    "S_nplus1 = torch.cat((S, indices), dim=1)  # Concatenate along the sequence length dimension\n",
    "print(\"S: \", S.shape, S)\n",
    "print(\"S_nplus1: \", S_nplus1.shape, S_nplus1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b3883a",
   "metadata": {},
   "source": [
    "# stage 2: implementing gamma-neighborhood selection and in-sequence concept embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a096bc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=2\n",
    "n=5\n",
    "d=3\n",
    "v=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dcb8994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S:  torch.Size([2, 5]) tensor([[4, 8, 7, 4, 0],\n",
      "        [5, 9, 8, 7, 1]])\n",
      "E:  torch.Size([10, 3]) tensor([[-0.0038,  0.9374, -0.3481],\n",
      "        [-0.2898,  0.8896,  0.3529],\n",
      "        [ 0.3230, -0.9239,  0.2051],\n",
      "        [-0.0869,  0.6198, -0.7799],\n",
      "        [-0.8146, -0.3411,  0.4692],\n",
      "        [-0.2261,  0.0461,  0.9730],\n",
      "        [ 0.3822,  0.0012, -0.9241],\n",
      "        [ 0.8660, -0.1081, -0.4882],\n",
      "        [-0.1144, -0.9439, -0.3097],\n",
      "        [ 0.6993,  0.0981,  0.7080]])\n",
      "X:  torch.Size([2, 5, 3]) tensor([[[-0.8146, -0.3411,  0.4692],\n",
      "         [-0.1144, -0.9439, -0.3097],\n",
      "         [ 0.8660, -0.1081, -0.4882],\n",
      "         [-0.8146, -0.3411,  0.4692],\n",
      "         [-0.0038,  0.9374, -0.3481]],\n",
      "\n",
      "        [[-0.2261,  0.0461,  0.9730],\n",
      "         [ 0.6993,  0.0981,  0.7080],\n",
      "         [-0.1144, -0.9439, -0.3097],\n",
      "         [ 0.8660, -0.1081, -0.4882],\n",
      "         [-0.2898,  0.8896,  0.3529]]])\n"
     ]
    }
   ],
   "source": [
    "# create sequence & embedding matrix\n",
    "S = torch.randint(low=0, high=v, size=(b, n))\n",
    "E = torch.randn(v,d)\n",
    "\n",
    "# cosine norm for E\n",
    "E = E / torch.norm(E, p=2, dim=1, keepdim=True) \n",
    "\n",
    "# Look up the embeddings\n",
    "X = F.embedding(S, E)\n",
    "\n",
    "print(\"S: \", S.shape, S)\n",
    "print(\"E: \", E.shape, E)\n",
    "print(\"X: \", X.shape, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d67bdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xi:  torch.Size([2, 5, 3]) tensor([[[-0.5501, -0.8779,  0.9953],\n",
      "         [-0.3516, -0.1752, -0.8265],\n",
      "         [ 0.4086, -0.3332, -0.9993],\n",
      "         [-0.5501, -0.8779,  0.9953],\n",
      "         [-0.0119,  0.1953, -0.8883]],\n",
      "\n",
      "        [[-0.6521,  0.1445,  0.0847],\n",
      "         [ 0.8103,  0.3033,  0.7939],\n",
      "         [-0.3516, -0.1752, -0.8265],\n",
      "         [ 0.4086, -0.3332, -0.9993],\n",
      "         [-0.7897,  0.3398,  0.8952]]])\n"
     ]
    }
   ],
   "source": [
    "Xi=torch.sin(torch.pi*X)\n",
    "print(\"Xi: \", Xi.shape, Xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b53a71b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norms:  torch.Size([2, 5, 1]) tensor([[[1.4367],\n",
      "         [0.9151],\n",
      "         [1.1299],\n",
      "         [1.4367],\n",
      "         [0.9096]],\n",
      "\n",
      "        [[0.6733],\n",
      "         [1.1742],\n",
      "         [0.9151],\n",
      "         [1.1299],\n",
      "         [1.2411]]])\n",
      "Xf:  torch.Size([2, 5, 3]) tensor([[[-0.3829, -0.6111,  0.6928],\n",
      "         [-0.3842, -0.1915, -0.9032],\n",
      "         [ 0.3617, -0.2949, -0.8844],\n",
      "         [-0.3829, -0.6111,  0.6928],\n",
      "         [-0.0131,  0.2147, -0.9766]],\n",
      "\n",
      "        [[-0.9686,  0.2146,  0.1258],\n",
      "         [ 0.6900,  0.2583,  0.6761],\n",
      "         [-0.3842, -0.1915, -0.9032],\n",
      "         [ 0.3617, -0.2949, -0.8844],\n",
      "         [-0.6363,  0.2738,  0.7212]]])\n"
     ]
    }
   ],
   "source": [
    "# Normalize each vector to have a unit length\n",
    "norms = torch.norm(Xi, p=2, dim=2, keepdim=True)\n",
    "Xf = Xi / norms\n",
    "print(\"norms: \", norms.shape, norms)\n",
    "print(\"Xf: \", Xf.shape, Xf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fdda332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:  torch.Size([2, 2, 3]) tensor([[[-0.1230,  0.7641,  1.2563],\n",
      "         [ 0.4142, -0.6066,  0.5286]],\n",
      "\n",
      "        [[ 1.0814, -0.6043, -0.5363],\n",
      "         [ 0.0151, -0.4517, -1.7105]]])\n"
     ]
    }
   ],
   "source": [
    "W = torch.randn(b,n)\n",
    "C = torch.matmul(W,Xf)\n",
    "print(\"C: \", C.shape, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d119d9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_last: torch.Size([2, 3]) tensor([[ 1.0814, -0.6043, -0.5363],\n",
      "        [ 0.0151, -0.4517, -1.7105]])\n",
      "C_last_norms: torch.Size([2, 1]) tensor([[1.3499],\n",
      "        [1.7692]])\n",
      "C_prime torch.Size([2, 3]) tensor([[ 0.8011, -0.4476, -0.3973],\n",
      "        [ 0.0086, -0.2553, -0.9668]])\n"
     ]
    }
   ],
   "source": [
    "# Normalize each vector to have a unit length & select only final row\n",
    "C_last = C[-1]\n",
    "C_last_norms = torch.norm(C_last, p=2, dim=1, keepdim=True)\n",
    "C_prime = C_last / C_last_norms\n",
    "\n",
    "print(\"C_last:\", C_last.shape, C_last)\n",
    "print(\"C_last_norms:\", C_last_norms.shape, C_last_norms)\n",
    "print(\"C_prime\", C_prime.shape, C_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c45d20bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E.T:  torch.Size([3, 10]) tensor([[-0.0038, -0.2898,  0.3230, -0.0869, -0.8146, -0.2261,  0.3822,  0.8660,\n",
      "         -0.1144,  0.6993],\n",
      "        [ 0.9374,  0.8896, -0.9239,  0.6198, -0.3411,  0.0461,  0.0012, -0.1081,\n",
      "         -0.9439,  0.0981],\n",
      "        [-0.3481,  0.3529,  0.2051, -0.7799,  0.4692,  0.9730, -0.9241, -0.4882,\n",
      "         -0.3097,  0.7080]])\n",
      "Y:  torch.Size([2, 10]) tensor([[-0.2844, -0.7706,  0.5909, -0.0372, -0.6863, -0.5884,  0.6728,  0.9361,\n",
      "          0.4539,  0.2350],\n",
      "        [ 0.0972, -0.5709,  0.0404,  0.5951, -0.3735, -0.9544,  0.8964,  0.5070,\n",
      "          0.5394, -0.7036]])\n",
      "Y Max: tensor([0.9361, 0.8964])\n",
      "Y Min: tensor([-0.7706, -0.9544])\n",
      "Y Mean: tensor([0.0522, 0.0073])\n"
     ]
    }
   ],
   "source": [
    "# Perform cosine similarity, which simplifies down to dot product\n",
    "# We transpose E to get shape (d, v) and then use torch.matmul for batched matrix multiplication\n",
    "Y = torch.matmul(C_prime, E.T)\n",
    "print(\"E.T: \", E.T.shape, E.T)\n",
    "print(\"Y: \", Y.shape, Y)\n",
    "\n",
    "# let's make sure Y looks good\n",
    "# Calculating statistics\n",
    "max_values = torch.max(Y, dim=1).values\n",
    "min_values = torch.min(Y, dim=1).values\n",
    "mean_values = torch.mean(Y, dim=1)\n",
    "median_values = torch.median(Y, dim=1).values\n",
    "\n",
    "# Printing the results\n",
    "print(\"Y Max:\", max_values)\n",
    "print(\"Y Min:\", min_values)\n",
    "print(\"Y Mean:\", mean_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25587e20",
   "metadata": {},
   "source": [
    "### the conditional parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc47a685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:  torch.Size([2]) tensor([0.9361, 0.8964])\n",
      "H:  torch.Size([2]) tensor([7, 6])\n"
     ]
    }
   ],
   "source": [
    "# finding closest tokens to the raw output & their similarity scores\n",
    "G, H = torch.max(Y, dim=1)\n",
    "print(\"G: \", G.shape, G)\n",
    "print(\"H: \", H.shape, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36978b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.91 # $-1\\leq \\gamma < 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8d6500a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:  torch.float32 torch.Size([2]) tensor([1., 0.])\n"
     ]
    }
   ],
   "source": [
    "A = (G > gamma).float()\n",
    "print(\"A: \", A.dtype, A.shape, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d902aa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_unsqueeze:  torch.Size([2, 1]) tensor([[1.],\n",
      "        [0.]])\n",
      "A_expand:  torch.Size([2, 10]) tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "A_unsqueeze = A.unsqueeze(1)\n",
    "print(\"A_unsqueeze: \", A_unsqueeze.shape, A_unsqueeze)\n",
    "A_expand = A_unsqueeze.expand(-1, v)\n",
    "print(\"A_expand: \", A_expand.shape, A_expand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e1186c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I:  torch.float32 torch.Size([2, 10]) tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "A_prime_expand:  torch.float32 torch.Size([2, 10]) tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "I = torch.ones(b,v).float()\n",
    "print(\"I: \", I.dtype, I.shape, I)\n",
    "A_prime_expand = I-A_expand\n",
    "print(\"A_prime_expand: \", A_prime_expand.dtype, A_prime_expand.shape, A_prime_expand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a07b9a5",
   "metadata": {},
   "source": [
    "### only used for trainnig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ebb58dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ideal_indices:  torch.Size([2]) tensor([9, 7])\n",
      "Q:  torch.float32 torch.Size([2, 10]) tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Generate random indices for one-hot positions\n",
    "# Each index is between 0 and v-1\n",
    "ideal_indices = torch.randint(low=0, high=v, size=(b,))\n",
    "print(\"ideal_indices: \", ideal_indices.shape, ideal_indices)\n",
    "\n",
    "# Create the one-hot matrix\n",
    "Q = torch.nn.functional.one_hot(ideal_indices, num_classes=v).float()\n",
    "\n",
    "print(\"Q: \", Q.dtype, Q.shape, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32c24ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_prime:  torch.Size([2, 10]) tensor([[-1., -1., -1., -1., -1., -1., -1., -1., -1.,  1.],\n",
      "        [-1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.]])\n"
     ]
    }
   ],
   "source": [
    "# Create a mask where zeros are marked\n",
    "zero_mask_Q = Q == 0\n",
    "\n",
    "# Replace zeros with -1\n",
    "Q[zero_mask_Q] = -1\n",
    "print(\"Q_prime: \", Q.shape, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6e457f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_ideal:  torch.Size([2, 10]) tensor([[-1., -1., -1., -1., -1., -1., -1., -1., -1.,  1.],\n",
      "        [-0., -0., -0., -0., -0., -0., -0.,  0., -0., -0.]])\n"
     ]
    }
   ],
   "source": [
    "Q_ideal = Q*A_expand\n",
    "print(\"Q_ideal: \", Q_ideal.shape, Q_ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd926da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_concepts:  torch.Size([2, 10]) tensor([[-0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0972, -0.5709,  0.0404,  0.5951, -0.3735, -0.9544,  0.8964,  0.5070,\n",
      "          0.5394, -0.7036]])\n"
     ]
    }
   ],
   "source": [
    "Y_concepts = Y*A_prime_expand\n",
    "print(\"Y_concepts: \", Y_concepts.shape, Y_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67d352e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train:  torch.Size([2, 10]) tensor([[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         -1.0000,  1.0000],\n",
      "        [ 0.0972, -0.5709,  0.0404,  0.5951, -0.3735, -0.9544,  0.8964,  0.5070,\n",
      "          0.5394, -0.7036]])\n"
     ]
    }
   ],
   "source": [
    "Y_train = Y_concepts + Q_ideal\n",
    "print(\"Y_train: \", Y_train.shape, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a19be14",
   "metadata": {},
   "source": [
    "### only used for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab7225f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:  torch.Size([2, 10]) tensor([[0.0607, 0.0373, 0.1457, 0.0778, 0.0406, 0.0448, 0.1581, 0.2058, 0.1271,\n",
      "         0.1021],\n",
      "        [0.0925, 0.0474, 0.0874, 0.1522, 0.0578, 0.0323, 0.2057, 0.1393, 0.1439,\n",
      "         0.0415]])\n",
      "tensor(0.5220) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Apply softmax along the last dimension (v)\n",
    "P = F.softmax(Y, dim=-1)\n",
    "print(\"P: \", P.shape, P)\n",
    "print(torch.sum(Y[0], dim=-1), torch.sum(P[0], dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "379a5cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_nplus1:  torch.Size([2]) tensor([7, 6])\n"
     ]
    }
   ],
   "source": [
    "S_nplus1 = torch.max(P, dim=1).indices\n",
    "print(\"S_nplus1: \", S_nplus1.shape, S_nplus1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5211ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_nplus1_prime:  torch.Size([2]) tensor([ 7, -1])\n"
     ]
    }
   ],
   "source": [
    "# Create a mask where zeros are marked\n",
    "zero_mask_A = A == 0\n",
    "\n",
    "# Replace zeros with -1\n",
    "S_nplus1[zero_mask_A] = -1\n",
    "\n",
    "print(\"S_nplus1_prime: \", S_nplus1.shape, S_nplus1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7972e3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_old:  torch.Size([2, 5]) tensor([[4, 8, 7, 4, 0],\n",
      "        [5, 9, 8, 7, 1]])\n",
      "S_new:  torch.Size([2, 6]) tensor([[ 4,  8,  7,  4,  0,  7],\n",
      "        [ 5,  9,  8,  7,  1, -1]])\n"
     ]
    }
   ],
   "source": [
    "print(\"S_old: \", S.shape, S)\n",
    "S_nplus1_unsqueeze = S_nplus1.unsqueeze(dim=1)\n",
    "S = torch.concat((S,S_nplus1_unsqueeze), dim=1)\n",
    "print(\"S_new: \", S.shape, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b33aa0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon:  torch.Size([1, 3]) tensor([[0., 0., 0.]])\n",
      "E_prime:  torch.Size([11, 3]) tensor([[-0.0038,  0.9374, -0.3481],\n",
      "        [-0.2898,  0.8896,  0.3529],\n",
      "        [ 0.3230, -0.9239,  0.2051],\n",
      "        [-0.0869,  0.6198, -0.7799],\n",
      "        [-0.8146, -0.3411,  0.4692],\n",
      "        [-0.2261,  0.0461,  0.9730],\n",
      "        [ 0.3822,  0.0012, -0.9241],\n",
      "        [ 0.8660, -0.1081, -0.4882],\n",
      "        [-0.1144, -0.9439, -0.3097],\n",
      "        [ 0.6993,  0.0981,  0.7080],\n",
      "        [ 0.0000,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "epsilon = torch.zeros(1,d)\n",
    "print(\"epsilon: \", epsilon.shape, epsilon)\n",
    "E_prime = torch.cat((E,epsilon), dim=0)\n",
    "print(\"E_prime: \", E_prime.shape, E_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9bd4897",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Z_token \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39membedding(S_nplus1,E_prime)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZ_token: \u001b[39m\u001b[38;5;124m\"\u001b[39m, Z_token\u001b[38;5;241m.\u001b[39mshape, Z_token)\n",
      "File \u001b[0;32m~/local-repos/next-concept-predictor/venv/lib/python3.11/site-packages/torch/nn/functional.py:2233\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2227\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2228\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2230\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2231\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39membedding(weight, \u001b[38;5;28minput\u001b[39m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "Z_token = F.embedding(S_nplus1,E_prime)\n",
    "print(\"Z_token: \", Z_token.shape, Z_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "037abc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_prime_concept:  torch.Size([2, 3]) tensor([[-0.4552, -0.2610, -0.8513],\n",
      "        [ 0.0000, -0.0000, -0.0000]])\n"
     ]
    }
   ],
   "source": [
    "C_prime_concept = C_prime*A_prime_expand[:,0:d]\n",
    "print(\"C_prime_concept: \", C_prime_concept.shape, C_prime_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c082c554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z_prime:  torch.Size([2, 3]) tensor([[-0.4552, -0.2610, -0.8513],\n",
      "        [ 0.7900, -0.5789, -0.2020]])\n"
     ]
    }
   ],
   "source": [
    "Z_prime = Z + C_prime_concept\n",
    "print(\"Z_prime: \", Z_prime.shape, Z_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6594e940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  torch.Size([2, 5, 3]) tensor([[[ 0.1426,  0.6498, -0.7466],\n",
      "         [-0.8485,  0.5243,  0.0723],\n",
      "         [-0.9660,  0.1084, -0.2348],\n",
      "         [ 0.1370,  0.5486, -0.8248],\n",
      "         [-0.9660,  0.1084, -0.2348]],\n",
      "\n",
      "        [[ 0.7900, -0.5789, -0.2020],\n",
      "         [-0.8571, -0.3588, -0.3697],\n",
      "         [-0.8571, -0.3588, -0.3697],\n",
      "         [-0.8571, -0.3588, -0.3697],\n",
      "         [-0.8485,  0.5243,  0.0723]]])\n",
      "X_new:  torch.Size([2, 6, 3]) tensor([[[ 0.1426,  0.6498, -0.7466],\n",
      "         [-0.8485,  0.5243,  0.0723],\n",
      "         [-0.9660,  0.1084, -0.2348],\n",
      "         [ 0.1370,  0.5486, -0.8248],\n",
      "         [-0.9660,  0.1084, -0.2348],\n",
      "         [-0.4552, -0.2610, -0.8513]],\n",
      "\n",
      "        [[ 0.7900, -0.5789, -0.2020],\n",
      "         [-0.8571, -0.3588, -0.3697],\n",
      "         [-0.8571, -0.3588, -0.3697],\n",
      "         [-0.8571, -0.3588, -0.3697],\n",
      "         [-0.8485,  0.5243,  0.0723],\n",
      "         [ 0.7900, -0.5789, -0.2020]]])\n"
     ]
    }
   ],
   "source": [
    "print(\"X: \", X.shape, X)\n",
    "X_new = torch.cat((X,Z_prime.unsqueeze(1)), dim=1)\n",
    "print(\"X_new: \", X_new.shape, X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3b8a89",
   "metadata": {},
   "source": [
    "## change in gamma over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "855a8337",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_00 = -1\n",
    "gamma_f0 = -1\n",
    "gamma_0f = 0.8\n",
    "gamma_ff = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "799def73",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6 # sequence length\n",
    "m = 9 # num of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3db4e937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n"
     ]
    }
   ],
   "source": [
    "delta_gamma_m = (gamma_0f - gamma_00)/m\n",
    "print(delta_gamma_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4eaf9778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This epoch, to become a token a concept needs cos similarity at least gamma_0,0 = -1.00\n",
      "\tAt the 1'th token in this sequence, gamma_0,0 = -1.00\n",
      "\tAt the 2'th token in this sequence, gamma_1,0 = -1.00\n",
      "\tAt the 3'th token in this sequence, gamma_2,0 = -1.00\n",
      "\tAt the 4'th token in this sequence, gamma_3,0 = -1.00\n",
      "\tAt the 5'th token in this sequence, gamma_4,0 = -1.00\n",
      "\tAt the 6'th token in this sequence, gamma_5,0 = -1.00\n",
      "\tAt the 7'th token in this sequence, gamma_6,0 = -1.00\n",
      "\tAt the 8'th token in this sequence, gamma_7,0 = -1.00\n",
      "\tAt the 9'th token in this sequence, gamma_8,0 = -1.00\n",
      "\tAt the 10'th token in this sequence, gamma_9,0 = -1.00\n",
      "\tAt the 11'th token in this sequence, gamma_10,0 = -1.00\n",
      "\tAt the 12'th token in this sequence, gamma_11,0 = -1.00\n",
      "This epoch, to become a token a concept needs cos similarity at least gamma_0,1 = -0.80\n",
      "\tAt the 1'th token in this sequence, gamma_0,1 = -0.80\n",
      "\tAt the 2'th token in this sequence, gamma_1,1 = -0.83\n",
      "\tAt the 3'th token in this sequence, gamma_2,1 = -0.87\n",
      "\tAt the 4'th token in this sequence, gamma_3,1 = -0.90\n",
      "\tAt the 5'th token in this sequence, gamma_4,1 = -0.93\n",
      "\tAt the 6'th token in this sequence, gamma_5,1 = -0.97\n",
      "\tAt the 7'th token in this sequence, gamma_6,1 = -1.00\n",
      "\tAt the 8'th token in this sequence, gamma_7,1 = -1.00\n",
      "\tAt the 9'th token in this sequence, gamma_8,1 = -1.00\n",
      "\tAt the 10'th token in this sequence, gamma_9,1 = -1.00\n",
      "\tAt the 11'th token in this sequence, gamma_10,1 = -1.00\n",
      "\tAt the 12'th token in this sequence, gamma_11,1 = -1.00\n",
      "This epoch, to become a token a concept needs cos similarity at least gamma_0,2 = -0.60\n",
      "\tAt the 1'th token in this sequence, gamma_0,2 = -0.60\n",
      "\tAt the 2'th token in this sequence, gamma_1,2 = -0.67\n",
      "\tAt the 3'th token in this sequence, gamma_2,2 = -0.73\n",
      "\tAt the 4'th token in this sequence, gamma_3,2 = -0.80\n",
      "\tAt the 5'th token in this sequence, gamma_4,2 = -0.87\n",
      "\tAt the 6'th token in this sequence, gamma_5,2 = -0.93\n",
      "\tAt the 7'th token in this sequence, gamma_6,2 = -1.00\n",
      "\tAt the 8'th token in this sequence, gamma_7,2 = -1.00\n",
      "\tAt the 9'th token in this sequence, gamma_8,2 = -1.00\n",
      "\tAt the 10'th token in this sequence, gamma_9,2 = -1.00\n",
      "\tAt the 11'th token in this sequence, gamma_10,2 = -1.00\n",
      "\tAt the 12'th token in this sequence, gamma_11,2 = -1.00\n",
      "This epoch, to become a token a concept needs cos similarity at least gamma_0,3 = -0.40\n",
      "\tAt the 1'th token in this sequence, gamma_0,3 = -0.40\n",
      "\tAt the 2'th token in this sequence, gamma_1,3 = -0.50\n",
      "\tAt the 3'th token in this sequence, gamma_2,3 = -0.60\n",
      "\tAt the 4'th token in this sequence, gamma_3,3 = -0.70\n",
      "\tAt the 5'th token in this sequence, gamma_4,3 = -0.80\n",
      "\tAt the 6'th token in this sequence, gamma_5,3 = -0.90\n",
      "\tAt the 7'th token in this sequence, gamma_6,3 = -1.00\n",
      "\tAt the 8'th token in this sequence, gamma_7,3 = -1.00\n",
      "\tAt the 9'th token in this sequence, gamma_8,3 = -1.00\n",
      "\tAt the 10'th token in this sequence, gamma_9,3 = -1.00\n",
      "\tAt the 11'th token in this sequence, gamma_10,3 = -1.00\n",
      "\tAt the 12'th token in this sequence, gamma_11,3 = -1.00\n",
      "This epoch, to become a token a concept needs cos similarity at least gamma_0,4 = -0.20\n",
      "\tAt the 1'th token in this sequence, gamma_0,4 = -0.20\n",
      "\tAt the 2'th token in this sequence, gamma_1,4 = -0.33\n",
      "\tAt the 3'th token in this sequence, gamma_2,4 = -0.47\n",
      "\tAt the 4'th token in this sequence, gamma_3,4 = -0.60\n",
      "\tAt the 5'th token in this sequence, gamma_4,4 = -0.73\n",
      "\tAt the 6'th token in this sequence, gamma_5,4 = -0.87\n",
      "\tAt the 7'th token in this sequence, gamma_6,4 = -1.00\n",
      "\tAt the 8'th token in this sequence, gamma_7,4 = -1.00\n",
      "\tAt the 9'th token in this sequence, gamma_8,4 = -1.00\n",
      "\tAt the 10'th token in this sequence, gamma_9,4 = -1.00\n",
      "\tAt the 11'th token in this sequence, gamma_10,4 = -1.00\n",
      "\tAt the 12'th token in this sequence, gamma_11,4 = -1.00\n",
      "This epoch, to become a token a concept needs cos similarity at least gamma_0,5 = 0.00\n",
      "\tAt the 1'th token in this sequence, gamma_0,5 = 0.00\n",
      "\tAt the 2'th token in this sequence, gamma_1,5 = -0.17\n",
      "\tAt the 3'th token in this sequence, gamma_2,5 = -0.33\n",
      "\tAt the 4'th token in this sequence, gamma_3,5 = -0.50\n",
      "\tAt the 5'th token in this sequence, gamma_4,5 = -0.67\n",
      "\tAt the 6'th token in this sequence, gamma_5,5 = -0.83\n",
      "\tAt the 7'th token in this sequence, gamma_6,5 = -1.00\n",
      "\tAt the 8'th token in this sequence, gamma_7,5 = -1.00\n",
      "\tAt the 9'th token in this sequence, gamma_8,5 = -1.00\n",
      "\tAt the 10'th token in this sequence, gamma_9,5 = -1.00\n",
      "\tAt the 11'th token in this sequence, gamma_10,5 = -1.00\n",
      "\tAt the 12'th token in this sequence, gamma_11,5 = -1.00\n",
      "This epoch, to become a token a concept needs cos similarity at least gamma_0,6 = 0.20\n",
      "\tAt the 1'th token in this sequence, gamma_0,6 = 0.20\n",
      "\tAt the 2'th token in this sequence, gamma_1,6 = 0.00\n",
      "\tAt the 3'th token in this sequence, gamma_2,6 = -0.20\n",
      "\tAt the 4'th token in this sequence, gamma_3,6 = -0.40\n",
      "\tAt the 5'th token in this sequence, gamma_4,6 = -0.60\n",
      "\tAt the 6'th token in this sequence, gamma_5,6 = -0.80\n",
      "\tAt the 7'th token in this sequence, gamma_6,6 = -1.00\n",
      "\tAt the 8'th token in this sequence, gamma_7,6 = -1.00\n",
      "\tAt the 9'th token in this sequence, gamma_8,6 = -1.00\n",
      "\tAt the 10'th token in this sequence, gamma_9,6 = -1.00\n",
      "\tAt the 11'th token in this sequence, gamma_10,6 = -1.00\n",
      "\tAt the 12'th token in this sequence, gamma_11,6 = -1.00\n",
      "This epoch, to become a token a concept needs cos similarity at least gamma_0,7 = 0.40\n",
      "\tAt the 1'th token in this sequence, gamma_0,7 = 0.40\n",
      "\tAt the 2'th token in this sequence, gamma_1,7 = 0.17\n",
      "\tAt the 3'th token in this sequence, gamma_2,7 = -0.07\n",
      "\tAt the 4'th token in this sequence, gamma_3,7 = -0.30\n",
      "\tAt the 5'th token in this sequence, gamma_4,7 = -0.53\n",
      "\tAt the 6'th token in this sequence, gamma_5,7 = -0.77\n",
      "\tAt the 7'th token in this sequence, gamma_6,7 = -1.00\n",
      "\tAt the 8'th token in this sequence, gamma_7,7 = -1.00\n",
      "\tAt the 9'th token in this sequence, gamma_8,7 = -1.00\n",
      "\tAt the 10'th token in this sequence, gamma_9,7 = -1.00\n",
      "\tAt the 11'th token in this sequence, gamma_10,7 = -1.00\n",
      "\tAt the 12'th token in this sequence, gamma_11,7 = -1.00\n",
      "This epoch, to become a token a concept needs cos similarity at least gamma_0,8 = 0.60\n",
      "\tAt the 1'th token in this sequence, gamma_0,8 = 0.60\n",
      "\tAt the 2'th token in this sequence, gamma_1,8 = 0.33\n",
      "\tAt the 3'th token in this sequence, gamma_2,8 = 0.07\n",
      "\tAt the 4'th token in this sequence, gamma_3,8 = -0.20\n",
      "\tAt the 5'th token in this sequence, gamma_4,8 = -0.47\n",
      "\tAt the 6'th token in this sequence, gamma_5,8 = -0.73\n",
      "\tAt the 7'th token in this sequence, gamma_6,8 = -1.00\n",
      "\tAt the 8'th token in this sequence, gamma_7,8 = -1.00\n",
      "\tAt the 9'th token in this sequence, gamma_8,8 = -1.00\n",
      "\tAt the 10'th token in this sequence, gamma_9,8 = -1.00\n",
      "\tAt the 11'th token in this sequence, gamma_10,8 = -1.00\n",
      "\tAt the 12'th token in this sequence, gamma_11,8 = -1.00\n"
     ]
    }
   ],
   "source": [
    "for i in range(m):\n",
    "    gamma_i = gamma_00 + i*delta_gamma_m\n",
    "    print(f\"This epoch, to become a token a concept needs cos similarity at least gamma_0,{i} = {gamma_i:.2f}\")\n",
    "    \n",
    "    delta_gamma_n = (gamma_i - gamma_ff)/n\n",
    "    for j in range(2*n):\n",
    "        \n",
    "        print(f\"\\tAt the {j+1}'th token in this sequence, gamma_{j},{i} = {max(-1, gamma_i - j*delta_gamma_n):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdb4772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
