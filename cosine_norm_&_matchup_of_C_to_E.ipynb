{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a0fdc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/tunadorable/local-repos/next-concept-predictor/venv/lib/python3.11/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "525a8ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e38d65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineNormalization(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(CosineNormalization, self).__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        norm = x.pow(2).sum(dim=self.dim, keepdim=True).sqrt()\n",
    "        return x / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "174b253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "cosine_norm = CosineNormalization(dim=2)  # normalizing along dimension d in a (b,n,d)\n",
    "input_tensor = torch.randn(2, 3, 2)  # Example input with b=2, n=3 and d=2\n",
    "normalized_tensor = cosine_norm(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b589f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.8320, -0.0399],\n",
       "         [-1.9510,  0.6486],\n",
       "         [-0.7931,  1.0168]],\n",
       "\n",
       "        [[ 0.7166,  0.9704],\n",
       "         [ 0.9085, -1.2551],\n",
       "         [-0.3724, -0.1848]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4df16122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9998, -0.0218],\n",
       "         [-0.9489,  0.3155],\n",
       "         [-0.6150,  0.7885]],\n",
       "\n",
       "        [[ 0.5941,  0.8044],\n",
       "         [ 0.5863, -0.8101],\n",
       "         [-0.8957, -0.4446]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c81f497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's check C against E to find our token of interest\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7ca17c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_batch(C, E):\n",
    "    # Normalize the vectors in C and E to have unit length\n",
    "    #C_norm = F.normalize(C, p=2, dim=1)\n",
    "    #E_norm = F.normalize(E, p=2, dim=1)\n",
    "    # actually they should be going in already normalized\n",
    "    # however i do need to look into just using F.normalize instead of the function above\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarity = torch.matmul(C, E.T)\n",
    "    print(\"similarity shape: \", similarity.shape)\n",
    "    print(\"similarity: \",similarity)\n",
    "    \n",
    "    # Find the indices of the most similar vectors\n",
    "    most_similar_indices = torch.argmax(similarity, dim=1)\n",
    "    print(\"most_similar_indices shape: \",most_similar_indices.shape)\n",
    "    print(\"most_similar_indices: \",most_similar_indices)\n",
    "    \n",
    "    # Select the vectors from E based on these indices\n",
    "    selected_vectors = E[most_similar_indices]\n",
    "\n",
    "    return selected_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7023c23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "b, d, v = 2, 4, 10  # Example dimensions\n",
    "C = torch.randn(b, d)  # Tensor of shape (b, d)\n",
    "E = torch.randn(v, d)  # Embedding matrix of shape (v, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c481312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_norm_1 = CosineNormalization(dim=1)  # normalizing along dimension d in a (x,d)\n",
    "\n",
    "C_norm = cos_norm_1(C)\n",
    "E_norm = cos_norm_1(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40017a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity shape:  torch.Size([2, 10])\n",
      "similarity:  tensor([[ 0.8218,  0.4293, -0.8940, -0.3390, -0.4694, -0.1859,  0.4158, -0.4712,\n",
      "         -0.2731,  0.8189],\n",
      "        [-0.8956, -0.4395,  0.6102, -0.2264,  0.0549,  0.0660,  0.0517,  0.1872,\n",
      "          0.3604, -0.8554]])\n",
      "most_similar_indices shape:  torch.Size([2])\n",
      "most_similar_indices:  tensor([0, 2])\n",
      "result shape:  torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "result = cosine_similarity_batch(C_norm, E_norm)\n",
    "print(\"result shape: \",result.shape)  # Should be (b, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8130e321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7605, -0.0776,  0.6437, -0.0352],\n",
      "        [-0.7925, -0.0571, -0.3291,  0.5102]])\n",
      "tensor([[ 0.6790,  0.4184,  0.5071, -0.3268],\n",
      "        [ 0.8471, -0.3412, -0.3651,  0.1809],\n",
      "        [-0.6143,  0.4927, -0.6089, -0.0958],\n",
      "        [-0.1163,  0.3717, -0.3900, -0.8344],\n",
      "        [ 0.1721, -0.0535, -0.9525, -0.2454],\n",
      "        [-0.6059, -0.3464,  0.3513, -0.6240],\n",
      "        [ 0.1537,  0.3670,  0.5488,  0.7352],\n",
      "        [-0.4630,  0.8167, -0.1044, -0.3282],\n",
      "        [-0.3290,  0.8725,  0.0887,  0.3501],\n",
      "        [ 0.9893, -0.0718,  0.0897, -0.0900]])\n",
      "tensor([[ 0.6790,  0.4184,  0.5071, -0.3268],\n",
      "        [-0.6143,  0.4927, -0.6089, -0.0958]])\n"
     ]
    }
   ],
   "source": [
    "print(C_norm)\n",
    "print(E_norm)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a907c2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's define a \"neighborhood\" size around each token vector\n",
    "# if C is not actually within one of these neighborhoods, meaning if it doesn't reach a \n",
    "#     critical level of cosine similarity with a vector in E, then it'll just return\n",
    "#     the vector that was originally in C\n",
    "def cosine_similarity_batch_with_threshold(C, E, similarity_threshold):\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarity = torch.matmul(C_norm, E_norm.T)\n",
    "    print(\"similarity shape: \", similarity.shape)\n",
    "    print(\"similarity: \",similarity)\n",
    "\n",
    "    # Find the indices and values of the most similar vectors\n",
    "    most_similar_values, most_similar_indices = torch.max(similarity, dim=1)\n",
    "    print(\"most_similar_indices shape: \",most_similar_indices.shape)\n",
    "    print(\"most_similar_indices: \",most_similar_indices)\n",
    "    print(\"most_similar_values shape: \",most_similar_values.shape)\n",
    "    print(\"most_similar_values: \",most_similar_values)\n",
    "\n",
    "    # Check if the most similar vector is above the threshold\n",
    "    is_above_threshold = most_similar_values >= similarity_threshold\n",
    "\n",
    "    # Select the vectors from E or keep the original from C based on the threshold check\n",
    "    selected_vectors = torch.where(is_above_threshold.unsqueeze(1), E[most_similar_indices], C)\n",
    "\n",
    "    return selected_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d5123b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity shape:  torch.Size([2, 10])\n",
      "similarity:  tensor([[ 0.8218,  0.4293, -0.8940, -0.3390, -0.4694, -0.1859,  0.4158, -0.4712,\n",
      "         -0.2731,  0.8189],\n",
      "        [-0.8956, -0.4395,  0.6102, -0.2264,  0.0549,  0.0660,  0.0517,  0.1872,\n",
      "          0.3604, -0.8554]])\n",
      "most_similar_indices shape:  torch.Size([2])\n",
      "most_similar_indices:  tensor([0, 2])\n",
      "most_similar_values shape:  torch.Size([2])\n",
      "most_similar_values:  tensor([0.8218, 0.6102])\n",
      "result shape:  torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "# Example Usage (C, E, and C_norm and E_norm were defined earlier)\n",
    "similarity_threshold = 0.8  # Define your similarity threshold\n",
    "\n",
    "result = cosine_similarity_batch_with_threshold(C_norm, E_norm, similarity_threshold)\n",
    "print(\"result shape: \",result.shape)  # Should be (b, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f3d748b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7605, -0.0776,  0.6437, -0.0352],\n",
      "        [-0.7925, -0.0571, -0.3291,  0.5102]])\n",
      "tensor([[ 0.6790,  0.4184,  0.5071, -0.3268],\n",
      "        [ 0.8471, -0.3412, -0.3651,  0.1809],\n",
      "        [-0.6143,  0.4927, -0.6089, -0.0958],\n",
      "        [-0.1163,  0.3717, -0.3900, -0.8344],\n",
      "        [ 0.1721, -0.0535, -0.9525, -0.2454],\n",
      "        [-0.6059, -0.3464,  0.3513, -0.6240],\n",
      "        [ 0.1537,  0.3670,  0.5488,  0.7352],\n",
      "        [-0.4630,  0.8167, -0.1044, -0.3282],\n",
      "        [-0.3290,  0.8725,  0.0887,  0.3501],\n",
      "        [ 0.9893, -0.0718,  0.0897, -0.0900]])\n",
      "tensor([[ 0.6790,  0.4184,  0.5071, -0.3268],\n",
      "        [-0.7925, -0.0571, -0.3291,  0.5102]])\n"
     ]
    }
   ],
   "source": [
    "print(C_norm)\n",
    "print(E_norm)\n",
    "print(result)\n",
    "# we see here, at least in the example that's here while i'm writing this, that\n",
    "#   one vector got replaced and another did not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8936bda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
